{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea1f4f1-6843-45b7-b9ac-ee69529e954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These scripts are to load AQR Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c57d60-8534-41b1-9037-19f28351b058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This script loads from all papers, but new links need to be provided, and if their format changes\n",
    "#then headers would need to be adjusted etc.  It checks for current data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04c54452-537d-49d4-8747-da8eff7a6e64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 20:37:19,493 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx...\n",
      "2025-04-03 20:37:20,127 - INFO - Raw data sample:         Date  US Stock Selection Value  US Stock Selection Momentum  US Stock Selection Defensive  US Stock Selection Multi-style  Intl Stock Selection Value  Intl Stock Selection Momentum  Intl Stock Selection Defensive  Intl Stock Selection Multi-style  Equity indices Value  Equity indices Momentum  Equity indices Carry  Equity indices Defensive  Equity indices Multi-style  Fixed income Value  Fixed income Momentum  Fixed income Carry  Fixed income Defensive  Fixed income Multi-style  Currencies Value  Currencies Momentum  Currencies Carry  Currencies Multi-style  Commodities Value  Commodities Momentum  Commodities Carry  Commodities Multi-style  All Stock Selection Value  All Stock Selection Momentum  All Stock Selection Defensive  All Stock Selection Multi-style  All Macro Value  All Macro Momentum  All Macro Carry  All Macro Defensive  All Macro Multi-style  All asset classes Value  All asset classes Momentum  All asset classes Carry  All asset classes Defensive  All asset classes Multi-style  Equity indices Market  Fixed income Market  Commodities Market  All Macro Market\n",
      "0 1926-07-30                 -0.019856                          NaN                           NaN                       -0.019856                         NaN                            NaN                             NaN                               NaN              0.018504                -0.014570             -0.054632                  0.128464                    0.019442            0.007577               0.023084            0.009647               -0.039520                  0.000197               NaN                  NaN               NaN                     NaN           0.104659             -0.134935          -0.072653                -0.034309                  -0.019856                           NaN                            NaN                        -0.019856         0.025068           -0.016425        -0.013252            -0.016099              -0.008416                 0.016263                   -0.016425                -0.013252                    -0.016099                      -0.009751               0.042891             0.002895            0.086836          0.015705\n",
      "1 1926-08-31                  0.052351                          NaN                           NaN                        0.052351                         NaN                            NaN                             NaN                               NaN              0.028721                -0.001318             -0.005503                  0.000734                    0.005659           -0.012583               0.022356           -0.000458               -0.011514                 -0.000550               NaN                  NaN               NaN                     NaN          -0.084515              0.043961           0.012637                -0.009306                   0.052351                           NaN                            NaN                         0.052351        -0.013229            0.024592         0.001997            -0.009631              -0.002552                -0.000913                    0.024592                 0.001997                    -0.009631                       0.004053               0.019221             0.009251           -0.063341          0.003819\n",
      "2 1926-09-30                 -0.023349                          NaN                           NaN                       -0.023349                         NaN                            NaN                             NaN                               NaN             -0.030772                 0.025641             -0.023250                  0.060385                    0.008001            0.020661               0.008820            0.001813                0.009440                  0.010184               NaN                  NaN               NaN                     NaN           0.089314              0.014832          -0.085248                 0.006300                  -0.023349                           NaN                            NaN                        -0.023349         0.018493            0.011748        -0.019091             0.017356               0.009013                 0.010665                    0.011748                -0.019091                     0.017356                       0.005100              -0.002631             0.000141           -0.019535         -0.002052\n",
      "3 1926-10-29                  0.008253                          NaN                           NaN                        0.008253                         NaN                            NaN                             NaN                               NaN              0.069517                -0.023010              0.004499                 -0.073278                   -0.005568           -0.016574               0.018789           -0.007214               -0.021477                 -0.006619               NaN                  NaN               NaN                     NaN           0.062234              0.012712          -0.027356                 0.015863                   0.008253                           NaN                            NaN                         0.008253         0.014303            0.013163        -0.010564            -0.029830              -0.000518                 0.013172                    0.013163                -0.010564                    -0.029830                       0.000578              -0.011521             0.000915           -0.054320         -0.005737\n",
      "4 1926-11-30                  0.002025                          NaN                           NaN                        0.002025                         NaN                            NaN                             NaN                               NaN              0.045331                -0.013281              0.018751                 -0.051409                   -0.000152            0.014119               0.016595            0.019469               -0.016915                  0.008317               NaN                  NaN               NaN                     NaN          -0.004848             -0.006935          -0.005093                -0.005626                   0.002025                           NaN                            NaN                         0.002025         0.018649            0.007463         0.014296            -0.022982               0.003909                 0.015526                    0.007463                 0.014296                    -0.022982                       0.003630               0.005766             0.001606           -0.044697         -0.001882\n",
      "2025-04-03 20:37:20,835 - INFO - Found 46491 existing keys in aqr_century_factors.\n",
      "2025-04-03 20:37:21,686 - INFO - New rows to load: 0\n",
      "2025-04-03 20:37:21,688 - INFO - No new rows to load into aqr_century_factors.\n",
      "2025-04-03 20:37:21,710 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 0)...\n",
      "2025-04-03 20:37:22,076 - INFO - Raw data sample:          DATE  P1 (low quality)        P2        P3        P4        P5        P6        P7        P8        P9  P10 (high quality)    P10-P1  P1 (low quality).1  P2.1  P3.1  P4.1  P5.1  P6.1  P7.1  P8.1  P9.1  P10 (high quality).1  P10-P1.1\n",
      "0  07/31/1957         -0.005017  0.016438 -0.001863  0.004807 -0.005883  0.017322  0.001817  0.017136  0.014402            0.017519  0.022535                 NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN                   NaN       NaN\n",
      "1  08/31/1957         -0.037498 -0.034978 -0.066123 -0.075569 -0.016631 -0.055152 -0.060160 -0.050194 -0.052107           -0.056645 -0.019147                 NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN                   NaN       NaN\n",
      "2  09/30/1957         -0.052741 -0.042106 -0.062913 -0.068924 -0.042417 -0.073249 -0.075578 -0.015640 -0.065713           -0.052810 -0.000070                 NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN                   NaN       NaN\n",
      "3  10/31/1957         -0.030079 -0.036808 -0.033168 -0.063987 -0.034294 -0.041036 -0.037275 -0.043252 -0.042036           -0.017737  0.012341                 NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN                   NaN       NaN\n",
      "4  11/30/1957          0.049104  0.048572  0.056684  0.043276  0.049264  0.000825 -0.003886  0.016266  0.038895            0.038904 -0.010200                 NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN                   NaN       NaN\n",
      "2025-04-03 20:37:22,446 - INFO - Found 44315 existing keys in aqr_factors.\n",
      "2025-04-03 20:37:22,683 - INFO - New rows to load: 0\n",
      "2025-04-03 20:37:22,684 - INFO - No new rows to load into aqr_factors.\n",
      "2025-04-03 20:37:22,706 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Momentum Indices Monthly (1).xlsx (sheet 1)...\n",
      "2025-04-03 20:37:22,826 - INFO - Raw data sample:        Month  U.S. Large Cap  U.S. Small Cap  International  Unnamed: 4    Year  U.S. Large Cap.1  U.S. Small Cap.1  International.1\n",
      "0 1980-01-31        0.120377        0.111434            NaN         NaN  1980.0          0.596875          0.648018              NaN\n",
      "1 1980-02-29        0.071722        0.010630            NaN         NaN  1981.0         -0.182923         -0.034643              NaN\n",
      "2 1980-03-31       -0.163214       -0.206128            NaN         NaN  1982.0          0.320510          0.417030              NaN\n",
      "3 1980-04-30        0.054521        0.081259            NaN         NaN  1983.0          0.193039          0.294642              NaN\n",
      "4 1980-05-31        0.045035        0.073112            NaN         NaN  1984.0          0.035458          0.016650              NaN\n",
      "2025-04-03 20:37:22,829 - INFO - Trimmed TSM to 4 columns: ['date', 'U.S. Large Cap', 'U.S. Small Cap', 'International']\n",
      "2025-04-03 20:37:23,336 - INFO - Found 44315 existing keys in aqr_factors.\n",
      "2025-04-03 20:37:23,395 - INFO - New rows to load: 1506\n",
      "2025-04-03 20:37:23,731 - INFO - Loaded 1506 rows into aqr_factors.\n",
      "2025-04-03 20:37:23,747 - INFO - Processing sheet BAB from C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx...\n",
      "2025-04-03 20:37:24,890 - INFO - Raw data sample for BAB:          DATE  AUS  AUT  BEL  CAN  CHE  DEU  DNK  ESP  FIN  FRA  GBR  GRC  HKG  IRL  ISR  ITA  JPN  NLD  NOR  NZL  PRT  SGP  SWE       USA  Global  Global Ex USA  Europe  North America  Pacific\n",
      "0  12/31/1930  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN -0.000558     NaN            NaN     NaN            NaN      NaN\n",
      "1  01/31/1931  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN -0.022446     NaN            NaN     NaN            NaN      NaN\n",
      "2  02/28/1931  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN -0.077423     NaN            NaN     NaN            NaN      NaN\n",
      "3  03/31/1931  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  0.029235     NaN            NaN     NaN            NaN      NaN\n",
      "4  04/30/1931  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN -0.012986     NaN            NaN     NaN            NaN      NaN\n",
      "2025-04-03 20:37:25,485 - INFO - Found 45821 existing keys in aqr_factors for BAB.\n",
      "2025-04-03 20:37:25,532 - INFO - New rows to load for BAB: 0\n",
      "2025-04-03 20:37:25,533 - INFO - No new rows to load for BAB into aqr_factors.\n",
      "2025-04-03 20:37:25,534 - INFO - Processing sheet MKT from C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx...\n",
      "2025-04-03 20:37:26,091 - INFO - Raw data sample for MKT:          DATE  AUS  AUT  BEL  CAN  CHE  DEU  DNK  ESP  FIN  FRA  GBR  GRC  HKG  IRL  ISR  ITA  JPN  NLD  NOR  NZL  PRT  SGP  SWE       USA  Global  Global Ex USA  Europe  North America  Pacific\n",
      "0  07/31/1926  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  0.028335     NaN            NaN     NaN            NaN      NaN\n",
      "1  08/31/1926  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  0.026245     NaN            NaN     NaN            NaN      NaN\n",
      "2  09/30/1926  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  0.003287     NaN            NaN     NaN            NaN      NaN\n",
      "3  10/31/1926  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN -0.031103     NaN            NaN     NaN            NaN      NaN\n",
      "4  11/30/1926  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  0.024357     NaN            NaN     NaN            NaN      NaN\n",
      "2025-04-03 20:37:26,618 - INFO - Found 45821 existing keys in aqr_factors for MKT.\n",
      "2025-04-03 20:37:26,652 - INFO - New rows to load for MKT: 0\n",
      "2025-04-03 20:37:26,654 - INFO - No new rows to load for MKT into aqr_factors.\n",
      "2025-04-03 20:37:26,655 - INFO - Processing sheet SMB from C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx...\n",
      "2025-04-03 20:37:27,183 - INFO - Raw data sample for SMB:          DATE  AUS  AUT  BEL  CAN  CHE  DEU  DNK  ESP  FIN  FRA  GBR  GRC  HKG  IRL  ISR  ITA  JPN  NLD  NOR  NZL  PRT  SGP  SWE       USA  Global  Global Ex USA  Europe  North America  Pacific\n",
      "0  07/31/1926  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN -0.016588     NaN            NaN     NaN            NaN      NaN\n",
      "1  08/31/1926  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN -0.013958     NaN            NaN     NaN            NaN      NaN\n",
      "2  09/30/1926  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN -0.011979     NaN            NaN     NaN            NaN      NaN\n",
      "3  10/31/1926  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  0.005102     NaN            NaN     NaN            NaN      NaN\n",
      "4  11/30/1926  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN -0.012421     NaN            NaN     NaN            NaN      NaN\n",
      "2025-04-03 20:37:27,588 - INFO - Found 45821 existing keys in aqr_factors for SMB.\n",
      "2025-04-03 20:37:27,623 - INFO - New rows to load for SMB: 0\n",
      "2025-04-03 20:37:27,624 - INFO - No new rows to load for SMB into aqr_factors.\n",
      "2025-04-03 20:37:27,625 - INFO - Processing sheet HML_FF from C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx...\n",
      "2025-04-03 20:37:28,138 - INFO - Raw data sample for HML_FF:          DATE  AUS  AUT  BEL  CAN  CHE  DEU  DNK  ESP  FIN  FRA  GBR  GRC  HKG  IRL  ISR  ITA  JPN  NLD  NOR  NZL  PRT  SGP  SWE       USA  Global  Global Ex USA  Europe  North America  Pacific\n",
      "0  07/31/1926  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN -0.027195     NaN            NaN     NaN            NaN      NaN\n",
      "1  08/31/1926  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  0.054077     NaN            NaN     NaN            NaN      NaN\n",
      "2  09/30/1926  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN -0.005076     NaN            NaN     NaN            NaN      NaN\n",
      "3  10/31/1926  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  0.010814     NaN            NaN     NaN            NaN      NaN\n",
      "4  11/30/1926  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  0.002133     NaN            NaN     NaN            NaN      NaN\n",
      "2025-04-03 20:37:28,752 - INFO - Found 45821 existing keys in aqr_factors for HML_FF.\n",
      "2025-04-03 20:37:28,786 - INFO - New rows to load for HML_FF: 0\n",
      "2025-04-03 20:37:28,788 - INFO - No new rows to load for HML_FF into aqr_factors.\n",
      "2025-04-03 20:37:28,788 - INFO - Processing sheet HML_Devil from C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx...\n",
      "2025-04-03 20:37:29,378 - INFO - Raw data sample for HML_Devil:          DATE  AUS  AUT  BEL  CAN  CHE  DEU  DNK  ESP  FIN  FRA  GBR  GRC  HKG  IRL  ISR  ITA  JPN  NLD  NOR  NZL  PRT  SGP  SWE       USA  Global  Global Ex USA  Europe  North America  Pacific\n",
      "0  07/31/1926  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN -0.019856     NaN            NaN     NaN            NaN      NaN\n",
      "1  08/31/1926  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  0.052351     NaN            NaN     NaN            NaN      NaN\n",
      "2  09/30/1926  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN -0.023349     NaN            NaN     NaN            NaN      NaN\n",
      "3  10/31/1926  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  0.008253     NaN            NaN     NaN            NaN      NaN\n",
      "4  11/30/1926  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  0.002025     NaN            NaN     NaN            NaN      NaN\n",
      "2025-04-03 20:37:30,211 - INFO - Found 45821 existing keys in aqr_factors for HML_Devil.\n",
      "2025-04-03 20:37:30,255 - INFO - New rows to load for HML_Devil: 0\n",
      "2025-04-03 20:37:30,256 - INFO - No new rows to load for HML_Devil into aqr_factors.\n",
      "2025-04-03 20:37:30,257 - INFO - Processing sheet UMD from C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx...\n",
      "2025-04-03 20:37:30,951 - INFO - Raw data sample for UMD:          DATE  AUS  AUT  BEL  CAN  CHE  DEU  DNK  ESP  FIN  FRA  GBR  GRC  HKG  IRL  ISR  ITA  JPN  NLD  NOR  NZL  PRT  SGP  SWE       USA  Global  Global Ex USA  Europe  North America  Pacific\n",
      "0  01/31/1927  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  0.026664     NaN            NaN     NaN            NaN      NaN\n",
      "1  02/28/1927  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN -0.009261     NaN            NaN     NaN            NaN      NaN\n",
      "2  03/31/1927  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  0.051651     NaN            NaN     NaN            NaN      NaN\n",
      "3  04/30/1927  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  0.030603     NaN            NaN     NaN            NaN      NaN\n",
      "4  05/31/1927  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  0.053263     NaN            NaN     NaN            NaN      NaN\n",
      "2025-04-03 20:37:31,503 - INFO - Found 45821 existing keys in aqr_factors for UMD.\n",
      "2025-04-03 20:37:31,552 - INFO - New rows to load for UMD: 0\n",
      "2025-04-03 20:37:31,554 - INFO - No new rows to load for UMD into aqr_factors.\n",
      "2025-04-03 20:37:31,555 - INFO - Processing sheet ME from C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx...\n",
      "2025-04-03 20:37:32,216 - INFO - Raw data sample for ME:          DATE  AUT  HKG  ESP  GBR  ITA  DEU  DNK  NZL  NLD           USA  PRT  BEL  ISR  GRC  NOR  SGP  CHE  IRL  CAN  FIN  JPN  SWE  FRA  AUS  Global Ex USA  Global  Europe  North America  Pacific\n",
      "0  07/31/1926  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  27892.934187  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN            NaN     NaN     NaN            NaN      NaN\n",
      "1  08/31/1926  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  28213.969313  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN            NaN     NaN     NaN            NaN      NaN\n",
      "2  09/30/1926  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  29432.298000  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN            NaN     NaN     NaN            NaN      NaN\n",
      "3  10/31/1926  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  29322.096875  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN            NaN     NaN     NaN            NaN      NaN\n",
      "4  11/30/1926  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  28528.546063  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN            NaN     NaN     NaN            NaN      NaN\n",
      "2025-04-03 20:37:32,743 - INFO - Found 45821 existing keys in aqr_factors for ME.\n",
      "2025-04-03 20:37:32,789 - INFO - New rows to load for ME: 0\n",
      "2025-04-03 20:37:32,791 - INFO - No new rows to load for ME into aqr_factors.\n",
      "2025-04-03 20:37:32,791 - INFO - Processing sheet RF from C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx...\n",
      "2025-04-03 20:37:33,360 - INFO - Raw data sample for RF:          DATE  Risk Free Rate\n",
      "0  07/31/1926          0.0022\n",
      "1  08/31/1926          0.0025\n",
      "2  09/30/1926          0.0023\n",
      "3  10/31/1926          0.0032\n",
      "4  11/30/1926          0.0031\n",
      "2025-04-03 20:37:34,010 - INFO - Found 45821 existing keys in aqr_factors for RF.\n",
      "2025-04-03 20:37:34,081 - INFO - New rows to load for RF: 0\n",
      "2025-04-03 20:37:34,083 - INFO - No new rows to load for RF into aqr_factors.\n",
      "2025-04-03 20:37:34,111 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx (sheet 0)...\n",
      "2025-04-03 20:37:34,470 - INFO - Raw data sample:    Unnamed: 0  Excess return of equal-weight commodities portfolio  Excess spot return of equal-weight commodities portfolio  Interest rate adjusted carry of equal-weight commodities portfolio  Spot return of equal-weight commodities portfolio  Carry of equal-weight commodities portfolio  Excess return of long/short commodities portfolio  Excess spot return of long/short commodities portfolio  Interest rate adjusted carry of long/short commodities portfolio  Aggregate backwardation/contango State of backwardation/contango State of inflation\n",
      "0  1877-02-28                                            -0.082566                                                 -0.078306                                                           -0.004693                                          -0.075823                                    -0.007367                                           0.037587                                                0.036226                                                          0.001941                         -0.018610                        Contango       Inflation Up\n",
      "1  1877-03-30                                            -0.042898                                                 -0.029286                                                           -0.013603                                          -0.026724                                    -0.016199                                           0.021791                                                0.038555                                                         -0.016068                         -0.018124                        Contango     Inflation Down\n",
      "2  1877-04-30                                             0.215684                                                  0.245092                                                           -0.022365                                           0.248377                                    -0.024938                                          -0.201387                                               -0.256192                                                          0.039244                         -0.041487                        Contango       Inflation Up\n",
      "3  1877-05-31                                            -0.150368                                                 -0.141387                                                           -0.010990                                          -0.139164                                    -0.013543                                           0.077681                                                0.045014                                                          0.038919                         -0.012697                        Contango       Inflation Up\n",
      "4  1877-06-29                                            -0.059275                                                 -0.062911                                                            0.009672                                          -0.060538                                     0.007121                                          -0.040316                                               -0.146906                                                          0.119123                         -0.012168                        Contango       Inflation Up\n",
      "2025-04-03 20:37:35,054 - INFO - Found 45821 existing keys in aqr_factors.\n",
      "2025-04-03 20:37:35,421 - INFO - New rows to load: 0\n",
      "2025-04-03 20:37:35,422 - INFO - No new rows to load into aqr_factors.\n",
      "2025-04-03 20:37:35,449 - INFO - All data processing complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import VARCHAR, DATE, DECIMAL\n",
    "from sqlalchemy.sql import text\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    handlers=[logging.StreamHandler(), logging.FileHandler('load_aqr_data.log')])\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Database connection\n",
    "engine = create_engine(\"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/CWA_Fund_Database?driver=ODBC+Driver+18+for+SQL+Server&trusted_connection=yes&TrustServerCertificate=yes\")\n",
    "\n",
    "# File configuration\n",
    "data_files = {\n",
    "    \"Century\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx\",\n",
    "        \"header\": 18,\n",
    "        \"paper\": \"Century of Factor Premia Monthly-Ilmanen et al. (2021)\"\n",
    "    },\n",
    "    \"QMJ\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx\",\n",
    "        \"header\": 18,\n",
    "        \"paper\": \"Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)\"\n",
    "    },\n",
    "    \"TSM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Momentum Indices Monthly (1).xlsx\",\n",
    "        \"header\": 1,  # Corrected to 1 as per your instruction (row 2 in Excel)\n",
    "        \"sheet\": 1,   # Sheet 2 (0-based index)\n",
    "        \"paper\": \"Time Series Momentum (Moskowitz et al., 2012)\"\n",
    "    },\n",
    "    \"BAB_multi\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx\",\n",
    "        \"sheets\": {\n",
    "            \"BAB\": {\"sheet\": 0, \"header\": 18, \"paper\": \"Betting Against Beta (Frazzini and Pedersen, 2014)\", \"factor_symbol\": \"BAB\", \"factor_name\": \"Betting Against Beta\"},\n",
    "            \"MKT\": {\"sheet\": 4, \"header\": 18, \"paper\": \"Fama-French Factors\", \"factor_symbol\": \"MKT\", \"factor_name\": \"Market\"},\n",
    "            \"SMB\": {\"sheet\": 5, \"header\": 18, \"paper\": \"Fama-French Factors\", \"factor_symbol\": \"SMB\", \"factor_name\": \"Small Minus Big\"},\n",
    "            \"HML_FF\": {\"sheet\": 6, \"header\": 18, \"paper\": \"Fama-French Factors\", \"factor_symbol\": \"HML-FF\", \"factor_name\": \"High Minus Low (Fama-French)\"},\n",
    "            \"HML_Devil\": {\"sheet\": 7, \"header\": 18, \"paper\": \"AQR Factors\", \"factor_symbol\": \"HML-Devil\", \"factor_name\": \"High Minus Low (AQR)\"},\n",
    "            \"UMD\": {\"sheet\": 8, \"header\": 18, \"paper\": \"Fama-French Factors\", \"factor_symbol\": \"UMD\", \"factor_name\": \"Up Minus Down\"},\n",
    "            \"ME\": {\"sheet\": 9, \"header\": 18, \"paper\": \"AQR Factors\", \"factor_symbol\": \"ME\", \"factor_name\": \"Market Equity\"},\n",
    "            \"RF\": {\"sheet\": 10, \"header\": 18, \"paper\": \"Fama-French Factors\", \"factor_symbol\": \"RF\", \"factor_name\": \"Risk-Free Rate\"}\n",
    "        }\n",
    "    },\n",
    "    \"COM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx\",\n",
    "        \"header\": 10,\n",
    "        \"paper\": \"Commodities Paper (TBD)\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def process_century_data(file_config):\n",
    "    logger.info(f\"Processing {file_config['path']}...\")\n",
    "    try:\n",
    "        df = pd.read_excel(file_config['path'], sheet_name=0, header=file_config['header'])\n",
    "        logger.info(f\"Raw data sample: {df.head().to_string()}\")\n",
    "        df = df.rename(columns={df.columns[0]: 'date'})\n",
    "        df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "        for col in df.columns[1:]:\n",
    "            df[col] = pd.to_numeric(df[col].replace('', '0%').str.rstrip('%') if isinstance(df[col].iloc[0], str) else df[col], errors='coerce') / 100\n",
    "        df_long = df.melt(id_vars=['date'], var_name='portfolio', value_name='value')\n",
    "        df_long = df_long.dropna(subset=['value', 'date'])\n",
    "        df_long['factor'] = df_long['portfolio'].str.extract('(Value|Momentum|Carry|Defensive|Multi-style|Market)')\n",
    "        df_long['asset_class'] = df_long['portfolio'].str.extract('(Stock Selection|Equity indices|Fixed income|Currencies|Commodities|All Macro|All asset classes)')\n",
    "        df_long['region'] = df_long['portfolio'].apply(lambda x: 'US' if 'US' in x else 'Intl' if 'Intl' in x else 'Global')\n",
    "        df_long['associated_paper'] = file_config['paper']\n",
    "        df_long = df_long[['factor', 'portfolio', 'asset_class', 'region', 'date', 'value', 'associated_paper']]\n",
    "\n",
    "        with engine.connect() as connection:\n",
    "            existing = pd.read_sql(\"SELECT factor, portfolio, date FROM aqr_century_factors\", connection)\n",
    "            existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "            existing_keys = set(tuple(row) for row in existing[['factor', 'portfolio', 'date']].values)\n",
    "            logger.info(f\"Found {len(existing_keys)} existing keys in aqr_century_factors.\")\n",
    "\n",
    "        df_long['date_str'] = df_long['date'].dt.strftime('%Y-%m-%d')\n",
    "        df_long['key'] = df_long.apply(lambda row: (row['factor'], row['portfolio'], row['date_str']), axis=1)\n",
    "        df_new = df_long[~df_long['key'].isin(existing_keys)].drop(columns=['date_str', 'key'])\n",
    "        logger.info(f\"New rows to load: {len(df_new)}\")\n",
    "\n",
    "        if not df_new.empty:\n",
    "            df_new.to_sql('aqr_century_factors', engine, if_exists='append', index=False,\n",
    "                          dtype={'factor': VARCHAR(50), 'portfolio': VARCHAR(100), 'asset_class': VARCHAR(50),\n",
    "                                 'region': VARCHAR(50), 'date': DATE, 'value': DECIMAL(15, 6), 'associated_paper': VARCHAR(150)})\n",
    "            logger.info(f\"Loaded {len(df_new)} rows into aqr_century_factors.\")\n",
    "        else:\n",
    "            logger.info(\"No new rows to load into aqr_century_factors.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing {file_config['path']}: {str(e)}\")\n",
    "\n",
    "def process_aqr_data(file_config, factor_symbol, factor_name, has_portfolios=False, regions=None, sheet=0):\n",
    "    logger.info(f\"Processing {file_config['path']} (sheet {sheet})...\")\n",
    "    try:\n",
    "        df = pd.read_excel(file_config['path'], sheet_name=sheet, header=file_config['header'])\n",
    "        logger.info(f\"Raw data sample: {df.head().to_string()}\")\n",
    "        if factor_symbol == \"COM\":\n",
    "            df.columns = ['date'] + df.columns[1:].tolist()\n",
    "        else:\n",
    "            df = df.rename(columns={df.columns[0]: 'date'})\n",
    "        df['date'] = pd.to_datetime(df['date'], format='%b-%y' if factor_symbol == \"TSM\" else None, errors='coerce')\n",
    "        # Limit TSM to 4 columns: \"date\", \"U.S. Large Cap\", \"U.S. Small Cap\", \"International\"\n",
    "        if factor_symbol == \"TSM\" and len(df.columns) > 4:\n",
    "            df = df.iloc[:, :4]\n",
    "            logger.info(f\"Trimmed TSM to 4 columns: {df.columns.tolist()}\")\n",
    "        for col in df.columns[1:]:\n",
    "            df[col] = pd.to_numeric(df[col].replace('', '0%').str.rstrip('%') if isinstance(df[col].iloc[0], str) else df[col], errors='coerce') / 100\n",
    "        df_long = df.melt(id_vars=['date'], var_name='portfolio', value_name='value')\n",
    "        df_long = df_long.dropna(subset=['value', 'date'])\n",
    "\n",
    "        if has_portfolios:  # For QMJ, TSM, Commodities\n",
    "            df_long['factor_symbol'] = factor_symbol\n",
    "            df_long['factor_name'] = factor_name\n",
    "            df_long['portfolio'] = df_long['portfolio']\n",
    "            df_long['region'] = df_long['portfolio'].apply(\n",
    "                lambda x: 'US' if 'U.S.' in str(x) or 'USA' in str(x) else 'Intl' if 'International' in str(x) else 'Global'\n",
    "            ) if factor_symbol == \"TSM\" else \"Global\"\n",
    "        else:  # For BAB, MKT, SMB, etc.\n",
    "            df_long['factor_symbol'] = factor_symbol\n",
    "            df_long['factor_name'] = factor_name\n",
    "            df_long['portfolio'] = factor_symbol\n",
    "            df_long['region'] = df_long['portfolio'].apply(\n",
    "                lambda x: 'US' if 'USA' in str(x) else 'Global' if 'Global' in str(x) else 'Intl'\n",
    "            )\n",
    "            if regions:\n",
    "                df_long = df_long[df_long['region'].isin(regions)]\n",
    "\n",
    "        df_long['associated_paper'] = file_config['paper']\n",
    "        df_long = df_long[['factor_symbol', 'factor_name', 'portfolio', 'region', 'date', 'value', 'associated_paper']]\n",
    "\n",
    "        with engine.connect() as connection:\n",
    "            existing = pd.read_sql(\"SELECT factor_symbol, portfolio, region, date FROM aqr_factors\", connection)\n",
    "            existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "            existing_keys = set(tuple(row) for row in existing[['factor_symbol', 'portfolio', 'region', 'date']].values)\n",
    "            logger.info(f\"Found {len(existing_keys)} existing keys in aqr_factors.\")\n",
    "\n",
    "        df_long['date_str'] = df_long['date'].dt.strftime('%Y-%m-%d')\n",
    "        df_long['key'] = df_long.apply(lambda row: (row['factor_symbol'], row['portfolio'], row['region'], row['date_str']), axis=1)\n",
    "        df_new = df_long[~df_long['key'].isin(existing_keys)].drop(columns=['date_str', 'key'])\n",
    "        logger.info(f\"New rows to load: {len(df_new)}\")\n",
    "\n",
    "        if not df_new.empty:\n",
    "            df_new.to_sql('aqr_factors', engine, if_exists='append', index=False,\n",
    "                          dtype={'factor_symbol': VARCHAR(20), 'factor_name': VARCHAR(100), 'portfolio': VARCHAR(100),\n",
    "                                 'region': VARCHAR(50), 'date': DATE, 'value': DECIMAL(15, 6), 'associated_paper': VARCHAR(150)})\n",
    "            logger.info(f\"Loaded {len(df_new)} rows into aqr_factors.\")\n",
    "        else:\n",
    "            logger.info(\"No new rows to load into aqr_factors.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing {file_config['path']}: {str(e)}\")\n",
    "\n",
    "def process_multi_sheet_data(file_config):\n",
    "    for factor, config in file_config['sheets'].items():\n",
    "        logger.info(f\"Processing sheet {factor} from {file_config['path']}...\")\n",
    "        try:\n",
    "            df = pd.read_excel(file_config['path'], sheet_name=config['sheet'], header=config['header'])\n",
    "            logger.info(f\"Raw data sample for {factor}: {df.head().to_string()}\")\n",
    "            df = df.rename(columns={df.columns[0]: 'date'})\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            for col in df.columns[1:]:\n",
    "                df[col] = pd.to_numeric(df[col].replace('', '0%').str.rstrip('%') if isinstance(df[col].iloc[0], str) else df[col], errors='coerce') / 100\n",
    "            df_long = df.melt(id_vars=['date'], var_name='portfolio', value_name='value')\n",
    "            df_long = df_long.dropna(subset=['value', 'date'])\n",
    "\n",
    "            if factor == \"RF\":  # Special case for RF\n",
    "                df_long['factor_symbol'] = config['factor_symbol']\n",
    "                df_long['factor_name'] = config['factor_name']\n",
    "                df_long['portfolio'] = config['factor_symbol']\n",
    "                df_long['region'] = 'Global'\n",
    "            else:  # BAB, MKT, SMB, etc.\n",
    "                df_long['factor_symbol'] = config['factor_symbol']\n",
    "                df_long['factor_name'] = config['factor_name']\n",
    "                df_long['portfolio'] = config['factor_symbol']\n",
    "                df_long['region'] = df_long['portfolio'].apply(\n",
    "                    lambda x: 'US' if 'USA' in str(x) else 'Global' if 'Global' in str(x) else 'Intl'\n",
    "                )\n",
    "                df_long = df_long[df_long['region'].isin([\"USA\", \"Global\", \"Global Ex USA\"])]\n",
    "\n",
    "            df_long['associated_paper'] = config['paper']\n",
    "            df_long = df_long[['factor_symbol', 'factor_name', 'portfolio', 'region', 'date', 'value', 'associated_paper']]\n",
    "\n",
    "            with engine.connect() as connection:\n",
    "                existing = pd.read_sql(\"SELECT factor_symbol, portfolio, region, date FROM aqr_factors\", connection)\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(tuple(row) for row in existing[['factor_symbol', 'portfolio', 'region', 'date']].values)\n",
    "                logger.info(f\"Found {len(existing_keys)} existing keys in aqr_factors for {factor}.\")\n",
    "\n",
    "            df_long['date_str'] = df_long['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_long['key'] = df_long.apply(lambda row: (row['factor_symbol'], row['portfolio'], row['region'], row['date_str']), axis=1)\n",
    "            df_new = df_long[~df_long['key'].isin(existing_keys)].drop(columns=['date_str', 'key'])\n",
    "            logger.info(f\"New rows to load for {factor}: {len(df_new)}\")\n",
    "\n",
    "            if not df_new.empty:\n",
    "                df_new.to_sql('aqr_factors', engine, if_exists='append', index=False,\n",
    "                              dtype={'factor_symbol': VARCHAR(20), 'factor_name': VARCHAR(100), 'portfolio': VARCHAR(100),\n",
    "                                     'region': VARCHAR(50), 'date': DATE, 'value': DECIMAL(15, 6), 'associated_paper': VARCHAR(150)})\n",
    "                logger.info(f\"Loaded {len(df_new)} rows for {factor} into aqr_factors.\")\n",
    "            else:\n",
    "                logger.info(f\"No new rows to load for {factor} into aqr_factors.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing sheet {factor} in {file_config['path']}: {str(e)}\")\n",
    "\n",
    "# Process all files\n",
    "process_century_data(data_files[\"Century\"])\n",
    "process_aqr_data(data_files[\"QMJ\"], \"QMJ\", \"Quality Minus Junk\", has_portfolios=True)\n",
    "process_aqr_data(data_files[\"TSM\"], \"TSM\", \"Momentum\", has_portfolios=True, sheet=data_files[\"TSM\"][\"sheet\"])\n",
    "process_multi_sheet_data(data_files[\"BAB_multi\"])\n",
    "process_aqr_data(data_files[\"COM\"], \"COM\", \"Commodities\", has_portfolios=True)\n",
    "\n",
    "logger.info(\"All data processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb53d03-5c40-4778-8a17-b7990e6ca384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated Loading script to include TSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "637c9ece-544d-477a-951c-58a766c1e420",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 16:08:52,643 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx...\n",
      "2025-04-06 16:08:52,653 - INFO - Table contains 4537 rows. Will filter out duplicates before loading.\n",
      "2025-04-06 16:08:52,860 - INFO - Read 481 rows with columns: ['Unnamed: 0', 'TSMOM', 'TSMOM^CM', 'TSMOM^EQ', 'TSMOM^FI', 'TSMOM^FX']\n",
      "2025-04-06 16:08:52,865 - INFO - First 5 rows sample:   Unnamed: 0     TSMOM  TSMOM^CM  TSMOM^EQ  TSMOM^FI  TSMOM^FX\n",
      "0 1985-01-31  0.043066 -0.014042  0.153376 -0.015625  0.056041\n",
      "1 1985-02-28  0.038128  0.047449  0.043061 -0.193815  0.099316\n",
      "2 1985-03-29 -0.052719 -0.083491  0.032803  0.071045 -0.117085\n",
      "3 1985-04-30  0.039634  0.060051  0.024413  0.047500  0.019504\n",
      "4 1985-05-31  0.063918  0.045516  0.121216  0.144524  0.020146\n",
      "2025-04-06 16:08:52,868 - INFO - After filtering invalid dates, 481 rows remain.\n",
      "2025-04-06 16:08:52,878 - INFO - Filtered to 5 portfolio columns: ['TSMOM', 'TSMOM^CM', 'TSMOM^EQ', 'TSMOM^FI', 'TSMOM^FX']\n",
      "2025-04-06 16:08:52,886 - INFO - Melted to 2405 rows.\n",
      "2025-04-06 16:08:52,889 - INFO - After dropping rows with missing values, 2405 rows remain.\n",
      "2025-04-06 16:08:53,198 - INFO - After dropping duplicates within new data, 2405 rows remain.\n",
      "2025-04-06 16:08:53,542 - INFO - Found 4537 existing keys in the table.\n",
      "2025-04-06 16:08:53,544 - INFO - Sample of existing keys: [('Defensive', '1933-11-30', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Stock Selection'), ('Momentum', '1992-07-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Stock Selection'), ('Multi-style', '2003-02-28', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Stock Selection'), ('Multi-style', '1948-12-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Stock Selection'), ('Multi-style', '1977-09-30', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Stock Selection')]\n",
      "2025-04-06 16:08:53,584 - INFO - Sample of new keys: [('TSMOM', '1985-01-31', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', 'Multi-Asset'), ('TSMOM', '1985-02-28', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', 'Multi-Asset'), ('TSMOM', '1985-03-29', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', 'Multi-Asset'), ('TSMOM', '1985-04-30', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', 'Multi-Asset'), ('TSMOM', '1985-05-31', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', 'Multi-Asset')]\n",
      "2025-04-06 16:08:53,599 - INFO - After filtering out existing keys, 2405 new rows to load.\n",
      "2025-04-06 16:08:53,603 - INFO - Sample of new data to load:   factor       date                                           associated_paper  asset_class     value  region\n",
      "0  TSMOM 1985-01-31  Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)  Multi-Asset  0.043066  Global\n",
      "1  TSMOM 1985-02-28  Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)  Multi-Asset  0.038128  Global\n",
      "2  TSMOM 1985-03-29  Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)  Multi-Asset -0.052719  Global\n",
      "3  TSMOM 1985-04-30  Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)  Multi-Asset  0.039634  Global\n",
      "4  TSMOM 1985-05-31  Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)  Multi-Asset  0.063918  Global\n",
      "2025-04-06 16:08:54,435 - INFO - Successfully loaded 2405 new rows into database.\n",
      "2025-04-06 16:08:54,440 - INFO - Total rows in factor_returns: 6942\n",
      "2025-04-06 16:08:54,441 - INFO - Processing complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import VARCHAR, DATE, DECIMAL\n",
    "from sqlalchemy.sql import text\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(), logging.FileHandler('load_aqr_data.log')]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Database connection string\n",
    "connection_string = (\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/CWA_Fund_Database\"\n",
    "    \"?driver=ODBC+Driver+18+for+SQL+Server\"\n",
    "    \"&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Toggle for dataset selection\n",
    "load_qmj = False  # Set to True for QMJ\n",
    "load_tsmom = True  # Set to True for TSMOM\n",
    "if load_qmj:\n",
    "    filepath = r\"C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx\"\n",
    "    paper = \"Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)\"\n",
    "    portfolio_columns = [\n",
    "        \"P1 (low quality)\", \"P2\", \"P3\", \"P4\", \"P5\", \"P6\", \"P7\", \"P8\", \"P9\", \"P10 (high quality)\", \"P10-P1\"\n",
    "    ]\n",
    "    header_row = 18  # Header row for QMJ dataset\n",
    "    def classify_portfolio(portfolio_name):\n",
    "        if portfolio_name == \"P10-P1\":\n",
    "            factor = \"QMJ\"\n",
    "            asset_class = \"Stock Selection\"\n",
    "            region = \"Global\"\n",
    "        elif portfolio_name == \"P1 (low quality)\":\n",
    "            factor = \"QMJ-P1\"\n",
    "            asset_class = \"Stock Selection\"\n",
    "            region = \"Global\"\n",
    "        elif portfolio_name == \"P10 (high quality)\":\n",
    "            factor = \"QMJ-P10\"\n",
    "            asset_class = \"Stock Selection\"\n",
    "            region = \"Global\"\n",
    "        elif portfolio_name in [\"P2\", \"P3\", \"P4\", \"P5\", \"P6\", \"P7\", \"P8\", \"P9\"]:\n",
    "            factor = f\"QMJ-{portfolio_name}\"\n",
    "            asset_class = \"Stock Selection\"\n",
    "            region = \"Global\"\n",
    "        else:\n",
    "            raise ValueError(f\"Unrecognized portfolio name: {portfolio_name}\")\n",
    "        return factor, asset_class, region\n",
    "elif load_tsmom:\n",
    "    filepath = r\"C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx\"\n",
    "    paper = \"Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)\"\n",
    "    portfolio_columns = [\n",
    "        \"TSMOM\", \"TSMOM^CM\", \"TSMOM^EQ\", \"TSMOM^FI\", \"TSMOM^FX\"\n",
    "    ]\n",
    "    header_row = 17  # Header row for TSMOM dataset (row 18 in Excel, 0-based index 17)\n",
    "    def classify_portfolio(portfolio_name):\n",
    "        # Map column names to desired factor names\n",
    "        factor_map = {\n",
    "            \"TSMOM\": \"TSMOM\",\n",
    "            \"TSMOM^CM\": \"TSM-Commodities\",\n",
    "            \"TSMOM^EQ\": \"TSM-Equity\",\n",
    "            \"TSMOM^FI\": \"TSM-Fixed-Income\",\n",
    "            \"TSMOM^FX\": \"TSM-Currency\"\n",
    "        }\n",
    "        factor = factor_map.get(portfolio_name, portfolio_name)\n",
    "        \n",
    "        # Define asset class and region based on portfolio\n",
    "        if portfolio_name == \"TSMOM\":\n",
    "            asset_class = \"Multi-Asset\"\n",
    "            region = \"Global\"\n",
    "        elif portfolio_name == \"TSMOM^CM\":\n",
    "            asset_class = \"Commodities\"\n",
    "            region = \"Global\"\n",
    "        elif portfolio_name == \"TSMOM^EQ\":\n",
    "            asset_class = \"Equity\"\n",
    "            region = \"Global\"\n",
    "        elif portfolio_name == \"TSMOM^FI\":\n",
    "            asset_class = \"Fixed Income\"\n",
    "            region = \"Global\"\n",
    "        elif portfolio_name == \"TSMOM^FX\":\n",
    "            asset_class = \"Currencies\"\n",
    "            region = \"Global\"\n",
    "        else:\n",
    "            raise ValueError(f\"Unrecognized portfolio name: {portfolio_name}\")\n",
    "        return factor, asset_class, region\n",
    "else:\n",
    "    filepath = r\"C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx\"\n",
    "    paper = \"Century of Factor Premia Monthly-Ilmanen et al. (2021)\"\n",
    "    portfolio_columns = [\n",
    "        \"US Stock Selection Value\", \"US Stock Selection Momentum\", \"US Stock Selection Defensive\", \"US Stock Selection Multi-style\",\n",
    "        \"Intl Stock Selection Value\", \"Intl Stock Selection Momentum\", \"Intl Stock Selection Defensive\", \"Intl Stock Selection Multi-style\",\n",
    "        \"Equity indices Value\", \"Equity indices Momentum\", \"Equity indices Carry\", \"Equity indices Defensive\", \"Equity indices Multi-style\",\n",
    "        \"Fixed income Value\", \"Fixed income Momentum\", \"Fixed income Carry\", \"Fixed income Defensive\", \"Fixed income Multi-style\",\n",
    "        \"Currencies Value\", \"Currencies Momentum\", \"Currencies Carry\", \"Currencies Multi-style\",\n",
    "        \"Commodities Value\", \"Commodities Momentum\", \"Commodities Carry\", \"Commodities Multi-style\",\n",
    "        \"All Stock Selection Value\", \"All Stock Selection Momentum\", \"All Stock Selection Defensive\", \"All Stock Selection Multi-style\",\n",
    "        \"All Macro Value\", \"All Macro Momentum\", \"All Macro Carry\", \"All Macro Defensive\", \"All Macro Multi-style\",\n",
    "        \"All asset classes Value\", \"All asset classes Momentum\", \"All asset classes Carry\", \"All asset classes Defensive\", \"All asset classes Multi-style\",\n",
    "        \"Equity indices Market\", \"Fixed income Market\", \"Commodities Market\", \"All Macro Market\"\n",
    "    ]\n",
    "    header_row = 18  # Header row for Century dataset\n",
    "    def classify_portfolio(portfolio_name):\n",
    "        # Use the full portfolio name as the factor to ensure uniqueness\n",
    "        factor = portfolio_name  # e.g., \"US Stock Selection Value\"\n",
    "        if \"US Stock Selection\" in portfolio_name:\n",
    "            asset_class = \"Stock Selection\"\n",
    "            region = \"US\"\n",
    "        elif \"Intl Stock Selection\" in portfolio_name:\n",
    "            asset_class = \"Stock Selection\"\n",
    "            region = \"Intl\"\n",
    "        elif \"All Stock Selection\" in portfolio_name:\n",
    "            asset_class = \"All Stock Selection\"\n",
    "            region = \"Global\"\n",
    "        elif \"Equity indices\" in portfolio_name:\n",
    "            asset_class = \"Equity Indices\"\n",
    "            region = \"Global\"\n",
    "        elif \"Fixed income\" in portfolio_name:\n",
    "            asset_class = \"Fixed Income\"\n",
    "            region = None\n",
    "        elif \"Currencies\" in portfolio_name:\n",
    "            asset_class = \"Currencies\"\n",
    "            region = None\n",
    "        elif \"Commodities\" in portfolio_name:\n",
    "            asset_class = \"Commodities\"\n",
    "            region = None\n",
    "        elif \"All Macro\" in portfolio_name:\n",
    "            asset_class = \"All Macro\"\n",
    "            region = \"Global\"\n",
    "        elif \"All asset classes\" in portfolio_name:\n",
    "            asset_class = \"All Asset Classes\"\n",
    "            region = \"Global\"\n",
    "        else:\n",
    "            raise ValueError(f\"Unrecognized asset class in portfolio name: {portfolio_name}\")\n",
    "        return factor, asset_class, region\n",
    "\n",
    "# Process the Excel file\n",
    "logger.info(f\"Processing {filepath}...\")\n",
    "\n",
    "# Verify table state (optional pre-check)\n",
    "with engine.connect() as connection:\n",
    "    row_count = connection.execute(text(\"SELECT COUNT(*) FROM factor_returns\")).scalar()\n",
    "    if row_count > 0:\n",
    "        logger.info(f\"Table contains {row_count} rows. Will filter out duplicates before loading.\")\n",
    "    else:\n",
    "        logger.info(f\"Table is empty with {row_count} rows.\")\n",
    "\n",
    "try:\n",
    "    # Read the Excel file with the specified header row\n",
    "    df = pd.read_excel(filepath, sheet_name=0, header=header_row)\n",
    "    logger.info(f\"Read {len(df)} rows with columns: {list(df.columns)}\")\n",
    "\n",
    "    # Log a sample of the data to debug\n",
    "    logger.info(f\"First 5 rows sample: {df.head().to_string()}\")\n",
    "\n",
    "    # Rename first column to 'date'\n",
    "    df = df.rename(columns={df.columns[0]: 'date'})\n",
    "\n",
    "    # Convert date column to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "    # Filter out invalid dates\n",
    "    df = df[df['date'].notna()]\n",
    "    logger.info(f\"After filtering invalid dates, {len(df)} rows remain.\")\n",
    "\n",
    "    # Filter to only known portfolio columns (strictly enforce 39 columns for Century, 11 for QMJ, 5 for TSMOM)\n",
    "    valid_columns = ['date'] + portfolio_columns\n",
    "    available_columns = [col for col in df.columns if col in valid_columns]\n",
    "    expected_count = 39 if not load_qmj and not load_tsmom else (5 if load_tsmom else 11)\n",
    "    if len(available_columns) - 1 != expected_count:  # -1 for 'date'\n",
    "        missing = [col for col in valid_columns if col not in df.columns]\n",
    "        extra = [col for col in df.columns if col not in valid_columns]\n",
    "        logger.warning(f\"Expected {expected_count} portfolios, found {len(available_columns) - 1}. Missing: {missing}, Extra: {extra}\")\n",
    "    df = df[available_columns]\n",
    "    logger.info(f\"Filtered to {len(df.columns) - 1} portfolio columns: {available_columns[1:]}\")\n",
    "\n",
    "    # Melt to long format\n",
    "    df_long = df.melt(id_vars=['date'], var_name='portfolio_name', value_name='value')\n",
    "    logger.info(f\"Melted to {len(df_long)} rows.\")\n",
    "\n",
    "    # Remove rows with missing values\n",
    "    df_long = df_long.dropna(subset=['value'])\n",
    "    logger.info(f\"After dropping rows with missing values, {len(df_long)} rows remain.\")\n",
    "\n",
    "    # Apply classification\n",
    "    df_long[['factor', 'asset_class', 'region']] = df_long['portfolio_name'].apply(\n",
    "        lambda x: pd.Series(classify_portfolio(x))\n",
    "    )\n",
    "\n",
    "    # Add associated paper\n",
    "    df_long['associated_paper'] = paper\n",
    "\n",
    "    # Ensure column names match table\n",
    "    df_long = df_long[['factor', 'date', 'associated_paper', 'asset_class', 'value', 'region']]\n",
    "\n",
    "    # Drop duplicates within the new data\n",
    "    df_long = df_long.drop_duplicates(subset=['factor', 'date', 'associated_paper', 'asset_class'])\n",
    "    logger.info(f\"After dropping duplicates within new data, {len(df_long)} rows remain.\")\n",
    "\n",
    "    # Fetch existing keys from the table\n",
    "    with engine.connect() as connection:\n",
    "        existing_keys = pd.read_sql(\n",
    "            text(\"SELECT factor, date, associated_paper, asset_class FROM factor_returns\"),\n",
    "            connection\n",
    "        )\n",
    "        existing_keys['date'] = pd.to_datetime(existing_keys['date']).dt.tz_localize(None)  # Remove timezone\n",
    "        # Convert to string for consistent comparison\n",
    "        existing_keys['date_str'] = existing_keys['date'].dt.strftime('%Y-%m-%d')\n",
    "        existing_keys_set = set(\n",
    "            (row['factor'], row['date_str'], row['associated_paper'], row['asset_class'])\n",
    "            for _, row in existing_keys.iterrows()\n",
    "        )\n",
    "        logger.info(f\"Found {len(existing_keys_set)} existing keys in the table.\")\n",
    "        # Log a sample of existing keys for debugging\n",
    "        logger.info(f\"Sample of existing keys: {list(existing_keys_set)[:5]}\")\n",
    "\n",
    "    # Filter out rows that already exist in the table\n",
    "    df_long['date'] = df_long['date'].dt.tz_localize(None)  # Remove timezone\n",
    "    df_long['date_str'] = df_long['date'].dt.strftime('%Y-%m-%d')\n",
    "    df_long['key'] = df_long.apply(\n",
    "        lambda row: (row['factor'], row['date_str'], row['associated_paper'], row['asset_class']), axis=1\n",
    "    )\n",
    "    # Log a sample of new keys for debugging\n",
    "    logger.info(f\"Sample of new keys: {list(df_long['key'].head())}\")\n",
    "    df_new = df_long[~df_long['key'].isin(existing_keys_set)].drop(columns=['date_str', 'key'])\n",
    "    logger.info(f\"After filtering out existing keys, {len(df_new)} new rows to load.\")\n",
    "\n",
    "    # Log a sample of new data to load\n",
    "    if not df_new.empty:\n",
    "        logger.info(f\"Sample of new data to load: {df_new.head().to_string()}\")\n",
    "    else:\n",
    "        logger.info(\"No new data to load after filtering.\")\n",
    "\n",
    "    # Load only new rows into MSSQL database with batching\n",
    "    if not df_new.empty:\n",
    "        df_new.to_sql(\n",
    "            'factor_returns',\n",
    "            engine,\n",
    "            if_exists='append',\n",
    "            index=False,\n",
    "            dtype={\n",
    "                'factor': VARCHAR(50),\n",
    "                'date': DATE,\n",
    "                'associated_paper': VARCHAR(100),\n",
    "                'asset_class': VARCHAR(50),\n",
    "                'value': DECIMAL(15, 6),\n",
    "                'region': VARCHAR(50)\n",
    "            },\n",
    "            chunksize=1000\n",
    "        )\n",
    "        logger.info(f\"Successfully loaded {len(df_new)} new rows into database.\")\n",
    "    else:\n",
    "        logger.info(\"No new rows to load after filtering duplicates.\")\n",
    "\n",
    "    # Verify total rows\n",
    "    with engine.connect() as connection:\n",
    "        total_rows = connection.execute(text(\"SELECT COUNT(*) FROM factor_returns\")).scalar()\n",
    "        logger.info(f\"Total rows in factor_returns: {total_rows}\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error loading data: {str(e)}\")\n",
    "\n",
    "logger.info(\"Processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e48705a-01ab-438d-a60c-25bb5a57d4a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb939e6-94f0-45b3-bd20-20604347cb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the Quality Factor Loading QMJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660dda4e-b915-4cc4-b9f1-13cdc7a05372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e4419f8-2c25-44b8-a346-67b2f0b06442",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 18:20:12,111 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx...\n",
      "2025-04-03 18:20:12,487 - INFO - Read 809 rows with columns: ['DATE', 'P1 (low quality)', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10 (high quality)', 'P10-P1', 'P1 (low quality).1', 'P2.1', 'P3.1', 'P4.1', 'P5.1', 'P6.1', 'P7.1', 'P8.1', 'P9.1', 'P10 (high quality).1', 'P10-P1.1']\n",
      "2025-04-03 18:20:12,493 - INFO - After filtering invalid dates, 809 rows remain.\n",
      "2025-04-03 18:20:12,495 - INFO - Filtered to 11 portfolio columns: ['P1 (low quality)', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10 (high quality)', 'P10-P1']\n",
      "2025-04-03 18:20:12,501 - INFO - Melted to 8899 rows.\n",
      "2025-04-03 18:20:12,505 - INFO - After dropping rows with missing values, 8899 rows remain.\n",
      "2025-04-03 18:20:13,391 - INFO - After dropping duplicates, 8899 rows remain.\n",
      "2025-04-03 18:20:14,209 - INFO - Successfully loaded 8899 rows into database.\n",
      "2025-04-03 18:20:14,210 - INFO - Processing complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import VARCHAR, DATE, DECIMAL\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(), logging.FileHandler('load_aqr_data.log')]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Database connection string\n",
    "connection_string = (\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/CWA_Fund_Database\"\n",
    "    \"?driver=ODBC+Driver+18+for+SQL+Server\"\n",
    "    \"&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# File path\n",
    "filepath = r\"C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx\"\n",
    "\n",
    "# Associated paper\n",
    "paper = \"Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)\"\n",
    "\n",
    "# Known portfolio columns (11 total, updated to match file)\n",
    "portfolio_columns = [\n",
    "    \"P1 (low quality)\", \"P2\", \"P3\", \"P4\", \"P5\", \"P6\", \"P7\", \"P8\", \"P9\", \"P10 (high quality)\", \"P10-P1\"\n",
    "]\n",
    "\n",
    "# Mapping function to classify portfolios\n",
    "def classify_portfolio(portfolio_name):\n",
    "    if portfolio_name == \"P10-P1\":\n",
    "        factor = \"QMJ\"  # Factor value for Quality Minus Junk\n",
    "        asset_class = \"Stock Selection\"\n",
    "        region = \"Global\"\n",
    "    elif portfolio_name == \"P1 (low quality)\":\n",
    "        factor = \"QMJ-P1\"\n",
    "        asset_class = \"Stock Selection\"\n",
    "        region = \"Global\"\n",
    "    elif portfolio_name == \"P10 (high quality)\":\n",
    "        factor = \"QMJ-P10\"\n",
    "        asset_class = \"Stock Selection\"\n",
    "        region = \"Global\"\n",
    "    elif portfolio_name in [\"P2\", \"P3\", \"P4\", \"P5\", \"P6\", \"P7\", \"P8\", \"P9\"]:\n",
    "        factor = f\"QMJ-{portfolio_name}\"  # e.g., QMJ-P2, QMJ-P3, ..., QMJ-P9\n",
    "        asset_class = \"Stock Selection\"\n",
    "        region = \"Global\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized portfolio name: {portfolio_name}\")\n",
    "\n",
    "    return factor, asset_class, region\n",
    "\n",
    "# Process the Excel file\n",
    "logger.info(f\"Processing {filepath}...\")\n",
    "\n",
    "try:\n",
    "    # Read the Excel file with header=18\n",
    "    df = pd.read_excel(filepath, sheet_name=0, header=18)\n",
    "    logger.info(f\"Read {len(df)} rows with columns: {list(df.columns)}\")\n",
    "\n",
    "    # Rename first column to 'date'\n",
    "    df = df.rename(columns={df.columns[0]: 'date'})\n",
    "\n",
    "    # Convert date column to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "    # Filter out invalid dates\n",
    "    df = df[df['date'].notna()]\n",
    "    logger.info(f\"After filtering invalid dates, {len(df)} rows remain.\")\n",
    "\n",
    "    # Filter to only known portfolio columns\n",
    "    valid_columns = ['date'] + portfolio_columns\n",
    "    df = df[valid_columns]\n",
    "    missing = [col for col in portfolio_columns if col not in df.columns]\n",
    "    if missing:\n",
    "        logger.warning(f\"Missing columns: {missing}\")\n",
    "    extra = [col for col in df.columns if col not in valid_columns]\n",
    "    if extra:\n",
    "        logger.warning(f\"Extra columns ignored: {extra}\")\n",
    "    logger.info(f\"Filtered to {len(df.columns) - 1} portfolio columns: {valid_columns[1:]}\")\n",
    "\n",
    "    # Melt to long format\n",
    "    df_long = df.melt(id_vars=['date'], var_name='portfolio_name', value_name='value')\n",
    "    logger.info(f\"Melted to {len(df_long)} rows.\")\n",
    "\n",
    "    # Remove rows with missing values\n",
    "    df_long = df_long.dropna(subset=['value'])\n",
    "    logger.info(f\"After dropping rows with missing values, {len(df_long)} rows remain.\")\n",
    "\n",
    "    # Apply classification\n",
    "    df_long[['factor', 'asset_class', 'region']] = df_long['portfolio_name'].apply(\n",
    "        lambda x: pd.Series(classify_portfolio(x))\n",
    "    )\n",
    "\n",
    "    # Add associated paper\n",
    "    df_long['associated_paper'] = paper\n",
    "\n",
    "    # Ensure column names match table\n",
    "    df_long = df_long[['factor', 'date', 'associated_paper', 'asset_class', 'value', 'region']]\n",
    "\n",
    "    # Drop duplicates based on primary key\n",
    "    df_long = df_long.drop_duplicates(subset=['factor', 'date', 'associated_paper', 'asset_class'])\n",
    "    logger.info(f\"After dropping duplicates, {len(df_long)} rows remain.\")\n",
    "\n",
    "    # Load into MSSQL database\n",
    "    df_long.to_sql(\n",
    "        'factor_returns',\n",
    "        engine,\n",
    "        if_exists='append',\n",
    "        index=False,\n",
    "        dtype={\n",
    "            'factor': VARCHAR(50),\n",
    "            'date': DATE,\n",
    "            'associated_paper': VARCHAR(100),\n",
    "            'asset_class': VARCHAR(50),\n",
    "            'value': DECIMAL(15, 6),\n",
    "            'region': VARCHAR(50)\n",
    "        }\n",
    "    )\n",
    "    logger.info(f\"Successfully loaded {len(df_long)} rows into database.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error loading data: {str(e)}\")\n",
    "\n",
    "logger.info(\"Processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7f011f-4d60-44c4-8fce-39e94e9a8272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New consolidated load factors script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "996fc64d-536d-43b8-965a-6e07aa9e35b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 17:23:29,797 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:23:32,388 - INFO - Raw columns: ['12/31/1930', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', -0.000557986425086, 'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29']\n",
      "2025-04-10 17:23:32,419 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 0): \"The following id_vars or value_vars are not present in the DataFrame: ['date']\"\n",
      "2025-04-10 17:23:32,421 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 4)...\n",
      "2025-04-10 17:23:33,643 - INFO - Raw columns: ['07/31/1926', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', 0.0283354011258, 'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29']\n",
      "2025-04-10 17:23:33,660 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 4): \"The following id_vars or value_vars are not present in the DataFrame: ['date']\"\n",
      "2025-04-10 17:23:33,662 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 5)...\n",
      "2025-04-10 17:23:34,669 - INFO - Raw columns: ['07/31/1926', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', -0.016588027537, 'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29']\n",
      "2025-04-10 17:23:34,682 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 5): \"The following id_vars or value_vars are not present in the DataFrame: ['date']\"\n",
      "2025-04-10 17:23:34,685 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 6)...\n",
      "2025-04-10 17:23:35,873 - INFO - Raw columns: ['07/31/1926', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', -0.0271953118576, 'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29']\n",
      "2025-04-10 17:23:35,895 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 6): \"The following id_vars or value_vars are not present in the DataFrame: ['date']\"\n",
      "2025-04-10 17:23:35,897 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 7)...\n",
      "2025-04-10 17:23:37,012 - INFO - Raw columns: ['07/31/1926', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', -0.0198557509772, 'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29']\n",
      "2025-04-10 17:23:37,033 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 7): \"The following id_vars or value_vars are not present in the DataFrame: ['date']\"\n",
      "2025-04-10 17:23:37,034 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 8)...\n",
      "2025-04-10 17:23:38,128 - INFO - Raw columns: ['01/31/1927', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', 0.0266643513295, 'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29']\n",
      "2025-04-10 17:23:38,143 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 8): \"The following id_vars or value_vars are not present in the DataFrame: ['date']\"\n",
      "2025-04-10 17:23:38,146 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 9)...\n",
      "2025-04-10 17:23:39,087 - INFO - Raw columns: ['07/31/1926', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 27892.9341875, 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29']\n",
      "2025-04-10 17:23:39,103 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 9): \"The following id_vars or value_vars are not present in the DataFrame: ['date']\"\n",
      "2025-04-10 17:23:39,105 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 10)...\n",
      "2025-04-10 17:23:40,149 - INFO - Raw columns: ['DATE', 'Risk Free Rate']\n",
      "2025-04-10 17:23:40,168 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 10): \"The following id_vars or value_vars are not present in the DataFrame: ['date']\"\n",
      "2025-04-10 17:23:40,169 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:23:40,500 - INFO - Raw columns: ['Unnamed: 0', 'TSMOM', 'TSMOM^CM', 'TSMOM^EQ', 'TSMOM^FI', 'TSMOM^FX']\n",
      "2025-04-10 17:23:40,508 - ERROR - Error processing C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet 0): \"The following id_vars or value_vars are not present in the DataFrame: ['date']\"\n",
      "2025-04-10 17:23:40,510 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:23:41,512 - INFO - Raw columns: ['07/31/1957', -0.005016672241401992, 0.016438053192076186, -0.0018629379296232892, 0.004806585046341726, -0.005882511338651253, 0.017322414949695154, 0.0018166942388932648, 0.017135628005755674, 0.014401568183468263, 0.017518796894752758, 0.02253546913615475, 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22']\n",
      "2025-04-10 17:23:41,528 - ERROR - Error processing C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 0): \"The following id_vars or value_vars are not present in the DataFrame: ['date']\"\n",
      "2025-04-10 17:23:41,530 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx (sheet 0)...\n",
      "2025-04-10 17:23:42,836 - INFO - Raw columns: ['Date', 'US Stock Selection Value', 'US Stock Selection Momentum', 'US Stock Selection Defensive', 'US Stock Selection Multi-style', 'Intl Stock Selection Value', 'Intl Stock Selection Momentum', 'Intl Stock Selection Defensive', 'Intl Stock Selection Multi-style', 'Equity indices Value', 'Equity indices Momentum', 'Equity indices Carry', 'Equity indices Defensive', 'Equity indices Multi-style', 'Fixed income Value', 'Fixed income Momentum', 'Fixed income Carry', 'Fixed income Defensive', 'Fixed income Multi-style', 'Currencies Value', 'Currencies Momentum', 'Currencies Carry', 'Currencies Multi-style', 'Commodities Value', 'Commodities Momentum', 'Commodities Carry', 'Commodities Multi-style', 'All Stock Selection Value', 'All Stock Selection Momentum', 'All Stock Selection Defensive', 'All Stock Selection Multi-style', 'All Macro Value', 'All Macro Momentum', 'All Macro Carry', 'All Macro Defensive', 'All Macro Multi-style', 'All asset classes Value', 'All asset classes Momentum', 'All asset classes Carry', 'All asset classes Defensive', 'All asset classes Multi-style', 'Equity indices Market', 'Fixed income Market', 'Commodities Market', 'All Macro Market']\n",
      "2025-04-10 17:23:42,851 - ERROR - Error processing C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx (sheet 0): \"The following id_vars or value_vars are not present in the DataFrame: ['date']\"\n",
      "2025-04-10 17:23:42,853 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:23:43,489 - INFO - Raw columns: ['Unnamed: 0', 'Excess return of equal-weight commodities portfolio', 'Excess spot return of equal-weight commodities portfolio', 'Interest rate adjusted carry of equal-weight commodities portfolio', 'Spot return of equal-weight commodities portfolio', 'Carry of equal-weight commodities portfolio', 'Excess return of long/short commodities portfolio', 'Excess spot return of long/short commodities portfolio', 'Interest rate adjusted carry of long/short commodities portfolio', 'Aggregate backwardation/contango', 'State of backwardation/contango', 'State of inflation']\n",
      "2025-04-10 17:23:44,431 - INFO - No new rows to load into aqr_cmdty_factors.\n",
      "2025-04-10 17:23:44,432 - INFO - All data processing complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import VARCHAR, DATE, DECIMAL\n",
    "from sqlalchemy.sql import text\n",
    "import logging\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(), logging.FileHandler('load_aqr_data.log')]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Database connection\n",
    "engine = create_engine(\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/CWA_Fund_Database\"\n",
    "    \"?driver=ODBC+Driver+18+for+SQL+Server&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "# File configurations\n",
    "data_files = {\n",
    "    \"BAB_multi\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx\",\n",
    "        \"sheets\": {\n",
    "            \"BAB\": {\"sheet\": 0, \"header\": 19, \"paper\": \"Betting Against Beta (Frazzini and Pedersen, 2014)\", \"columns\": {\"USA\": \"BAB\", \"Global\": \"BAB\", \"Global Ex USA\": \"BAB\"}},\n",
    "            \"MKT\": {\"sheet\": 4, \"header\": 19, \"paper\": \"Fama-French Factors\", \"columns\": {\"USA\": \"MKT\", \"Global\": \"MKT\", \"Global Ex USA\": \"MKT\"}},\n",
    "            \"SMB\": {\"sheet\": 5, \"header\": 19, \"paper\": \"Fama-French Factors\", \"columns\": {\"USA\": \"SMB\", \"Global\": \"SMB\", \"Global Ex USA\": \"SMB\"}},\n",
    "            \"HML-FF\": {\"sheet\": 6, \"header\": 19, \"paper\": \"Fama-French Factors\", \"columns\": {\"USA\": \"HML-FF\", \"Global\": \"HML-FF\", \"Global Ex USA\": \"HML-FF\"}},\n",
    "            \"HML-D\": {\"sheet\": 7, \"header\": 19, \"paper\": \"The Devil's in HML's Details\", \"columns\": {\"USA\": \"HML-D\", \"Global\": \"HML-D\", \"Global Ex USA\": \"HML-D\"}},\n",
    "            \"UMD\": {\"sheet\": 8, \"header\": 19, \"paper\": \"On Persistence in Mutual Fund Performance\", \"columns\": {\"USA\": \"UMD\", \"Global\": \"UMD\", \"Global Ex USA\": \"UMD\"}},\n",
    "            \"ME\": {\"sheet\": 9, \"header\": 19, \"paper\": \"AQR Factors\", \"columns\": {\"USA\": \"ME\", \"Global\": \"ME\", \"Global Ex USA\": \"ME\"}},\n",
    "            \"RF\": {\"sheet\": 10, \"header\": 18, \"paper\": None, \"columns\": {\"Risk Free Rate\": \"RF\"}}\n",
    "        }\n",
    "    },\n",
    "    \"TSMOM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 17,\n",
    "        \"paper\": \"Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)\",\n",
    "        \"columns\": {\n",
    "            \"Unnamed: 0\": \"DATE\",\n",
    "            \"TSMOM\": \"TSM-MA\",\n",
    "            \"TSMOM^CM\": \"TSM-Com\",\n",
    "            \"TSMOM^EQ\": \"TSM-EQ\",\n",
    "            \"TSMOM^FI\": \"TSM-FI\",\n",
    "            \"TSMOM^FX\": \"TSM-FX\"\n",
    "        }\n",
    "    },\n",
    "    \"QMJ\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 19,\n",
    "        \"paper\": \"Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)\",\n",
    "        \"columns\": {\n",
    "            \"DATE\": \"DATE\",\n",
    "            \"P1 (low quality)\": \"QMJ-P1-LQ\",\n",
    "            \"P2\": \"QMJ-P2\",\n",
    "            \"P3\": \"QMJ-P3\",\n",
    "            \"P4\": \"QMJ-P4\",\n",
    "            \"P5\": \"QMJ-P5\",\n",
    "            \"P6\": \"QMJ-P6\",\n",
    "            \"P7\": \"QMJ-P7\",\n",
    "            \"P8\": \"QMJ-P8\",\n",
    "            \"P9\": \"QMJ-P9\",\n",
    "            \"P10 (high quality)\": \"QMJ-P10-HQ\",\n",
    "            \"P10-P1\": \"QMJ\"\n",
    "        }\n",
    "    },\n",
    "    \"Century\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 18,\n",
    "        \"paper\": \"Century of Factor Premia Monthly-Ilmanen et al. (2021)\",\n",
    "        \"columns\": {\n",
    "            \"Date\": \"DATE\",\n",
    "            \"US Stock Selection Value\": \"HML-FF-US\", \"US Stock Selection Momentum\": \"UMD-US\", \n",
    "            \"US Stock Selection Defensive\": \"BAB-US\", \"US Stock Selection Multi-style\": \"Multi-style-US\",\n",
    "            \"Intl Stock Selection Value\": \"HML-FF-Intl\", \"Intl Stock Selection Momentum\": \"UMD-Intl\", \n",
    "            \"Intl Stock Selection Defensive\": \"BAB-Intl\", \"Intl Stock Selection Multi-style\": \"Multi-style-Intl\",\n",
    "            \"Equity indices Value\": \"HML-Equity\", \"Equity indices Momentum\": \"UMD-Equity\", \n",
    "            \"Equity indices Carry\": \"Carry-Equity\", \"Equity indices Defensive\": \"BAB-Equity\", \n",
    "            \"Equity indices Multi-style\": \"Multi-style-Equity\",\n",
    "            \"Fixed income Value\": \"HML-FI\", \"Fixed income Momentum\": \"UMD-FI\", \n",
    "            \"Fixed income Carry\": \"Carry-FI\", \"Fixed income Defensive\": \"BAB-FI\", \n",
    "            \"Fixed income Multi-style\": \"Multi-style-FI\",\n",
    "            \"Currencies Value\": \"HML-FX\", \"Currencies Momentum\": \"UMD-FX\", \n",
    "            \"Currencies Carry\": \"Carry-FX\", \"Currencies Multi-style\": \"Multi-style-FX\",\n",
    "            \"Commodities Value\": \"HML-COM\", \"Commodities Momentum\": \"UMD-COM\", \n",
    "            \"Commodities Carry\": \"Carry-COM\", \"Commodities Multi-style\": \"Multi-style-COM\",\n",
    "            \"All Stock Selection Value\": \"HML-All-SS\", \"All Stock Selection Momentum\": \"UMD-All-SS\", \n",
    "            \"All Stock Selection Defensive\": \"BAB-All-SS\", \"All Stock Selection Multi-style\": \"Multi-style-All-SS\",\n",
    "            \"All Macro Value\": \"HML-All-Macro\", \"All Macro Momentum\": \"UMD-All-Macro\", \n",
    "            \"All Macro Carry\": \"Carry-All-Macro\", \"All Macro Defensive\": \"BAB-All-Macro\", \n",
    "            \"All Macro Multi-style\": \"Multi-style-All-Macro\",\n",
    "            \"All asset classes Value\": \"HML-All\", \"All asset classes Momentum\": \"UMD-All\", \n",
    "            \"All asset classes Carry\": \"Carry-All\", \"All asset classes Defensive\": \"BAB-All\", \n",
    "            \"All asset classes Multi-style\": \"Multi-style-All\",\n",
    "            \"Equity indices Market\": \"MKT-Equity\", \"Fixed income Market\": \"MKT-FI\", \n",
    "            \"Commodities Market\": \"MKT-COM\", \"All Macro Market\": \"MKT-All-Macro\"\n",
    "        }\n",
    "    },\n",
    "    \"COM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 10,\n",
    "        \"paper\": \"Commodities for the Long Run\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def process_factors(file_config, sheet=0, is_com=False, parent_path=None):\n",
    "    file_path = parent_path if parent_path else file_config['path']\n",
    "    logger.info(f\"Processing {file_path} (sheet {sheet})...\")\n",
    "    try:\n",
    "        # Read Excel with single header row\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet, header=file_config['header'])\n",
    "        logger.info(f\"Raw columns: {list(df.columns)}\")\n",
    "        \n",
    "        if is_com:\n",
    "            df.columns = [\n",
    "                'date', 'excess_return_eqwt', 'excess_spot_return_eqwt', 'ir_adjusted_carry_eqwt',\n",
    "                'spot_return_eqwt', 'carry_eqwt', 'excess_return_long_short', 'excess_spot_return_long_short',\n",
    "                'ir_adjusted_carry_long_short', 'aggregate_backwardation_contango', \n",
    "                'state_backwardation_contango', 'state_inflation'\n",
    "            ]\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            df['associated_paper'] = file_config['paper']\n",
    "            df = df.dropna(subset=['date'])\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                existing = pd.read_sql(\"SELECT date FROM aqr_cmdty_factors\", connection)\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(existing['date'])\n",
    "            \n",
    "            df['date_str'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_new = df[~df['date_str'].isin(existing_keys)].drop(columns=['date_str'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                df_new.to_sql(\n",
    "                    'aqr_cmdty_factors',\n",
    "                    engine,\n",
    "                    if_exists='append',\n",
    "                    index=False,\n",
    "                    dtype={\n",
    "                        'date': DATE,\n",
    "                        'excess_return_eqwt': DECIMAL(15, 6),\n",
    "                        'excess_spot_return_eqwt': DECIMAL(15, 6),\n",
    "                        'ir_adjusted_carry_eqwt': DECIMAL(15, 6),\n",
    "                        'spot_return_eqwt': DECIMAL(15, 6),\n",
    "                        'carry_eqwt': DECIMAL(15, 6),\n",
    "                        'excess_return_long_short': DECIMAL(15, 6),\n",
    "                        'excess_spot_return_long_short': DECIMAL(15, 6),\n",
    "                        'ir_adjusted_carry_long_short': DECIMAL(15, 6),\n",
    "                        'aggregate_backwardation_contango': DECIMAL(15, 6),\n",
    "                        'state_backwardation_contango': VARCHAR(50),\n",
    "                        'state_inflation': VARCHAR(50),\n",
    "                        'associated_paper': VARCHAR(100)\n",
    "                    }\n",
    "                )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into aqr_cmdty_factors.\")\n",
    "            else:\n",
    "                logger.info(\"No new rows to load into aqr_cmdty_factors.\")\n",
    "        else:\n",
    "            df = df.rename(columns={df.columns[0]: 'date'})\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            \n",
    "            if 'columns' in file_config:\n",
    "                valid_cols = list(file_config['columns'].keys())\n",
    "                df = df[[col for col in df.columns if col in valid_cols]]\n",
    "                df.columns = [file_config['columns'].get(col, col) for col in df.columns]\n",
    "            \n",
    "            df_long = df.melt(id_vars=['date'], var_name='factor', value_name='value')\n",
    "            df_long = df_long.dropna(subset=['value', 'date'])\n",
    "            \n",
    "            if 'TSMOM' in file_config['path']:\n",
    "                df_long['asset_class'] = df_long['factor'].map({\n",
    "                    \"TSM-MA\": \"Multi-Asset\",\n",
    "                    \"TSM-Com\": \"Commodities\",\n",
    "                    \"TSM-EQ\": \"Equity\",\n",
    "                    \"TSM-FI\": \"Fixed Income\",\n",
    "                    \"TSM-FX\": \"Currencies\"\n",
    "                })\n",
    "                df_long['region'] = \"Global\"\n",
    "            elif 'Quality Minus Junk' in file_config['path']:\n",
    "                df_long['asset_class'] = \"Equity\"\n",
    "                df_long['region'] = df_long['date'].apply(\n",
    "                    lambda x: \"USA\" if x < pd.Timestamp(\"1989-07-31\") else \"Global\"\n",
    "                )\n",
    "            elif 'Century' in file_config['path']:\n",
    "                df_long['asset_class'] = df_long['factor'].str.extract(\n",
    "                    '(Stock Selection|Equity indices|Fixed income|Currencies|Commodities|All Macro|All asset classes)'\n",
    "                )\n",
    "                df_long['region'] = df_long['factor'].apply(\n",
    "                    lambda x: 'US' if 'US' in x else 'Intl' if 'Intl' in x else 'Global'\n",
    "                )\n",
    "            else:  # BAB_multi\n",
    "                df_long['asset_class'] = \"Equity\" if 'Risk Free Rate' not in file_config['columns'] else \"Fixed Income\"\n",
    "                df_long['region'] = df_long['factor'].apply(\n",
    "                    lambda x: \"USA\" if 'USA' in df.columns[df.columns.get_loc(x)] or x == \"RF\"\n",
    "                    else \"Global\" if 'Global' in df.columns[df.columns.get_loc(x)]\n",
    "                    else \"Intl\"\n",
    "                )\n",
    "            \n",
    "            df_long['associated_paper'] = file_config['paper']\n",
    "            df_long = df_long[['factor', 'date', 'associated_paper', 'asset_class', 'value', 'region']]\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                existing = pd.read_sql(\n",
    "                    \"SELECT factor, date, associated_paper, asset_class FROM factor_returns\",\n",
    "                    connection\n",
    "                )\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(tuple(row) for row in existing[['factor', 'date', 'associated_paper', 'asset_class']].values)\n",
    "            \n",
    "            df_long['date_str'] = df_long['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_long['key'] = df_long.apply(\n",
    "                lambda row: (row['factor'], row['date_str'], row['associated_paper'] if row['associated_paper'] else 'None', row['asset_class']), axis=1\n",
    "            )\n",
    "            df_new = df_long[~df_long['key'].isin(existing_keys)].drop(columns=['date_str', 'key'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                df_new.to_sql(\n",
    "                    'factor_returns',\n",
    "                    engine,\n",
    "                    if_exists='append',\n",
    "                    index=False,\n",
    "                    dtype={\n",
    "                        'factor': VARCHAR(50),\n",
    "                        'date': DATE,\n",
    "                        'associated_paper': VARCHAR(100),\n",
    "                        'asset_class': VARCHAR(50),\n",
    "                        'value': DECIMAL(15, 6),\n",
    "                        'region': VARCHAR(50)\n",
    "                    }\n",
    "                )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into factor_returns from {file_path} (sheet {sheet}).\")\n",
    "            else:\n",
    "                logger.info(f\"No new rows to load into factor_returns from {file_path} (sheet {sheet}).\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing {file_path} (sheet {sheet}): {str(e)}\")\n",
    "\n",
    "# Process all datasets\n",
    "for key, config in data_files.items():\n",
    "    if key == \"BAB_multi\":\n",
    "        for subkey, subconfig in config['sheets'].items():\n",
    "            process_factors(subconfig, sheet=subconfig['sheet'], parent_path=config['path'])\n",
    "    elif key == \"COM\":\n",
    "        process_factors(config, sheet=config['sheet'], is_com=True)\n",
    "    else:\n",
    "        process_factors(config, sheet=config['sheet'])\n",
    "\n",
    "logger.info(\"All data processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fc38eb7-4669-493b-bb71-fd3821b5986d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 17:25:57,534 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:25:59,914 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:25:59,930 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 0): \"The following id_vars or value_vars are not present in the DataFrame: ['date']\"\n",
      "2025-04-10 17:25:59,931 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 4)...\n",
      "2025-04-10 17:26:01,416 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:26:01,434 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 4): \"The following id_vars or value_vars are not present in the DataFrame: ['date']\"\n",
      "2025-04-10 17:26:01,437 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 5)...\n",
      "2025-04-10 17:26:02,494 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:26:02,503 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 5): \"The following id_vars or value_vars are not present in the DataFrame: ['date']\"\n",
      "2025-04-10 17:26:02,505 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 6)...\n",
      "2025-04-10 17:26:03,672 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:26:03,685 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 6): \"The following id_vars or value_vars are not present in the DataFrame: ['date']\"\n",
      "2025-04-10 17:26:03,688 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 7)...\n",
      "2025-04-10 17:26:04,860 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:26:04,877 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 7): \"The following id_vars or value_vars are not present in the DataFrame: ['date']\"\n",
      "2025-04-10 17:26:04,879 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 8)...\n",
      "2025-04-10 17:26:06,127 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:26:06,149 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 8): \"The following id_vars or value_vars are not present in the DataFrame: ['date']\"\n",
      "2025-04-10 17:26:06,151 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 9)...\n",
      "2025-04-10 17:26:06,985 - INFO - Raw columns: ['DATE', 'AUT', 'HKG', 'ESP', 'GBR', 'ITA', 'DEU', 'DNK', 'NZL', 'NLD', 'USA', 'PRT', 'BEL', 'ISR', 'GRC', 'NOR', 'SGP', 'CHE', 'IRL', 'CAN', 'FIN', 'JPN', 'SWE', 'FRA', 'AUS', 'Global Ex USA', 'Global', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:26:06,998 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 9): \"The following id_vars or value_vars are not present in the DataFrame: ['date']\"\n",
      "2025-04-10 17:26:06,999 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 10)...\n",
      "2025-04-10 17:26:07,939 - INFO - Raw columns: ['DATE', 'Risk Free Rate']\n",
      "2025-04-10 17:26:07,955 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 10): \"The following id_vars or value_vars are not present in the DataFrame: ['date']\"\n",
      "2025-04-10 17:26:07,957 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:26:08,276 - INFO - Raw columns: ['Unnamed: 0', 'TSMOM', 'TSMOM^CM', 'TSMOM^EQ', 'TSMOM^FI', 'TSMOM^FX']\n",
      "2025-04-10 17:26:08,282 - ERROR - Error processing C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet 0): \"The following id_vars or value_vars are not present in the DataFrame: ['date']\"\n",
      "2025-04-10 17:26:08,285 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:26:09,314 - INFO - Raw columns: ['07/31/1957', -0.005016672241401992, 0.016438053192076186, -0.0018629379296232892, 0.004806585046341726, -0.005882511338651253, 0.017322414949695154, 0.0018166942388932648, 0.017135628005755674, 0.014401568183468263, 0.017518796894752758, 0.02253546913615475, 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22']\n",
      "2025-04-10 17:26:09,316 - ERROR - Error processing C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 0): 'float' object has no attribute 'upper'\n",
      "2025-04-10 17:26:09,317 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx (sheet 0)...\n",
      "2025-04-10 17:26:10,514 - INFO - Raw columns: ['Date', 'US Stock Selection Value', 'US Stock Selection Momentum', 'US Stock Selection Defensive', 'US Stock Selection Multi-style', 'Intl Stock Selection Value', 'Intl Stock Selection Momentum', 'Intl Stock Selection Defensive', 'Intl Stock Selection Multi-style', 'Equity indices Value', 'Equity indices Momentum', 'Equity indices Carry', 'Equity indices Defensive', 'Equity indices Multi-style', 'Fixed income Value', 'Fixed income Momentum', 'Fixed income Carry', 'Fixed income Defensive', 'Fixed income Multi-style', 'Currencies Value', 'Currencies Momentum', 'Currencies Carry', 'Currencies Multi-style', 'Commodities Value', 'Commodities Momentum', 'Commodities Carry', 'Commodities Multi-style', 'All Stock Selection Value', 'All Stock Selection Momentum', 'All Stock Selection Defensive', 'All Stock Selection Multi-style', 'All Macro Value', 'All Macro Momentum', 'All Macro Carry', 'All Macro Defensive', 'All Macro Multi-style', 'All asset classes Value', 'All asset classes Momentum', 'All asset classes Carry', 'All asset classes Defensive', 'All asset classes Multi-style', 'Equity indices Market', 'Fixed income Market', 'Commodities Market', 'All Macro Market']\n",
      "2025-04-10 17:26:10,530 - ERROR - Error processing C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx (sheet 0): \"The following id_vars or value_vars are not present in the DataFrame: ['date']\"\n",
      "2025-04-10 17:26:10,532 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:26:11,097 - INFO - Raw columns: ['Unnamed: 0', 'Excess return of equal-weight commodities portfolio', 'Excess spot return of equal-weight commodities portfolio', 'Interest rate adjusted carry of equal-weight commodities portfolio', 'Spot return of equal-weight commodities portfolio', 'Carry of equal-weight commodities portfolio', 'Excess return of long/short commodities portfolio', 'Excess spot return of long/short commodities portfolio', 'Interest rate adjusted carry of long/short commodities portfolio', 'Aggregate backwardation/contango', 'State of backwardation/contango', 'State of inflation']\n",
      "2025-04-10 17:26:11,535 - INFO - No new rows to load into aqr_cmdty_factors.\n",
      "2025-04-10 17:26:11,535 - INFO - All data processing complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import VARCHAR, DATE, DECIMAL\n",
    "from sqlalchemy.sql import text\n",
    "import logging\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(), logging.FileHandler('load_aqr_data.log')]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Database connection\n",
    "engine = create_engine(\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/CWA_Fund_Database\"\n",
    "    \"?driver=ODBC+Driver+18+for+SQL+Server&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "# File configurations\n",
    "data_files = {\n",
    "    \"BAB_multi\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx\",\n",
    "        \"sheets\": {\n",
    "            \"BAB\": {\"sheet\": 0, \"header\": 18, \"paper\": \"Betting Against Beta (Frazzini and Pedersen, 2014)\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"BAB\", \"Global\": \"BAB\", \"Global Ex USA\": \"BAB\"}},\n",
    "            \"MKT\": {\"sheet\": 4, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"MKT\", \"Global\": \"MKT\", \"Global Ex USA\": \"MKT\"}},\n",
    "            \"SMB\": {\"sheet\": 5, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"SMB\", \"Global\": \"SMB\", \"Global Ex USA\": \"SMB\"}},\n",
    "            \"HML-FF\": {\"sheet\": 6, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-FF\", \"Global\": \"HML-FF\", \"Global Ex USA\": \"HML-FF\"}},\n",
    "            \"HML-D\": {\"sheet\": 7, \"header\": 18, \"paper\": \"The Devil's in HML's Details\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-D\", \"Global\": \"HML-D\", \"Global Ex USA\": \"HML-D\"}},\n",
    "            \"UMD\": {\"sheet\": 8, \"header\": 18, \"paper\": \"On Persistence in Mutual Fund Performance\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"UMD\", \"Global\": \"UMD\", \"Global Ex USA\": \"UMD\"}},\n",
    "            \"ME\": {\"sheet\": 9, \"header\": 18, \"paper\": \"AQR Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"ME\", \"Global\": \"ME\", \"Global Ex USA\": \"ME\"}},\n",
    "            \"RF\": {\"sheet\": 10, \"header\": 18, \"paper\": None, \"columns\": {\"DATE\": \"DATE\", \"Risk Free Rate\": \"RF\"}}\n",
    "        }\n",
    "    },\n",
    "    \"TSMOM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 17,\n",
    "        \"paper\": \"Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)\",\n",
    "        \"columns\": {\n",
    "            \"Unnamed: 0\": \"DATE\",\n",
    "            \"TSMOM\": \"TSM-MA\",\n",
    "            \"TSMOM^CM\": \"TSM-Com\",\n",
    "            \"TSMOM^EQ\": \"TSM-EQ\",\n",
    "            \"TSMOM^FI\": \"TSM-FI\",\n",
    "            \"TSMOM^FX\": \"TSM-FX\"\n",
    "        }\n",
    "    },\n",
    "    \"QMJ\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 19,\n",
    "        \"paper\": \"Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)\",\n",
    "        \"columns\": {\n",
    "            \"DATE\": \"DATE\",\n",
    "            \"P1 (low quality)\": \"QMJ-P1-LQ\",\n",
    "            \"P2\": \"QMJ-P2\",\n",
    "            \"P3\": \"QMJ-P3\",\n",
    "            \"P4\": \"QMJ-P4\",\n",
    "            \"P5\": \"QMJ-P5\",\n",
    "            \"P6\": \"QMJ-P6\",\n",
    "            \"P7\": \"QMJ-P7\",\n",
    "            \"P8\": \"QMJ-P8\",\n",
    "            \"P9\": \"QMJ-P9\",\n",
    "            \"P10 (high quality)\": \"QMJ-P10-HQ\",\n",
    "            \"P10-P1\": \"QMJ\"\n",
    "        }\n",
    "    },\n",
    "    \"Century\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 18,\n",
    "        \"paper\": \"Century of Factor Premia Monthly-Ilmanen et al. (2021)\",\n",
    "        \"columns\": {\n",
    "            \"Date\": \"DATE\",\n",
    "            \"US Stock Selection Value\": \"HML-FF-US\", \"US Stock Selection Momentum\": \"UMD-US\", \n",
    "            \"US Stock Selection Defensive\": \"BAB-US\", \"US Stock Selection Multi-style\": \"Multi-style-US\",\n",
    "            \"Intl Stock Selection Value\": \"HML-FF-Intl\", \"Intl Stock Selection Momentum\": \"UMD-Intl\", \n",
    "            \"Intl Stock Selection Defensive\": \"BAB-Intl\", \"Intl Stock Selection Multi-style\": \"Multi-style-Intl\",\n",
    "            \"Equity indices Value\": \"HML-Equity\", \"Equity indices Momentum\": \"UMD-Equity\", \n",
    "            \"Equity indices Carry\": \"Carry-Equity\", \"Equity indices Defensive\": \"BAB-Equity\", \n",
    "            \"Equity indices Multi-style\": \"Multi-style-Equity\",\n",
    "            \"Fixed income Value\": \"HML-FI\", \"Fixed income Momentum\": \"UMD-FI\", \n",
    "            \"Fixed income Carry\": \"Carry-FI\", \"Fixed income Defensive\": \"BAB-FI\", \n",
    "            \"Fixed income Multi-style\": \"Multi-style-FI\",\n",
    "            \"Currencies Value\": \"HML-FX\", \"Currencies Momentum\": \"UMD-FX\", \n",
    "            \"Currencies Carry\": \"Carry-FX\", \"Currencies Multi-style\": \"Multi-style-FX\",\n",
    "            \"Commodities Value\": \"HML-COM\", \"Commodities Momentum\": \"UMD-COM\", \n",
    "            \"Commodities Carry\": \"Carry-COM\", \"Commodities Multi-style\": \"Multi-style-COM\",\n",
    "            \"All Stock Selection Value\": \"HML-All-SS\", \"All Stock Selection Momentum\": \"UMD-All-SS\", \n",
    "            \"All Stock Selection Defensive\": \"BAB-All-SS\", \"All Stock Selection Multi-style\": \"Multi-style-All-SS\",\n",
    "            \"All Macro Value\": \"HML-All-Macro\", \"All Macro Momentum\": \"UMD-All-Macro\", \n",
    "            \"All Macro Carry\": \"Carry-All-Macro\", \"All Macro Defensive\": \"BAB-All-Macro\", \n",
    "            \"All Macro Multi-style\": \"Multi-style-All-Macro\",\n",
    "            \"All asset classes Value\": \"HML-All\", \"All asset classes Momentum\": \"UMD-All\", \n",
    "            \"All asset classes Carry\": \"Carry-All\", \"All asset classes Defensive\": \"BAB-All\", \n",
    "            \"All asset classes Multi-style\": \"Multi-style-All\",\n",
    "            \"Equity indices Market\": \"MKT-Equity\", \"Fixed income Market\": \"MKT-FI\", \n",
    "            \"Commodities Market\": \"MKT-COM\", \"All Macro Market\": \"MKT-All-Macro\"\n",
    "        }\n",
    "    },\n",
    "    \"COM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 10,\n",
    "        \"paper\": \"Commodities for the Long Run\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def process_factors(file_config, sheet=0, is_com=False, parent_path=None):\n",
    "    file_path = parent_path if parent_path else file_config['path']\n",
    "    logger.info(f\"Processing {file_path} (sheet {sheet})...\")\n",
    "    try:\n",
    "        # Read Excel with correct header row\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet, header=file_config['header'])\n",
    "        logger.info(f\"Raw columns: {list(df.columns)}\")\n",
    "        \n",
    "        if is_com:\n",
    "            df.columns = [\n",
    "                'date', 'excess_return_eqwt', 'excess_spot_return_eqwt', 'ir_adjusted_carry_eqwt',\n",
    "                'spot_return_eqwt', 'carry_eqwt', 'excess_return_long_short', 'excess_spot_return_long_short',\n",
    "                'ir_adjusted_carry_long_short', 'aggregate_backwardation_contango', \n",
    "                'state_backwardation_contango', 'state_inflation'\n",
    "            ]\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            df['associated_paper'] = file_config['paper']\n",
    "            df = df.dropna(subset=['date'])\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                existing = pd.read_sql(\"SELECT date FROM aqr_cmdty_factors\", connection)\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(existing['date'])\n",
    "            \n",
    "            df['date_str'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_new = df[~df['date_str'].isin(existing_keys)].drop(columns=['date_str'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                df_new.to_sql(\n",
    "                    'aqr_cmdty_factors',\n",
    "                    engine,\n",
    "                    if_exists='append',\n",
    "                    index=False,\n",
    "                    dtype={\n",
    "                        'date': DATE,\n",
    "                        'excess_return_eqwt': DECIMAL(15, 6),\n",
    "                        'excess_spot_return_eqwt': DECIMAL(15, 6),\n",
    "                        'ir_adjusted_carry_eqwt': DECIMAL(15, 6),\n",
    "                        'spot_return_eqwt': DECIMAL(15, 6),\n",
    "                        'carry_eqwt': DECIMAL(15, 6),\n",
    "                        'excess_return_long_short': DECIMAL(15, 6),\n",
    "                        'excess_spot_return_long_short': DECIMAL(15, 6),\n",
    "                        'ir_adjusted_carry_long_short': DECIMAL(15, 6),\n",
    "                        'aggregate_backwardation_contango': DECIMAL(15, 6),\n",
    "                        'state_backwardation_contango': VARCHAR(50),\n",
    "                        'state_inflation': VARCHAR(50),\n",
    "                        'associated_paper': VARCHAR(100)\n",
    "                    }\n",
    "                )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into aqr_cmdty_factors.\")\n",
    "            else:\n",
    "                logger.info(\"No new rows to load into aqr_cmdty_factors.\")\n",
    "        else:\n",
    "            # Rename date column based on actual header\n",
    "            date_col = next((col for col in df.columns if 'DATE' in col.upper() or 'Date' in col), df.columns[0])\n",
    "            df = df.rename(columns={date_col: 'date'})\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            \n",
    "            if 'columns' in file_config:\n",
    "                valid_cols = list(file_config['columns'].keys())\n",
    "                df = df[[col for col in df.columns if col in valid_cols]]\n",
    "                df.columns = [file_config['columns'].get(col, col) for col in df.columns]\n",
    "            \n",
    "            df_long = df.melt(id_vars=['date'], var_name='factor', value_name='value')\n",
    "            df_long = df_long.dropna(subset=['value', 'date'])\n",
    "            \n",
    "            if 'TSMOM' in file_config['path']:\n",
    "                df_long['asset_class'] = df_long['factor'].map({\n",
    "                    \"TSM-MA\": \"Multi-Asset\",\n",
    "                    \"TSM-Com\": \"Commodities\",\n",
    "                    \"TSM-EQ\": \"Equity\",\n",
    "                    \"TSM-FI\": \"Fixed Income\",\n",
    "                    \"TSM-FX\": \"Currencies\"\n",
    "                })\n",
    "                df_long['region'] = \"Global\"\n",
    "            elif 'Quality Minus Junk' in file_config['path']:\n",
    "                df_long['asset_class'] = \"Equity\"\n",
    "                df_long['region'] = df_long['date'].apply(\n",
    "                    lambda x: \"USA\" if x < pd.Timestamp(\"1989-07-31\") else \"Global\"\n",
    "                )\n",
    "            elif 'Century' in file_config['path']:\n",
    "                df_long['asset_class'] = df_long['factor'].str.extract(\n",
    "                    '(Stock Selection|Equity indices|Fixed income|Currencies|Commodities|All Macro|All asset classes)'\n",
    "                )\n",
    "                df_long['region'] = df_long['factor'].apply(\n",
    "                    lambda x: 'US' if 'US' in x else 'Intl' if 'Intl' in x else 'Global'\n",
    "                )\n",
    "            else:  # BAB_multi\n",
    "                df_long['asset_class'] = \"Equity\" if 'Risk Free Rate' not in file_config['columns'].values() else \"Fixed Income\"\n",
    "                df_long['region'] = df_long.apply(\n",
    "                    lambda row: \"USA\" if 'USA' in df.columns[df.columns.get_loc(row['factor'])] or row['factor'] == \"RF\"\n",
    "                    else \"Global\" if 'Global' in df.columns[df.columns.get_loc(row['factor'])]\n",
    "                    else \"Intl\", axis=1\n",
    "                )\n",
    "            \n",
    "            df_long['associated_paper'] = file_config['paper']\n",
    "            df_long = df_long[['factor', 'date', 'associated_paper', 'asset_class', 'value', 'region']]\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                existing = pd.read_sql(\n",
    "                    \"SELECT factor, date, associated_paper, asset_class FROM factor_returns\",\n",
    "                    connection\n",
    "                )\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(tuple(row) for row in existing[['factor', 'date', 'associated_paper', 'asset_class']].values)\n",
    "            \n",
    "            df_long['date_str'] = df_long['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_long['key'] = df_long.apply(\n",
    "                lambda row: (row['factor'], row['date_str'], row['associated_paper'] if row['associated_paper'] else 'None', row['asset_class']), axis=1\n",
    "            )\n",
    "            df_new = df_long[~df_long['key'].isin(existing_keys)].drop(columns=['date_str', 'key'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                df_new.to_sql(\n",
    "                    'factor_returns',\n",
    "                    engine,\n",
    "                    if_exists='append',\n",
    "                    index=False,\n",
    "                    dtype={\n",
    "                        'factor': VARCHAR(50),\n",
    "                        'date': DATE,\n",
    "                        'associated_paper': VARCHAR(100),\n",
    "                        'asset_class': VARCHAR(50),\n",
    "                        'value': DECIMAL(15, 6),\n",
    "                        'region': VARCHAR(50)\n",
    "                    }\n",
    "                )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into factor_returns from {file_path} (sheet {sheet}).\")\n",
    "            else:\n",
    "                logger.info(f\"No new rows to load into factor_returns from {file_path} (sheet {sheet}).\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing {file_path} (sheet {sheet}): {str(e)}\")\n",
    "\n",
    "# Process all datasets\n",
    "for key, config in data_files.items():\n",
    "    if key == \"BAB_multi\":\n",
    "        for subkey, subconfig in config['sheets'].items():\n",
    "            process_factors(subconfig, sheet=subconfig['sheet'], parent_path=config['path'])\n",
    "    elif key == \"COM\":\n",
    "        process_factors(config, sheet=config['sheet'], is_com=True)\n",
    "    else:\n",
    "        process_factors(config, sheet=config['sheet'])\n",
    "\n",
    "logger.info(\"All data processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b479d980-d077-4d0f-8488-2f86a2469535",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 17:31:55,474 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:31:56,894 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:31:56,896 - INFO - Columns after renaming: ['date', 'BAB', 'BAB', 'BAB']\n",
      "2025-04-10 17:31:56,918 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 0): 'path'\n",
      "2025-04-10 17:31:56,920 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 4)...\n",
      "2025-04-10 17:31:57,618 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:31:57,620 - INFO - Columns after renaming: ['date', 'MKT', 'MKT', 'MKT']\n",
      "2025-04-10 17:31:57,633 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 4): 'path'\n",
      "2025-04-10 17:31:57,634 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 5)...\n",
      "2025-04-10 17:31:58,351 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:31:58,354 - INFO - Columns after renaming: ['date', 'SMB', 'SMB', 'SMB']\n",
      "2025-04-10 17:31:58,370 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 5): 'path'\n",
      "2025-04-10 17:31:58,372 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 6)...\n",
      "2025-04-10 17:31:59,221 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:31:59,224 - INFO - Columns after renaming: ['date', 'HML-FF', 'HML-FF', 'HML-FF']\n",
      "2025-04-10 17:31:59,238 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 6): 'path'\n",
      "2025-04-10 17:31:59,240 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 7)...\n",
      "2025-04-10 17:31:59,965 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:31:59,967 - INFO - Columns after renaming: ['date', 'HML-D', 'HML-D', 'HML-D']\n",
      "2025-04-10 17:31:59,982 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 7): 'path'\n",
      "2025-04-10 17:31:59,984 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 8)...\n",
      "2025-04-10 17:32:00,803 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:32:00,805 - INFO - Columns after renaming: ['date', 'UMD', 'UMD', 'UMD']\n",
      "2025-04-10 17:32:00,815 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 8): 'path'\n",
      "2025-04-10 17:32:00,816 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 9)...\n",
      "2025-04-10 17:32:01,255 - INFO - Raw columns: ['DATE', 'AUT', 'HKG', 'ESP', 'GBR', 'ITA', 'DEU', 'DNK', 'NZL', 'NLD', 'USA', 'PRT', 'BEL', 'ISR', 'GRC', 'NOR', 'SGP', 'CHE', 'IRL', 'CAN', 'FIN', 'JPN', 'SWE', 'FRA', 'AUS', 'Global Ex USA', 'Global', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:32:01,257 - INFO - Columns after renaming: ['date', 'ME', 'ME', 'ME']\n",
      "2025-04-10 17:32:01,266 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 9): 'path'\n",
      "2025-04-10 17:32:01,267 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 10)...\n",
      "2025-04-10 17:32:01,801 - INFO - Raw columns: ['DATE', 'Risk Free Rate']\n",
      "2025-04-10 17:32:01,803 - INFO - Columns after renaming: ['date', 'RF']\n",
      "2025-04-10 17:32:01,811 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 10): 'path'\n",
      "2025-04-10 17:32:01,812 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:32:02,069 - INFO - Raw columns: ['Unnamed: 0', 'TSMOM', 'TSMOM^CM', 'TSMOM^EQ', 'TSMOM^FI', 'TSMOM^FX']\n",
      "2025-04-10 17:32:02,072 - INFO - Columns after renaming: ['date', 'TSM-MA', 'TSM-Com', 'TSM-EQ', 'TSM-FI', 'TSM-FX']\n",
      "2025-04-10 17:32:02,743 - INFO - Loaded 2405 new rows into factor_returns from C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet 0).\n",
      "2025-04-10 17:32:02,744 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:32:03,135 - INFO - Raw columns: ['07/31/1957', -0.005016672241401992, 0.016438053192076186, -0.0018629379296232892, 0.004806585046341726, -0.005882511338651253, 0.017322414949695154, 0.0018166942388932648, 0.017135628005755674, 0.014401568183468263, 0.017518796894752758, 0.02253546913615475, 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22']\n",
      "2025-04-10 17:32:03,136 - WARNING - Expected columns not found in Quality Minus Junk file. Assigning columns manually.\n",
      "2025-04-10 17:32:03,138 - ERROR - Error processing C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 0): Length mismatch: Expected axis has 23 elements, new values have 12 elements\n",
      "2025-04-10 17:32:03,138 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx (sheet 0)...\n",
      "2025-04-10 17:32:03,839 - INFO - Raw columns: ['Date', 'US Stock Selection Value', 'US Stock Selection Momentum', 'US Stock Selection Defensive', 'US Stock Selection Multi-style', 'Intl Stock Selection Value', 'Intl Stock Selection Momentum', 'Intl Stock Selection Defensive', 'Intl Stock Selection Multi-style', 'Equity indices Value', 'Equity indices Momentum', 'Equity indices Carry', 'Equity indices Defensive', 'Equity indices Multi-style', 'Fixed income Value', 'Fixed income Momentum', 'Fixed income Carry', 'Fixed income Defensive', 'Fixed income Multi-style', 'Currencies Value', 'Currencies Momentum', 'Currencies Carry', 'Currencies Multi-style', 'Commodities Value', 'Commodities Momentum', 'Commodities Carry', 'Commodities Multi-style', 'All Stock Selection Value', 'All Stock Selection Momentum', 'All Stock Selection Defensive', 'All Stock Selection Multi-style', 'All Macro Value', 'All Macro Momentum', 'All Macro Carry', 'All Macro Defensive', 'All Macro Multi-style', 'All asset classes Value', 'All asset classes Momentum', 'All asset classes Carry', 'All asset classes Defensive', 'All asset classes Multi-style', 'Equity indices Market', 'Fixed income Market', 'Commodities Market', 'All Macro Market']\n",
      "2025-04-10 17:32:03,842 - INFO - Columns after renaming: ['date', 'HML-FF-US', 'UMD-US', 'BAB-US', 'Multi-style-US', 'HML-FF-Intl', 'UMD-Intl', 'BAB-Intl', 'Multi-style-Intl', 'HML-Equity', 'UMD-Equity', 'Carry-Equity', 'BAB-Equity', 'Multi-style-Equity', 'HML-FI', 'UMD-FI', 'Carry-FI', 'BAB-FI', 'Multi-style-FI', 'HML-FX', 'UMD-FX', 'Carry-FX', 'Multi-style-FX', 'HML-COM', 'UMD-COM', 'Carry-COM', 'Multi-style-COM', 'HML-All-SS', 'UMD-All-SS', 'BAB-All-SS', 'Multi-style All-SS', 'HML-All-Macro', 'UMD-All-Macro', 'Carry-All-Macro', 'BAB-All-Macro', 'Multi-style-All-Macro', 'HML-All', 'UMD-All', 'Carry-All', 'BAB-All', 'Multi-style-All', 'MKT-Equity', 'MKT-FI', 'MKT-COM', 'MKT-All-Macro']\n",
      "2025-04-10 17:32:32,602 - INFO - Loaded 46491 new rows into factor_returns from C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx (sheet 0).\n",
      "2025-04-10 17:32:32,609 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:32:33,072 - INFO - Raw columns: ['Unnamed: 0', 'Excess return of equal-weight commodities portfolio', 'Excess spot return of equal-weight commodities portfolio', 'Interest rate adjusted carry of equal-weight commodities portfolio', 'Spot return of equal-weight commodities portfolio', 'Carry of equal-weight commodities portfolio', 'Excess return of long/short commodities portfolio', 'Excess spot return of long/short commodities portfolio', 'Interest rate adjusted carry of long/short commodities portfolio', 'Aggregate backwardation/contango', 'State of backwardation/contango', 'State of inflation']\n",
      "2025-04-10 17:32:33,092 - INFO - No new rows to load into aqr_cmdty_factors.\n",
      "2025-04-10 17:32:33,093 - INFO - All data processing complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import VARCHAR, DATE, DECIMAL\n",
    "import logging\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(), logging.FileHandler('load_aqr_data.log')]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Database connection\n",
    "engine = create_engine(\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/CWA_Fund_Database\"\n",
    "    \"?driver=ODBC+Driver+18+for+SQL+Server&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "# File configurations\n",
    "data_files = {\n",
    "    \"BAB_multi\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx\",\n",
    "        \"sheets\": {\n",
    "            \"BAB\": {\"sheet\": 0, \"header\": 18, \"paper\": \"Betting Against Beta (Frazzini and Pedersen, 2014)\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"BAB\", \"Global\": \"BAB\", \"Global Ex USA\": \"BAB\"}},\n",
    "            \"MKT\": {\"sheet\": 4, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"MKT\", \"Global\": \"MKT\", \"Global Ex USA\": \"MKT\"}},\n",
    "            \"SMB\": {\"sheet\": 5, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"SMB\", \"Global\": \"SMB\", \"Global Ex USA\": \"SMB\"}},\n",
    "            \"HML-FF\": {\"sheet\": 6, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-FF\", \"Global\": \"HML-FF\", \"Global Ex USA\": \"HML-FF\"}},\n",
    "            \"HML-D\": {\"sheet\": 7, \"header\": 18, \"paper\": \"The Devil's in HML's Details\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-D\", \"Global\": \"HML-D\", \"Global Ex USA\": \"HML-D\"}},\n",
    "            \"UMD\": {\"sheet\": 8, \"header\": 18, \"paper\": \"On Persistence in Mutual Fund Performance\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"UMD\", \"Global\": \"UMD\", \"Global Ex USA\": \"UMD\"}},\n",
    "            \"ME\": {\"sheet\": 9, \"header\": 18, \"paper\": \"AQR Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"ME\", \"Global\": \"ME\", \"Global Ex USA\": \"ME\"}},\n",
    "            \"RF\": {\"sheet\": 10, \"header\": 18, \"paper\": None, \"columns\": {\"DATE\": \"DATE\", \"Risk Free Rate\": \"RF\"}}\n",
    "        }\n",
    "    },\n",
    "    \"TSMOM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 17,\n",
    "        \"paper\": \"Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)\",\n",
    "        \"columns\": {\n",
    "            \"Unnamed: 0\": \"DATE\",\n",
    "            \"TSMOM\": \"TSM-MA\",\n",
    "            \"TSMOM^CM\": \"TSM-Com\",\n",
    "            \"TSMOM^EQ\": \"TSM-EQ\",\n",
    "            \"TSMOM^FI\": \"TSM-FI\",\n",
    "            \"TSMOM^FX\": \"TSM-FX\"\n",
    "        }\n",
    "    },\n",
    "    \"QMJ\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 19,\n",
    "        \"paper\": \"Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)\",\n",
    "        \"columns\": {\n",
    "            \"DATE\": \"DATE\",\n",
    "            \"P1 (low quality)\": \"QMJ-P1-LQ\",\n",
    "            \"P2\": \"QMJ-P2\",\n",
    "            \"P3\": \"QMJ-P3\",\n",
    "            \"P4\": \"QMJ-P4\",\n",
    "            \"P5\": \"QMJ-P5\",\n",
    "            \"P6\": \"QMJ-P6\",\n",
    "            \"P7\": \"QMJ-P7\",\n",
    "            \"P8\": \"QMJ-P8\",\n",
    "            \"P9\": \"QMJ-P9\",\n",
    "            \"P10 (high quality)\": \"QMJ-P10-HQ\",\n",
    "            \"P10-P1\": \"QMJ\"\n",
    "        }\n",
    "    },\n",
    "    \"Century\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 18,\n",
    "        \"paper\": \"Century of Factor Premia Monthly-Ilmanen et al. (2021)\",\n",
    "        \"columns\": {\n",
    "            \"Date\": \"DATE\",\n",
    "            \"US Stock Selection Value\": \"HML-FF-US\", \"US Stock Selection Momentum\": \"UMD-US\", \n",
    "            \"US Stock Selection Defensive\": \"BAB-US\", \"US Stock Selection Multi-style\": \"Multi-style-US\",\n",
    "            \"Intl Stock Selection Value\": \"HML-FF-Intl\", \"Intl Stock Selection Momentum\": \"UMD-Intl\", \n",
    "            \"Intl Stock Selection Defensive\": \"BAB-Intl\", \"Intl Stock Selection Multi-style\": \"Multi-style-Intl\",\n",
    "            \"Equity indices Value\": \"HML-Equity\", \"Equity indices Momentum\": \"UMD-Equity\", \n",
    "            \"Equity indices Carry\": \"Carry-Equity\", \"Equity indices Defensive\": \"BAB-Equity\", \n",
    "            \"Equity indices Multi-style\": \"Multi-style-Equity\",\n",
    "            \"Fixed income Value\": \"HML-FI\", \"Fixed income Momentum\": \"UMD-FI\", \n",
    "            \"Fixed income Carry\": \"Carry-FI\", \"Fixed income Defensive\": \"BAB-FI\", \n",
    "            \"Fixed income Multi-style\": \"Multi-style-FI\",\n",
    "            \"Currencies Value\": \"HML-FX\", \"Currencies Momentum\": \"UMD-FX\", \n",
    "            \"Currencies Carry\": \"Carry-FX\", \"Currencies Multi-style\": \"Multi-style-FX\",\n",
    "            \"Commodities Value\": \"HML-COM\", \"Commodities Momentum\": \"UMD-COM\", \n",
    "            \"Commodities Carry\": \"Carry-COM\", \"Commodities Multi-style\": \"Multi-style-COM\",\n",
    "            \"All Stock Selection Value\": \"HML-All-SS\", \"All Stock Selection Momentum\": \"UMD-All-SS\", \n",
    "            \"All Stock Selection Defensive\": \"BAB-All-SS\", \"All Stock Selection Multi-style\": \"Multi-style All-SS\",\n",
    "            \"All Macro Value\": \"HML-All-Macro\", \"All Macro Momentum\": \"UMD-All-Macro\", \n",
    "            \"All Macro Carry\": \"Carry-All-Macro\", \"All Macro Defensive\": \"BAB-All-Macro\", \n",
    "            \"All Macro Multi-style\": \"Multi-style-All-Macro\",\n",
    "            \"All asset classes Value\": \"HML-All\", \"All asset classes Momentum\": \"UMD-All\", \n",
    "            \"All asset classes Carry\": \"Carry-All\", \"All asset classes Defensive\": \"BAB-All\", \n",
    "            \"All asset classes Multi-style\": \"Multi-style-All\",\n",
    "            \"Equity indices Market\": \"MKT-Equity\", \"Fixed income Market\": \"MKT-FI\", \n",
    "            \"Commodities Market\": \"MKT-COM\", \"All Macro Market\": \"MKT-All-Macro\"\n",
    "        }\n",
    "    },\n",
    "    \"COM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 10,\n",
    "        \"paper\": \"Commodities for the Long Run\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def process_factors(file_config, sheet=0, is_com=False, parent_path=None):\n",
    "    file_path = parent_path if parent_path else file_config['path']\n",
    "    logger.info(f\"Processing {file_path} (sheet {sheet})...\")\n",
    "    try:\n",
    "        # Read Excel with correct header row\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet, header=file_config['header'])\n",
    "        logger.info(f\"Raw columns: {list(df.columns)}\")\n",
    "        \n",
    "        if is_com:\n",
    "            df.columns = [\n",
    "                'date', 'excess_return_eqwt', 'excess_spot_return_eqwt', 'ir_adjusted_carry_eqwt',\n",
    "                'spot_return_eqwt', 'carry_eqwt', 'excess_return_long_short', 'excess_spot_return_long_short',\n",
    "                'ir_adjusted_carry_long_short', 'aggregate_backwardation_contango', \n",
    "                'state_backwardation_contango', 'state_inflation'\n",
    "            ]\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            df['associated_paper'] = file_config['paper']\n",
    "            df = df.dropna(subset=['date'])\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                existing = pd.read_sql(\"SELECT date FROM aqr_cmdty_factors\", connection)\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(existing['date'])\n",
    "            \n",
    "            df['date_str'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_new = df[~df['date_str'].isin(existing_keys)].drop(columns=['date_str'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                df_new.to_sql(\n",
    "                    'aqr_cmdty_factors',\n",
    "                    engine,\n",
    "                    if_exists='append',\n",
    "                    index=False,\n",
    "                    dtype={\n",
    "                        'date': DATE,\n",
    "                        'excess_return_eqwt': DECIMAL(15, 6),\n",
    "                        'excessЗапрос спот_возврат_eqwt': DECIMAL(15, 6),\n",
    "                        'ir_adjusted_carry_eqwt': DECIMAL(15, 6),\n",
    "                        'spot_return_eqwt': DECIMAL(15, 6),\n",
    "                        'carry_eqwt': DECIMAL(15, 6),\n",
    "                        'excess_return_long_short': DECIMAL(15, 6),\n",
    "                        'excess_spot_return_long_short': DECIMAL(15, 6),\n",
    "                        'ir_adjusted_carry_long_short': DECIMAL(15, 6),\n",
    "                        'aggregate_backwardation_contango': DECIMAL(15, 6),\n",
    "                        'state_backwardation_contango': VARCHAR(50),\n",
    "                        'state_inflation': VARCHAR(50),\n",
    "                        'associated_paper': VARCHAR(100)\n",
    "                    }\n",
    "                )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into aqr_cmdty_factors.\")\n",
    "            else:\n",
    "                logger.info(\"No new rows to load into aqr_cmdty_factors.\")\n",
    "        else:\n",
    "            # Identify date column\n",
    "            date_col = next(\n",
    "                (col for col in df.columns if isinstance(col, str) and ('DATE' in col.upper() or 'Date' in col)),\n",
    "                df.columns[0]\n",
    "            )\n",
    "            \n",
    "            # Special handling for Quality Minus Junk due to header mismatch\n",
    "            if 'Quality Minus Junk' in file_path:\n",
    "                expected_cols = list(file_config['columns'].keys())\n",
    "                if not any(col in df.columns for col in expected_cols[1:]):  # Exclude DATE\n",
    "                    logger.warning(\"Expected columns not found in Quality Minus Junk file. Assigning columns manually.\")\n",
    "                    df.columns = [\n",
    "                        'DATE', 'P1 (low quality)', 'P2', 'P3', 'P4', 'P5', \n",
    "                        'P6', 'P7', 'P8', 'P9', 'P10 (high quality)', 'P10-P1'\n",
    "                    ]\n",
    "            \n",
    "            # Filter and rename columns\n",
    "            if 'columns' in file_config:\n",
    "                valid_cols = list(file_config['columns'].keys())\n",
    "                if date_col not in valid_cols:\n",
    "                    valid_cols.append(date_col)\n",
    "                df = df[[col for col in df.columns if col in valid_cols]]\n",
    "                new_columns = []\n",
    "                for col in df.columns:\n",
    "                    if col == date_col:\n",
    "                        new_columns.append('date')\n",
    "                    else:\n",
    "                        new_columns.append(file_config['columns'].get(col, col))\n",
    "                df.columns = new_columns\n",
    "            else:\n",
    "                df = df.rename(columns={date_col: 'date'})\n",
    "            \n",
    "            logger.info(f\"Columns after renaming: {list(df.columns)}\")\n",
    "            \n",
    "            # Parse dates\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            \n",
    "            # Melt the DataFrame\n",
    "            df_long = df.melt(id_vars=['date'], var_name='factor', value_name='value')\n",
    "            df_long = df_long.dropna(subset=['value', 'date'])\n",
    "            \n",
    "            # Assign asset class and region\n",
    "            if 'TSMOM' in file_config['path']:\n",
    "                df_long['asset_class'] = df_long['factor'].map({\n",
    "                    \"TSM-MA\": \"Multi-Asset\",\n",
    "                    \"TSM-Com\": \"Commodities\",\n",
    "                    \"TSM-EQ\": \"Equity\",\n",
    "                    \"TSM-FI\": \"Fixed Income\",\n",
    "                    \"TSM-FX\": \"Currencies\"\n",
    "                })\n",
    "                df_long['region'] = \"Global\"\n",
    "            elif 'Quality Minus Junk' in file_config['path']:\n",
    "                df_long['asset_class'] = \"Equity\"\n",
    "                df_long['region'] = df_long['date'].apply(\n",
    "                    lambda x: \"USA\" if x < pd.Timestamp(\"1989-07-31\") else \"Global\"\n",
    "                )\n",
    "            elif 'Century' in file_config['path']:\n",
    "                df_long['asset_class'] = df_long['factor'].str.extract(\n",
    "                    '(Stock Selection|Equity indices|Fixed income|Currencies|Commodities|All Macro|All asset classes)'\n",
    "                )[0]\n",
    "                df_long['region'] = df_long['factor'].apply(\n",
    "                    lambda x: 'US' if 'US' in x else 'Intl' if 'Intl' in x else 'Global'\n",
    "                )\n",
    "            else:  # BAB_multi\n",
    "                df_long['asset_class'] = \"Equity\" if 'Risk Free Rate' not in file_config.get('columns', {}).values() else \"Fixed Income\"\n",
    "                region_map = {}\n",
    "                for col, new_name in file_config.get('columns', {}).items():\n",
    "                    if col == 'DATE':\n",
    "                        continue\n",
    "                    if col == 'USA':\n",
    "                        region_map[new_name] = 'USA'\n",
    "                    elif col == 'Global':\n",
    "                        region_map[new_name] = 'Global'\n",
    "                    elif col == 'Global Ex USA':\n",
    "                        region_map[new_name] = 'Intl'\n",
    "                    else:\n",
    "                        region_map[new_name] = 'Intl'\n",
    "                region_map['RF'] = 'USA'\n",
    "                df_long['region'] = df_long['factor'].map(region_map)\n",
    "            \n",
    "            df_long['associated_paper'] = file_config['paper']\n",
    "            df_long = df_long[['factor', 'date', 'associated_paper', 'asset_class', 'value', 'region']]\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                existing = pd.read_sql(\n",
    "                    \"SELECT factor, date, associated_paper, asset_class FROM factor_returns\",\n",
    "                    connection\n",
    "                )\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(tuple(row) for row in existing[['factor', 'date', 'associated_paper', 'asset_class']].values)\n",
    "            \n",
    "            df_long['date_str'] = df_long['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_long['key'] = df_long.apply(\n",
    "                lambda row: (\n",
    "                    row['factor'],\n",
    "                    row['date_str'],\n",
    "                    row['associated_paper'] if row['associated_paper'] else 'None',\n",
    "                    row['asset_class'] if row['asset_class'] else 'None'\n",
    "                ), axis=1\n",
    "            )\n",
    "            df_new = df_long[~df_long['key'].isin(existing_keys)].drop(columns=['date_str', 'key'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                df_new.to_sql(\n",
    "                    'factor_returns',\n",
    "                    engine,\n",
    "                    if_exists='append',\n",
    "                    index=False,\n",
    "                    dtype={\n",
    "                        'factor': VARCHAR(50),\n",
    "                        'date': DATE,\n",
    "                        'associated_paper': VARCHAR(100),\n",
    "                        'asset_class': VARCHAR(50),\n",
    "                        'value': DECIMAL(15, 6),\n",
    "                        'region': VARCHAR(50)\n",
    "                    }\n",
    "                )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into factor_returns from {file_path} (sheet {sheet}).\")\n",
    "            else:\n",
    "                logger.info(f\"No new rows to load into factor_returns from {file_path} (sheet {sheet}).\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing {file_path} (sheet {sheet}): {str(e)}\")\n",
    "\n",
    "# Process all datasets\n",
    "for key, config in data_files.items():\n",
    "    if key == \"BAB_multi\":\n",
    "        for subkey, subconfig in config['sheets'].items():\n",
    "            process_factors(subconfig, sheet=subconfig['sheet'], parent_path=config['path'])\n",
    "    elif key == \"COM\":\n",
    "        process_factors(config, sheet=config['sheet'], is_com=True)\n",
    "    else:\n",
    "        process_factors(config, sheet=config['sheet'])\n",
    "\n",
    "logger.info(\"All data processing complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee867f2c-361e-4746-b90b-56e75fa4b4cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 17:33:07,210 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:33:08,533 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:33:08,536 - INFO - Columns after renaming: ['date', 'BAB', 'BAB', 'BAB']\n",
      "2025-04-10 17:33:08,547 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 0): 'path'\n",
      "2025-04-10 17:33:08,549 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 4)...\n",
      "2025-04-10 17:33:09,167 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:33:09,169 - INFO - Columns after renaming: ['date', 'MKT', 'MKT', 'MKT']\n",
      "2025-04-10 17:33:09,181 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 4): 'path'\n",
      "2025-04-10 17:33:09,183 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 5)...\n",
      "2025-04-10 17:33:09,914 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:33:09,917 - INFO - Columns after renaming: ['date', 'SMB', 'SMB', 'SMB']\n",
      "2025-04-10 17:33:09,929 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 5): 'path'\n",
      "2025-04-10 17:33:09,930 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 6)...\n",
      "2025-04-10 17:33:10,465 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:33:10,468 - INFO - Columns after renaming: ['date', 'HML-FF', 'HML-FF', 'HML-FF']\n",
      "2025-04-10 17:33:10,476 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 6): 'path'\n",
      "2025-04-10 17:33:10,477 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 7)...\n",
      "2025-04-10 17:33:11,024 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:33:11,026 - INFO - Columns after renaming: ['date', 'HML-D', 'HML-D', 'HML-D']\n",
      "2025-04-10 17:33:11,036 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 7): 'path'\n",
      "2025-04-10 17:33:11,037 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 8)...\n",
      "2025-04-10 17:33:11,691 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:33:11,694 - INFO - Columns after renaming: ['date', 'UMD', 'UMD', 'UMD']\n",
      "2025-04-10 17:33:11,705 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 8): 'path'\n",
      "2025-04-10 17:33:11,712 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 9)...\n",
      "2025-04-10 17:33:12,154 - INFO - Raw columns: ['DATE', 'AUT', 'HKG', 'ESP', 'GBR', 'ITA', 'DEU', 'DNK', 'NZL', 'NLD', 'USA', 'PRT', 'BEL', 'ISR', 'GRC', 'NOR', 'SGP', 'CHE', 'IRL', 'CAN', 'FIN', 'JPN', 'SWE', 'FRA', 'AUS', 'Global Ex USA', 'Global', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:33:12,155 - INFO - Columns after renaming: ['date', 'ME', 'ME', 'ME']\n",
      "2025-04-10 17:33:12,169 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 9): 'path'\n",
      "2025-04-10 17:33:12,171 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 10)...\n",
      "2025-04-10 17:33:12,751 - INFO - Raw columns: ['DATE', 'Risk Free Rate']\n",
      "2025-04-10 17:33:12,753 - INFO - Columns after renaming: ['date', 'RF']\n",
      "2025-04-10 17:33:12,765 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 10): 'path'\n",
      "2025-04-10 17:33:12,766 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:33:13,048 - INFO - Raw columns: ['Unnamed: 0', 'TSMOM', 'TSMOM^CM', 'TSMOM^EQ', 'TSMOM^FI', 'TSMOM^FX']\n",
      "2025-04-10 17:33:13,051 - INFO - Columns after renaming: ['date', 'TSM-MA', 'TSM-Com', 'TSM-EQ', 'TSM-FI', 'TSM-FX']\n",
      "2025-04-10 17:33:13,779 - INFO - No new rows to load into factor_returns from C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet 0).\n",
      "2025-04-10 17:33:13,805 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:33:14,323 - INFO - Raw columns: ['DATE', 'P1 (low quality)', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10 (high quality)', 'P10-P1', 'P1 (low quality).1', 'P2.1', 'P3.1', 'P4.1', 'P5.1', 'P6.1', 'P7.1', 'P8.1', 'P9.1', 'P10 (high quality).1', 'P10-P1.1']\n",
      "2025-04-10 17:33:14,326 - INFO - Columns after renaming: ['date', 'QMJ-P1-LQ', 'QMJ-P2', 'QMJ-P3', 'QMJ-P4', 'QMJ-P5', 'QMJ-P6', 'QMJ-P7', 'QMJ-P8', 'QMJ-P9', 'QMJ-P10-HQ', 'QMJ']\n",
      "2025-04-10 17:33:18,635 - INFO - Loaded 8899 new rows into factor_returns from C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 0).\n",
      "2025-04-10 17:33:18,651 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx (sheet 0)...\n",
      "2025-04-10 17:33:19,302 - INFO - Raw columns: ['Date', 'US Stock Selection Value', 'US Stock Selection Momentum', 'US Stock Selection Defensive', 'US Stock Selection Multi-style', 'Intl Stock Selection Value', 'Intl Stock Selection Momentum', 'Intl Stock Selection Defensive', 'Intl Stock Selection Multi-style', 'Equity indices Value', 'Equity indices Momentum', 'Equity indices Carry', 'Equity indices Defensive', 'Equity indices Multi-style', 'Fixed income Value', 'Fixed income Momentum', 'Fixed income Carry', 'Fixed income Defensive', 'Fixed income Multi-style', 'Currencies Value', 'Currencies Momentum', 'Currencies Carry', 'Currencies Multi-style', 'Commodities Value', 'Commodities Momentum', 'Commodities Carry', 'Commodities Multi-style', 'All Stock Selection Value', 'All Stock Selection Momentum', 'All Stock Selection Defensive', 'All Stock Selection Multi-style', 'All Macro Value', 'All Macro Momentum', 'All Macro Carry', 'All Macro Defensive', 'All Macro Multi-style', 'All asset classes Value', 'All asset classes Momentum', 'All asset classes Carry', 'All asset classes Defensive', 'All asset classes Multi-style', 'Equity indices Market', 'Fixed income Market', 'Commodities Market', 'All Macro Market']\n",
      "2025-04-10 17:33:19,304 - INFO - Columns after renaming: ['date', 'HML-FF-US', 'UMD-US', 'BAB-US', 'Multi-style-US', 'HML-FF-Intl', 'UMD-Intl', 'BAB-Intl', 'Multi-style-Intl', 'HML-Equity', 'UMD-Equity', 'Carry-Equity', 'BAB-Equity', 'Multi-style-Equity', 'HML-FI', 'UMD-FI', 'Carry-FI', 'BAB-FI', 'Multi-style-FI', 'HML-FX', 'UMD-FX', 'Carry-FX', 'Multi-style-FX', 'HML-COM', 'UMD-COM', 'Carry-COM', 'Multi-style-COM', 'HML-All-SS', 'UMD-All-SS', 'BAB-All-SS', 'Multi-style-All-SS', 'HML-All-Macro', 'UMD-All-Macro', 'Carry-All-Macro', 'BAB-All-Macro', 'Multi-style-All-Macro', 'HML-All', 'UMD-All', 'Carry-All', 'BAB-All', 'Multi-style-All', 'MKT-Equity', 'MKT-FI', 'MKT-COM', 'MKT-All-Macro']\n",
      "2025-04-10 17:33:21,863 - ERROR - Error processing C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx (sheet 0): (pyodbc.IntegrityError) ('23000', \"[23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Violation of PRIMARY KEY constraint 'PK__factor_r__C3CBC7054E79A6D5'. Cannot insert duplicate key in object 'dbo.factor_returns'. The duplicate key value is (HML-FF-US, 1926-07-30, Century of Factor Premia Monthly-Ilmanen et al. (2021)). (2627) (SQLExecDirectW); [23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]The statement has been terminated. (3621)\")\n",
      "[SQL: INSERT INTO factor_returns (factor, date, associated_paper, asset_class, value, region) VALUES (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ... 6723 characters truncated ... , (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?)]\n",
      "[parameters: ('HML-FF-US', datetime.datetime(1926, 7, 30, 0, 0), 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', None, -0.0198557509772, 'US', 'HML-FF-US', datetime.datetime(1926, 8, 31, 0, 0), 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', None, 0.0523514868609, 'US', 'HML-FF-US', datetime.datetime(1926, 9, 30, 0, 0), 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', None, -0.0233491305501, 'US', 'HML-FF-US', datetime.datetime(1926, 10, 29, 0, 0), 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', None, 0.00825290745545, 'US', 'HML-FF-US', datetime.datetime(1926, 11, 30, 0, 0), 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', None, 0.00202531611231, 'US', 'HML-FF-US', datetime.datetime(1926, 12, 31, 0, 0), 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', None, 0.0218206425858, 'US', 'HML-FF-US', datetime.datetime(1927, 1, 31, 0, 0), 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', None, 0.0404056052839, 'US', 'HML-FF-US', datetime.datetime(1927, 2, 28, 0, 0), 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', None, 0.0243950756231, 'US', 'HML-FF-US', datetime.datetime(1927, 3, 31, 0, 0) ... 1994 parameters truncated ... 0.0132496578724, 'US', 'HML-FF-US', datetime.datetime(1954, 12, 31, 0, 0), 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', None, 0.049878087231, 'US', 'HML-FF-US', datetime.datetime(1955, 1, 31, 0, 0), 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', None, 0.0120630159573, 'US', 'HML-FF-US', datetime.datetime(1955, 2, 28, 0, 0), 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', None, -0.00362549395881, 'US', 'HML-FF-US', datetime.datetime(1955, 3, 31, 0, 0), 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', None, 0.00458426345341, 'US', 'HML-FF-US', datetime.datetime(1955, 4, 29, 0, 0), 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', None, -8.04120203348e-05, 'US', 'HML-FF-US', datetime.datetime(1955, 5, 31, 0, 0), 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', None, -0.0129862609517, 'US', 'HML-FF-US', datetime.datetime(1955, 6, 30, 0, 0), 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', None, -0.00613422319856, 'US', 'HML-FF-US', datetime.datetime(1955, 7, 29, 0, 0), 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', None, -0.000182027880921, 'US')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-04-10 17:33:21,864 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:33:22,339 - INFO - Raw columns: ['Unnamed: 0', 'Excess return of equal-weight commodities portfolio', 'Excess spot return of equal-weight commodities portfolio', 'Interest rate adjusted carry of equal-weight commodities portfolio', 'Spot return of equal-weight commodities portfolio', 'Carry of equal-weight commodities portfolio', 'Excess return of long/short commodities portfolio', 'Excess spot return of long/short commodities portfolio', 'Interest rate adjusted carry of long/short commodities portfolio', 'Aggregate backwardation/contango', 'State of backwardation/contango', 'State of inflation']\n",
      "2025-04-10 17:33:22,373 - INFO - No new rows to load into aqr_cmdty_factors.\n",
      "2025-04-10 17:33:22,375 - INFO - All data processing complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import VARCHAR, DATE, DECIMAL\n",
    "from sqlalchemy.sql import text\n",
    "import logging\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(), logging.FileHandler('load_aqr_data.log')]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Database connection\n",
    "engine = create_engine(\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/CWA_Fund_Database\"\n",
    "    \"?driver=ODBC+Driver+18+for+SQL+Server&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "# File configurations\n",
    "data_files = {\n",
    "    \"BAB_multi\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx\",\n",
    "        \"sheets\": {\n",
    "            \"BAB\": {\"sheet\": 0, \"header\": 18, \"paper\": \"Betting Against Beta (Frazzini and Pedersen, 2014)\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"BAB\", \"Global\": \"BAB\", \"Global Ex USA\": \"BAB\"}},\n",
    "            \"MKT\": {\"sheet\": 4, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"MKT\", \"Global\": \"MKT\", \"Global Ex USA\": \"MKT\"}},\n",
    "            \"SMB\": {\"sheet\": 5, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"SMB\", \"Global\": \"SMB\", \"Global Ex USA\": \"SMB\"}},\n",
    "            \"HML-FF\": {\"sheet\": 6, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-FF\", \"Global\": \"HML-FF\", \"Global Ex USA\": \"HML-FF\"}},\n",
    "            \"HML-D\": {\"sheet\": 7, \"header\": 18, \"paper\": \"The Devil's in HML's Details\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-D\", \"Global\": \"HML-D\", \"Global Ex USA\": \"HML-D\"}},\n",
    "            \"UMD\": {\"sheet\": 8, \"header\": 18, \"paper\": \"On Persistence in Mutual Fund Performance\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"UMD\", \"Global\": \"UMD\", \"Global Ex USA\": \"UMD\"}},\n",
    "            \"ME\": {\"sheet\": 9, \"header\": 18, \"paper\": \"AQR Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"ME\", \"Global\": \"ME\", \"Global Ex USA\": \"ME\"}},\n",
    "            \"RF\": {\"sheet\": 10, \"header\": 18, \"paper\": None, \"columns\": {\"DATE\": \"DATE\", \"Risk Free Rate\": \"RF\"}}\n",
    "        }\n",
    "    },\n",
    "    \"TSMOM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 17,\n",
    "        \"paper\": \"Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)\",\n",
    "        \"columns\": {\n",
    "            \"Unnamed: 0\": \"DATE\",\n",
    "            \"TSMOM\": \"TSM-MA\",\n",
    "            \"TSMOM^CM\": \"TSM-Com\",\n",
    "            \"TSMOM^EQ\": \"TSM-EQ\",\n",
    "            \"TSMOM^FI\": \"TSM-FI\",\n",
    "            \"TSMOM^FX\": \"TSM-FX\"\n",
    "        }\n",
    "    },\n",
    "    \"QMJ\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 18,\n",
    "        \"paper\": \"Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)\",\n",
    "        \"columns\": {\n",
    "            \"DATE\": \"DATE\",\n",
    "            \"P1 (low quality)\": \"QMJ-P1-LQ\",\n",
    "            \"P2\": \"QMJ-P2\",\n",
    "            \"P3\": \"QMJ-P3\",\n",
    "            \"P4\": \"QMJ-P4\",\n",
    "            \"P5\": \"QMJ-P5\",\n",
    "            \"P6\": \"QMJ-P6\",\n",
    "            \"P7\": \"QMJ-P7\",\n",
    "            \"P8\": \"QMJ-P8\",\n",
    "            \"P9\": \"QMJ-P9\",\n",
    "            \"P10 (high quality)\": \"QMJ-P10-HQ\",\n",
    "            \"P10-P1\": \"QMJ\"\n",
    "        }\n",
    "    },\n",
    "    \"Century\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 18,\n",
    "        \"paper\": \"Century of Factor Premia Monthly-Ilmanen et al. (2021)\",\n",
    "        \"columns\": {\n",
    "            \"Date\": \"DATE\",\n",
    "            \"US Stock Selection Value\": \"HML-FF-US\", \"US Stock Selection Momentum\": \"UMD-US\", \n",
    "            \"US Stock Selection Defensive\": \"BAB-US\", \"US Stock Selection Multi-style\": \"Multi-style-US\",\n",
    "            \"Intl Stock Selection Value\": \"HML-FF-Intl\", \"Intl Stock Selection Momentum\": \"UMD-Intl\", \n",
    "            \"Intl Stock Selection Defensive\": \"BAB-Intl\", \"Intl Stock Selection Multi-style\": \"Multi-style-Intl\",\n",
    "            \"Equity indices Value\": \"HML-Equity\", \"Equity indices Momentum\": \"UMD-Equity\", \n",
    "            \"Equity indices Carry\": \"Carry-Equity\", \"Equity indices Defensive\": \"BAB-Equity\", \n",
    "            \"Equity indices Multi-style\": \"Multi-style-Equity\",\n",
    "            \"Fixed income Value\": \"HML-FI\", \"Fixed income Momentum\": \"UMD-FI\", \n",
    "            \"Fixed income Carry\": \"Carry-FI\", \"Fixed income Defensive\": \"BAB-FI\", \n",
    "            \"Fixed income Multi-style\": \"Multi-style-FI\",\n",
    "            \"Currencies Value\": \"HML-FX\", \"Currencies Momentum\": \"UMD-FX\", \n",
    "            \"Currencies Carry\": \"Carry-FX\", \"Currencies Multi-style\": \"Multi-style-FX\",\n",
    "            \"Commodities Value\": \"HML-COM\", \"Commodities Momentum\": \"UMD-COM\", \n",
    "            \"Commodities Carry\": \"Carry-COM\", \"Commodities Multi-style\": \"Multi-style-COM\",\n",
    "            \"All Stock Selection Value\": \"HML-All-SS\", \"All Stock Selection Momentum\": \"UMD-All-SS\", \n",
    "            \"All Stock Selection Defensive\": \"BAB-All-SS\", \"All Stock Selection Multi-style\": \"Multi-style-All-SS\",\n",
    "            \"All Macro Value\": \"HML-All-Macro\", \"All Macro Momentum\": \"UMD-All-Macro\", \n",
    "            \"All Macro Carry\": \"Carry-All-Macro\", \"All Macro Defensive\": \"BAB-All-Macro\", \n",
    "            \"All Macro Multi-style\": \"Multi-style-All-Macro\",\n",
    "            \"All asset classes Value\": \"HML-All\", \"All asset classes Momentum\": \"UMD-All\", \n",
    "            \"All asset classes Carry\": \"Carry-All\", \"All asset classes Defensive\": \"BAB-All\", \n",
    "            \"All asset classes Multi-style\": \"Multi-style-All\",\n",
    "            \"Equity indices Market\": \"MKT-Equity\", \"Fixed income Market\": \"MKT-FI\", \n",
    "            \"Commodities Market\": \"MKT-COM\", \"All Macro Market\": \"MKT-All-Macro\"\n",
    "        }\n",
    "    },\n",
    "    \"COM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 10,\n",
    "        \"paper\": \"Commodities for the Long Run\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def process_factors(file_config, sheet=0, is_com=False, parent_path=None):\n",
    "    file_path = parent_path if parent_path else file_config['path']\n",
    "    logger.info(f\"Processing {file_path} (sheet {sheet})...\")\n",
    "    try:\n",
    "        # Read Excel with correct header row\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet, header=file_config['header'])\n",
    "        logger.info(f\"Raw columns: {list(df.columns)}\")\n",
    "        \n",
    "        if is_com:\n",
    "            df.columns = [\n",
    "                'date', 'excess_return_eqwt', 'excess_spot_return_eqwt', 'ir_adjusted_carry_eqwt',\n",
    "                'spot_return_eqwt', 'carry_eqwt', 'excess_return_long_short', 'excess_spot_return_long_short',\n",
    "                'ir_adjusted_carry_long_short', 'aggregate_backwardation_contango', \n",
    "                'state_backwardation_contango', 'state_inflation'\n",
    "            ]\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            df['associated_paper'] = file_config['paper']\n",
    "            df = df.dropna(subset=['date'])\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                existing = pd.read_sql(\"SELECT date FROM aqr_cmdty_factors\", connection)\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(existing['date'])\n",
    "            \n",
    "            df['date_str'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_new = df[~df['date_str'].isin(existing_keys)].drop(columns=['date_str'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                df_new.to_sql(\n",
    "                    'aqr_cmdty_factors',\n",
    "                    engine,\n",
    "                    if_exists='append',\n",
    "                    index=False,\n",
    "                    dtype={\n",
    "                        'date': DATE,\n",
    "                        'excess_return_eqwt': DECIMAL(15, 6),\n",
    "                        'excess_spot_return_eqwt': DECIMAL(15, 6),\n",
    "                        'ir_adjusted_carry_eqwt': DECIMAL(15, 6),\n",
    "                        'spot_return_eqwt': DECIMAL(15, 6),\n",
    "                        'carry_eqwt': DECIMAL(15, 6),\n",
    "                        'excess_return_long_short': DECIMAL(15, 6),\n",
    "                        'excess_spot_return_long_short': DECIMAL(15, 6),\n",
    "                        'ir_adjusted_carry_long_short': DECIMAL(15, 6),\n",
    "                        'aggregate_backwardation_contango': DECIMAL(15, 6),\n",
    "                        'state_backwardation_contango': VARCHAR(50),\n",
    "                        'state_inflation': VARCHAR(50),\n",
    "                        'associated_paper': VARCHAR(100)\n",
    "                    }\n",
    "                )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into aqr_cmdty_factors.\")\n",
    "            else:\n",
    "                logger.info(\"No new rows to load into aqr_cmdty_factors.\")\n",
    "        else:\n",
    "            # Identify date column\n",
    "            date_col = next(\n",
    "                (col for col in df.columns if isinstance(col, str) and ('DATE' in col.upper() or 'Date' in col)),\n",
    "                df.columns[0]\n",
    "            )\n",
    "            \n",
    "            # Filter and rename columns\n",
    "            if 'columns' in file_config:\n",
    "                valid_cols = list(file_config['columns'].keys())\n",
    "                if date_col not in valid_cols:\n",
    "                    valid_cols.append(date_col)\n",
    "                df = df[[col for col in df.columns if col in valid_cols]]\n",
    "                new_columns = []\n",
    "                for col in df.columns:\n",
    "                    if col == date_col:\n",
    "                        new_columns.append('date')\n",
    "                    else:\n",
    "                        new_columns.append(file_config['columns'].get(col, col))\n",
    "                df.columns = new_columns\n",
    "            else:\n",
    "                df = df.rename(columns={date_col: 'date'})\n",
    "            \n",
    "            logger.info(f\"Columns after renaming: {list(df.columns)}\")\n",
    "            \n",
    "            # Parse dates\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            \n",
    "            # Melt the DataFrame\n",
    "            df_long = df.melt(id_vars=['date'], var_name='factor', value_name='value')\n",
    "            df_long = df_long.dropna(subset=['value', 'date'])\n",
    "            \n",
    "            # Assign asset class and region\n",
    "            if 'TSMOM' in file_config['path']:\n",
    "                df_long['asset_class'] = df_long['factor'].map({\n",
    "                    \"TSM-MA\": \"Multi-Asset\",\n",
    "                    \"TSM-Com\": \"Commodities\",\n",
    "                    \"TSM-EQ\": \"Equity\",\n",
    "                    \"TSM-FI\": \"Fixed Income\",\n",
    "                    \"TSM-FX\": \"Currencies\"\n",
    "                })\n",
    "                df_long['region'] = \"Global\"\n",
    "            elif 'Quality Minus Junk' in file_config['path']:\n",
    "                df_long['asset_class'] = \"Equity\"\n",
    "                df_long['region'] = df_long['date'].apply(\n",
    "                    lambda x: \"USA\" if x < pd.Timestamp(\"1989-07-31\") else \"Global\"\n",
    "                )\n",
    "            elif 'Century' in file_config['path']:\n",
    "                df_long['asset_class'] = df_long['factor'].str.extract(\n",
    "                    '(Stock Selection|Equity indices|Fixed income|Currencies|Commodities|All Macro|All asset classes)'\n",
    "                )\n",
    "                df_long['region'] = df_long['factor'].apply(\n",
    "                    lambda x: 'US' if 'US' in x else 'Intl' if 'Intl' in x else 'Global'\n",
    "                )\n",
    "            else:  # BAB_multi\n",
    "                df_long['asset_class'] = \"Equity\" if 'Risk Free Rate' not in file_config['columns'].values() else \"Fixed Income\"\n",
    "                region_map = {}\n",
    "                for col, factor in file_config['columns'].items():\n",
    "                    if col == 'DATE':\n",
    "                        continue\n",
    "                    if col == 'USA':\n",
    "                        region_map[factor] = 'USA'\n",
    "                    elif col == 'Global':\n",
    "                        region_map[factor] = 'Global'\n",
    "                    elif col == 'Global Ex USA':\n",
    "                        region_map[factor] = 'Intl'\n",
    "                region_map['RF'] = 'USA'\n",
    "                df_long['region'] = df_long['factor'].map(region_map)\n",
    "            \n",
    "            df_long['associated_paper'] = file_config['paper']\n",
    "            df_long = df_long[['factor', 'date', 'associated_paper', 'asset_class', 'value', 'region']]\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                existing = pd.read_sql(\n",
    "                    \"SELECT factor, date, associated_paper, asset_class FROM factor_returns\",\n",
    "                    connection\n",
    "                )\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(tuple(row) for row in existing[['factor', 'date', 'associated_paper', 'asset_class']].values)\n",
    "            \n",
    "            df_long['date_str'] = df_long['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_long['key'] = df_long.apply(\n",
    "                lambda row: (row['factor'], row['date_str'], row['associated_paper'] if row['associated_paper'] else 'None', row['asset_class']), axis=1\n",
    "            )\n",
    "            df_new = df_long[~df_long['key'].isin(existing_keys)].drop(columns=['date_str', 'key'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                df_new.to_sql(\n",
    "                    'factor_returns',\n",
    "                    engine,\n",
    "                    if_exists='append',\n",
    "                    index=False,\n",
    "                    dtype={\n",
    "                        'factor': VARCHAR(50),\n",
    "                        'date': DATE,\n",
    "                        'associated_paper': VARCHAR(100),\n",
    "                        'asset_class': VARCHAR(50),\n",
    "                        'value': DECIMAL(15, 6),\n",
    "                        'region': VARCHAR(50)\n",
    "                    }\n",
    "                )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into factor_returns from {file_path} (sheet {sheet}).\")\n",
    "            else:\n",
    "                logger.info(f\"No new rows to load into factor_returns from {file_path} (sheet {sheet}).\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing {file_path} (sheet {sheet}): {str(e)}\")\n",
    "\n",
    "# Process all datasets\n",
    "for key, config in data_files.items():\n",
    "    if key == \"BAB_multi\":\n",
    "        for subkey, subconfig in config['sheets'].items():\n",
    "            process_factors(subconfig, sheet=subconfig['sheet'], parent_path=config['path'])\n",
    "    elif key == \"COM\":\n",
    "        process_factors(config, sheet=config['sheet'], is_com=True)\n",
    "    else:\n",
    "        process_factors(config, sheet=config['sheet'])\n",
    "\n",
    "logger.info(\"All data processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bea917a-0553-4b7d-bf4b-a64b373bdf14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 17:35:29,053 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:35:30,378 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:35:30,380 - INFO - Columns after renaming: ['date', 'BAB', 'BAB', 'BAB']\n",
      "2025-04-10 17:35:30,392 - INFO - Rows after melting: 2039\n",
      "2025-04-10 17:35:30,394 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 0): 'path'\n",
      "2025-04-10 17:35:30,395 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 4)...\n",
      "2025-04-10 17:35:30,968 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:35:30,971 - INFO - Columns after renaming: ['date', 'MKT', 'MKT', 'MKT']\n",
      "2025-04-10 17:35:30,982 - INFO - Rows after melting: 2166\n",
      "2025-04-10 17:35:30,983 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 4): 'path'\n",
      "2025-04-10 17:35:30,984 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 5)...\n",
      "2025-04-10 17:35:31,523 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:35:31,527 - INFO - Columns after renaming: ['date', 'SMB', 'SMB', 'SMB']\n",
      "2025-04-10 17:35:31,543 - INFO - Rows after melting: 2151\n",
      "2025-04-10 17:35:31,544 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 5): 'path'\n",
      "2025-04-10 17:35:31,545 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 6)...\n",
      "2025-04-10 17:35:32,150 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:35:32,152 - INFO - Columns after renaming: ['date', 'HML-FF', 'HML-FF', 'HML-FF']\n",
      "2025-04-10 17:35:32,166 - INFO - Rows after melting: 2151\n",
      "2025-04-10 17:35:32,168 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 6): 'path'\n",
      "2025-04-10 17:35:32,169 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 7)...\n",
      "2025-04-10 17:35:32,755 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:35:32,757 - INFO - Columns after renaming: ['date', 'HML-D', 'HML-D', 'HML-D']\n",
      "2025-04-10 17:35:32,768 - INFO - Rows after melting: 2154\n",
      "2025-04-10 17:35:32,769 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 7): 'path'\n",
      "2025-04-10 17:35:32,769 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 8)...\n",
      "2025-04-10 17:35:33,534 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:35:33,537 - INFO - Columns after renaming: ['date', 'UMD', 'UMD', 'UMD']\n",
      "2025-04-10 17:35:33,546 - INFO - Rows after melting: 2136\n",
      "2025-04-10 17:35:33,548 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 8): 'path'\n",
      "2025-04-10 17:35:33,549 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 9)...\n",
      "2025-04-10 17:35:33,987 - INFO - Raw columns: ['DATE', 'AUT', 'HKG', 'ESP', 'GBR', 'ITA', 'DEU', 'DNK', 'NZL', 'NLD', 'USA', 'PRT', 'BEL', 'ISR', 'GRC', 'NOR', 'SGP', 'CHE', 'IRL', 'CAN', 'FIN', 'JPN', 'SWE', 'FRA', 'AUS', 'Global Ex USA', 'Global', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:35:33,989 - INFO - Columns after renaming: ['date', 'ME', 'ME', 'ME']\n",
      "2025-04-10 17:35:33,999 - INFO - Rows after melting: 2210\n",
      "2025-04-10 17:35:34,000 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 9): 'path'\n",
      "2025-04-10 17:35:34,001 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 10)...\n",
      "2025-04-10 17:35:34,471 - INFO - Raw columns: ['DATE', 'Risk Free Rate']\n",
      "2025-04-10 17:35:34,473 - INFO - Columns after renaming: ['date', 'RF']\n",
      "2025-04-10 17:35:34,481 - INFO - Rows after melting: 1183\n",
      "2025-04-10 17:35:34,482 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 10): 'path'\n",
      "2025-04-10 17:35:34,483 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:35:34,657 - INFO - Raw columns: ['Unnamed: 0', 'TSMOM', 'TSMOM^CM', 'TSMOM^EQ', 'TSMOM^FI', 'TSMOM^FX']\n",
      "2025-04-10 17:35:34,659 - INFO - Columns after renaming: ['date', 'TSM-MA', 'TSM-Com', 'TSM-EQ', 'TSM-FI', 'TSM-FX']\n",
      "2025-04-10 17:35:34,663 - INFO - Rows after melting: 2405\n",
      "2025-04-10 17:35:35,996 - INFO - Loaded 2405 new rows into factor_returns from C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet 0).\n",
      "2025-04-10 17:35:35,997 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:35:36,338 - INFO - Raw columns: ['DATE', 'P1 (low quality)', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10 (high quality)', 'P10-P1', 'P1 (low quality).1', 'P2.1', 'P3.1', 'P4.1', 'P5.1', 'P6.1', 'P7.1', 'P8.1', 'P9.1', 'P10 (high quality).1', 'P10-P1.1']\n",
      "2025-04-10 17:35:36,339 - INFO - Columns after renaming: ['date', 'QMJ-P1-LQ', 'QMJ-P2', 'QMJ-P3', 'QMJ-P4', 'QMJ-P5', 'QMJ-P6', 'QMJ-P7', 'QMJ-P8', 'QMJ-P9', 'QMJ-P10-HQ', 'QMJ']\n",
      "2025-04-10 17:35:36,348 - INFO - Rows after melting: 8899\n",
      "2025-04-10 17:35:39,211 - INFO - Loaded 8899 new rows into factor_returns from C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 0).\n",
      "2025-04-10 17:35:39,212 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx (sheet 0)...\n",
      "2025-04-10 17:35:39,853 - INFO - Raw columns: ['Date', 'US Stock Selection Value', 'US Stock Selection Momentum', 'US Stock Selection Defensive', 'US Stock Selection Multi-style', 'Intl Stock Selection Value', 'Intl Stock Selection Momentum', 'Intl Stock Selection Defensive', 'Intl Stock Selection Multi-style', 'Equity indices Value', 'Equity indices Momentum', 'Equity indices Carry', 'Equity indices Defensive', 'Equity indices Multi-style', 'Fixed income Value', 'Fixed income Momentum', 'Fixed income Carry', 'Fixed income Defensive', 'Fixed income Multi-style', 'Currencies Value', 'Currencies Momentum', 'Currencies Carry', 'Currencies Multi-style', 'Commodities Value', 'Commodities Momentum', 'Commodities Carry', 'Commodities Multi-style', 'All Stock Selection Value', 'All Stock Selection Momentum', 'All Stock Selection Defensive', 'All Stock Selection Multi-style', 'All Macro Value', 'All Macro Momentum', 'All Macro Carry', 'All Macro Defensive', 'All Macro Multi-style', 'All asset classes Value', 'All asset classes Momentum', 'All asset classes Carry', 'All asset classes Defensive', 'All asset classes Multi-style', 'Equity indices Market', 'Fixed income Market', 'Commodities Market', 'All Macro Market']\n",
      "2025-04-10 17:35:39,855 - INFO - Columns after renaming: ['date', 'HML-FF-US', 'UMD-US', 'BAB-US', 'Multi-style-US', 'HML-FF-Intl', 'UMD-Intl', 'BAB-Intl', 'Multi-style-Intl', 'HML-Equity', 'UMD-Equity', 'Carry-Equity', 'BAB-Equity', 'Multi-style-Equity', 'HML-FI', 'UMD-FI', 'Carry-FI', 'BAB-FI', 'Multi-style-FI', 'HML-FX', 'UMD-FX', 'Carry-FX', 'Multi-style-FX', 'HML-COM', 'UMD-COM', 'Carry-COM', 'Multi-style-COM', 'HML-All-SS', 'UMD-All-SS', 'BAB-All-SS', 'Multi-style-All-SS', 'HML-All-Macro', 'UMD-All-Macro', 'Carry-All-Macro', 'BAB-All-Macro', 'Multi-style-All-Macro', 'HML-All', 'UMD-All', 'Carry-All', 'BAB-All', 'Multi-style-All', 'MKT-Equity', 'MKT-FI', 'MKT-COM', 'MKT-All-Macro']\n",
      "2025-04-10 17:35:39,869 - INFO - Rows after melting: 46491\n",
      "2025-04-10 17:35:48,314 - INFO - Loaded 46491 new rows into factor_returns from C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx (sheet 0).\n",
      "2025-04-10 17:35:48,320 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:35:48,737 - INFO - Raw columns: ['Unnamed: 0', 'Excess return of equal-weight commodities portfolio', 'Excess spot return of equal-weight commodities portfolio', 'Interest rate adjusted carry of equal-weight commodities portfolio', 'Spot return of equal-weight commodities portfolio', 'Carry of equal-weight commodities portfolio', 'Excess return of long/short commodities portfolio', 'Excess spot return of long/short commodities portfolio', 'Interest rate adjusted carry of long/short commodities portfolio', 'Aggregate backwardation/contango', 'State of backwardation/contango', 'State of inflation']\n",
      "2025-04-10 17:35:48,762 - INFO - No new rows to load into aqr_cmdty_factors.\n",
      "2025-04-10 17:35:48,765 - INFO - All data processing complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import VARCHAR, DATE, DECIMAL\n",
    "from sqlalchemy.sql import text\n",
    "import logging\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(), logging.FileHandler('load_aqr_data.log')]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Database connection\n",
    "engine = create_engine(\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/CWA_Fund_Database\"\n",
    "    \"?driver=ODBC+Driver+18+for+SQL+Server&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "# File configurations\n",
    "data_files = {\n",
    "    \"BAB_multi\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx\",\n",
    "        \"sheets\": {\n",
    "            \"BAB\": {\"sheet\": 0, \"header\": 18, \"paper\": \"Betting Against Beta (Frazzini and Pedersen, 2014)\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"BAB\", \"Global\": \"BAB\", \"Global Ex USA\": \"BAB\"}},\n",
    "            \"MKT\": {\"sheet\": 4, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"MKT\", \"Global\": \"MKT\", \"Global Ex USA\": \"MKT\"}},\n",
    "            \"SMB\": {\"sheet\": 5, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"SMB\", \"Global\": \"SMB\", \"Global Ex USA\": \"SMB\"}},\n",
    "            \"HML-FF\": {\"sheet\": 6, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-FF\", \"Global\": \"HML-FF\", \"Global Ex USA\": \"HML-FF\"}},\n",
    "            \"HML-D\": {\"sheet\": 7, \"header\": 18, \"paper\": \"The Devil's in HML's Details\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-D\", \"Global\": \"HML-D\", \"Global Ex USA\": \"HML-D\"}},\n",
    "            \"UMD\": {\"sheet\": 8, \"header\": 18, \"paper\": \"On Persistence in Mutual Fund Performance\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"UMD\", \"Global\": \"UMD\", \"Global Ex USA\": \"UMD\"}},\n",
    "            \"ME\": {\"sheet\": 9, \"header\": 18, \"paper\": \"AQR Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"ME\", \"Global\": \"ME\", \"Global Ex USA\": \"ME\"}},\n",
    "            \"RF\": {\"sheet\": 10, \"header\": 18, \"paper\": None, \"columns\": {\"DATE\": \"DATE\", \"Risk Free Rate\": \"RF\"}}\n",
    "        }\n",
    "    },\n",
    "    \"TSMOM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 17,\n",
    "        \"paper\": \"Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)\",\n",
    "        \"columns\": {\n",
    "            \"Unnamed: 0\": \"DATE\",\n",
    "            \"TSMOM\": \"TSM-MA\",\n",
    "            \"TSMOM^CM\": \"TSM-Com\",\n",
    "            \"TSMOM^EQ\": \"TSM-EQ\",\n",
    "            \"TSMOM^FI\": \"TSM-FI\",\n",
    "            \"TSMOM^FX\": \"TSM-FX\"\n",
    "        }\n",
    "    },\n",
    "    \"QMJ\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 18,\n",
    "        \"paper\": \"Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)\",\n",
    "        \"columns\": {\n",
    "            \"DATE\": \"DATE\",\n",
    "            \"P1 (low quality)\": \"QMJ-P1-LQ\",\n",
    "            \"P2\": \"QMJ-P2\",\n",
    "            \"P3\": \"QMJ-P3\",\n",
    "            \"P4\": \"QMJ-P4\",\n",
    "            \"P5\": \"QMJ-P5\",\n",
    "            \"P6\": \"QMJ-P6\",\n",
    "            \"P7\": \"QMJ-P7\",\n",
    "            \"P8\": \"QMJ-P8\",\n",
    "            \"P9\": \"QMJ-P9\",\n",
    "            \"P10 (high quality)\": \"QMJ-P10-HQ\",\n",
    "            \"P10-P1\": \"QMJ\"\n",
    "        }\n",
    "    },\n",
    "    \"Century\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 18,\n",
    "        \"paper\": \"Century of Factor Premia Monthly-Ilmanen et al. (2021)\",\n",
    "        \"columns\": {\n",
    "            \"Date\": \"DATE\",\n",
    "            \"US Stock Selection Value\": \"HML-FF-US\", \"US Stock Selection Momentum\": \"UMD-US\", \n",
    "            \"US Stock Selection Defensive\": \"BAB-US\", \"US Stock Selection Multi-style\": \"Multi-style-US\",\n",
    "            \"Intl Stock Selection Value\": \"HML-FF-Intl\", \"Intl Stock Selection Momentum\": \"UMD-Intl\", \n",
    "            \"Intl Stock Selection Defensive\": \"BAB-Intl\", \"Intl Stock Selection Multi-style\": \"Multi-style-Intl\",\n",
    "            \"Equity indices Value\": \"HML-Equity\", \"Equity indices Momentum\": \"UMD-Equity\", \n",
    "            \"Equity indices Carry\": \"Carry-Equity\", \"Equity indices Defensive\": \"BAB-Equity\", \n",
    "            \"Equity indices Multi-style\": \"Multi-style-Equity\",\n",
    "            \"Fixed income Value\": \"HML-FI\", \"Fixed income Momentum\": \"UMD-FI\", \n",
    "            \"Fixed income Carry\": \"Carry-FI\", \"Fixed income Defensive\": \"BAB-FI\", \n",
    "            \"Fixed income Multi-style\": \"Multi-style-FI\",\n",
    "            \"Currencies Value\": \"HML-FX\", \"Currencies Momentum\": \"UMD-FX\", \n",
    "            \"Currencies Carry\": \"Carry-FX\", \"Currencies Multi-style\": \"Multi-style-FX\",\n",
    "            \"Commodities Value\": \"HML-COM\", \"Commodities Momentum\": \"UMD-COM\", \n",
    "            \"Commodities Carry\": \"Carry-COM\", \"Commodities Multi-style\": \"Multi-style-COM\",\n",
    "            \"All Stock Selection Value\": \"HML-All-SS\", \"All Stock Selection Momentum\": \"UMD-All-SS\", \n",
    "            \"All Stock Selection Defensive\": \"BAB-All-SS\", \"All Stock Selection Multi-style\": \"Multi-style-All-SS\",\n",
    "            \"All Macro Value\": \"HML-All-Macro\", \"All Macro Momentum\": \"UMD-All-Macro\", \n",
    "            \"All Macro Carry\": \"Carry-All-Macro\", \"All Macro Defensive\": \"BAB-All-Macro\", \n",
    "            \"All Macro Multi-style\": \"Multi-style-All-Macro\",\n",
    "            \"All asset classes Value\": \"HML-All\", \"All asset classes Momentum\": \"UMD-All\", \n",
    "            \"All asset classes Carry\": \"Carry-All\", \"All asset classes Defensive\": \"BAB-All\", \n",
    "            \"All asset classes Multi-style\": \"Multi-style-All\",\n",
    "            \"Equity indices Market\": \"MKT-Equity\", \"Fixed income Market\": \"MKT-FI\", \n",
    "            \"Commodities Market\": \"MKT-COM\", \"All Macro Market\": \"MKT-All-Macro\"\n",
    "        }\n",
    "    },\n",
    "    \"COM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 10,\n",
    "        \"paper\": \"Commodities for the Long Run\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def process_factors(file_config, sheet=0, is_com=False, parent_path=None):\n",
    "    file_path = parent_path if parent_path else file_config['path']\n",
    "    logger.info(f\"Processing {file_path} (sheet {sheet})...\")\n",
    "    try:\n",
    "        # Read Excel with correct header row\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet, header=file_config['header'])\n",
    "        logger.info(f\"Raw columns: {list(df.columns)}\")\n",
    "        \n",
    "        if is_com:\n",
    "            df.columns = [\n",
    "                'date', 'excess_return_eqwt', 'excess_spot_return_eqwt', 'ir_adjusted_carry_eqwt',\n",
    "                'spot_return_eqwt', 'carry_eqwt', 'excess_return_long_short', 'excess_spot_return_long_short',\n",
    "                'ir_adjusted_carry_long_short', 'aggregate_backwardation_contango', \n",
    "                'state_backwardation_contango', 'state_inflation'\n",
    "            ]\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            df['associated_paper'] = file_config['paper']\n",
    "            df = df.dropna(subset=['date'])\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                existing = pd.read_sql(\"SELECT date FROM aqr_cmdty_factors\", connection)\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(existing['date'])\n",
    "            \n",
    "            df['date_str'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_new = df[~df['date_str'].isin(existing_keys)].drop(columns=['date_str'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                df_new.to_sql(\n",
    "                    'aqr_cmdty_factors',\n",
    "                    engine,\n",
    "                    if_exists='append',\n",
    "                    index=False,\n",
    "                    dtype={\n",
    "                        'date': DATE,\n",
    "                        'excess_return_eqwt': DECIMAL(15, 6),\n",
    "                        'excess_spot_return_eqwt': DECIMAL(15, 6),\n",
    "                        'ir_adjusted_carry_eqwt': DECIMAL(15, 6),\n",
    "                        'spot_return_eqwt': DECIMAL(15, 6),\n",
    "                        'carry_eqwt': DECIMAL(15, 6),\n",
    "                        'excess_return_long_short': DECIMAL(15, 6),\n",
    "                        'excess_spot_return_long_short': DECIMAL(15, 6),\n",
    "                        'ir_adjusted_carry_long_short': DECIMAL(15, 6),\n",
    "                        'aggregate_backwardation_contango': DECIMAL(15, 6),\n",
    "                        'state_backwardation_contango': VARCHAR(50),\n",
    "                        'state_inflation': VARCHAR(50),\n",
    "                        'associated_paper': VARCHAR(100)\n",
    "                    }\n",
    "                )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into aqr_cmdty_factors.\")\n",
    "            else:\n",
    "                logger.info(\"No new rows to load into aqr_cmdty_factors.\")\n",
    "        else:\n",
    "            # Identify date column\n",
    "            date_col = next(\n",
    "                (col for col in df.columns if isinstance(col, str) and ('DATE' in col.upper() or 'Date' in col)),\n",
    "                df.columns[0]\n",
    "            )\n",
    "            \n",
    "            # Filter and rename columns\n",
    "            if 'columns' in file_config:\n",
    "                valid_cols = list(file_config['columns'].keys())\n",
    "                if date_col not in valid_cols:\n",
    "                    valid_cols.append(date_col)\n",
    "                df = df[[col for col in df.columns if col in valid_cols]]\n",
    "                new_columns = []\n",
    "                for col in df.columns:\n",
    "                    if col == date_col:\n",
    "                        new_columns.append('date')\n",
    "                    else:\n",
    "                        new_columns.append(file_config['columns'].get(col, col))\n",
    "                df.columns = new_columns\n",
    "            \n",
    "            logger.info(f\"Columns after renaming: {list(df.columns)}\")\n",
    "            \n",
    "            # Parse dates\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            \n",
    "            # Melt the DataFrame\n",
    "            df_long = df.melt(id_vars=['date'], var_name='factor', value_name='value')\n",
    "            df_long = df_long.dropna(subset=['value', 'date'])\n",
    "            logger.info(f\"Rows after melting: {len(df_long)}\")\n",
    "            \n",
    "            # Assign asset class and region\n",
    "            if 'TSMOM' in file_config['path']:\n",
    "                df_long['asset_class'] = df_long['factor'].map({\n",
    "                    \"TSM-MA\": \"Multi-Asset\",\n",
    "                    \"TSM-Com\": \"Commodities\",\n",
    "                    \"TSM-EQ\": \"Equity\",\n",
    "                    \"TSM-FI\": \"Fixed Income\",\n",
    "                    \"TSM-FX\": \"Currencies\"\n",
    "                })\n",
    "                df_long['region'] = \"Global\"\n",
    "            elif 'Quality Minus Junk' in file_config['path']:\n",
    "                df_long['asset_class'] = \"Equity\"\n",
    "                df_long['region'] = df_long['date'].apply(\n",
    "                    lambda x: \"USA\" if x < pd.Timestamp(\"1989-07-31\") else \"Global\"\n",
    "                )\n",
    "            elif 'Century' in file_config['path']:\n",
    "                df_long['asset_class'] = df_long['factor'].str.extract(\n",
    "                    '(Stock Selection|Equity indices|Fixed income|Currencies|Commodities|All Macro|All asset classes)'\n",
    "                ).fillna('Equity')  # Default to Equity if no match\n",
    "                df_long['region'] = df_long['factor'].apply(\n",
    "                    lambda x: 'US' if 'US' in x else 'Intl' if 'Intl' in x else 'Global'\n",
    "                )\n",
    "            else:  # BAB_multi\n",
    "                df_long['asset_class'] = \"Equity\" if 'Risk Free Rate' not in file_config['columns'].values() else \"Fixed Income\"\n",
    "                region_map = {}\n",
    "                for col, factor in file_config['columns'].items():\n",
    "                    if col == 'DATE':\n",
    "                        continue\n",
    "                    if col == 'USA':\n",
    "                        region_map[factor] = 'USA'\n",
    "                    elif col == 'Global':\n",
    "                        region_map[factor] = 'Global'\n",
    "                    elif col == 'Global Ex USA':\n",
    "                        region_map[factor] = 'Intl'\n",
    "                region_map['RF'] = 'USA'\n",
    "                df_long['region'] = df_long['factor'].map(region_map)\n",
    "            \n",
    "            df_long['associated_paper'] = file_config['paper']\n",
    "            df_long = df_long[['factor', 'date', 'associated_paper', 'asset_class', 'value', 'region']]\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                existing = pd.read_sql(\n",
    "                    \"SELECT factor, date, associated_paper, asset_class FROM factor_returns\",\n",
    "                    connection\n",
    "                )\n",
    "                # Handle NULL asset_class in existing data\n",
    "                existing['asset_class'] = existing['asset_class'].fillna('Unknown')\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(tuple(row) for row in existing[['factor', 'date', 'associated_paper', 'asset_class']].values)\n",
    "            \n",
    "            df_long['date_str'] = df_long['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_long['asset_class'] = df_long['asset_class'].fillna('Unknown')  # Ensure no NULLs\n",
    "            df_long['key'] = df_long.apply(\n",
    "                lambda row: (row['factor'], row['date_str'], row['associated_paper'] if row['associated_paper'] else 'None', row['asset_class']), axis=1\n",
    "            )\n",
    "            df_new = df_long[~df_long['key'].isin(existing_keys)].drop(columns=['date_str', 'key'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                df_new.to_sql(\n",
    "                    'factor_returns',\n",
    "                    engine,\n",
    "                    if_exists='append',\n",
    "                    index=False,\n",
    "                    dtype={\n",
    "                        'factor': VARCHAR(50),\n",
    "                        'date': DATE,\n",
    "                        'associated_paper': VARCHAR(100),\n",
    "                        'asset_class': VARCHAR(50),\n",
    "                        'value': DECIMAL(15, 6),\n",
    "                        'region': VARCHAR(50)\n",
    "                    }\n",
    "                )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into factor_returns from {file_path} (sheet {sheet}).\")\n",
    "            else:\n",
    "                logger.info(f\"No new rows to load into factor_returns from {file_path} (sheet {sheet}).\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing {file_path} (sheet {sheet}): {str(e)}\")\n",
    "\n",
    "# Process all datasets\n",
    "for key, config in data_files.items():\n",
    "    if key == \"BAB_multi\":\n",
    "        for subkey, subconfig in config['sheets'].items():\n",
    "            process_factors(subconfig, sheet=subconfig['sheet'], parent_path=config['path'])\n",
    "    elif key == \"COM\":\n",
    "        process_factors(config, sheet=config['sheet'], is_com=True)\n",
    "    else:\n",
    "        process_factors(config, sheet=config['sheet'])\n",
    "\n",
    "logger.info(\"All data processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae28fc22-eb7f-4b9c-aa5b-0c770a2fdaec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 17:39:12,908 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:39:14,416 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:39:14,419 - INFO - Columns after renaming: ['date', 'BAB', 'BAB', 'BAB']\n",
      "2025-04-10 17:39:14,432 - INFO - Rows after melting: 2039\n",
      "2025-04-10 17:39:14,434 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 0): 'path'\n",
      "2025-04-10 17:39:14,436 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 4)...\n",
      "2025-04-10 17:39:15,090 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:39:15,092 - INFO - Columns after renaming: ['date', 'MKT', 'MKT', 'MKT']\n",
      "2025-04-10 17:39:15,105 - INFO - Rows after melting: 2166\n",
      "2025-04-10 17:39:15,106 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 4): 'path'\n",
      "2025-04-10 17:39:15,107 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 5)...\n",
      "2025-04-10 17:39:15,733 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:39:15,735 - INFO - Columns after renaming: ['date', 'SMB', 'SMB', 'SMB']\n",
      "2025-04-10 17:39:15,746 - INFO - Rows after melting: 2151\n",
      "2025-04-10 17:39:15,747 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 5): 'path'\n",
      "2025-04-10 17:39:15,748 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 6)...\n",
      "2025-04-10 17:39:16,368 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:39:16,371 - INFO - Columns after renaming: ['date', 'HML-FF', 'HML-FF', 'HML-FF']\n",
      "2025-04-10 17:39:16,382 - INFO - Rows after melting: 2151\n",
      "2025-04-10 17:39:16,384 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 6): 'path'\n",
      "2025-04-10 17:39:16,385 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 7)...\n",
      "2025-04-10 17:39:16,916 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:39:16,919 - INFO - Columns after renaming: ['date', 'HML-D', 'HML-D', 'HML-D']\n",
      "2025-04-10 17:39:16,929 - INFO - Rows after melting: 2154\n",
      "2025-04-10 17:39:16,930 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 7): 'path'\n",
      "2025-04-10 17:39:16,932 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 8)...\n",
      "2025-04-10 17:39:17,560 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:39:17,563 - INFO - Columns after renaming: ['date', 'UMD', 'UMD', 'UMD']\n",
      "2025-04-10 17:39:17,574 - INFO - Rows after melting: 2136\n",
      "2025-04-10 17:39:17,576 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 8): 'path'\n",
      "2025-04-10 17:39:17,577 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 9)...\n",
      "2025-04-10 17:39:17,964 - INFO - Raw columns: ['DATE', 'AUT', 'HKG', 'ESP', 'GBR', 'ITA', 'DEU', 'DNK', 'NZL', 'NLD', 'USA', 'PRT', 'BEL', 'ISR', 'GRC', 'NOR', 'SGP', 'CHE', 'IRL', 'CAN', 'FIN', 'JPN', 'SWE', 'FRA', 'AUS', 'Global Ex USA', 'Global', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:39:17,966 - INFO - Columns after renaming: ['date', 'ME', 'ME', 'ME']\n",
      "2025-04-10 17:39:17,978 - INFO - Rows after melting: 2210\n",
      "2025-04-10 17:39:17,979 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 9): 'path'\n",
      "2025-04-10 17:39:17,980 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 10)...\n",
      "2025-04-10 17:39:18,537 - INFO - Raw columns: ['DATE', 'Risk Free Rate']\n",
      "2025-04-10 17:39:18,540 - INFO - Columns after renaming: ['date', 'RF']\n",
      "2025-04-10 17:39:18,549 - INFO - Rows after melting: 1183\n",
      "2025-04-10 17:39:18,551 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 10): 'path'\n",
      "2025-04-10 17:39:18,551 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:39:18,808 - INFO - Raw columns: ['Unnamed: 0', 'TSMOM', 'TSMOM^CM', 'TSMOM^EQ', 'TSMOM^FI', 'TSMOM^FX']\n",
      "2025-04-10 17:39:18,811 - INFO - Columns after renaming: ['date', 'TSM-MA', 'TSM-Com', 'TSM-EQ', 'TSM-FI', 'TSM-FX']\n",
      "2025-04-10 17:39:18,817 - INFO - Rows after melting: 2405\n",
      "2025-04-10 17:39:19,701 - INFO - Loaded 2405 new rows into factor_returns from C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet 0).\n",
      "2025-04-10 17:39:19,702 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:39:20,022 - INFO - Raw columns: ['DATE', 'P1 (low quality)', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10 (high quality)', 'P10-P1', 'P1 (low quality).1', 'P2.1', 'P3.1', 'P4.1', 'P5.1', 'P6.1', 'P7.1', 'P8.1', 'P9.1', 'P10 (high quality).1', 'P10-P1.1']\n",
      "2025-04-10 17:39:20,026 - INFO - Columns after renaming: ['date', 'QMJ-P1-LQ', 'QMJ-P2', 'QMJ-P3', 'QMJ-P4', 'QMJ-P5', 'QMJ-P6', 'QMJ-P7', 'QMJ-P8', 'QMJ-P9', 'QMJ-P10-HQ', 'QMJ']\n",
      "2025-04-10 17:39:20,036 - INFO - Rows after melting: 8899\n",
      "2025-04-10 17:39:22,892 - INFO - Loaded 8899 new rows into factor_returns from C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 0).\n",
      "2025-04-10 17:39:22,894 - INFO - Skipping Century as data is already fully loaded.\n",
      "2025-04-10 17:39:22,895 - INFO - Skipping COM as data is already fully loaded.\n",
      "2025-04-10 17:39:22,895 - INFO - All data processing complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import VARCHAR, DATE, DECIMAL\n",
    "from sqlalchemy.sql import text\n",
    "import logging\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(), logging.FileHandler('load_aqr_data.log')]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Database connection\n",
    "engine = create_engine(\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/CWA_Fund_Database\"\n",
    "    \"?driver=ODBC+Driver+18+for+SQL+Server&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "# File configurations\n",
    "data_files = {\n",
    "    \"BAB_multi\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx\",\n",
    "        \"sheets\": {\n",
    "            \"BAB\": {\"sheet\": 0, \"header\": 18, \"paper\": \"Betting Against Beta (Frazzini and Pedersen, 2014)\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"BAB\", \"Global\": \"BAB\", \"Global Ex USA\": \"BAB\"}},\n",
    "            \"MKT\": {\"sheet\": 4, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"MKT\", \"Global\": \"MKT\", \"Global Ex USA\": \"MKT\"}},\n",
    "            \"SMB\": {\"sheet\": 5, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"SMB\", \"Global\": \"SMB\", \"Global Ex USA\": \"SMB\"}},\n",
    "            \"HML-FF\": {\"sheet\": 6, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-FF\", \"Global\": \"HML-FF\", \"Global Ex USA\": \"HML-FF\"}},\n",
    "            \"HML-D\": {\"sheet\": 7, \"header\": 18, \"paper\": \"The Devil's in HML's Details\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-D\", \"Global\": \"HML-D\", \"Global Ex USA\": \"HML-D\"}},\n",
    "            \"UMD\": {\"sheet\": 8, \"header\": 18, \"paper\": \"On Persistence in Mutual Fund Performance\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"UMD\", \"Global\": \"UMD\", \"Global Ex USA\": \"UMD\"}},\n",
    "            \"ME\": {\"sheet\": 9, \"header\": 18, \"paper\": \"AQR Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"ME\", \"Global\": \"ME\", \"Global Ex USA\": \"ME\"}},\n",
    "            \"RF\": {\"sheet\": 10, \"header\": 18, \"paper\": None, \"columns\": {\"DATE\": \"DATE\", \"Risk Free Rate\": \"RF\"}}\n",
    "        }\n",
    "    },\n",
    "    \"TSMOM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 17,\n",
    "        \"paper\": \"Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)\",\n",
    "        \"columns\": {\n",
    "            \"Unnamed: 0\": \"DATE\",\n",
    "            \"TSMOM\": \"TSM-MA\",\n",
    "            \"TSMOM^CM\": \"TSM-Com\",\n",
    "            \"TSMOM^EQ\": \"TSM-EQ\",\n",
    "            \"TSMOM^FI\": \"TSM-FI\",\n",
    "            \"TSMOM^FX\": \"TSM-FX\"\n",
    "        }\n",
    "    },\n",
    "    \"QMJ\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 18,\n",
    "        \"paper\": \"Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)\",\n",
    "        \"columns\": {\n",
    "            \"DATE\": \"DATE\",\n",
    "            \"P1 (low quality)\": \"QMJ-P1-LQ\",\n",
    "            \"P2\": \"QMJ-P2\",\n",
    "            \"P3\": \"QMJ-P3\",\n",
    "            \"P4\": \"QMJ-P4\",\n",
    "            \"P5\": \"QMJ-P5\",\n",
    "            \"P6\": \"QMJ-P6\",\n",
    "            \"P7\": \"QMJ-P7\",\n",
    "            \"P8\": \"QMJ-P8\",\n",
    "            \"P9\": \"QMJ-P9\",\n",
    "            \"P10 (high quality)\": \"QMJ-P10-HQ\",\n",
    "            \"P10-P1\": \"QMJ\"\n",
    "        }\n",
    "    },\n",
    "    \"Century\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 18,\n",
    "        \"paper\": \"Century of Factor Premia Monthly-Ilmanen et al. (2021)\",\n",
    "        \"columns\": {\n",
    "            \"Date\": \"DATE\",\n",
    "            \"US Stock Selection Value\": \"HML-FF-US\", \"US Stock Selection Momentum\": \"UMD-US\", \n",
    "            \"US Stock Selection Defensive\": \"BAB-US\", \"US Stock Selection Multi-style\": \"Multi-style-US\",\n",
    "            \"Intl Stock Selection Value\": \"HML-FF-Intl\", \"Intl Stock Selection Momentum\": \"UMD-Intl\", \n",
    "            \"Intl Stock Selection Defensive\": \"BAB-Intl\", \"Intl Stock Selection Multi-style\": \"Multi-style-Intl\",\n",
    "            \"Equity indices Value\": \"HML-Equity\", \"Equity indices Momentum\": \"UMD-Equity\", \n",
    "            \"Equity indices Carry\": \"Carry-Equity\", \"Equity indices Defensive\": \"BAB-Equity\", \n",
    "            \"Equity indices Multi-style\": \"Multi-style-Equity\",\n",
    "            \"Fixed income Value\": \"HML-FI\", \"Fixed income Momentum\": \"UMD-FI\", \n",
    "            \"Fixed income Carry\": \"Carry-FI\", \"Fixed income Defensive\": \"BAB-FI\", \n",
    "            \"Fixed income Multi-style\": \"Multi-style-FI\",\n",
    "            \"Currencies Value\": \"HML-FX\", \"Currencies Momentum\": \"UMD-FX\", \n",
    "            \"Currencies Carry\": \"Carry-FX\", \"Currencies Multi-style\": \"Multi-style-FX\",\n",
    "            \"Commodities Value\": \"HML-COM\", \"Commodities Momentum\": \"UMD-COM\", \n",
    "            \"Commodities Carry\": \"Carry-COM\", \"Commodities Multi-style\": \"Multi-style-COM\",\n",
    "            \"All Stock Selection Value\": \"HML-All-SS\", \"All Stock Selection Momentum\": \"UMD-All-SS\", \n",
    "            \"All Stock Selection Defensive\": \"BAB-All-SS\", \"All Stock Selection Multi-style\": \"Multi-style-All-SS\",\n",
    "            \"All Macro Value\": \"HML-All-Macro\", \"All Macro Momentum\": \"UMD-All-Macro\", \n",
    "            \"All Macro Carry\": \"Carry-All-Macro\", \"All Macro Defensive\": \"BAB-All-Macro\", \n",
    "            \"All Macro Multi-style\": \"Multi-style-All-Macro\",\n",
    "            \"All asset classes Value\": \"HML-All\", \"All asset classes Momentum\": \"UMD-All\", \n",
    "            \"All asset classes Carry\": \"Carry-All\", \"All asset classes Defensive\": \"BAB-All\", \n",
    "            \"All asset classes Multi-style\": \"Multi-style-All\",\n",
    "            \"Equity indices Market\": \"MKT-Equity\", \"Fixed income Market\": \"MKT-FI\", \n",
    "            \"Commodities Market\": \"MKT-COM\", \"All Macro Market\": \"MKT-All-Macro\"\n",
    "        }\n",
    "    },\n",
    "    \"COM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 10,\n",
    "        \"paper\": \"Commodities for the Long Run\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def process_factors(file_config, sheet=0, is_com=False, parent_path=None):\n",
    "    file_path = parent_path if parent_path else file_config['path']\n",
    "    logger.info(f\"Processing {file_path} (sheet {sheet})...\")\n",
    "    try:\n",
    "        # Read Excel with correct header row\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet, header=file_config['header'])\n",
    "        logger.info(f\"Raw columns: {list(df.columns)}\")\n",
    "        \n",
    "        if is_com:\n",
    "            df.columns = [\n",
    "                'date', 'excess_return_eqwt', 'excess_spot_return_eqwt', 'ir_adjusted_carry_eqwt',\n",
    "                'spot_return_eqwt', 'carry_eqwt', 'excess_return_long_short', 'excess_spot_return_long_short',\n",
    "                'ir_adjusted_carry_long_short', 'aggregate_backwardation_contango', \n",
    "                'state_backwardation_contango', 'state_inflation'\n",
    "            ]\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            df['associated_paper'] = file_config['paper']\n",
    "            df = df.dropna(subset=['date'])\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                existing = pd.read_sql(\"SELECT date FROM aqr_cmdty_factors\", connection)\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(existing['date'])\n",
    "            \n",
    "            df['date_str'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_new = df[~df['date_str'].isin(existing_keys)].drop(columns=['date_str'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                df_new.to_sql(\n",
    "                    'aqr_cmdty_factors',\n",
    "                    engine,\n",
    "                    if_exists='append',\n",
    "                    index=False,\n",
    "                    dtype={\n",
    "                        'date': DATE,\n",
    "                        'excess_return_eqwt': DECIMAL(15, 6),\n",
    "                        'excess_spot_return_eqwt': DECIMAL(15, 6),\n",
    "                        'ir_adjusted_carry_eqwt': DECIMAL(15, 6),\n",
    "                        'spot_return_eqwt': DECIMAL(15, 6),\n",
    "                        'carry_eqwt': DECIMAL(15, 6),\n",
    "                        'excess_return_long_short': DECIMAL(15, 6),\n",
    "                        'excess_spot_return_long_short': DECIMAL(15, 6),\n",
    "                        'ir_adjusted_carry_long_short': DECIMAL(15, 6),\n",
    "                        'aggregate_backwardation_contango': DECIMAL(15, 6),\n",
    "                        'state_backwardation_contango': VARCHAR(50),\n",
    "                        'state_inflation': VARCHAR(50),\n",
    "                        'associated_paper': VARCHAR(100)\n",
    "                    }\n",
    "                )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into aqr_cmdty_factors.\")\n",
    "            else:\n",
    "                logger.info(\"No new rows to load into aqr_cmdty_factors.\")\n",
    "        else:\n",
    "            # Identify date column\n",
    "            date_col = next(\n",
    "                (col for col in df.columns if isinstance(col, str) and ('DATE' in col.upper() or 'Date' in col)),\n",
    "                df.columns[0]\n",
    "            )\n",
    "            \n",
    "            # Filter and rename columns\n",
    "            if 'columns' in file_config:\n",
    "                valid_cols = list(file_config['columns'].keys())\n",
    "                if date_col not in valid_cols:\n",
    "                    valid_cols.append(date_col)\n",
    "                df = df[[col for col in df.columns if col in valid_cols]]\n",
    "                new_columns = []\n",
    "                for col in df.columns:\n",
    "                    if col == date_col:\n",
    "                        new_columns.append('date')\n",
    "                    else:\n",
    "                        new_columns.append(file_config['columns'].get(col, col))\n",
    "                df.columns = new_columns\n",
    "            \n",
    "            logger.info(f\"Columns after renaming: {list(df.columns)}\")\n",
    "            \n",
    "            # Parse dates\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            \n",
    "            # Melt the DataFrame\n",
    "            df_long = df.melt(id_vars=['date'], var_name='factor', value_name='value')\n",
    "            df_long = df_long.dropna(subset=['value', 'date'])\n",
    "            logger.info(f\"Rows after melting: {len(df_long)}\")\n",
    "            \n",
    "            # Assign asset class and region\n",
    "            if 'TSMOM' in file_config['path']:\n",
    "                df_long['asset_class'] = df_long['factor'].map({\n",
    "                    \"TSM-MA\": \"Multi-Asset\",\n",
    "                    \"TSM-Com\": \"Commodities\",\n",
    "                    \"TSM-EQ\": \"Equity\",\n",
    "                    \"TSM-FI\": \"Fixed Income\",\n",
    "                    \"TSM-FX\": \"Currencies\"\n",
    "                })\n",
    "                df_long['region'] = \"Global\"\n",
    "            elif 'Quality Minus Junk' in file_config['path']:\n",
    "                df_long['asset_class'] = \"Equity\"\n",
    "                df_long['region'] = df_long['date'].apply(\n",
    "                    lambda x: \"USA\" if x < pd.Timestamp(\"1989-07-31\") else \"Global\"\n",
    "                )\n",
    "            elif 'Century' in file_config['path']:\n",
    "                df_long['asset_class'] = df_long['factor'].str.extract(\n",
    "                    '(Stock Selection|Equity indices|Fixed income|Currencies|Commodities|All Macro|All asset classes)'\n",
    "                ).fillna('Equity')\n",
    "                df_long['region'] = df_long['factor'].apply(\n",
    "                    lambda x: 'US' if 'US' in x else 'Intl' if 'Intl' in x else 'Global'\n",
    "                )\n",
    "            else:  # BAB_multi\n",
    "                df_long['asset_class'] = \"Equity\" if 'Risk Free Rate' not in file_config['columns'].values() else \"Fixed Income\"\n",
    "                # Create region mapping based on original column names\n",
    "                region_map = {}\n",
    "                orig_cols = list(file_config['columns'].keys())\n",
    "                for i, col in enumerate(df.columns):\n",
    "                    if col == 'date':\n",
    "                        continue\n",
    "                    orig_col = list(file_config['columns'].keys())[i]  # Match by position\n",
    "                    factor = file_config['columns'][orig_col]\n",
    "                    if orig_col == 'USA':\n",
    "                        region_map[factor + '_USA'] = 'USA'\n",
    "                    elif orig_col == 'Global':\n",
    "                        region_map[factor + '_Global'] = 'Global'\n",
    "                    elif orig_col == 'Global Ex USA':\n",
    "                        region_map[factor + '_Intl'] = 'Intl'\n",
    "                    elif orig_col == 'Risk Free Rate':\n",
    "                        region_map['RF'] = 'USA'\n",
    "                # Apply region based on factor and original column\n",
    "                df_long['region'] = df_long.apply(\n",
    "                    lambda row: next((reg for key, reg in region_map.items() if row['factor'] in key), 'Unknown'), axis=1\n",
    "                )\n",
    "                # Adjust factor to avoid duplicates\n",
    "                df_long['factor'] = df_long.apply(\n",
    "                    lambda row: f\"{row['factor']}_{row['region']}\" if row['factor'] != 'RF' else 'RF', axis=1\n",
    "                )\n",
    "            \n",
    "            df_long['associated_paper'] = file_config['paper']\n",
    "            df_long = df_long[['factor', 'date', 'associated_paper', 'asset_class', 'value', 'region']]\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                existing = pd.read_sql(\n",
    "                    \"SELECT factor, date, associated_paper, asset_class FROM factor_returns\",\n",
    "                    connection\n",
    "                )\n",
    "                existing['asset_class'] = existing['asset_class'].fillna('Unknown')\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(tuple(row) for row in existing[['factor', 'date', 'associated_paper', 'asset_class']].values)\n",
    "            \n",
    "            df_long['date_str'] = df_long['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_long['asset_class'] = df_long['asset_class'].fillna('Unknown')\n",
    "            df_long['key'] = df_long.apply(\n",
    "                lambda row: (row['factor'], row['date_str'], row['associated_paper'] if row['associated_paper'] else 'None', row['asset_class']), axis=1\n",
    "            )\n",
    "            df_new = df_long[~df_long['key'].isin(existing_keys)].drop(columns=['date_str', 'key'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                df_new.to_sql(\n",
    "                    'factor_returns',\n",
    "                    engine,\n",
    "                    if_exists='append',\n",
    "                    index=False,\n",
    "                    dtype={\n",
    "                        'factor': VARCHAR(50),\n",
    "                        'date': DATE,\n",
    "                        'associated_paper': VARCHAR(100),\n",
    "                        'asset_class': VARCHAR(50),\n",
    "                        'value': DECIMAL(15, 6),\n",
    "                        'region': VARCHAR(50)\n",
    "                    }\n",
    "                )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into factor_returns from {file_path} (sheet {sheet}).\")\n",
    "            else:\n",
    "                logger.info(f\"No new rows to load into factor_returns from {file_path} (sheet {sheet}).\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing {file_path} (sheet {sheet}): {str(e)}\")\n",
    "\n",
    "# Process all datasets, skipping Century and COM since they're complete\n",
    "for key, config in data_files.items():\n",
    "    if key in [\"Century\", \"COM\"]:\n",
    "        logger.info(f\"Skipping {key} as data is already fully loaded.\")\n",
    "        continue\n",
    "    if key == \"BAB_multi\":\n",
    "        for subkey, subconfig in config['sheets'].items():\n",
    "            process_factors(subconfig, sheet=subconfig['sheet'], parent_path=config['path'])\n",
    "    else:\n",
    "        process_factors(config, sheet=config['sheet'])\n",
    "\n",
    "logger.info(\"All data processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d56f0a8-72e5-4cb4-95fc-ec126015f05f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 17:42:27,129 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:42:28,463 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:42:28,466 - INFO - Columns after renaming: ['date', 'BAB', 'BAB', 'BAB']\n",
      "2025-04-10 17:42:28,477 - INFO - Rows after melting: 2039\n",
      "2025-04-10 17:42:28,479 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 0): 'path'\n",
      "2025-04-10 17:42:28,480 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 4)...\n",
      "2025-04-10 17:42:29,211 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:42:29,213 - INFO - Columns after renaming: ['date', 'MKT', 'MKT', 'MKT']\n",
      "2025-04-10 17:42:29,228 - INFO - Rows after melting: 2166\n",
      "2025-04-10 17:42:29,229 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 4): 'path'\n",
      "2025-04-10 17:42:29,231 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 5)...\n",
      "2025-04-10 17:42:29,776 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:42:29,778 - INFO - Columns after renaming: ['date', 'SMB', 'SMB', 'SMB']\n",
      "2025-04-10 17:42:29,789 - INFO - Rows after melting: 2151\n",
      "2025-04-10 17:42:29,790 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 5): 'path'\n",
      "2025-04-10 17:42:29,791 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 6)...\n",
      "2025-04-10 17:42:30,476 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:42:30,478 - INFO - Columns after renaming: ['date', 'HML-FF', 'HML-FF', 'HML-FF']\n",
      "2025-04-10 17:42:30,490 - INFO - Rows after melting: 2151\n",
      "2025-04-10 17:42:30,491 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 6): 'path'\n",
      "2025-04-10 17:42:30,492 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 7)...\n",
      "2025-04-10 17:42:31,118 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:42:31,121 - INFO - Columns after renaming: ['date', 'HML-D', 'HML-D', 'HML-D']\n",
      "2025-04-10 17:42:31,133 - INFO - Rows after melting: 2154\n",
      "2025-04-10 17:42:31,133 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 7): 'path'\n",
      "2025-04-10 17:42:31,135 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 8)...\n",
      "2025-04-10 17:42:31,732 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:42:31,734 - INFO - Columns after renaming: ['date', 'UMD', 'UMD', 'UMD']\n",
      "2025-04-10 17:42:31,744 - INFO - Rows after melting: 2136\n",
      "2025-04-10 17:42:31,745 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 8): 'path'\n",
      "2025-04-10 17:42:31,746 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 9)...\n",
      "2025-04-10 17:42:32,275 - INFO - Raw columns: ['DATE', 'AUT', 'HKG', 'ESP', 'GBR', 'ITA', 'DEU', 'DNK', 'NZL', 'NLD', 'USA', 'PRT', 'BEL', 'ISR', 'GRC', 'NOR', 'SGP', 'CHE', 'IRL', 'CAN', 'FIN', 'JPN', 'SWE', 'FRA', 'AUS', 'Global Ex USA', 'Global', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:42:32,276 - INFO - Columns after renaming: ['date', 'ME', 'ME', 'ME']\n",
      "2025-04-10 17:42:32,290 - INFO - Rows after melting: 2210\n",
      "2025-04-10 17:42:32,291 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 9): 'path'\n",
      "2025-04-10 17:42:32,292 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 10)...\n",
      "2025-04-10 17:42:32,910 - INFO - Raw columns: ['DATE', 'Risk Free Rate']\n",
      "2025-04-10 17:42:32,912 - INFO - Columns after renaming: ['date', 'RF']\n",
      "2025-04-10 17:42:32,922 - INFO - Rows after melting: 1183\n",
      "2025-04-10 17:42:32,923 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 10): 'path'\n",
      "2025-04-10 17:42:32,924 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:42:33,078 - INFO - Raw columns: ['Unnamed: 0', 'TSMOM', 'TSMOM^CM', 'TSMOM^EQ', 'TSMOM^FI', 'TSMOM^FX']\n",
      "2025-04-10 17:42:33,080 - INFO - Columns after renaming: ['date', 'TSM-MA', 'TSM-Com', 'TSM-EQ', 'TSM-FI', 'TSM-FX']\n",
      "2025-04-10 17:42:33,086 - INFO - Rows after melting: 2405\n",
      "2025-04-10 17:42:33,889 - INFO - Loaded 2405 new rows into factor_returns from C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet 0).\n",
      "2025-04-10 17:42:33,894 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:42:34,259 - INFO - Raw columns: ['DATE', 'P1 (low quality)', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10 (high quality)', 'P10-P1', 'P1 (low quality).1', 'P2.1', 'P3.1', 'P4.1', 'P5.1', 'P6.1', 'P7.1', 'P8.1', 'P9.1', 'P10 (high quality).1', 'P10-P1.1']\n",
      "2025-04-10 17:42:34,261 - INFO - Columns after renaming: ['date', 'QMJ-P1-LQ', 'QMJ-P2', 'QMJ-P3', 'QMJ-P4', 'QMJ-P5', 'QMJ-P6', 'QMJ-P7', 'QMJ-P8', 'QMJ-P9', 'QMJ-P10-HQ', 'QMJ']\n",
      "2025-04-10 17:42:34,272 - INFO - Rows after melting: 8899\n",
      "2025-04-10 17:42:34,580 - INFO - No new rows to load into factor_returns from C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 0).\n",
      "2025-04-10 17:42:34,588 - INFO - Skipping Century as data is already fully loaded.\n",
      "2025-04-10 17:42:34,589 - INFO - Skipping COM as data is already fully loaded.\n",
      "2025-04-10 17:42:34,590 - INFO - All data processing complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import VARCHAR, DATE, DECIMAL\n",
    "from sqlalchemy.sql import text\n",
    "import logging\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(), logging.FileHandler('load_aqr_data.log')]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Database connection\n",
    "engine = create_engine(\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/CWA_Fund_Database\"\n",
    "    \"?driver=ODBC+Driver+18+for+SQL+Server&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "# File configurations\n",
    "data_files = {\n",
    "    \"BAB_multi\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx\",\n",
    "        \"sheets\": {\n",
    "            \"BAB\": {\"sheet\": 0, \"header\": 18, \"paper\": \"Betting Against Beta (Frazzini and Pedersen, 2014)\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"BAB\", \"Global\": \"BAB\", \"Global Ex USA\": \"BAB\"}},\n",
    "            \"MKT\": {\"sheet\": 4, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"MKT\", \"Global\": \"MKT\", \"Global Ex USA\": \"MKT\"}},\n",
    "            \"SMB\": {\"sheet\": 5, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"SMB\", \"Global\": \"SMB\", \"Global Ex USA\": \"SMB\"}},\n",
    "            \"HML-FF\": {\"sheet\": 6, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-FF\", \"Global\": \"HML-FF\", \"Global Ex USA\": \"HML-FF\"}},\n",
    "            \"HML-D\": {\"sheet\": 7, \"header\": 18, \"paper\": \"The Devil's in HML's Details\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-D\", \"Global\": \"HML-D\", \"Global Ex USA\": \"HML-D\"}},\n",
    "            \"UMD\": {\"sheet\": 8, \"header\": 18, \"paper\": \"On Persistence in Mutual Fund Performance\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"UMD\", \"Global\": \"UMD\", \"Global Ex USA\": \"UMD\"}},\n",
    "            \"ME\": {\"sheet\": 9, \"header\": 18, \"paper\": \"AQR Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"ME\", \"Global\": \"ME\", \"Global Ex USA\": \"ME\"}},\n",
    "            \"RF\": {\"sheet\": 10, \"header\": 18, \"paper\": None, \"columns\": {\"DATE\": \"DATE\", \"Risk Free Rate\": \"RF\"}}\n",
    "        }\n",
    "    },\n",
    "    \"TSMOM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 17,\n",
    "        \"paper\": \"Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)\",\n",
    "        \"columns\": {\n",
    "            \"Unnamed: 0\": \"DATE\",\n",
    "            \"TSMOM\": \"TSM-MA\",\n",
    "            \"TSMOM^CM\": \"TSM-Com\",\n",
    "            \"TSMOM^EQ\": \"TSM-EQ\",\n",
    "            \"TSMOM^FI\": \"TSM-FI\",\n",
    "            \"TSMOM^FX\": \"TSM-FX\"\n",
    "        }\n",
    "    },\n",
    "    \"QMJ\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 18,\n",
    "        \"paper\": \"Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)\",\n",
    "        \"columns\": {\n",
    "            \"DATE\": \"DATE\",\n",
    "            \"P1 (low quality)\": \"QMJ-P1-LQ\",\n",
    "            \"P2\": \"QMJ-P2\",\n",
    "            \"P3\": \"QMJ-P3\",\n",
    "            \"P4\": \"QMJ-P4\",\n",
    "            \"P5\": \"QMJ-P5\",\n",
    "            \"P6\": \"QMJ-P6\",\n",
    "            \"P7\": \"QMJ-P7\",\n",
    "            \"P8\": \"QMJ-P8\",\n",
    "            \"P9\": \"QMJ-P9\",\n",
    "            \"P10 (high quality)\": \"QMJ-P10-HQ\",\n",
    "            \"P10-P1\": \"QMJ\"\n",
    "        }\n",
    "    },\n",
    "    \"Century\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 18,\n",
    "        \"paper\": \"Century of Factor Premia Monthly-Ilmanen et al. (2021)\",\n",
    "        \"columns\": {\n",
    "            \"Date\": \"DATE\",\n",
    "            \"US Stock Selection Value\": \"HML-FF-US\", \"US Stock Selection Momentum\": \"UMD-US\", \n",
    "            \"US Stock Selection Defensive\": \"BAB-US\", \"US Stock Selection Multi-style\": \"Multi-style-US\",\n",
    "            \"Intl Stock Selection Value\": \"HML-FF-Intl\", \"Intl Stock Selection Momentum\": \"UMD-Intl\", \n",
    "            \"Intl Stock Selection Defensive\": \"BAB-Intl\", \"Intl Stock Selection Multi-style\": \"Multi-style-Intl\",\n",
    "            \"Equity indices Value\": \"HML-Equity\", \"Equity indices Momentum\": \"UMD-Equity\", \n",
    "            \"Equity indices Carry\": \"Carry-Equity\", \"Equity indices Defensive\": \"BAB-Equity\", \n",
    "            \"Equity indices Multi-style\": \"Multi-style-Equity\",\n",
    "            \"Fixed income Value\": \"HML-FI\", \"Fixed income Momentum\": \"UMD-FI\", \n",
    "            \"Fixed income Carry\": \"Carry-FI\", \"Fixed income Defensive\": \"BAB-FI\", \n",
    "            \"Fixed income Multi-style\": \"Multi-style-FI\",\n",
    "            \"Currencies Value\": \"HML-FX\", \"Currencies Momentum\": \"UMD-FX\", \n",
    "            \"Currencies Carry\": \"Carry-FX\", \"Currencies Multi-style\": \"Multi-style-FX\",\n",
    "            \"Commodities Value\": \"HML-COM\", \"Commodities Momentum\": \"UMD-COM\", \n",
    "            \"Commodities Carry\": \"Carry-COM\", \"Commodities Multi-style\": \"Multi-style-COM\",\n",
    "            \"All Stock Selection Value\": \"HML-All-SS\", \"All Stock Selection Momentum\": \"UMD-All-SS\", \n",
    "            \"All Stock Selection Defensive\": \"BAB-All-SS\", \"All Stock Selection Multi-style\": \"Multi-style-All-SS\",\n",
    "            \"All Macro Value\": \"HML-All-Macro\", \"All Macro Momentum\": \"UMD-All-Macro\", \n",
    "            \"All Macro Carry\": \"Carry-All-Macro\", \"All Macro Defensive\": \"BAB-All-Macro\", \n",
    "            \"All Macro Multi-style\": \"Multi-style-All-Macro\",\n",
    "            \"All asset classes Value\": \"HML-All\", \"All asset classes Momentum\": \"UMD-All\", \n",
    "            \"All asset classes Carry\": \"Carry-All\", \"All asset classes Defensive\": \"BAB-All\", \n",
    "            \"All asset classes Multi-style\": \"Multi-style-All\",\n",
    "            \"Equity indices Market\": \"MKT-Equity\", \"Fixed income Market\": \"MKT-FI\", \n",
    "            \"Commodities Market\": \"MKT-COM\", \"All Macro Market\": \"MKT-All-Macro\"\n",
    "        }\n",
    "    },\n",
    "    \"COM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 10,\n",
    "        \"paper\": \"Commodities for the Long Run\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def process_factors(file_config, sheet=0, is_com=False, parent_path=None):\n",
    "    file_path = parent_path if parent_path else file_config['path']\n",
    "    logger.info(f\"Processing {file_path} (sheet {sheet})...\")\n",
    "    try:\n",
    "        # Read Excel with correct header row\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet, header=file_config['header'])\n",
    "        logger.info(f\"Raw columns: {list(df.columns)}\")\n",
    "        \n",
    "        if is_com:\n",
    "            df.columns = [\n",
    "                'date', 'excess_return_eqwt', 'excess_spot_return_eqwt', 'ir_adjusted_carry_eqwt',\n",
    "                'spot_return_eqwt', 'carry_eqwt', 'excess_return_long_short', 'excess_spot_return_long_short',\n",
    "                'ir_adjusted_carry_long_short', 'aggregate_backwardation_contango', \n",
    "                'state_backwardation_contango', 'state_inflation'\n",
    "            ]\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            df['associated_paper'] = file_config['paper']\n",
    "            df = df.dropna(subset=['date'])\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                existing = pd.read_sql(\"SELECT date FROM aqr_cmdty_factors\", connection)\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(existing['date'])\n",
    "            \n",
    "            df['date_str'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_new = df[~df['date_str'].isin(existing_keys)].drop(columns=['date_str'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                df_new.to_sql(\n",
    "                    'aqr_cmdty_factors',\n",
    "                    engine,\n",
    "                    if_exists='append',\n",
    "                    index=False,\n",
    "                    dtype={\n",
    "                        'date': DATE,\n",
    "                        'excess_return_eqwt': DECIMAL(15, 6),\n",
    "                        'excess_spot_return_eqwt': DECIMAL(15, 6),\n",
    "                        'ir_adjusted_carry_eqwt': DECIMAL(15, 6),\n",
    "                        'spot_return_eqwt': DECIMAL(15, 6),\n",
    "                        'carry_eqwt': DECIMAL(15, 6),\n",
    "                        'excess_return_long_short': DECIMAL(15, 6),\n",
    "                        'excess_spot_return_long_short': DECIMAL(15, 6),\n",
    "                        'ir_adjusted_carry_long_short': DECIMAL(15, 6),\n",
    "                        'aggregate_backwardation_contango': DECIMAL(15, 6),\n",
    "                        'state_backwardation_contango': VARCHAR(50),\n",
    "                        'state_inflation': VARCHAR(50),\n",
    "                        'associated_paper': VARCHAR(100)\n",
    "                    }\n",
    "                )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into aqr_cmdty_factors.\")\n",
    "            else:\n",
    "                logger.info(\"No new rows to load into aqr_cmdty_factors.\")\n",
    "        else:\n",
    "            # Identify date column\n",
    "            date_col = next(\n",
    "                (col for col in df.columns if isinstance(col, str) and ('DATE' in col.upper() or 'Date' in col)),\n",
    "                df.columns[0]\n",
    "            )\n",
    "            \n",
    "            # Filter and rename columns\n",
    "            if 'columns' in file_config:\n",
    "                valid_cols = list(file_config['columns'].keys())\n",
    "                if date_col not in valid_cols:\n",
    "                    valid_cols.append(date_col)\n",
    "                df = df[[col for col in df.columns if col in valid_cols]]\n",
    "                new_columns = []\n",
    "                for col in df.columns:\n",
    "                    if col == date_col:\n",
    "                        new_columns.append('date')\n",
    "                    else:\n",
    "                        new_columns.append(file_config['columns'].get(col, col))\n",
    "                df.columns = new_columns\n",
    "            \n",
    "            logger.info(f\"Columns after renaming: {list(df.columns)}\")\n",
    "            \n",
    "            # Parse dates\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            \n",
    "            # Melt the DataFrame with value_vars to track original columns\n",
    "            value_vars = [col for col in df.columns if col != 'date']\n",
    "            df_long = df.melt(id_vars=['date'], value_vars=value_vars, var_name='factor', value_name='value')\n",
    "            df_long = df_long.dropna(subset=['value', 'date'])\n",
    "            logger.info(f\"Rows after melting: {len(df_long)}\")\n",
    "            \n",
    "            # Assign asset class and region\n",
    "            if 'TSMOM' in file_config['path']:\n",
    "                df_long['asset_class'] = df_long['factor'].map({\n",
    "                    \"TSM-MA\": \"Multi-Asset\",\n",
    "                    \"TSM-Com\": \"Commodities\",\n",
    "                    \"TSM-EQ\": \"Equity\",\n",
    "                    \"TSM-FI\": \"Fixed Income\",\n",
    "                    \"TSM-FX\": \"Currencies\"\n",
    "                })\n",
    "                df_long['region'] = \"Global\"\n",
    "            elif 'Quality Minus Junk' in file_config['path']:\n",
    "                df_long['asset_class'] = \"Equity\"\n",
    "                df_long['region'] = df_long['date'].apply(\n",
    "                    lambda x: \"USA\" if x < pd.Timestamp(\"1989-07-31\") else \"Global\"\n",
    "                )\n",
    "            elif 'Century' in file_config['path']:\n",
    "                df_long['asset_class'] = df_long['factor'].str.extract(\n",
    "                    '(Stock Selection|Equity indices|Fixed income|Currencies|Commodities|All Macro|All asset classes)'\n",
    "                ).fillna('Equity')\n",
    "                df_long['region'] = df_long['factor'].apply(\n",
    "                    lambda x: 'US' if 'US' in x else 'Intl' if 'Intl' in x else 'Global'\n",
    "                )\n",
    "            else:  # BAB_multi\n",
    "                df_long['asset_class'] = \"Equity\" if 'Risk Free Rate' not in file_config['columns'].values() else \"Fixed Income\"\n",
    "                # Map regions based on original column names\n",
    "                region_map = {\n",
    "                    'USA': 'USA',\n",
    "                    'Global': 'Global',\n",
    "                    'Global Ex USA': 'Intl',\n",
    "                    'Risk Free Rate': 'USA'\n",
    "                }\n",
    "                df_long['region'] = df_long['factor'].map(\n",
    "                    lambda x: region_map.get(next((k for k, v in file_config['columns'].items() if v == x and k != 'DATE'), ''), 'Unknown')\n",
    "                )\n",
    "                # Append region to factor to avoid duplicates\n",
    "                df_long['factor'] = df_long.apply(\n",
    "                    lambda row: f\"{row['factor']}_{row['region']}\" if row['factor'] != 'RF' and row['region'] != 'Unknown' else row['factor'], axis=1\n",
    "                )\n",
    "            \n",
    "            df_long['associated_paper'] = file_config['paper']\n",
    "            df_long = df_long[['factor', 'date', 'associated_paper', 'asset_class', 'value', 'region']]\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                existing = pd.read_sql(\n",
    "                    \"SELECT factor, date, associated_paper, asset_class FROM factor_returns\",\n",
    "                    connection\n",
    "                )\n",
    "                existing['asset_class'] = existing['asset_class'].fillna('Unknown')\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(tuple(row) for row in existing[['factor', 'date', 'associated_paper', 'asset_class']].values)\n",
    "            \n",
    "            df_long['date_str'] = df_long['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_long['asset_class'] = df_long['asset_class'].fillna('Unknown')\n",
    "            df_long['key'] = df_long.apply(\n",
    "                lambda row: (row['factor'], row['date_str'], row['associated_paper'] if row['associated_paper'] else 'None', row['asset_class']), axis=1\n",
    "            )\n",
    "            df_new = df_long[~df_long['key'].isin(existing_keys)].drop(columns=['date_str', 'key'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                df_new.to_sql(\n",
    "                    'factor_returns',\n",
    "                    engine,\n",
    "                    if_exists='append',\n",
    "                    index=False,\n",
    "                    dtype={\n",
    "                        'factor': VARCHAR(50),\n",
    "                        'date': DATE,\n",
    "                        'associated_paper': VARCHAR(100),\n",
    "                        'asset_class': VARCHAR(50),\n",
    "                        'value': DECIMAL(15, 6),\n",
    "                        'region': VARCHAR(50)\n",
    "                    }\n",
    "                )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into factor_returns from {file_path} (sheet {sheet}).\")\n",
    "            else:\n",
    "                logger.info(f\"No new rows to load into factor_returns from {file_path} (sheet {sheet}).\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing {file_path} (sheet {sheet}): {str(e)}\")\n",
    "\n",
    "# Process all datasets, skipping Century and COM since they're complete\n",
    "for key, config in data_files.items():\n",
    "    if key in [\"Century\", \"COM\"]:\n",
    "        logger.info(f\"Skipping {key} as data is already fully loaded.\")\n",
    "        continue\n",
    "    if key == \"BAB_multi\":\n",
    "        for subkey, subconfig in config['sheets'].items():\n",
    "            process_factors(subconfig, sheet=subconfig['sheet'], parent_path=config['path'])\n",
    "    else:\n",
    "        process_factors(config, sheet=config['sheet'])\n",
    "\n",
    "logger.info(\"All data processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65f03371-e4f2-4f75-9871-9de73b28a1ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 17:44:59,653 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:45:00,932 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:45:00,934 - INFO - Columns after renaming: ['date', 'BAB', 'BAB', 'BAB']\n",
      "2025-04-10 17:45:00,946 - INFO - Rows after melting: 2039\n",
      "2025-04-10 17:45:00,947 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 0): 'path'\n",
      "2025-04-10 17:45:00,948 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 4)...\n",
      "2025-04-10 17:45:01,618 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:45:01,620 - INFO - Columns after renaming: ['date', 'MKT', 'MKT', 'MKT']\n",
      "2025-04-10 17:45:01,637 - INFO - Rows after melting: 2166\n",
      "2025-04-10 17:45:01,639 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 4): 'path'\n",
      "2025-04-10 17:45:01,640 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 5)...\n",
      "2025-04-10 17:45:02,211 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:45:02,213 - INFO - Columns after renaming: ['date', 'SMB', 'SMB', 'SMB']\n",
      "2025-04-10 17:45:02,227 - INFO - Rows after melting: 2151\n",
      "2025-04-10 17:45:02,229 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 5): 'path'\n",
      "2025-04-10 17:45:02,229 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 6)...\n",
      "2025-04-10 17:45:02,858 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:45:02,860 - INFO - Columns after renaming: ['date', 'HML-FF', 'HML-FF', 'HML-FF']\n",
      "2025-04-10 17:45:02,871 - INFO - Rows after melting: 2151\n",
      "2025-04-10 17:45:02,872 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 6): 'path'\n",
      "2025-04-10 17:45:02,873 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 7)...\n",
      "2025-04-10 17:45:03,387 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:45:03,391 - INFO - Columns after renaming: ['date', 'HML-D', 'HML-D', 'HML-D']\n",
      "2025-04-10 17:45:03,402 - INFO - Rows after melting: 2154\n",
      "2025-04-10 17:45:03,403 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 7): 'path'\n",
      "2025-04-10 17:45:03,404 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 8)...\n",
      "2025-04-10 17:45:03,946 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:45:03,948 - INFO - Columns after renaming: ['date', 'UMD', 'UMD', 'UMD']\n",
      "2025-04-10 17:45:03,957 - INFO - Rows after melting: 2136\n",
      "2025-04-10 17:45:03,958 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 8): 'path'\n",
      "2025-04-10 17:45:03,960 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 9)...\n",
      "2025-04-10 17:45:04,515 - INFO - Raw columns: ['DATE', 'AUT', 'HKG', 'ESP', 'GBR', 'ITA', 'DEU', 'DNK', 'NZL', 'NLD', 'USA', 'PRT', 'BEL', 'ISR', 'GRC', 'NOR', 'SGP', 'CHE', 'IRL', 'CAN', 'FIN', 'JPN', 'SWE', 'FRA', 'AUS', 'Global Ex USA', 'Global', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:45:04,517 - INFO - Columns after renaming: ['date', 'ME', 'ME', 'ME']\n",
      "2025-04-10 17:45:04,530 - INFO - Rows after melting: 2210\n",
      "2025-04-10 17:45:04,531 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 9): 'path'\n",
      "2025-04-10 17:45:04,532 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 10)...\n",
      "2025-04-10 17:45:05,092 - INFO - Raw columns: ['DATE', 'Risk Free Rate']\n",
      "2025-04-10 17:45:05,095 - INFO - Columns after renaming: ['date', 'RF']\n",
      "2025-04-10 17:45:05,105 - INFO - Rows after melting: 1183\n",
      "2025-04-10 17:45:05,106 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 10): 'path'\n",
      "2025-04-10 17:45:05,107 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:45:05,300 - INFO - Raw columns: ['Unnamed: 0', 'TSMOM', 'TSMOM^CM', 'TSMOM^EQ', 'TSMOM^FI', 'TSMOM^FX']\n",
      "2025-04-10 17:45:05,303 - INFO - Columns after renaming: ['date', 'TSM-MA', 'TSM-Com', 'TSM-EQ', 'TSM-FI', 'TSM-FX']\n",
      "2025-04-10 17:45:05,310 - INFO - Rows after melting: 2405\n",
      "2025-04-10 17:45:05,563 - INFO - No new rows to load into factor_returns from C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet 0).\n",
      "2025-04-10 17:45:05,569 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:45:06,024 - INFO - Raw columns: ['DATE', 'P1 (low quality)', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10 (high quality)', 'P10-P1', 'P1 (low quality).1', 'P2.1', 'P3.1', 'P4.1', 'P5.1', 'P6.1', 'P7.1', 'P8.1', 'P9.1', 'P10 (high quality).1', 'P10-P1.1']\n",
      "2025-04-10 17:45:06,026 - INFO - Columns after renaming: ['date', 'QMJ-P1-LQ', 'QMJ-P2', 'QMJ-P3', 'QMJ-P4', 'QMJ-P5', 'QMJ-P6', 'QMJ-P7', 'QMJ-P8', 'QMJ-P9', 'QMJ-P10-HQ', 'QMJ']\n",
      "2025-04-10 17:45:06,035 - INFO - Rows after melting: 8899\n",
      "2025-04-10 17:45:06,371 - INFO - No new rows to load into factor_returns from C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 0).\n",
      "2025-04-10 17:45:06,378 - INFO - Skipping Century as data is already fully loaded.\n",
      "2025-04-10 17:45:06,379 - INFO - Skipping COM as data is already fully loaded.\n",
      "2025-04-10 17:45:06,380 - INFO - All data processing complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import VARCHAR, DATE, DECIMAL\n",
    "from sqlalchemy.sql import text\n",
    "import logging\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(), logging.FileHandler('load_aqr_data.log')]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Database connection\n",
    "engine = create_engine(\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/CWA_Fund_Database\"\n",
    "    \"?driver=ODBC+Driver+18+for+SQL+Server&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "# File configurations\n",
    "data_files = {\n",
    "    \"BAB_multi\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx\",\n",
    "        \"sheets\": {\n",
    "            \"BAB\": {\"sheet\": 0, \"header\": 18, \"paper\": \"Betting Against Beta (Frazzini and Pedersen, 2014)\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"BAB\", \"Global\": \"BAB\", \"Global Ex USA\": \"BAB\"}},\n",
    "            \"MKT\": {\"sheet\": 4, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"MKT\", \"Global\": \"MKT\", \"Global Ex USA\": \"MKT\"}},\n",
    "            \"SMB\": {\"sheet\": 5, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"SMB\", \"Global\": \"SMB\", \"Global Ex USA\": \"SMB\"}},\n",
    "            \"HML-FF\": {\"sheet\": 6, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-FF\", \"Global\": \"HML-FF\", \"Global Ex USA\": \"HML-FF\"}},\n",
    "            \"HML-D\": {\"sheet\": 7, \"header\": 18, \"paper\": \"The Devil's in HML's Details\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-D\", \"Global\": \"HML-D\", \"Global Ex USA\": \"HML-D\"}},\n",
    "            \"UMD\": {\"sheet\": 8, \"header\": 18, \"paper\": \"On Persistence in Mutual Fund Performance\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"UMD\", \"Global\": \"UMD\", \"Global Ex USA\": \"UMD\"}},\n",
    "            \"ME\": {\"sheet\": 9, \"header\": 18, \"paper\": \"AQR Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"ME\", \"Global\": \"ME\", \"Global Ex USA\": \"ME\"}},\n",
    "            \"RF\": {\"sheet\": 10, \"header\": 18, \"paper\": None, \"columns\": {\"DATE\": \"DATE\", \"Risk Free Rate\": \"RF\"}}\n",
    "        }\n",
    "    },\n",
    "    \"TSMOM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 17,\n",
    "        \"paper\": \"Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)\",\n",
    "        \"columns\": {\n",
    "            \"Unnamed: 0\": \"DATE\",\n",
    "            \"TSMOM\": \"TSM-MA\",\n",
    "            \"TSMOM^CM\": \"TSM-Com\",\n",
    "            \"TSMOM^EQ\": \"TSM-EQ\",\n",
    "            \"TSMOM^FI\": \"TSM-FI\",\n",
    "            \"TSMOM^FX\": \"TSM-FX\"\n",
    "        }\n",
    "    },\n",
    "    \"QMJ\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 18,\n",
    "        \"paper\": \"Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)\",\n",
    "        \"columns\": {\n",
    "            \"DATE\": \"DATE\",\n",
    "            \"P1 (low quality)\": \"QMJ-P1-LQ\",\n",
    "            \"P2\": \"QMJ-P2\",\n",
    "            \"P3\": \"QMJ-P3\",\n",
    "            \"P4\": \"QMJ-P4\",\n",
    "            \"P5\": \"QMJ-P5\",\n",
    "            \"P6\": \"QMJ-P6\",\n",
    "            \"P7\": \"QMJ-P7\",\n",
    "            \"P8\": \"QMJ-P8\",\n",
    "            \"P9\": \"QMJ-P9\",\n",
    "            \"P10 (high quality)\": \"QMJ-P10-HQ\",\n",
    "            \"P10-P1\": \"QMJ\"\n",
    "        }\n",
    "    },\n",
    "    \"Century\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 18,\n",
    "        \"paper\": \"Century of Factor Premia Monthly-Ilmanen et al. (2021)\",\n",
    "        \"columns\": {\n",
    "            \"Date\": \"DATE\",\n",
    "            \"US Stock Selection Value\": \"HML-FF-US\", \"US Stock Selection Momentum\": \"UMD-US\", \n",
    "            \"US Stock Selection Defensive\": \"BAB-US\", \"US Stock Selection Multi-style\": \"Multi-style-US\",\n",
    "            \"Intl Stock Selection Value\": \"HML-FF-Intl\", \"Intl Stock Selection Momentum\": \"UMD-Intl\", \n",
    "            \"Intl Stock Selection Defensive\": \"BAB-Intl\", \"Intl Stock Selection Multi-style\": \"Multi-style-Intl\",\n",
    "            \"Equity indices Value\": \"HML-Equity\", \"Equity indices Momentum\": \"UMD-Equity\", \n",
    "            \"Equity indices Carry\": \"Carry-Equity\", \"Equity indices Defensive\": \"BAB-Equity\", \n",
    "            \"Equity indices Multi-style\": \"Multi-style-Equity\",\n",
    "            \"Fixed income Value\": \"HML-FI\", \"Fixed income Momentum\": \"UMD-FI\", \n",
    "            \"Fixed income Carry\": \"Carry-FI\", \"Fixed income Defensive\": \"BAB-FI\", \n",
    "            \"Fixed income Multi-style\": \"Multi-style-FI\",\n",
    "            \"Currencies Value\": \"HML-FX\", \"Currencies Momentum\": \"UMD-FX\", \n",
    "            \"Currencies Carry\": \"Carry-FX\", \"Currencies Multi-style\": \"Multi-style-FX\",\n",
    "            \"Commodities Value\": \"HML-COM\", \"Commodities Momentum\": \"UMD-COM\", \n",
    "            \"Commodities Carry\": \"Carry-COM\", \"Commodities Multi-style\": \"Multi-style-COM\",\n",
    "            \"All Stock Selection Value\": \"HML-All-SS\", \"All Stock Selection Momentum\": \"UMD-All-SS\", \n",
    "            \"All Stock Selection Defensive\": \"BAB-All-SS\", \"All Stock Selection Multi-style\": \"Multi-style-All-SS\",\n",
    "            \"All Macro Value\": \"HML-All-Macro\", \"All Macro Momentum\": \"UMD-All-Macro\", \n",
    "            \"All Macro Carry\": \"Carry-All-Macro\", \"All Macro Defensive\": \"BAB-All-Macro\", \n",
    "            \"All Macro Multi-style\": \"Multi-style-All-Macro\",\n",
    "            \"All asset classes Value\": \"HML-All\", \"All asset classes Momentum\": \"UMD-All\", \n",
    "            \"All asset classes Carry\": \"Carry-All\", \"All asset classes Defensive\": \"BAB-All\", \n",
    "            \"All asset classes Multi-style\": \"Multi-style-All\",\n",
    "            \"Equity indices Market\": \"MKT-Equity\", \"Fixed income Market\": \"MKT-FI\", \n",
    "            \"Commodities Market\": \"MKT-COM\", \"All Macro Market\": \"MKT-All-Macro\"\n",
    "        }\n",
    "    },\n",
    "    \"COM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 10,\n",
    "        \"paper\": \"Commodities for the Long Run\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def process_factors(file_config, sheet=0, is_com=False, parent_path=None):\n",
    "    file_path = parent_path if parent_path else file_config['path']\n",
    "    logger.info(f\"Processing {file_path} (sheet {sheet})...\")\n",
    "    try:\n",
    "        # Read Excel with correct header row\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet, header=file_config['header'])\n",
    "        logger.info(f\"Raw columns: {list(df.columns)}\")\n",
    "        \n",
    "        if is_com:\n",
    "            df.columns = [\n",
    "                'date', 'excess_return_eqwt', 'excess_spot_return_eqwt', 'ir_adjusted_carry_eqwt',\n",
    "                'spot_return_eqwt', 'carry_eqwt', 'excess_return_long_short', 'excess_spot_return_long_short',\n",
    "                'ir_adjusted_carry_long_short', 'aggregate_backwardation_contango', \n",
    "                'state_backwardation_contango', 'state_inflation'\n",
    "            ]\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            df['associated_paper'] = file_config['paper']\n",
    "            df = df.dropna(subset=['date'])\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                existing = pd.read_sql(\"SELECT date FROM aqr_cmdty_factors\", connection)\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(existing['date'])\n",
    "            \n",
    "            df['date_str'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_new = df[~df['date_str'].isin(existing_keys)].drop(columns=['date_str'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                df_new.to_sql(\n",
    "                    'aqr_cmdty_factors',\n",
    "                    engine,\n",
    "                    if_exists='append',\n",
    "                    index=False,\n",
    "                    dtype={\n",
    "                        'date': DATE,\n",
    "                        'excess_return_eqwt': DECIMAL(15, 6),\n",
    "                        'excess_spot_return_eqwt': DECIMAL(15, 6),\n",
    "                        'ir_adjusted_carry_eqwt': DECIMAL(15, 6),\n",
    "                        'spot_return_eqwt': DECIMAL(15, 6),\n",
    "                        'carry_eqwt': DECIMAL(15, 6),\n",
    "                        'excess_return_long_short': DECIMAL(15, 6),\n",
    "                        'excess_spot_return_long_short': DECIMAL(15, 6),\n",
    "                        'ir_adjusted_carry_long_short': DECIMAL(15, 6),\n",
    "                        'aggregate_backwardation_contango': DECIMAL(15, 6),\n",
    "                        'state_backwardation_contango': VARCHAR(50),\n",
    "                        'state_inflation': VARCHAR(50),\n",
    "                        'associated_paper': VARCHAR(100)\n",
    "                    }\n",
    "                )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into aqr_cmdty_factors.\")\n",
    "            else:\n",
    "                logger.info(\"No new rows to load into aqr_cmdty_factors.\")\n",
    "        else:\n",
    "            # Identify date column\n",
    "            date_col = next(\n",
    "                (col for col in df.columns if isinstance(col, str) and ('DATE' in col.upper() or 'Date' in col)),\n",
    "                df.columns[0]\n",
    "            )\n",
    "            \n",
    "            # Filter and rename columns, keeping original column names for region mapping\n",
    "            if 'columns' in file_config:\n",
    "                valid_cols = list(file_config['columns'].keys())\n",
    "                if date_col not in valid_cols:\n",
    "                    valid_cols.append(date_col)\n",
    "                df = df[[col for col in df.columns if col in valid_cols]]\n",
    "                orig_cols = df.columns.tolist()\n",
    "                new_columns = []\n",
    "                for col in df.columns:\n",
    "                    if col == date_col:\n",
    "                        new_columns.append('date')\n",
    "                    else:\n",
    "                        new_columns.append(file_config['columns'].get(col, col))\n",
    "                df.columns = new_columns\n",
    "            \n",
    "            logger.info(f\"Columns after renaming: {list(df.columns)}\")\n",
    "            \n",
    "            # Parse dates\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            \n",
    "            # Melt the DataFrame with value_vars to track original columns\n",
    "            value_vars = [col for col in df.columns if col != 'date']\n",
    "            df_long = df.melt(id_vars=['date'], value_vars=value_vars, var_name='factor', value_name='value')\n",
    "            df_long = df_long.dropna(subset=['value', 'date'])\n",
    "            logger.info(f\"Rows after melting: {len(df_long)}\")\n",
    "            \n",
    "            # Assign asset class and region\n",
    "            if 'TSMOM' in file_config['path']:\n",
    "                df_long['asset_class'] = df_long['factor'].map({\n",
    "                    \"TSM-MA\": \"Multi-Asset\",\n",
    "                    \"TSM-Com\": \"Commodities\",\n",
    "                    \"TSM-EQ\": \"Equity\",\n",
    "                    \"TSM-FI\": \"Fixed Income\",\n",
    "                    \"TSM-FX\": \"Currencies\"\n",
    "                })\n",
    "                df_long['region'] = \"Global\"\n",
    "            elif 'Quality Minus Junk' in file_config['path']:\n",
    "                df_long['asset_class'] = \"Equity\"\n",
    "                df_long['region'] = df_long['date'].apply(\n",
    "                    lambda x: \"USA\" if x < pd.Timestamp(\"1989-07-31\") else \"Global\"\n",
    "                )\n",
    "            elif 'Century' in file_config['path']:\n",
    "                df_long['asset_class'] = df_long['factor'].str.extract(\n",
    "                    '(Stock Selection|Equity indices|Fixed income|Currencies|Commodities|All Macro|All asset classes)'\n",
    "                ).fillna('Equity')\n",
    "                df_long['region'] = df_long['factor'].apply(\n",
    "                    lambda x: 'US' if 'US' in x else 'Intl' if 'Intl' in x else 'Global'\n",
    "                )\n",
    "            else:  # BAB_multi\n",
    "                df_long['asset_class'] = \"Equity\" if 'Risk Free Rate' not in file_config['columns'].values() else \"Fixed Income\"\n",
    "                # Map regions based on original column names\n",
    "                region_map = {}\n",
    "                factor_map = {}\n",
    "                for orig_col, factor in file_config['columns'].items():\n",
    "                    if orig_col == 'DATE':\n",
    "                        continue\n",
    "                    if orig_col == 'USA':\n",
    "                        region_map[factor] = 'USA'\n",
    "                    elif orig_col == 'Global':\n",
    "                        region_map[factor] = 'Global'\n",
    "                    elif orig_col == 'Global Ex USA':\n",
    "                        region_map[factor] = 'Intl'\n",
    "                    elif orig_col == 'Risk Free Rate':\n",
    "                        region_map[factor] = 'USA'\n",
    "                    factor_map[orig_col] = factor\n",
    "                \n",
    "                # Assign region and adjust factor\n",
    "                df_long['region'] = df_long['factor'].map(lambda x: region_map.get(x, 'Unknown'))\n",
    "                df_long['factor'] = df_long.apply(\n",
    "                    lambda row: f\"{row['factor']}_{row['region']}\" if row['factor'] != 'RF' and row['region'] != 'Unknown' else row['factor'], axis=1\n",
    "                )\n",
    "            \n",
    "            df_long['associated_paper'] = file_config['paper']\n",
    "            df_long = df_long[['factor', 'date', 'associated_paper', 'asset_class', 'value', 'region']]\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                existing = pd.read_sql(\n",
    "                    \"SELECT factor, date, associated_paper, asset_class FROM factor_returns\",\n",
    "                    connection\n",
    "                )\n",
    "                existing['asset_class'] = existing['asset_class'].fillna('Unknown')\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(tuple(row) for row in existing[['factor', 'date', 'associated_paper', 'asset_class']].values)\n",
    "            \n",
    "            df_long['date_str'] = df_long['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_long['asset_class'] = df_long['asset_class'].fillna('Unknown')\n",
    "            df_long['key'] = df_long.apply(\n",
    "                lambda row: (row['factor'], row['date_str'], row['associated_paper'] if row['associated_paper'] else 'None', row['asset_class']), axis=1\n",
    "            )\n",
    "            df_new = df_long[~df_long['key'].isin(existing_keys)].drop(columns=['date_str', 'key'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                df_new.to_sql(\n",
    "                    'factor_returns',\n",
    "                    engine,\n",
    "                    if_exists='append',\n",
    "                    index=False,\n",
    "                    dtype={\n",
    "                        'factor': VARCHAR(50),\n",
    "                        'date': DATE,\n",
    "                        'associated_paper': VARCHAR(100),\n",
    "                        'asset_class': VARCHAR(50),\n",
    "                        'value': DECIMAL(15, 6),\n",
    "                        'region': VARCHAR(50)\n",
    "                    }\n",
    "                )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into factor_returns from {file_path} (sheet {sheet}).\")\n",
    "            else:\n",
    "                logger.info(f\"No new rows to load into factor_returns from {file_path} (sheet {sheet}).\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing {file_path} (sheet {sheet}): {str(e)}\")\n",
    "\n",
    "# Process all datasets, skipping Century and COM since they're complete\n",
    "for key, config in data_files.items():\n",
    "    if key in [\"Century\", \"COM\"]:\n",
    "        logger.info(f\"Skipping {key} as data is already fully loaded.\")\n",
    "        continue\n",
    "    if key == \"BAB_multi\":\n",
    "        for subkey, subconfig in config['sheets'].items():\n",
    "            process_factors(subconfig, sheet=subconfig['sheet'], parent_path=config['path'])\n",
    "    else:\n",
    "        process_factors(config, sheet=config['sheet'])\n",
    "\n",
    "logger.info(\"All data processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b18bc87a-4627-4bde-8bfa-e1df1e00ad30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 17:56:45,191 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:56:46,503 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:56:46,505 - INFO - Columns after renaming: ['date', 'BAB', 'BAB', 'BAB']\n",
      "2025-04-10 17:56:46,518 - INFO - Rows after melting: 2039\n",
      "2025-04-10 17:56:46,519 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 0): 'path'\n",
      "2025-04-10 17:56:46,521 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 4)...\n",
      "2025-04-10 17:56:47,150 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:56:47,152 - INFO - Columns after renaming: ['date', 'MKT', 'MKT', 'MKT']\n",
      "2025-04-10 17:56:47,165 - INFO - Rows after melting: 2166\n",
      "2025-04-10 17:56:47,166 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 4): 'path'\n",
      "2025-04-10 17:56:47,167 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 5)...\n",
      "2025-04-10 17:56:47,726 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:56:47,728 - INFO - Columns after renaming: ['date', 'SMB', 'SMB', 'SMB']\n",
      "2025-04-10 17:56:47,739 - INFO - Rows after melting: 2151\n",
      "2025-04-10 17:56:47,740 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 5): 'path'\n",
      "2025-04-10 17:56:47,741 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 6)...\n",
      "2025-04-10 17:56:48,390 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:56:48,393 - INFO - Columns after renaming: ['date', 'HML-FF', 'HML-FF', 'HML-FF']\n",
      "2025-04-10 17:56:48,404 - INFO - Rows after melting: 2151\n",
      "2025-04-10 17:56:48,406 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 6): 'path'\n",
      "2025-04-10 17:56:48,407 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 7)...\n",
      "2025-04-10 17:56:48,988 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:56:48,990 - INFO - Columns after renaming: ['date', 'HML-D', 'HML-D', 'HML-D']\n",
      "2025-04-10 17:56:49,003 - INFO - Rows after melting: 2154\n",
      "2025-04-10 17:56:49,004 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 7): 'path'\n",
      "2025-04-10 17:56:49,005 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 8)...\n",
      "2025-04-10 17:56:49,577 - INFO - Raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:56:49,580 - INFO - Columns after renaming: ['date', 'UMD', 'UMD', 'UMD']\n",
      "2025-04-10 17:56:49,613 - INFO - Rows after melting: 2136\n",
      "2025-04-10 17:56:49,615 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 8): 'path'\n",
      "2025-04-10 17:56:49,617 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 9)...\n",
      "2025-04-10 17:56:50,130 - INFO - Raw columns: ['DATE', 'AUT', 'HKG', 'ESP', 'GBR', 'ITA', 'DEU', 'DNK', 'NZL', 'NLD', 'USA', 'PRT', 'BEL', 'ISR', 'GRC', 'NOR', 'SGP', 'CHE', 'IRL', 'CAN', 'FIN', 'JPN', 'SWE', 'FRA', 'AUS', 'Global Ex USA', 'Global', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 17:56:50,132 - INFO - Columns after renaming: ['date', 'ME', 'ME', 'ME']\n",
      "2025-04-10 17:56:50,145 - INFO - Rows after melting: 2210\n",
      "2025-04-10 17:56:50,146 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 9): 'path'\n",
      "2025-04-10 17:56:50,147 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 10)...\n",
      "2025-04-10 17:56:50,633 - INFO - Raw columns: ['DATE', 'Risk Free Rate']\n",
      "2025-04-10 17:56:50,635 - INFO - Columns after renaming: ['date', 'RF']\n",
      "2025-04-10 17:56:50,646 - INFO - Rows after melting: 1183\n",
      "2025-04-10 17:56:50,648 - ERROR - Error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 10): 'path'\n",
      "2025-04-10 17:56:50,648 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:56:50,820 - INFO - Raw columns: ['Unnamed: 0', 'TSMOM', 'TSMOM^CM', 'TSMOM^EQ', 'TSMOM^FI', 'TSMOM^FX']\n",
      "2025-04-10 17:56:50,821 - INFO - Columns after renaming: ['date', 'TSM-MA', 'TSM-Com', 'TSM-EQ', 'TSM-FI', 'TSM-FX']\n",
      "2025-04-10 17:56:50,828 - INFO - Rows after melting: 2405\n",
      "2025-04-10 17:56:51,238 - INFO - No new rows to load into factor_returns from C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet 0).\n",
      "2025-04-10 17:56:51,246 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 0)...\n",
      "2025-04-10 17:56:51,685 - INFO - Raw columns: ['DATE', 'P1 (low quality)', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10 (high quality)', 'P10-P1', 'P1 (low quality).1', 'P2.1', 'P3.1', 'P4.1', 'P5.1', 'P6.1', 'P7.1', 'P8.1', 'P9.1', 'P10 (high quality).1', 'P10-P1.1']\n",
      "2025-04-10 17:56:51,687 - INFO - Columns after renaming: ['date', 'QMJ-P1-LQ', 'QMJ-P2', 'QMJ-P3', 'QMJ-P4', 'QMJ-P5', 'QMJ-P6', 'QMJ-P7', 'QMJ-P8', 'QMJ-P9', 'QMJ-P10-HQ', 'QMJ']\n",
      "2025-04-10 17:56:51,700 - INFO - Rows after melting: 8899\n",
      "2025-04-10 17:56:52,053 - INFO - No new rows to load into factor_returns from C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 0).\n",
      "2025-04-10 17:56:52,062 - INFO - Skipping Century as data is already fully loaded.\n",
      "2025-04-10 17:56:52,063 - INFO - Skipping COM as data is already fully loaded.\n",
      "2025-04-10 17:56:52,064 - INFO - All data processing complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import VARCHAR, DATE, DECIMAL\n",
    "from sqlalchemy.sql import text\n",
    "import logging\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(), logging.FileHandler('load_aqr_data.log')]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Database connection\n",
    "engine = create_engine(\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/CWA_Fund_Database\"\n",
    "    \"?driver=ODBC+Driver+18+for+SQL+Server&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "# File configurations (Lines 20-149)\n",
    "data_files = {\n",
    "    \"BAB_multi\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx\",\n",
    "        \"sheets\": {\n",
    "            \"BAB\": {\"sheet\": 0, \"header\": 18, \"paper\": \"Betting Against Beta (Frazzini and Pedersen, 2014)\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"BAB\", \"Global\": \"BAB\", \"Global Ex USA\": \"BAB\"}},\n",
    "            \"MKT\": {\"sheet\": 4, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"MKT\", \"Global\": \"MKT\", \"Global Ex USA\": \"MKT\"}},\n",
    "            \"SMB\": {\"sheet\": 5, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"SMB\", \"Global\": \"SMB\", \"Global Ex USA\": \"SMB\"}},\n",
    "            \"HML-FF\": {\"sheet\": 6, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-FF\", \"Global\": \"HML-FF\", \"Global Ex USA\": \"HML-FF\"}},\n",
    "            \"HML-D\": {\"sheet\": 7, \"header\": 18, \"paper\": \"The Devil's in HML's Details\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-D\", \"Global\": \"HML-D\", \"Global Ex USA\": \"HML-D\"}},\n",
    "            \"UMD\": {\"sheet\": 8, \"header\": 18, \"paper\": \"On Persistence in Mutual Fund Performance\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"UMD\", \"Global\": \"UMD\", \"Global Ex USA\": \"UMD\"}},\n",
    "            \"ME\": {\"sheet\": 9, \"header\": 18, \"paper\": \"AQR Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"ME\", \"Global\": \"ME\", \"Global Ex USA\": \"ME\"}},\n",
    "            \"RF\": {\"sheet\": 10, \"header\": 18, \"paper\": None, \"columns\": {\"DATE\": \"DATE\", \"Risk Free Rate\": \"RF\"}}\n",
    "        }\n",
    "    },\n",
    "    \"TSMOM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 17,\n",
    "        \"paper\": \"Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)\",\n",
    "        \"columns\": {\n",
    "            \"Unnamed: 0\": \"DATE\",\n",
    "            \"TSMOM\": \"TSM-MA\",\n",
    "            \"TSMOM^CM\": \"TSM-Com\",\n",
    "            \"TSMOM^EQ\": \"TSM-EQ\",\n",
    "            \"TSMOM^FI\": \"TSM-FI\",\n",
    "            \"TSMOM^FX\": \"TSM-FX\"\n",
    "        }\n",
    "    },\n",
    "    \"QMJ\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 18,\n",
    "        \"paper\": \"Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)\",\n",
    "        \"columns\": {\n",
    "            \"DATE\": \"DATE\",\n",
    "            \"P1 (low quality)\": \"QMJ-P1-LQ\",\n",
    "            \"P2\": \"QMJ-P2\",\n",
    "            \"P3\": \"QMJ-P3\",\n",
    "            \"P4\": \"QMJ-P4\",\n",
    "            \"P5\": \"QMJ-P5\",\n",
    "            \"P6\": \"QMJ-P6\",\n",
    "            \"P7\": \"QMJ-P7\",\n",
    "            \"P8\": \"QMJ-P8\",\n",
    "            \"P9\": \"QMJ-P9\",\n",
    "            \"P10 (high quality)\": \"QMJ-P10-HQ\",\n",
    "            \"P10-P1\": \"QMJ\"\n",
    "        }\n",
    "    },\n",
    "    \"Century\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 18,\n",
    "        \"paper\": \"Century of Factor Premia Monthly-Ilmanen et al. (2021)\",\n",
    "        \"columns\": {\n",
    "            \"Date\": \"DATE\",\n",
    "            \"US Stock Selection Value\": \"HML-FF-US\", \"US Stock Selection Momentum\": \"UMD-US\", \n",
    "            \"US Stock Selection Defensive\": \"BAB-US\", \"US Stock Selection Multi-style\": \"Multi-style-US\",\n",
    "            \"Intl Stock Selection Value\": \"HML-FF-Intl\", \"Intl Stock Selection Momentum\": \"UMD-Intl\", \n",
    "            \"Intl Stock Selection Defensive\": \"BAB-Intl\", \"Intl Stock Selection Multi-style\": \"Multi-style-Intl\",\n",
    "            \"Equity indices Value\": \"HML-Equity\", \"Equity indices Momentum\": \"UMD-Equity\", \n",
    "            \"Equity indices Carry\": \"Carry-Equity\", \"Equity indices Defensive\": \"BAB-Equity\", \n",
    "            \"Equity indices Multi-style\": \"Multi-style-Equity\",\n",
    "            \"Fixed income Value\": \"HML-FI\", \"Fixed income Momentum\": \"UMD-FI\", \n",
    "            \"Fixed income Carry\": \"Carry-FI\", \"Fixed income Defensive\": \"BAB-FI\", \n",
    "            \"Fixed income Multi-style\": \"Multi-style-FI\",\n",
    "            \"Currencies Value\": \"HML-FX\", \"Currencies Momentum\": \"UMD-FX\", \n",
    "            \"Currencies Carry\": \"Carry-FX\", \"Currencies Multi-style\": \"Multi-style-FX\",\n",
    "            \"Commodities Value\": \"HML-COM\", \"Commodities Momentum\": \"UMD-COM\", \n",
    "            \"Commodities Carry\": \"Carry-COM\", \"Commodities Multi-style\": \"Multi-style-COM\",\n",
    "            \"All Stock Selection Value\": \"HML-All-SS\", \"All Stock Selection Momentum\": \"UMD-All-SS\", \n",
    "            \"All Stock Selection Defensive\": \"BAB-All-SS\", \"All Stock Selection Multi-style\": \"Multi-style-All-SS\",\n",
    "            \"All Macro Value\": \"HML-All-Macro\", \"All Macro Momentum\": \"UMD-All-Macro\", \n",
    "            \"All Macro Carry\": \"Carry-All-Macro\", \"All Macro Defensive\": \"BAB-All-Macro\", \n",
    "            \"All Macro Multi-style\": \"Multi-style-All-Macro\",\n",
    "            \"All asset classes Value\": \"HML-All\", \"All asset classes Momentum\": \"UMD-All\", \n",
    "            \"All asset classes Carry\": \"Carry-All\", \"All asset classes Defensive\": \"BAB-All\", \n",
    "            \"All asset classes Multi-style\": \"Multi-style-All\",\n",
    "            \"Equity indices Market\": \"MKT-Equity\", \"Fixed income Market\": \"MKT-FI\", \n",
    "            \"Commodities Market\": \"MKT-COM\", \"All Macro Market\": \"MKT-All-Macro\"\n",
    "        }\n",
    "    },\n",
    "    \"COM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 10,\n",
    "        \"paper\": \"Commodities for the Long Run\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Line 150\n",
    "def process_factors(file_config, sheet=0, is_com=False, parent_path=None):\n",
    "    file_path = parent_path if parent_path else file_config['path']\n",
    "    logger.info(f\"Processing {file_path} (sheet {sheet})...\")\n",
    "    try:\n",
    "        # Read Excel with correct header row\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet, header=file_config['header'])\n",
    "        logger.info(f\"Raw columns: {list(df.columns)}\")\n",
    "        \n",
    "        if is_com:\n",
    "            df.columns = [\n",
    "                'date', 'excess_return_eqwt', 'excess_spot_return_eqwt', 'ir_adjusted_carry_eqwt',\n",
    "                'spot_return_eqwt', 'carry_eqwt', 'excess_return_long_short', 'excess_spot_return_long_short',\n",
    "                'ir_adjusted_carry_long_short', 'aggregate_backwardation_contango', \n",
    "                'state_backwardation_contango', 'state_inflation'\n",
    "            ]\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            df['associated_paper'] = file_config['paper']\n",
    "            df = df.dropna(subset=['date'])\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                existing = pd.read_sql(\"SELECT date FROM aqr_cmdty_factors\", connection)\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(existing['date'])\n",
    "            \n",
    "            df['date_str'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_new = df[~df['date_str'].isin(existing_keys)].drop(columns=['date_str'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                df_new.to_sql(\n",
    "                    'aqr_cmdty_factors',\n",
    "                    engine,\n",
    "                    if_exists='append',\n",
    "                    index=False,\n",
    "                    dtype={\n",
    "                        'date': DATE,\n",
    "                        'excess_return_eqwt': DECIMAL(15, 6),\n",
    "                        'excess_spot_return_eqwt': DECIMAL(15, 6),\n",
    "                        'ir_adjusted_carry_eqwt': DECIMAL(15, 6),\n",
    "                        'spot_return_eqwt': DECIMAL(15, 6),\n",
    "                        'carry_eqwt': DECIMAL(15, 6),\n",
    "                        'excess_return_long_short': DECIMAL(15, 6),\n",
    "                        'excess_spot_return_long_short': DECIMAL(15, 6),\n",
    "                        'ir_adjusted_carry_long_short': DECIMAL(15, 6),\n",
    "                        'aggregate_backwardation_contango': DECIMAL(15, 6),\n",
    "                        'state_backwardation_contango': VARCHAR(50),\n",
    "                        'state_inflation': VARCHAR(50),\n",
    "                        'associated_paper': VARCHAR(100)\n",
    "                    }\n",
    "                )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into aqr_cmdty_factors.\")\n",
    "            else:\n",
    "                logger.info(\"No new rows to load into aqr_cmdty_factors.\")\n",
    "        else:\n",
    "            # Identify date column (Line 209)\n",
    "            date_col = next(\n",
    "                (col for col in df.columns if isinstance(col, str) and ('DATE' in col.upper() or 'Date' in col)),\n",
    "                df.columns[0]\n",
    "            )\n",
    "            \n",
    "            # Filter and rename columns, keeping track of original columns (Line 214)\n",
    "            orig_cols = df.columns.tolist()\n",
    "            if 'columns' in file_config:\n",
    "                valid_cols = list(file_config['columns'].keys())\n",
    "                if date_col not in valid_cols:\n",
    "                    valid_cols.append(date_col)\n",
    "                df = df[[col for col in df.columns if col in valid_cols]]\n",
    "                new_columns = []\n",
    "                for col in df.columns:\n",
    "                    if col == date_col:\n",
    "                        new_columns.append('date')\n",
    "                    else:\n",
    "                        new_columns.append(file_config['columns'].get(col, col))\n",
    "                df.columns = new_columns\n",
    "            \n",
    "            logger.info(f\"Columns after renaming: {list(df.columns)}\")\n",
    "            \n",
    "            # Parse dates (Line 236)\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            \n",
    "            # Melt the DataFrame with value_vars to track original columns (Line 239)\n",
    "            value_vars = [col for col in df.columns if col != 'date']\n",
    "            df_long = df.melt(id_vars=['date'], value_vars=value_vars, var_name='factor', value_name='value')\n",
    "            df_long = df_long.dropna(subset=['value', 'date'])\n",
    "            logger.info(f\"Rows after melting: {len(df_long)}\")\n",
    "            \n",
    "            # Assign asset class and region (Line 246)\n",
    "            if 'TSMOM' in file_config['path']:\n",
    "                df_long['asset_class'] = df_long['factor'].map({\n",
    "                    \"TSM-MA\": \"Multi-Asset\",\n",
    "                    \"TSM-Com\": \"Commodities\",\n",
    "                    \"TSM-EQ\": \"Equity\",\n",
    "                    \"TSM-FI\": \"Fixed Income\",\n",
    "                    \"TSM-FX\": \"Currencies\"\n",
    "                })\n",
    "                df_long['region'] = \"Global\"\n",
    "            elif 'Quality Minus Junk' in file_config['path']:\n",
    "                df_long['asset_class'] = \"Equity\"\n",
    "                df_long['region'] = df_long['date'].apply(\n",
    "                    lambda x: \"USA\" if x < pd.Timestamp(\"1989-07-31\") else \"Global\"\n",
    "                )\n",
    "            elif 'Century' in file_config['path']:\n",
    "                df_long['asset_class'] = df_long['factor'].str.extract(\n",
    "                    '(Stock Selection|Equity indices|Fixed income|Currencies|Commodities|All Macro|All asset classes)'\n",
    "                ).fillna('Equity')\n",
    "                df_long['region'] = df_long['factor'].apply(\n",
    "                    lambda x: 'US' if 'US' in x else 'Intl' if 'Intl' in x else 'Global'\n",
    "                )\n",
    "            else:  # BAB_multi (Line 260)\n",
    "                df_long['asset_class'] = \"Equity\" if 'Risk Free Rate' not in file_config['columns'].values() else \"Fixed Income\"\n",
    "                # Map regions based on original column names before melting (Lines 262-272)\n",
    "                region_map = {}\n",
    "                for i, col in enumerate(orig_cols):\n",
    "                    if col == date_col:\n",
    "                        continue\n",
    "                    factor = file_config['columns'].get(col, col)\n",
    "                    if col == 'USA':\n",
    "                        region_map[factor] = 'USA'\n",
    "                    elif col == 'Global':\n",
    "                        region_map[factor] = 'Global'\n",
    "                    elif col == 'Global Ex USA':\n",
    "                        region_map[factor] = 'Intl'\n",
    "                    elif col == 'Risk Free Rate':\n",
    "                        region_map[factor] = 'USA'\n",
    "                # Assign region and adjust factor (Lines 274-278)\n",
    "                df_long['region'] = df_long['factor'].map(region_map)\n",
    "                df_long['factor'] = df_long.apply(\n",
    "                    lambda row: f\"{row['factor']}_{row['region']}\" if row['factor'] != 'RF' and row['region'] is not None else row['factor'], axis=1\n",
    "                )\n",
    "            \n",
    "            df_long['associated_paper'] = file_config['paper']\n",
    "            df_long = df_long[['factor', 'date', 'associated_paper', 'asset_class', 'value', 'region']]\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                existing = pd.read_sql(\n",
    "                    \"SELECT factor, date, associated_paper, asset_class FROM factor_returns\",\n",
    "                    connection\n",
    "                )\n",
    "                existing['asset_class'] = existing['asset_class'].fillna('Unknown')\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(tuple(row) for row in existing[['factor', 'date', 'associated_paper', 'asset_class']].values)\n",
    "            \n",
    "            df_long['date_str'] = df_long['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_long['asset_class'] = df_long['asset_class'].fillna('Unknown')\n",
    "            df_long['key'] = df_long.apply(\n",
    "                lambda row: (row['factor'], row['date_str'], row['associated_paper'] if row['associated_paper'] else 'None', row['asset_class']), axis=1\n",
    "            )\n",
    "            df_new = df_long[~df_long['key'].isin(existing_keys)].drop(columns=['date_str', 'key'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                df_new.to_sql(\n",
    "                    'factor_returns',\n",
    "                    engine,\n",
    "                    if_exists='append',\n",
    "                    index=False,\n",
    "                    dtype={\n",
    "                        'factor': VARCHAR(50),\n",
    "                        'date': DATE,\n",
    "                        'associated_paper': VARCHAR(100),\n",
    "                        'asset_class': VARCHAR(50),\n",
    "                        'value': DECIMAL(15, 6),\n",
    "                        'region': VARCHAR(50)\n",
    "                    }\n",
    "                )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into factor_returns from {file_path} (sheet {sheet}).\")\n",
    "            else:\n",
    "                logger.info(f\"No new rows to load into factor_returns from {file_path} (sheet {sheet}).\")\n",
    "            \n",
    "    except Exception as e:  # Line 366\n",
    "        logger.error(f\"Error processing {file_path} (sheet {sheet}): {str(e)}\")\n",
    "\n",
    "# Process all datasets, skipping Century and COM since they're complete (Line 369)\n",
    "for key, config in data_files.items():\n",
    "    if key in [\"Century\", \"COM\"]:\n",
    "        logger.info(f\"Skipping {key} as data is already fully loaded.\")\n",
    "        continue\n",
    "    if key == \"BAB_multi\":\n",
    "        for subkey, subconfig in config['sheets'].items():\n",
    "            process_factors(subconfig, sheet=subconfig['sheet'], parent_path=config['path'])\n",
    "    else:\n",
    "        process_factors(config, sheet=config['sheet'])\n",
    "\n",
    "logger.info(\"All data processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "688c03b2-c749-4d4d-8eab-01072e519596",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 18:04:50,153 - INFO - Processing dataset: BAB_multi\n",
      "2025-04-10 18:04:50,155 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 0) with is_com=False\n",
      "2025-04-10 18:04:51,730 - INFO - Read 1129 rows with raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 18:04:51,733 - INFO - Columns after renaming: ['date', 'BAB', 'BAB', 'BAB']\n",
      "2025-04-10 18:04:52,682 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 0): IntegrityError: (pyodbc.IntegrityError) ('23000', \"[23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Violation of PRIMARY KEY constraint 'PK__factor_r__C3CBC7054E79A6D5'. Cannot insert duplicate key in object 'dbo.factor_returns'. The duplicate key value is (BAB_Intl, 1987-02-28, Betting Against Beta (Frazzini and Pedersen, 2014)). (2627) (SQLExecDirectW); [23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]The statement has been terminated. (3621)\")\n",
      "[SQL: INSERT INTO factor_returns (factor, date, associated_paper, asset_class, value, region) VALUES (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ... 6723 characters truncated ... , (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?)]\n",
      "[parameters: ('BAB_Intl', datetime.datetime(2018, 3, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.024726359719057713, 'Intl', 'BAB_Intl', datetime.datetime(2018, 4, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.0007799553393408837, 'Intl', 'BAB_Intl', datetime.datetime(2018, 5, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.0061733720885607715, 'Intl', 'BAB_Intl', datetime.datetime(2018, 6, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.023681918622375155, 'Intl', 'BAB_Intl', datetime.datetime(2018, 7, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', -0.003681432428082633, 'Intl', 'BAB_Intl', datetime.datetime(2018, 8, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', -0.012114392481366903, 'Intl', 'BAB_Intl', datetime.datetime(2018, 9, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', -0.006209095953888497, 'Intl', 'BAB_Intl', datetime.datetime(2018, 10, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.02111187283759784, 'Intl', 'BAB_Intl', datetime.datetime(2018, 11, 30, 0, 0) ... 1994 parameters truncated ... -0.028234639669040655, 'Intl', 'BAB_Intl', datetime.datetime(2008, 9, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', -0.04015145002280483, 'Intl', 'BAB_Intl', datetime.datetime(2008, 10, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', -0.06507843668705648, 'Intl', 'BAB_Intl', datetime.datetime(2008, 11, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', -0.025706387072742018, 'Intl', 'BAB_Intl', datetime.datetime(2008, 12, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', -0.04223042725213571, 'Intl', 'BAB_Intl', datetime.datetime(2009, 1, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.053884771313794676, 'Intl', 'BAB_Intl', datetime.datetime(2009, 2, 28, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', -0.0013600102720203353, 'Intl', 'BAB_Intl', datetime.datetime(2009, 3, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', -0.043388589580733355, 'Intl', 'BAB_Intl', datetime.datetime(2009, 4, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', -0.07292510221661865, 'Intl')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-04-10 18:04:52,683 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 4) with is_com=False\n",
      "2025-04-10 18:04:53,389 - INFO - Read 1182 rows with raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 18:04:53,392 - INFO - Columns after renaming: ['date', 'MKT', 'MKT', 'MKT']\n",
      "2025-04-10 18:04:54,026 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 4): IntegrityError: (pyodbc.IntegrityError) ('23000', \"[23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Violation of PRIMARY KEY constraint 'PK__factor_r__C3CBC7054E79A6D5'. Cannot insert duplicate key in object 'dbo.factor_returns'. The duplicate key value is (MKT_Intl, 1984-01-31, Fama-French Factors). (2627) (SQLExecDirectW); [23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]The statement has been terminated. (3621)\")\n",
      "[SQL: INSERT INTO factor_returns (factor, date, associated_paper, asset_class, value, region) VALUES (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ... 6723 characters truncated ... , (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?)]\n",
      "[parameters: ('MKT_Intl', datetime.datetime(2013, 10, 31, 0, 0), 'Fama-French Factors', 'Equity', 0.040744699841014996, 'Intl', 'MKT_Intl', datetime.datetime(2013, 11, 30, 0, 0), 'Fama-French Factors', 'Equity', 0.02651336571903575, 'Intl', 'MKT_Intl', datetime.datetime(2013, 12, 31, 0, 0), 'Fama-French Factors', 'Equity', 0.026990113917166176, 'Intl', 'MKT_Intl', datetime.datetime(2014, 1, 31, 0, 0), 'Fama-French Factors', 'Equity', -0.030288442319910888, 'Intl', 'MKT_Intl', datetime.datetime(2014, 2, 28, 0, 0), 'Fama-French Factors', 'Equity', 0.04681951057275386, 'Intl', 'MKT_Intl', datetime.datetime(2014, 3, 31, 0, 0), 'Fama-French Factors', 'Equity', 0.004226895440435092, 'Intl', 'MKT_Intl', datetime.datetime(2014, 4, 30, 0, 0), 'Fama-French Factors', 'Equity', 0.0010398803443404372, 'Intl', 'MKT_Intl', datetime.datetime(2014, 5, 31, 0, 0), 'Fama-French Factors', 'Equity', 0.020276557704712726, 'Intl', 'MKT_Intl', datetime.datetime(2014, 6, 30, 0, 0) ... 1994 parameters truncated ... -0.09140246944807537, 'Intl', 'MKT_Intl', datetime.datetime(2001, 3, 31, 0, 0), 'Fama-French Factors', 'Equity', -0.07494531599005091, 'Intl', 'MKT_Intl', datetime.datetime(2001, 4, 30, 0, 0), 'Fama-French Factors', 'Equity', 0.07508485497454191, 'Intl', 'MKT_Intl', datetime.datetime(2001, 5, 31, 0, 0), 'Fama-French Factors', 'Equity', -0.010474514368770739, 'Intl', 'MKT_Intl', datetime.datetime(2001, 6, 30, 0, 0), 'Fama-French Factors', 'Equity', -0.02931420942914372, 'Intl', 'MKT_Intl', datetime.datetime(2001, 7, 31, 0, 0), 'Fama-French Factors', 'Equity', -0.026175716039357342, 'Intl', 'MKT_Intl', datetime.datetime(2001, 8, 31, 0, 0), 'Fama-French Factors', 'Equity', -0.0468346643449563, 'Intl', 'MKT_Intl', datetime.datetime(2001, 9, 30, 0, 0), 'Fama-French Factors', 'Equity', -0.09906583041804193, 'Intl', 'MKT_Intl', datetime.datetime(2001, 10, 31, 0, 0), 'Fama-French Factors', 'Equity', 0.026689513188864582, 'Intl')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-04-10 18:04:54,027 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 5) with is_com=False\n",
      "2025-04-10 18:04:54,839 - INFO - Read 1181 rows with raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 18:04:54,842 - INFO - Columns after renaming: ['date', 'SMB', 'SMB', 'SMB']\n",
      "2025-04-10 18:04:55,297 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 5): IntegrityError: (pyodbc.IntegrityError) ('23000', \"[23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Violation of PRIMARY KEY constraint 'PK__factor_r__C3CBC7054E79A6D5'. Cannot insert duplicate key in object 'dbo.factor_returns'. The duplicate key value is (SMB_Intl, 1984-07-31, Fama-French Factors). (2627) (SQLExecDirectW); [23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]The statement has been terminated. (3621)\")\n",
      "[SQL: INSERT INTO factor_returns (factor, date, associated_paper, asset_class, value, region) VALUES (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ... 6723 characters truncated ... , (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?)]\n",
      "[parameters: ('SMB_Intl', datetime.datetime(2013, 10, 31, 0, 0), 'Fama-French Factors', 'Equity', -0.015588468883991955, 'Intl', 'SMB_Intl', datetime.datetime(2013, 11, 30, 0, 0), 'Fama-French Factors', 'Equity', 0.01065483414815262, 'Intl', 'SMB_Intl', datetime.datetime(2013, 12, 31, 0, 0), 'Fama-French Factors', 'Equity', -0.0010166842544921284, 'Intl', 'SMB_Intl', datetime.datetime(2014, 1, 31, 0, 0), 'Fama-French Factors', 'Equity', 0.007428787828202504, 'Intl', 'SMB_Intl', datetime.datetime(2014, 2, 28, 0, 0), 'Fama-French Factors', 'Equity', 0.0018911095129556061, 'Intl', 'SMB_Intl', datetime.datetime(2014, 3, 31, 0, 0), 'Fama-French Factors', 'Equity', -0.007537377322076746, 'Intl', 'SMB_Intl', datetime.datetime(2014, 4, 30, 0, 0), 'Fama-French Factors', 'Equity', -0.036172693683151236, 'Intl', 'SMB_Intl', datetime.datetime(2014, 5, 31, 0, 0), 'Fama-French Factors', 'Equity', -0.01391237448379029, 'Intl', 'SMB_Intl', datetime.datetime(2014, 6, 30, 0, 0) ... 1994 parameters truncated ... -0.04302753425772138, 'Intl', 'SMB_Intl', datetime.datetime(2001, 10, 31, 0, 0), 'Fama-French Factors', 'Equity', 0.04437886535965284, 'Intl', 'SMB_Intl', datetime.datetime(2001, 11, 30, 0, 0), 'Fama-French Factors', 'Equity', -0.0007389383728429238, 'Intl', 'SMB_Intl', datetime.datetime(2001, 12, 31, 0, 0), 'Fama-French Factors', 'Equity', 0.023116268340654826, 'Intl', 'SMB_Intl', datetime.datetime(2002, 1, 31, 0, 0), 'Fama-French Factors', 'Equity', 0.021369157183437584, 'Intl', 'SMB_Intl', datetime.datetime(2002, 2, 28, 0, 0), 'Fama-French Factors', 'Equity', -0.010535330167321437, 'Intl', 'SMB_Intl', datetime.datetime(2002, 3, 31, 0, 0), 'Fama-French Factors', 'Equity', 0.023330221817805488, 'Intl', 'SMB_Intl', datetime.datetime(2002, 4, 30, 0, 0), 'Fama-French Factors', 'Equity', 0.034445536190484724, 'Intl', 'SMB_Intl', datetime.datetime(2002, 5, 31, 0, 0), 'Fama-French Factors', 'Equity', -0.010465487612244091, 'Intl')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-04-10 18:04:55,299 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 6) with is_com=False\n",
      "2025-04-10 18:04:56,198 - INFO - Read 1181 rows with raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 18:04:56,201 - INFO - Columns after renaming: ['date', 'HML-FF', 'HML-FF', 'HML-FF']\n",
      "2025-04-10 18:04:56,841 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 6): IntegrityError: (pyodbc.IntegrityError) ('23000', \"[23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Violation of PRIMARY KEY constraint 'PK__factor_r__C3CBC7054E79A6D5'. Cannot insert duplicate key in object 'dbo.factor_returns'. The duplicate key value is (HML-FF_Intl, 1984-07-31, Fama-French Factors). (2627) (SQLExecDirectW); [23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]The statement has been terminated. (3621)\")\n",
      "[SQL: INSERT INTO factor_returns (factor, date, associated_paper, asset_class, value, region) VALUES (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ... 6723 characters truncated ... , (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?)]\n",
      "[parameters: ('HML-FF_Intl', datetime.datetime(2013, 10, 31, 0, 0), 'Fama-French Factors', 'Equity', 0.008126275592922588, 'Intl', 'HML-FF_Intl', datetime.datetime(2013, 11, 30, 0, 0), 'Fama-French Factors', 'Equity', -0.006213918038464201, 'Intl', 'HML-FF_Intl', datetime.datetime(2013, 12, 31, 0, 0), 'Fama-French Factors', 'Equity', 0.0005835877582695357, 'Intl', 'HML-FF_Intl', datetime.datetime(2014, 1, 31, 0, 0), 'Fama-French Factors', 'Equity', -0.009251287117120475, 'Intl', 'HML-FF_Intl', datetime.datetime(2014, 2, 28, 0, 0), 'Fama-French Factors', 'Equity', -0.006413256078610271, 'Intl', 'HML-FF_Intl', datetime.datetime(2014, 3, 31, 0, 0), 'Fama-French Factors', 'Equity', 0.03169030874251517, 'Intl', 'HML-FF_Intl', datetime.datetime(2014, 4, 30, 0, 0), 'Fama-French Factors', 'Equity', 0.01364073711053479, 'Intl', 'HML-FF_Intl', datetime.datetime(2014, 5, 31, 0, 0), 'Fama-French Factors', 'Equity', -0.0026271462733967656, 'Intl', 'HML-FF_Intl', datetime.datetime(2014, 6, 30, 0, 0) ... 1994 parameters truncated ... 0.0011436458225156463, 'Intl', 'HML-FF_Intl', datetime.datetime(2001, 10, 31, 0, 0), 'Fama-French Factors', 'Equity', -0.043722538653486104, 'Intl', 'HML-FF_Intl', datetime.datetime(2001, 11, 30, 0, 0), 'Fama-French Factors', 'Equity', -0.01613061192627387, 'Intl', 'HML-FF_Intl', datetime.datetime(2001, 12, 31, 0, 0), 'Fama-French Factors', 'Equity', 0.011513742700095602, 'Intl', 'HML-FF_Intl', datetime.datetime(2002, 1, 31, 0, 0), 'Fama-French Factors', 'Equity', 0.03356734390736426, 'Intl', 'HML-FF_Intl', datetime.datetime(2002, 2, 28, 0, 0), 'Fama-French Factors', 'Equity', 0.024212788104121793, 'Intl', 'HML-FF_Intl', datetime.datetime(2002, 3, 31, 0, 0), 'Fama-French Factors', 'Equity', 0.006571864421787964, 'Intl', 'HML-FF_Intl', datetime.datetime(2002, 4, 30, 0, 0), 'Fama-French Factors', 'Equity', 0.05046657745144843, 'Intl', 'HML-FF_Intl', datetime.datetime(2002, 5, 31, 0, 0), 'Fama-French Factors', 'Equity', 0.03897095652699924, 'Intl')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-04-10 18:04:56,842 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 7) with is_com=False\n",
      "2025-04-10 18:04:57,700 - INFO - Read 1182 rows with raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 18:04:57,704 - INFO - Columns after renaming: ['date', 'HML-D', 'HML-D', 'HML-D']\n",
      "2025-04-10 18:04:58,408 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 7): IntegrityError: (pyodbc.IntegrityError) ('23000', \"[23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Violation of PRIMARY KEY constraint 'PK__factor_r__C3CBC7054E79A6D5'. Cannot insert duplicate key in object 'dbo.factor_returns'. The duplicate key value is (HML-D_Intl, 1984-07-31, The Devil's in HML's Details). (2627) (SQLExecDirectW); [23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]The statement has been terminated. (3621)\")\n",
      "[SQL: INSERT INTO factor_returns (factor, date, associated_paper, asset_class, value, region) VALUES (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ... 6723 characters truncated ... , (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?)]\n",
      "[parameters: ('HML-D_Intl', datetime.datetime(2013, 10, 31, 0, 0), \"The Devil's in HML's Details\", 'Equity', 0.0072444105281305295, 'Intl', 'HML-D_Intl', datetime.datetime(2013, 11, 30, 0, 0), \"The Devil's in HML's Details\", 'Equity', -0.005184703242705693, 'Intl', 'HML-D_Intl', datetime.datetime(2013, 12, 31, 0, 0), \"The Devil's in HML's Details\", 'Equity', -0.005092753300083641, 'Intl', 'HML-D_Intl', datetime.datetime(2014, 1, 31, 0, 0), \"The Devil's in HML's Details\", 'Equity', -0.009014270054341142, 'Intl', 'HML-D_Intl', datetime.datetime(2014, 2, 28, 0, 0), \"The Devil's in HML's Details\", 'Equity', -0.009496538155720964, 'Intl', 'HML-D_Intl', datetime.datetime(2014, 3, 31, 0, 0), \"The Devil's in HML's Details\", 'Equity', 0.03441581628966687, 'Intl', 'HML-D_Intl', datetime.datetime(2014, 4, 30, 0, 0), \"The Devil's in HML's Details\", 'Equity', 0.024334649355976432, 'Intl', 'HML-D_Intl', datetime.datetime(2014, 5, 31, 0, 0), \"The Devil's in HML's Details\", 'Equity', -0.0043872889196122904, 'Intl', 'HML-D_Intl', datetime.datetime(2014, 6, 30, 0, 0) ... 1994 parameters truncated ... 0.016909269701957174, 'Intl', 'HML-D_Intl', datetime.datetime(2001, 9, 30, 0, 0), \"The Devil's in HML's Details\", 'Equity', -0.031155186944991396, 'Intl', 'HML-D_Intl', datetime.datetime(2001, 10, 31, 0, 0), \"The Devil's in HML's Details\", 'Equity', 0.007021243301153898, 'Intl', 'HML-D_Intl', datetime.datetime(2001, 11, 30, 0, 0), \"The Devil's in HML's Details\", 'Equity', 0.03149142164443875, 'Intl', 'HML-D_Intl', datetime.datetime(2001, 12, 31, 0, 0), \"The Devil's in HML's Details\", 'Equity', 0.007743100314369627, 'Intl', 'HML-D_Intl', datetime.datetime(2002, 1, 31, 0, 0), \"The Devil's in HML's Details\", 'Equity', 0.00634064776393236, 'Intl', 'HML-D_Intl', datetime.datetime(2002, 2, 28, 0, 0), \"The Devil's in HML's Details\", 'Equity', -0.0009196778618448396, 'Intl', 'HML-D_Intl', datetime.datetime(2002, 3, 31, 0, 0), \"The Devil's in HML's Details\", 'Equity', 0.02380782970640389, 'Intl', 'HML-D_Intl', datetime.datetime(2002, 4, 30, 0, 0), \"The Devil's in HML's Details\", 'Equity', 0.015381715521180367, 'Intl')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-04-10 18:04:58,409 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 8) with is_com=False\n",
      "2025-04-10 18:04:59,215 - INFO - Read 1176 rows with raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 18:04:59,218 - INFO - Columns after renaming: ['date', 'UMD', 'UMD', 'UMD']\n",
      "2025-04-10 18:04:59,944 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 8): IntegrityError: (pyodbc.IntegrityError) ('23000', \"[23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Violation of PRIMARY KEY constraint 'PK__factor_r__C3CBC7054E79A6D5'. Cannot insert duplicate key in object 'dbo.factor_returns'. The duplicate key value is (UMD_Intl, 1985-01-31, On Persistence in Mutual Fund Performance). (2627) (SQLExecDirectW); [23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]The statement has been terminated. (3621)\")\n",
      "[SQL: INSERT INTO factor_returns (factor, date, associated_paper, asset_class, value, region) VALUES (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ... 6723 characters truncated ... , (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?)]\n",
      "[parameters: ('UMD_Intl', datetime.datetime(2014, 4, 30, 0, 0), 'On Persistence in Mutual Fund Performance', 'Equity', -0.04315077904847455, 'Intl', 'UMD_Intl', datetime.datetime(2014, 5, 31, 0, 0), 'On Persistence in Mutual Fund Performance', 'Equity', 0.012067091700408518, 'Intl', 'UMD_Intl', datetime.datetime(2014, 6, 30, 0, 0), 'On Persistence in Mutual Fund Performance', 'Equity', 0.006253928654609622, 'Intl', 'UMD_Intl', datetime.datetime(2014, 7, 31, 0, 0), 'On Persistence in Mutual Fund Performance', 'Equity', -0.0006523035900165526, 'Intl', 'UMD_Intl', datetime.datetime(2014, 8, 31, 0, 0), 'On Persistence in Mutual Fund Performance', 'Equity', 0.009703868011299879, 'Intl', 'UMD_Intl', datetime.datetime(2014, 9, 30, 0, 0), 'On Persistence in Mutual Fund Performance', 'Equity', 0.01127236580703486, 'Intl', 'UMD_Intl', datetime.datetime(2014, 10, 31, 0, 0), 'On Persistence in Mutual Fund Performance', 'Equity', -0.0016423145212227802, 'Intl', 'UMD_Intl', datetime.datetime(2014, 11, 30, 0, 0), 'On Persistence in Mutual Fund Performance', 'Equity', 0.00907903172393267, 'Intl', 'UMD_Intl', datetime.datetime(2014, 12, 31, 0, 0) ... 1994 parameters truncated ... 0.02454839867509141, 'Intl', 'UMD_Intl', datetime.datetime(2002, 9, 30, 0, 0), 'On Persistence in Mutual Fund Performance', 'Equity', 0.09455445968723777, 'Intl', 'UMD_Intl', datetime.datetime(2002, 10, 31, 0, 0), 'On Persistence in Mutual Fund Performance', 'Equity', -0.05297015142448799, 'Intl', 'UMD_Intl', datetime.datetime(2002, 11, 30, 0, 0), 'On Persistence in Mutual Fund Performance', 'Equity', -0.11395292591341677, 'Intl', 'UMD_Intl', datetime.datetime(2002, 12, 31, 0, 0), 'On Persistence in Mutual Fund Performance', 'Equity', 0.09656001282528576, 'Intl', 'UMD_Intl', datetime.datetime(2003, 1, 31, 0, 0), 'On Persistence in Mutual Fund Performance', 'Equity', 0.01048439611252955, 'Intl', 'UMD_Intl', datetime.datetime(2003, 2, 28, 0, 0), 'On Persistence in Mutual Fund Performance', 'Equity', 0.03626111195157964, 'Intl', 'UMD_Intl', datetime.datetime(2003, 3, 31, 0, 0), 'On Persistence in Mutual Fund Performance', 'Equity', 0.018182495745141906, 'Intl', 'UMD_Intl', datetime.datetime(2003, 4, 30, 0, 0), 'On Persistence in Mutual Fund Performance', 'Equity', -0.09211410115601056, 'Intl')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-04-10 18:04:59,945 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 9) with is_com=False\n",
      "2025-04-10 18:05:00,699 - INFO - Read 1182 rows with raw columns: ['DATE', 'AUT', 'HKG', 'ESP', 'GBR', 'ITA', 'DEU', 'DNK', 'NZL', 'NLD', 'USA', 'PRT', 'BEL', 'ISR', 'GRC', 'NOR', 'SGP', 'CHE', 'IRL', 'CAN', 'FIN', 'JPN', 'SWE', 'FRA', 'AUS', 'Global Ex USA', 'Global', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-10 18:05:00,702 - INFO - Columns after renaming: ['date', 'ME', 'ME', 'ME']\n",
      "2025-04-10 18:05:01,346 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 9): IntegrityError: (pyodbc.IntegrityError) ('23000', \"[23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Violation of PRIMARY KEY constraint 'PK__factor_r__C3CBC7054E79A6D5'. Cannot insert duplicate key in object 'dbo.factor_returns'. The duplicate key value is (ME_Global, 1982-03-31, AQR Factors). (2627) (SQLExecDirectW); [23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]The statement has been terminated. (3621)\")\n",
      "[SQL: INSERT INTO factor_returns (factor, date, associated_paper, asset_class, value, region) VALUES (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ... 6723 characters truncated ... , (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?)]\n",
      "[parameters: ('ME_Global', datetime.datetime(2013, 10, 31, 0, 0), 'AQR Factors', 'Equity', 22025042.496611033, 'Global', 'ME_Global', datetime.datetime(2013, 11, 30, 0, 0), 'AQR Factors', 'Equity', 22861634.48946448, 'Global', 'ME_Global', datetime.datetime(2013, 12, 31, 0, 0), 'AQR Factors', 'Equity', 23435136.39110338, 'Global', 'ME_Global', datetime.datetime(2014, 1, 31, 0, 0), 'AQR Factors', 'Equity', 24059414.51842615, 'Global', 'ME_Global', datetime.datetime(2014, 2, 28, 0, 0), 'AQR Factors', 'Equity', 23353985.84743171, 'Global', 'ME_Global', datetime.datetime(2014, 3, 31, 0, 0), 'AQR Factors', 'Equity', 24409683.84168286, 'Global', 'ME_Global', datetime.datetime(2014, 4, 30, 0, 0), 'AQR Factors', 'Equity', 24513849.445184622, 'Global', 'ME_Global', datetime.datetime(2014, 5, 31, 0, 0), 'AQR Factors', 'Equity', 24377841.6124672, 'Global', 'ME_Global', datetime.datetime(2014, 6, 30, 0, 0) ... 1994 parameters truncated ... 11457733.633359252, 'Global', 'ME_Global', datetime.datetime(1999, 5, 31, 0, 0), 'AQR Factors', 'Equity', 12078683.798943782, 'Global', 'ME_Global', datetime.datetime(1999, 6, 30, 0, 0), 'AQR Factors', 'Equity', 11567199.628809815, 'Global', 'ME_Global', datetime.datetime(1999, 7, 31, 0, 0), 'AQR Factors', 'Equity', 12314891.485328583, 'Global', 'ME_Global', datetime.datetime(1999, 8, 31, 0, 0), 'AQR Factors', 'Equity', 12787885.625268705, 'Global', 'ME_Global', datetime.datetime(1999, 9, 30, 0, 0), 'AQR Factors', 'Equity', 13011178.449609442, 'Global', 'ME_Global', datetime.datetime(1999, 10, 31, 0, 0), 'AQR Factors', 'Equity', 13246267.472289233, 'Global', 'ME_Global', datetime.datetime(1999, 11, 30, 0, 0), 'AQR Factors', 'Equity', 13844990.210710546, 'Global', 'ME_Global', datetime.datetime(1999, 12, 31, 0, 0), 'AQR Factors', 'Equity', 14780722.25287978, 'Global')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-04-10 18:05:01,347 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 10) with is_com=False\n",
      "2025-04-10 18:05:02,095 - INFO - Read 1183 rows with raw columns: ['DATE', 'Risk Free Rate']\n",
      "2025-04-10 18:05:02,097 - INFO - Columns after renaming: ['date', 'RF']\n",
      "2025-04-10 18:05:02,758 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 10): IntegrityError: (pyodbc.IntegrityError) ('23000', \"[23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Cannot insert the value NULL into column 'associated_paper', table 'CWA_Fund_Database.dbo.factor_returns'; column does not allow nulls. INSERT fails. (515) (SQLExecDirectW); [23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]The statement has been terminated. (3621)\")\n",
      "[SQL: INSERT INTO factor_returns (factor, date, associated_paper, asset_class, value, region) VALUES (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ... 6723 characters truncated ... , (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?)]\n",
      "[parameters: ('RF', datetime.datetime(1926, 7, 31, 0, 0), None, 'Equity', 0.0022, 'USA', 'RF', datetime.datetime(1926, 8, 31, 0, 0), None, 'Equity', 0.0025, 'USA', 'RF', datetime.datetime(1926, 9, 30, 0, 0), None, 'Equity', 0.0023, 'USA', 'RF', datetime.datetime(1926, 10, 31, 0, 0), None, 'Equity', 0.0032, 'USA', 'RF', datetime.datetime(1926, 11, 30, 0, 0), None, 'Equity', 0.0031, 'USA', 'RF', datetime.datetime(1926, 12, 31, 0, 0), None, 'Equity', 0.0028000000000000004, 'USA', 'RF', datetime.datetime(1927, 1, 31, 0, 0), None, 'Equity', 0.0025, 'USA', 'RF', datetime.datetime(1927, 2, 28, 0, 0), None, 'Equity', 0.0026, 'USA', 'RF', datetime.datetime(1927, 3, 31, 0, 0) ... 1994 parameters truncated ... 0.0006, 'USA', 'RF', datetime.datetime(1954, 12, 31, 0, 0), None, 'Equity', 0.0008, 'USA', 'RF', datetime.datetime(1955, 1, 31, 0, 0), None, 'Equity', 0.0008, 'USA', 'RF', datetime.datetime(1955, 2, 28, 0, 0), None, 'Equity', 0.0009, 'USA', 'RF', datetime.datetime(1955, 3, 31, 0, 0), None, 'Equity', 0.001, 'USA', 'RF', datetime.datetime(1955, 4, 30, 0, 0), None, 'Equity', 0.001, 'USA', 'RF', datetime.datetime(1955, 5, 31, 0, 0), None, 'Equity', 0.0014000000000000002, 'USA', 'RF', datetime.datetime(1955, 6, 30, 0, 0), None, 'Equity', 0.001, 'USA', 'RF', datetime.datetime(1955, 7, 31, 0, 0), None, 'Equity', 0.001, 'USA')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-04-10 18:05:02,760 - INFO - Processing dataset: TSMOM\n",
      "2025-04-10 18:05:02,761 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet 0) with is_com=False\n",
      "2025-04-10 18:05:02,968 - INFO - Read 481 rows with raw columns: ['Unnamed: 0', 'TSMOM', 'TSMOM^CM', 'TSMOM^EQ', 'TSMOM^FI', 'TSMOM^FX']\n",
      "2025-04-10 18:05:02,970 - WARNING - No date column found in C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet 0). Using first column.\n",
      "2025-04-10 18:05:02,972 - INFO - Columns after renaming: ['date', 'TSM-MA', 'TSM-Com', 'TSM-EQ', 'TSM-FI', 'TSM-FX']\n",
      "2025-04-10 18:05:03,425 - INFO - No new rows to load into factor_returns from C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet 0)\n",
      "2025-04-10 18:05:03,448 - INFO - Processing dataset: QMJ\n",
      "2025-04-10 18:05:03,450 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 0) with is_com=False\n",
      "2025-04-10 18:05:03,979 - INFO - Read 809 rows with raw columns: ['DATE', 'P1 (low quality)', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10 (high quality)', 'P10-P1', 'P1 (low quality).1', 'P2.1', 'P3.1', 'P4.1', 'P5.1', 'P6.1', 'P7.1', 'P8.1', 'P9.1', 'P10 (high quality).1', 'P10-P1.1']\n",
      "2025-04-10 18:05:03,981 - INFO - Columns after renaming: ['date', 'QMJ-P1-LQ', 'QMJ-P2', 'QMJ-P3', 'QMJ-P4', 'QMJ-P5', 'QMJ-P6', 'QMJ-P7', 'QMJ-P8', 'QMJ-P9', 'QMJ-P10-HQ', 'QMJ']\n",
      "2025-04-10 18:05:04,601 - INFO - No new rows to load into factor_returns from C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 0)\n",
      "2025-04-10 18:05:04,621 - INFO - Processing dataset: Century\n",
      "2025-04-10 18:05:04,623 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx (sheet 0) with is_com=False\n",
      "2025-04-10 18:05:05,569 - INFO - Read 1182 rows with raw columns: ['Date', 'US Stock Selection Value', 'US Stock Selection Momentum', 'US Stock Selection Defensive', 'US Stock Selection Multi-style', 'Intl Stock Selection Value', 'Intl Stock Selection Momentum', 'Intl Stock Selection Defensive', 'Intl Stock Selection Multi-style', 'Equity indices Value', 'Equity indices Momentum', 'Equity indices Carry', 'Equity indices Defensive', 'Equity indices Multi-style', 'Fixed income Value', 'Fixed income Momentum', 'Fixed income Carry', 'Fixed income Defensive', 'Fixed income Multi-style', 'Currencies Value', 'Currencies Momentum', 'Currencies Carry', 'Currencies Multi-style', 'Commodities Value', 'Commodities Momentum', 'Commodities Carry', 'Commodities Multi-style', 'All Stock Selection Value', 'All Stock Selection Momentum', 'All Stock Selection Defensive', 'All Stock Selection Multi-style', 'All Macro Value', 'All Macro Momentum', 'All Macro Carry', 'All Macro Defensive', 'All Macro Multi-style', 'All asset classes Value', 'All asset classes Momentum', 'All asset classes Carry', 'All asset classes Defensive', 'All asset classes Multi-style', 'Equity indices Market', 'Fixed income Market', 'Commodities Market', 'All Macro Market']\n",
      "2025-04-10 18:05:05,573 - INFO - Columns after renaming: ['date', 'HML-FF-US', 'UMD-US', 'BAB-US', 'Multi-style-US', 'HML-FF-Intl', 'UMD-Intl', 'BAB-Intl', 'Multi-style-Intl', 'HML-Equity', 'UMD-Equity', 'Carry-Equity', 'BAB-Equity', 'Multi-style-Equity', 'HML-FI', 'UMD-FI', 'Carry-FI', 'BAB-FI', 'Multi-style-FI', 'HML-FX', 'UMD-FX', 'Carry-FX', 'Multi-style-FX', 'HML-COM', 'UMD-COM', 'Carry-COM', 'Multi-style-COM', 'HML-All-SS', 'UMD-All-SS', 'BAB-All-SS', 'Multi-style-All-SS', 'HML-All-Macro', 'UMD-All-Macro', 'Carry-All-Macro', 'BAB-All-Macro', 'Multi-style-All-Macro', 'HML-All', 'UMD-All', 'Carry-All', 'BAB-All', 'Multi-style-All', 'MKT-Equity', 'MKT-FI', 'MKT-COM', 'MKT-All-Macro']\n",
      "2025-04-10 18:05:19,281 - INFO - Loaded 46491 new rows into factor_returns from C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx (sheet 0)\n",
      "2025-04-10 18:05:19,297 - INFO - Processing dataset: COM\n",
      "2025-04-10 18:05:19,298 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx (sheet 0) with is_com=True\n",
      "2025-04-10 18:05:19,724 - INFO - Read 1776 rows with raw columns: ['Unnamed: 0', 'Excess return of equal-weight commodities portfolio', 'Excess spot return of equal-weight commodities portfolio', 'Interest rate adjusted carry of equal-weight commodities portfolio', 'Spot return of equal-weight commodities portfolio', 'Carry of equal-weight commodities portfolio', 'Excess return of long/short commodities portfolio', 'Excess spot return of long/short commodities portfolio', 'Interest rate adjusted carry of long/short commodities portfolio', 'Aggregate backwardation/contango', 'State of backwardation/contango', 'State of inflation']\n",
      "2025-04-10 18:05:19,725 - WARNING - Missing columns in C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx (sheet 0): ['Date', 'Excess Return (Eq Wt)', 'Excess Spot Return (Eq Wt)', 'IR-Adjusted Carry (Eq Wt)', 'Spot Return (Eq Wt)', 'Carry (Eq Wt)', 'Excess Return (Long-Short)', 'Excess Spot Return (Long-Short)', 'IR-Adjusted Carry (Long-Short)', 'Aggregate Backwardation/Contango', 'State Backwardation/Contango', 'State Inflation']\n",
      "2025-04-10 18:05:19,727 - ERROR - Key error processing C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx (sheet 0): 'date'\n",
      "2025-04-10 18:05:19,729 - INFO - All data processing complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import VARCHAR, DATE, DECIMAL\n",
    "import logging\n",
    "\n",
    "# Logging setup - Use DEBUG for detailed output during development\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,  # Changed to DEBUG for more visibility\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(), logging.FileHandler('load_aqr_data.log')]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Database connection\n",
    "engine = create_engine(\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/CWA_Fund_Database\"\n",
    "    \"?driver=ODBC+Driver+18+for+SQL+Server&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "# File configurations\n",
    "data_files = {\n",
    "    \"BAB_multi\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx\",\n",
    "        \"sheets\": {\n",
    "            \"BAB\": {\"sheet\": 0, \"header\": 18, \"paper\": \"Betting Against Beta (Frazzini and Pedersen, 2014)\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"BAB\", \"Global\": \"BAB\", \"Global Ex USA\": \"BAB\"}},\n",
    "            \"MKT\": {\"sheet\": 4, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"MKT\", \"Global\": \"MKT\", \"Global Ex USA\": \"MKT\"}},\n",
    "            \"SMB\": {\"sheet\": 5, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"SMB\", \"Global\": \"SMB\", \"Global Ex USA\": \"SMB\"}},\n",
    "            \"HML-FF\": {\"sheet\": 6, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-FF\", \"Global\": \"HML-FF\", \"Global Ex USA\": \"HML-FF\"}},\n",
    "            \"HML-D\": {\"sheet\": 7, \"header\": 18, \"paper\": \"The Devil's in HML's Details\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-D\", \"Global\": \"HML-D\", \"Global Ex USA\": \"HML-D\"}},\n",
    "            \"UMD\": {\"sheet\": 8, \"header\": 18, \"paper\": \"On Persistence in Mutual Fund Performance\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"UMD\", \"Global\": \"UMD\", \"Global Ex USA\": \"UMD\"}},\n",
    "            \"ME\": {\"sheet\": 9, \"header\": 18, \"paper\": \"AQR Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"ME\", \"Global\": \"ME\", \"Global Ex USA\": \"ME\"}},\n",
    "            \"RF\": {\"sheet\": 10, \"header\": 18, \"paper\": None, \"columns\": {\"DATE\": \"DATE\", \"Risk Free Rate\": \"RF\"}}\n",
    "        }\n",
    "    },\n",
    "    \"TSMOM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 17,\n",
    "        \"paper\": \"Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)\",\n",
    "        \"columns\": {\n",
    "            \"Unnamed: 0\": \"DATE\",\n",
    "            \"TSMOM\": \"TSM-MA\",\n",
    "            \"TSMOM^CM\": \"TSM-Com\",\n",
    "            \"TSMOM^EQ\": \"TSM-EQ\",\n",
    "            \"TSMOM^FI\": \"TSM-FI\",\n",
    "            \"TSMOM^FX\": \"TSM-FX\"\n",
    "        }\n",
    "    },\n",
    "    \"QMJ\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 18,\n",
    "        \"paper\": \"Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)\",\n",
    "        \"columns\": {\n",
    "            \"DATE\": \"DATE\",\n",
    "            \"P1 (low quality)\": \"QMJ-P1-LQ\",\n",
    "            \"P2\": \"QMJ-P2\",\n",
    "            \"P3\": \"QMJ-P3\",\n",
    "            \"P4\": \"QMJ-P4\",\n",
    "            \"P5\": \"QMJ-P5\",\n",
    "            \"P6\": \"QMJ-P6\",\n",
    "            \"P7\": \"QMJ-P7\",\n",
    "            \"P8\": \"QMJ-P8\",\n",
    "            \"P9\": \"QMJ-P9\",\n",
    "            \"P10 (high quality)\": \"QMJ-P10-HQ\",\n",
    "            \"P10-P1\": \"QMJ\"\n",
    "        }\n",
    "    },\n",
    "    \"Century\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 18,\n",
    "        \"paper\": \"Century of Factor Premia Monthly-Ilmanen et al. (2021)\",\n",
    "        \"columns\": {\n",
    "            \"Date\": \"DATE\",\n",
    "            \"US Stock Selection Value\": \"HML-FF-US\", \"US Stock Selection Momentum\": \"UMD-US\", \n",
    "            \"US Stock Selection Defensive\": \"BAB-US\", \"US Stock Selection Multi-style\": \"Multi-style-US\",\n",
    "            \"Intl Stock Selection Value\": \"HML-FF-Intl\", \"Intl Stock Selection Momentum\": \"UMD-Intl\", \n",
    "            \"Intl Stock Selection Defensive\": \"BAB-Intl\", \"Intl Stock Selection Multi-style\": \"Multi-style-Intl\",\n",
    "            \"Equity indices Value\": \"HML-Equity\", \"Equity indices Momentum\": \"UMD-Equity\", \n",
    "            \"Equity indices Carry\": \"Carry-Equity\", \"Equity indices Defensive\": \"BAB-Equity\", \n",
    "            \"Equity indices Multi-style\": \"Multi-style-Equity\",\n",
    "            \"Fixed income Value\": \"HML-FI\", \"Fixed income Momentum\": \"UMD-FI\", \n",
    "            \"Fixed income Carry\": \"Carry-FI\", \"Fixed income Defensive\": \"BAB-FI\", \n",
    "            \"Fixed income Multi-style\": \"Multi-style-FI\",\n",
    "            \"Currencies Value\": \"HML-FX\", \"Currencies Momentum\": \"UMD-FX\", \n",
    "            \"Currencies Carry\": \"Carry-FX\", \"Currencies Multi-style\": \"Multi-style-FX\",\n",
    "            \"Commodities Value\": \"HML-COM\", \"Commodities Momentum\": \"UMD-COM\", \n",
    "            \"Commodities Carry\": \"Carry-COM\", \"Commodities Multi-style\": \"Multi-style-COM\",\n",
    "            \"All Stock Selection Value\": \"HML-All-SS\", \"All Stock Selection Momentum\": \"UMD-All-SS\", \n",
    "            \"All Stock Selection Defensive\": \"BAB-All-SS\", \"All Stock Selection Multi-style\": \"Multi-style-All-SS\",\n",
    "            \"All Macro Value\": \"HML-All-Macro\", \"All Macro Momentum\": \"UMD-All-Macro\", \n",
    "            \"All Macro Carry\": \"Carry-All-Macro\", \"All Macro Defensive\": \"BAB-All-Macro\", \n",
    "            \"All Macro Multi-style\": \"Multi-style-All-Macro\",\n",
    "            \"All asset classes Value\": \"HML-All\", \"All asset classes Momentum\": \"UMD-All\", \n",
    "            \"All asset classes Carry\": \"Carry-All\", \"All asset classes Defensive\": \"BAB-All\", \n",
    "            \"All asset classes Multi-style\": \"Multi-style-All\",\n",
    "            \"Equity indices Market\": \"MKT-Equity\", \"Fixed income Market\": \"MKT-FI\", \n",
    "            \"Commodities Market\": \"MKT-COM\", \"All Macro Market\": \"MKT-All-Macro\"\n",
    "        }\n",
    "    },\n",
    "    \"COM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 10,\n",
    "        \"paper\": \"Commodities for the Long Run\",\n",
    "        \"columns\": {  # Added for flexibility\n",
    "            \"Date\": \"date\",\n",
    "            \"Excess Return (Eq Wt)\": \"excess_return_eqwt\",\n",
    "            \"Excess Spot Return (Eq Wt)\": \"excess_spot_return_eqwt\",\n",
    "            \"IR-Adjusted Carry (Eq Wt)\": \"ir_adjusted_carry_eqwt\",\n",
    "            \"Spot Return (Eq Wt)\": \"spot_return_eqwt\",\n",
    "            \"Carry (Eq Wt)\": \"carry_eqwt\",\n",
    "            \"Excess Return (Long-Short)\": \"excess_return_long_short\",\n",
    "            \"Excess Spot Return (Long-Short)\": \"excess_spot_return_long_short\",\n",
    "            \"IR-Adjusted Carry (Long-Short)\": \"ir_adjusted_carry_long_short\",\n",
    "            \"Aggregate Backwardation/Contango\": \"aggregate_backwardation_contango\",\n",
    "            \"State Backwardation/Contango\": \"state_backwardation_contango\",\n",
    "            \"State Inflation\": \"state_inflation\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "def process_factors(file_config, sheet=0, is_com=False, parent_path=None):\n",
    "    file_path = parent_path if parent_path else file_config['path']\n",
    "    logger.info(f\"Processing {file_path} (sheet {sheet}) with is_com={is_com}\")\n",
    "    try:\n",
    "        # Read Excel\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet, header=file_config['header'])\n",
    "        logger.info(f\"Read {len(df)} rows with raw columns: {list(df.columns)}\")\n",
    "        \n",
    "        if is_com:\n",
    "            # Commodity processing\n",
    "            if 'columns' in file_config:\n",
    "                expected_cols = list(file_config['columns'].keys())\n",
    "                missing_cols = [col for col in expected_cols if col not in df.columns]\n",
    "                if missing_cols:\n",
    "                    logger.warning(f\"Missing columns in {file_path} (sheet {sheet}): {missing_cols}\")\n",
    "                df = df[[col for col in df.columns if col in expected_cols]]\n",
    "                df.columns = [file_config['columns'][col] for col in df.columns]\n",
    "            else:\n",
    "                logger.warning(f\"No column mapping provided for {file_path} (sheet {sheet}). Using default commodity columns.\")\n",
    "                df.columns = [\n",
    "                    'date', 'excess_return_eqwt', 'excess_spot_return_eqwt', 'ir_adjusted_carry_eqwt',\n",
    "                    'spot_return_eqwt', 'carry_eqwt', 'excess_return_long_short', 'excess_spot_return_long_short',\n",
    "                    'ir_adjusted_carry_long_short', 'aggregate_backwardation_contango', \n",
    "                    'state_backwardation_contango', 'state_inflation'\n",
    "                ]\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            df['associated_paper'] = file_config['paper']\n",
    "            df = df.dropna(subset=['date'])\n",
    "            logger.debug(f\"After dropping NA dates, {len(df)} rows remain\")\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                # Optimize query by limiting date range\n",
    "                min_date = df['date'].min().strftime('%Y-%m-%d')\n",
    "                existing = pd.read_sql(f\"SELECT date FROM aqr_cmdty_factors WHERE date >= '{min_date}'\", connection)\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(existing['date'])\n",
    "            \n",
    "            df['date_str'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_new = df[~df['date_str'].isin(existing_keys)].drop(columns=['date_str'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                # Batch write for large datasets\n",
    "                for chunk in [df_new[i:i+10000] for i in range(0, len(df_new), 10000)]:\n",
    "                    chunk.to_sql(\n",
    "                        'aqr_cmdty_factors',\n",
    "                        engine,\n",
    "                        if_exists='append',\n",
    "                        index=False,\n",
    "                        dtype={\n",
    "                            'date': DATE,\n",
    "                            'excess_return_eqwt': DECIMAL(15, 6),\n",
    "                            'excess_spot_return_eqwt': DECIMAL(15, 6),\n",
    "                            'ir_adjusted_carry_eqwt': DECIMAL(15, 6),\n",
    "                            'spot_return_eqwt': DECIMAL(15, 6),\n",
    "                            'carry_eqwt': DECIMAL(15, 6),\n",
    "                            'excess_return_long_short': DECIMAL(15, 6),\n",
    "                            'excess_spot_return_long_short': DECIMAL(15, 6),\n",
    "                            'ir_adjusted_carry_long_short': DECIMAL(15, 6),\n",
    "                            'aggregate_backwardation_contango': DECIMAL(15, 6),\n",
    "                            'state_backwardation_contango': VARCHAR(50),\n",
    "                            'state_inflation': VARCHAR(50),\n",
    "                            'associated_paper': VARCHAR(100)\n",
    "                        }\n",
    "                    )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into aqr_cmdty_factors from {file_path} (sheet {sheet})\")\n",
    "            else:\n",
    "                logger.info(f\"No new rows to load into aqr_cmdty_factors from {file_path} (sheet {sheet})\")\n",
    "                logger.debug(f\"Input date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "                logger.debug(f\"Database date range: {existing['date'].min() if not existing.empty else 'N/A'} to {existing['date'].max() if not existing.empty else 'N/A'}\")\n",
    "        else:\n",
    "            # Factor processing\n",
    "            # Find date column\n",
    "            date_col = None\n",
    "            for col in df.columns:\n",
    "                if isinstance(col, str) and ('DATE' in col.upper() or 'Date' in col):\n",
    "                    date_col = col\n",
    "                    break\n",
    "            if date_col is None:\n",
    "                logger.warning(f\"No date column found in {file_path} (sheet {sheet}). Using first column.\")\n",
    "                date_col = df.columns[0]\n",
    "            \n",
    "            # Validate and rename columns\n",
    "            orig_cols = df.columns.tolist()\n",
    "            if 'columns' in file_config:\n",
    "                expected_cols = list(file_config['columns'].keys())\n",
    "                valid_cols = [col for col in expected_cols if col in df.columns]\n",
    "                missing_cols = [col for col in expected_cols if col not in df.columns]\n",
    "                if missing_cols:\n",
    "                    logger.warning(f\"Missing columns in {file_path} (sheet {sheet}): {missing_cols}\")\n",
    "                if not valid_cols:\n",
    "                    logger.error(f\"No valid columns found in {file_path} (sheet {sheet}). Skipping.\")\n",
    "                    return\n",
    "                if date_col not in valid_cols:\n",
    "                    valid_cols.append(date_col)\n",
    "                df = df[[col for col in df.columns if col in valid_cols]]\n",
    "                new_columns = ['date' if col == date_col else file_config['columns'].get(col, col) for col in df.columns]\n",
    "                df.columns = new_columns\n",
    "            else:\n",
    "                logger.warning(f\"No column mapping provided for {file_path} (sheet {sheet}). Using raw columns.\")\n",
    "            \n",
    "            logger.info(f\"Columns after renaming: {list(df.columns)}\")\n",
    "            \n",
    "            # Parse dates\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            invalid_dates = df['date'].isna().sum()\n",
    "            if invalid_dates > 0:\n",
    "                logger.warning(f\"Dropped {invalid_dates} rows due to invalid dates in {file_path} (sheet {sheet})\")\n",
    "            df = df.dropna(subset=['date'])\n",
    "            \n",
    "            # Melt DataFrame\n",
    "            value_vars = [col for col in df.columns if col != 'date']\n",
    "            df_long = df.melt(id_vars=['date'], value_vars=value_vars, var_name='factor', value_name='value')\n",
    "            df_long = df_long.dropna(subset=['value', 'date'])\n",
    "            logger.debug(f\"Rows after melting and dropping NA: {len(df_long)}\")\n",
    "            \n",
    "            # Assign asset class and region\n",
    "            file_path_for_check = parent_path if parent_path else file_config.get('path', '')\n",
    "            if 'TSMOM' in file_path_for_check:\n",
    "                df_long['asset_class'] = df_long['factor'].map({\n",
    "                    \"TSM-MA\": \"Multi-Asset\",\n",
    "                    \"TSM-Com\": \"Commodities\",\n",
    "                    \"TSM-EQ\": \"Equity\",\n",
    "                    \"TSM-FI\": \"Fixed Income\",\n",
    "                    \"TSM-FX\": \"Currencies\"\n",
    "                })\n",
    "                df_long['region'] = \"Global\"\n",
    "            elif 'Quality Minus Junk' in file_path_for_check:\n",
    "                df_long['asset_class'] = \"Equity\"\n",
    "                df_long['region'] = df_long['date'].apply(\n",
    "                    lambda x: \"USA\" if x < pd.Timestamp(\"1989-07-31\") else \"Global\"\n",
    "                )\n",
    "            elif 'Century' in file_path_for_check:\n",
    "                df_long['asset_class'] = df_long['factor'].str.extract(\n",
    "                    '(Stock Selection|Equity indices|Fixed income|Currencies|Commodities|All Macro|All asset classes)'\n",
    "                ).fillna('Equity')\n",
    "                df_long['region'] = df_long['factor'].apply(\n",
    "                    lambda x: 'US' if 'US' in x else 'Intl' if 'Intl' in x else 'Global'\n",
    "                )\n",
    "            else:  # BAB_multi\n",
    "                df_long['asset_class'] = \"Equity\" if 'Risk Free Rate' not in file_config['columns'].values() else \"Fixed Income\"\n",
    "                region_map = {}\n",
    "                for i, col in enumerate(orig_cols):\n",
    "                    if col == date_col:\n",
    "                        continue\n",
    "                    factor = file_config['columns'].get(col, col)\n",
    "                    if col == 'USA':\n",
    "                        region_map[factor] = 'USA'\n",
    "                    elif col == 'Global':\n",
    "                        region_map[factor] = 'Global'\n",
    "                    elif col == 'Global Ex USA':\n",
    "                        region_map[factor] = 'Intl'\n",
    "                    elif col == 'Risk Free Rate':\n",
    "                        region_map[factor] = 'USA'\n",
    "                df_long['region'] = df_long['factor'].map(region_map)\n",
    "                df_long['factor'] = df_long.apply(\n",
    "                    lambda row: f\"{row['factor']}_{row['region']}\" if row['factor'] != 'RF' and row['region'] is not None else row['factor'], axis=1\n",
    "                )\n",
    "            \n",
    "            df_long['associated_paper'] = file_config['paper']\n",
    "            df_long = df_long[['factor', 'date', 'associated_paper', 'asset_class', 'value', 'region']]\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                # Optimize query by limiting date range\n",
    "                min_date = df_long['date'].min().strftime('%Y-%m-%d')\n",
    "                existing = pd.read_sql(\n",
    "                    f\"SELECT factor, date, associated_paper, asset_class FROM factor_returns WHERE date >= '{min_date}'\",\n",
    "                    connection\n",
    "                )\n",
    "                existing['asset_class'] = existing['asset_class'].fillna('Unknown')\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(tuple(row) for row in existing[['factor', 'date', 'associated_paper', 'asset_class']].values)\n",
    "            \n",
    "            df_long['date_str'] = df_long['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_long['asset_class'] = df_long['asset_class'].fillna('Unknown')\n",
    "            df_long['key'] = df_long.apply(\n",
    "                lambda row: (row['factor'], row['date_str'], row['associated_paper'] if row['associated_paper'] else 'None', row['asset_class']), axis=1\n",
    "            )\n",
    "            df_new = df_long[~df_long['key'].isin(existing_keys)].drop(columns=['date_str', 'key'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                # Batch write for large datasets\n",
    "                for chunk in [df_new[i:i+10000] for i in range(0, len(df_new), 10000)]:\n",
    "                    chunk.to_sql(\n",
    "                        'factor_returns',\n",
    "                        engine,\n",
    "                        if_exists='append',\n",
    "                        index=False,\n",
    "                        dtype={\n",
    "                            'factor': VARCHAR(50),\n",
    "                            'date': DATE,\n",
    "                            'associated_paper': VARCHAR(100),\n",
    "                            'asset_class': VARCHAR(50),\n",
    "                            'value': DECIMAL(15, 6),\n",
    "                            'region': VARCHAR(50)\n",
    "                        }\n",
    "                    )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into factor_returns from {file_path} (sheet {sheet})\")\n",
    "            else:\n",
    "                logger.info(f\"No new rows to load into factor_returns from {file_path} (sheet {sheet})\")\n",
    "                logger.debug(f\"Input date range: {df_long['date'].min()} to {df_long['date'].max()}\")\n",
    "                logger.debug(f\"Database date range: {existing['date'].min() if not existing.empty else 'N/A'} to {existing['date'].max() if not existing.empty else 'N/A'}\")\n",
    "            \n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(f\"File not found: {file_path} (sheet {sheet}): {str(e)}\")\n",
    "    except pd.errors.ParserError as e:\n",
    "        logger.error(f\"Error parsing Excel file {file_path} (sheet {sheet}): {str(e)}\")\n",
    "    except KeyError as e:\n",
    "        logger.error(f\"Key error processing {file_path} (sheet {sheet}): {str(e)}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error processing {file_path} (sheet {sheet}): {type(e).__name__}: {str(e)}\")\n",
    "\n",
    "# Main loop - Process all datasets, no skips\n",
    "for key, config in data_files.items():\n",
    "    logger.info(f\"Processing dataset: {key}\")\n",
    "    if key == \"BAB_multi\":\n",
    "        for subkey, subconfig in config['sheets'].items():\n",
    "            process_factors(subconfig, sheet=subconfig['sheet'], parent_path=config['path'])\n",
    "    else:\n",
    "        is_com = (key == \"COM\")\n",
    "        process_factors(config, sheet=config['sheet'], is_com=is_com)\n",
    "\n",
    "logger.info(\"All data processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d7117a4-0ee6-4818-9c74-d3f0888df9dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 11:22:26,871 - INFO - Processing dataset: BAB_multi\n",
      "2025-04-11 11:22:26,872 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 0) with is_com=False\n",
      "2025-04-11 11:22:28,277 - INFO - Read 1129 rows with raw columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-11 11:22:28,279 - INFO - Columns after renaming: ['date', 'BAB', 'BAB', 'BAB']\n",
      "2025-04-11 11:22:28,290 - DEBUG - After dropping NA dates, 1129 rows remain\n",
      "2025-04-11 11:22:28,296 - DEBUG - Rows after melting and dropping NA: 2039\n",
      "2025-04-11 11:22:29,135 - DEBUG - Existing keys sample (first 5): [('TSM-Com_Unknown', '2016-10-31', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', 'Equity'), ('QMJ-P3', '1977-08-31', 'Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)', 'Equity'), ('Carry-All', '2022-04-29', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Equity'), ('Multi-style-Equity', '2024-05-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Equity'), ('ME_Global', '1985-04-30', 'AQR Factors', 'Equity')]\n",
      "2025-04-11 11:22:29,177 - DEBUG - New keys sample (first 5): [('BAB_Intl', '1930-12-31', 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity'), ('BAB_Intl', '1931-01-31', 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity'), ('BAB_Intl', '1931-02-28', 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity'), ('BAB_Intl', '1931-03-31', 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity'), ('BAB_Intl', '1931-04-30', 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity')]\n",
      "2025-04-11 11:22:29,302 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet 0): IntegrityError: (pyodbc.IntegrityError) ('23000', \"[23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Violation of PRIMARY KEY constraint 'PK__factor_r__C3CBC7054E79A6D5'. Cannot insert duplicate key in object 'dbo.factor_returns'. The duplicate key value is (BAB_Intl, 2018-03-31, Betting Against Beta (Frazzini and Pedersen, 2014)). (2627) (SQLExecDirectW); [23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]The statement has been terminated. (3621)\")\n",
      "[SQL: INSERT INTO factor_returns (factor, date, associated_paper, asset_class, value, region) VALUES (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ... 4663 characters truncated ... , (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?)]\n",
      "[parameters: ('BAB_Intl', datetime.datetime(2018, 3, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.024726359719057713, 'Intl', 'BAB_Intl', datetime.datetime(2018, 4, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.0007799553393408837, 'Intl', 'BAB_Intl', datetime.datetime(2018, 5, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.0061733720885607715, 'Intl', 'BAB_Intl', datetime.datetime(2018, 6, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.023681918622375155, 'Intl', 'BAB_Intl', datetime.datetime(2018, 7, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', -0.003681432428082633, 'Intl', 'BAB_Intl', datetime.datetime(2018, 8, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', -0.012114392481366903, 'Intl', 'BAB_Intl', datetime.datetime(2018, 9, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', -0.006209095953888497, 'Intl', 'BAB_Intl', datetime.datetime(2018, 10, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.02111187283759784, 'Intl', 'BAB_Intl', datetime.datetime(2018, 11, 30, 0, 0) ... 1376 parameters truncated ... -2.5060403776764988e-05, 'Intl', 'BAB_Intl', datetime.datetime(2024, 5, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.002565263878111521, 'Intl', 'BAB_Intl', datetime.datetime(2024, 6, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.012043546603209901, 'Intl', 'BAB_Intl', datetime.datetime(2024, 7, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.013925485845601635, 'Intl', 'BAB_Intl', datetime.datetime(2024, 8, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.02046397011764839, 'Intl', 'BAB_Intl', datetime.datetime(2024, 9, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', -0.0019636642634532978, 'Intl', 'BAB_Intl', datetime.datetime(2024, 10, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.004500638512225897, 'Intl', 'BAB_Intl', datetime.datetime(2024, 11, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', -0.0030851874094016255, 'Intl', 'BAB_Intl', datetime.datetime(2024, 12, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', -0.011472252667659768, 'Intl')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n"
     ]
    },
    {
     "ename": "IntegrityError",
     "evalue": "(pyodbc.IntegrityError) ('23000', \"[23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Violation of PRIMARY KEY constraint 'PK__factor_r__C3CBC7054E79A6D5'. Cannot insert duplicate key in object 'dbo.factor_returns'. The duplicate key value is (BAB_Intl, 2018-03-31, Betting Against Beta (Frazzini and Pedersen, 2014)). (2627) (SQLExecDirectW); [23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]The statement has been terminated. (3621)\")\n[SQL: INSERT INTO factor_returns (factor, date, associated_paper, asset_class, value, region) VALUES (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ... 4663 characters truncated ... , (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?)]\n[parameters: ('BAB_Intl', datetime.datetime(2018, 3, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.024726359719057713, 'Intl', 'BAB_Intl', datetime.datetime(2018, 4, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.0007799553393408837, 'Intl', 'BAB_Intl', datetime.datetime(2018, 5, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.0061733720885607715, 'Intl', 'BAB_Intl', datetime.datetime(2018, 6, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.023681918622375155, 'Intl', 'BAB_Intl', datetime.datetime(2018, 7, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', -0.003681432428082633, 'Intl', 'BAB_Intl', datetime.datetime(2018, 8, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', -0.012114392481366903, 'Intl', 'BAB_Intl', datetime.datetime(2018, 9, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', -0.006209095953888497, 'Intl', 'BAB_Intl', datetime.datetime(2018, 10, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.02111187283759784, 'Intl', 'BAB_Intl', datetime.datetime(2018, 11, 30, 0, 0) ... 1376 parameters truncated ... -2.5060403776764988e-05, 'Intl', 'BAB_Intl', datetime.datetime(2024, 5, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.002565263878111521, 'Intl', 'BAB_Intl', datetime.datetime(2024, 6, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.012043546603209901, 'Intl', 'BAB_Intl', datetime.datetime(2024, 7, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.013925485845601635, 'Intl', 'BAB_Intl', datetime.datetime(2024, 8, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.02046397011764839, 'Intl', 'BAB_Intl', datetime.datetime(2024, 9, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', -0.0019636642634532978, 'Intl', 'BAB_Intl', datetime.datetime(2024, 10, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.004500638512225897, 'Intl', 'BAB_Intl', datetime.datetime(2024, 11, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', -0.0030851874094016255, 'Intl', 'BAB_Intl', datetime.datetime(2024, 12, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', -0.011472252667659768, 'Intl')]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2115\u001b[0m, in \u001b[0;36mConnection._exec_insertmany_context\u001b[1;34m(self, dialect, context)\u001b[0m\n\u001b[0;32m   2114\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2115\u001b[0m         \u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2116\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2117\u001b[0m \u001b[43m            \u001b[49m\u001b[43msub_stmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2118\u001b[0m \u001b[43m            \u001b[49m\u001b[43msub_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2119\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2120\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2122\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:942\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 942\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIntegrityError\u001b[0m: ('23000', \"[23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Violation of PRIMARY KEY constraint 'PK__factor_r__C3CBC7054E79A6D5'. Cannot insert duplicate key in object 'dbo.factor_returns'. The duplicate key value is (BAB_Intl, 2018-03-31, Betting Against Beta (Frazzini and Pedersen, 2014)). (2627) (SQLExecDirectW); [23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]The statement has been terminated. (3621)\")",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 251\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBAB_multi\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subkey, subconfig \u001b[38;5;129;01min\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msheets\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 251\u001b[0m         \u001b[43mprocess_factors\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msheet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m     is_com \u001b[38;5;241m=\u001b[39m (key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[24], line 218\u001b[0m, in \u001b[0;36mprocess_factors\u001b[1;34m(file_config, sheet, is_com, parent_path)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df_new\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m [df_new[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m10000\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df_new), \u001b[38;5;241m10000\u001b[39m)]:\n\u001b[1;32m--> 218\u001b[0m         \u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfactor_returns\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m            \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m            \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mappend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfactor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mVARCHAR\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mDATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43massociated_paper\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mVARCHAR\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43masset_class\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mVARCHAR\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mDECIMAL\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mregion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mVARCHAR\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_new)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m new rows into factor_returns from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (sheet \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msheet\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\pandas\\core\\generic.py:3087\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2889\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2890\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[0;32m   2891\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3083\u001b[0m \u001b[38;5;124;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[0;32m   3084\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m   3085\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[1;32m-> 3087\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3088\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3098\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\pandas\\io\\sql.py:842\u001b[0m, in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m    837\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    838\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument should be either a Series or a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    839\u001b[0m     )\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con, schema\u001b[38;5;241m=\u001b[39mschema, need_transaction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m--> 842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\pandas\\io\\sql.py:2018\u001b[0m, in \u001b[0;36mSQLDatabase.to_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m   2006\u001b[0m sql_engine \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[0;32m   2008\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_table(\n\u001b[0;32m   2009\u001b[0m     frame\u001b[38;5;241m=\u001b[39mframe,\n\u001b[0;32m   2010\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2015\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   2016\u001b[0m )\n\u001b[1;32m-> 2018\u001b[0m total_inserted \u001b[38;5;241m=\u001b[39m \u001b[43msql_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert_records\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2020\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2027\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2028\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2030\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_case_sensitive(name\u001b[38;5;241m=\u001b[39mname, schema\u001b[38;5;241m=\u001b[39mschema)\n\u001b[0;32m   2031\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_inserted\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\pandas\\io\\sql.py:1567\u001b[0m, in \u001b[0;36mSQLAlchemyEngine.insert_records\u001b[1;34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[0m\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(msg, err_text):\n\u001b[0;32m   1566\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf cannot be used with MySQL\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m-> 1567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\pandas\\io\\sql.py:1558\u001b[0m, in \u001b[0;36mSQLAlchemyEngine.insert_records\u001b[1;34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[0m\n\u001b[0;32m   1555\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msqlalchemy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m exc\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mStatementError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1560\u001b[0m     \u001b[38;5;66;03m# GH34431\u001b[39;00m\n\u001b[0;32m   1561\u001b[0m     \u001b[38;5;66;03m# https://stackoverflow.com/a/67358288/6067848\u001b[39;00m\n\u001b[0;32m   1562\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m(1054, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown column \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf(e0)?\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfield list\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m))(?#\u001b[39m\n\u001b[0;32m   1563\u001b[0m \u001b[38;5;124m    )|inf can not be used with MySQL\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\pandas\\io\\sql.py:1119\u001b[0m, in \u001b[0;36mSQLTable.insert\u001b[1;34m(self, chunksize, method)\u001b[0m\n\u001b[0;32m   1116\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1118\u001b[0m chunk_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m(arr[start_i:end_i] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m data_list))\n\u001b[1;32m-> 1119\u001b[0m num_inserted \u001b[38;5;241m=\u001b[39m \u001b[43mexec_insert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;66;03m# GH 46891\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_inserted \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\pandas\\io\\sql.py:1010\u001b[0m, in \u001b[0;36mSQLTable._execute_insert\u001b[1;34m(self, conn, keys, data_iter)\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    999\u001b[0m \u001b[38;5;124;03mExecute SQL statement inserting data\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;124;03m   Each item contains a list of values to be inserted\u001b[39;00m\n\u001b[0;32m   1008\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(keys, row)) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m data_iter]\n\u001b[1;32m-> 1010\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mrowcount\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1416\u001b[0m, in \u001b[0;36mConnection.execute\u001b[1;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[0;32m   1414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1417\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1420\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\sqlalchemy\\sql\\elements.py:515\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[1;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[1;32m--> 515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1638\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[1;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[0;32m   1626\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1627\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[0;32m   1628\u001b[0m )\n\u001b[0;32m   1630\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[0;32m   1631\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[0;32m   1632\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1636\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[0;32m   1637\u001b[0m )\n\u001b[1;32m-> 1638\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[0;32m   1651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[0;32m   1652\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1653\u001b[0m         elem,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1657\u001b[0m         ret,\n\u001b[0;32m   1658\u001b[0m     )\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1841\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1838\u001b[0m context\u001b[38;5;241m.\u001b[39mpre_exec()\n\u001b[0;32m   1840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecute_style \u001b[38;5;129;01mis\u001b[39;00m ExecuteStyle\u001b[38;5;241m.\u001b[39mINSERTMANYVALUES:\n\u001b[1;32m-> 1841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_insertmany_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1842\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1843\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_single_context(\n\u001b[0;32m   1844\u001b[0m         dialect, context, statement, parameters\n\u001b[0;32m   1845\u001b[0m     )\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2123\u001b[0m, in \u001b[0;36mConnection._exec_insertmany_context\u001b[1;34m(self, dialect, context)\u001b[0m\n\u001b[0;32m   2115\u001b[0m         dialect\u001b[38;5;241m.\u001b[39mdo_execute(\n\u001b[0;32m   2116\u001b[0m             cursor,\n\u001b[0;32m   2117\u001b[0m             sub_stmt,\n\u001b[0;32m   2118\u001b[0m             sub_params,\n\u001b[0;32m   2119\u001b[0m             context,\n\u001b[0;32m   2120\u001b[0m         )\n\u001b[0;32m   2122\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 2123\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_long_statement\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_stmt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43msub_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_sub_exec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2130\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine_events:\n\u001b[0;32m   2133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[0;32m   2134\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2135\u001b[0m         cursor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2139\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[0;32m   2140\u001b[0m     )\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2352\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[0;32m   2350\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[0;32m   2351\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   2353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2354\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2115\u001b[0m, in \u001b[0;36mConnection._exec_insertmany_context\u001b[1;34m(self, dialect, context)\u001b[0m\n\u001b[0;32m   2113\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   2114\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2115\u001b[0m         \u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2116\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2117\u001b[0m \u001b[43m            \u001b[49m\u001b[43msub_stmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2118\u001b[0m \u001b[43m            \u001b[49m\u001b[43msub_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2119\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2120\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2122\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception(\n\u001b[0;32m   2124\u001b[0m         e,\n\u001b[0;32m   2125\u001b[0m         sql_util\u001b[38;5;241m.\u001b[39m_long_statement(sub_stmt),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2129\u001b[0m         is_sub_exec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   2130\u001b[0m     )\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:942\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 942\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIntegrityError\u001b[0m: (pyodbc.IntegrityError) ('23000', \"[23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Violation of PRIMARY KEY constraint 'PK__factor_r__C3CBC7054E79A6D5'. Cannot insert duplicate key in object 'dbo.factor_returns'. The duplicate key value is (BAB_Intl, 2018-03-31, Betting Against Beta (Frazzini and Pedersen, 2014)). (2627) (SQLExecDirectW); [23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]The statement has been terminated. (3621)\")\n[SQL: INSERT INTO factor_returns (factor, date, associated_paper, asset_class, value, region) VALUES (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ... 4663 characters truncated ... , (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?)]\n[parameters: ('BAB_Intl', datetime.datetime(2018, 3, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.024726359719057713, 'Intl', 'BAB_Intl', datetime.datetime(2018, 4, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.0007799553393408837, 'Intl', 'BAB_Intl', datetime.datetime(2018, 5, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.0061733720885607715, 'Intl', 'BAB_Intl', datetime.datetime(2018, 6, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.023681918622375155, 'Intl', 'BAB_Intl', datetime.datetime(2018, 7, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', -0.003681432428082633, 'Intl', 'BAB_Intl', datetime.datetime(2018, 8, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', -0.012114392481366903, 'Intl', 'BAB_Intl', datetime.datetime(2018, 9, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', -0.006209095953888497, 'Intl', 'BAB_Intl', datetime.datetime(2018, 10, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.02111187283759784, 'Intl', 'BAB_Intl', datetime.datetime(2018, 11, 30, 0, 0) ... 1376 parameters truncated ... -2.5060403776764988e-05, 'Intl', 'BAB_Intl', datetime.datetime(2024, 5, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.002565263878111521, 'Intl', 'BAB_Intl', datetime.datetime(2024, 6, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.012043546603209901, 'Intl', 'BAB_Intl', datetime.datetime(2024, 7, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.013925485845601635, 'Intl', 'BAB_Intl', datetime.datetime(2024, 8, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.02046397011764839, 'Intl', 'BAB_Intl', datetime.datetime(2024, 9, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', -0.0019636642634532978, 'Intl', 'BAB_Intl', datetime.datetime(2024, 10, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', 0.004500638512225897, 'Intl', 'BAB_Intl', datetime.datetime(2024, 11, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', -0.0030851874094016255, 'Intl', 'BAB_Intl', datetime.datetime(2024, 12, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Equity', -0.011472252667659768, 'Intl')]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import VARCHAR, DATE, DECIMAL\n",
    "import logging\n",
    "\n",
    "# Logging setup - Ensure DEBUG level is active\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(), logging.FileHandler('load_aqr_data.log')]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)  # Explicitly set to DEBUG\n",
    "\n",
    "# Database connection\n",
    "engine = create_engine(\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/CWA_Fund_Database\"\n",
    "    \"?driver=ODBC+Driver+18+for+SQL+Server&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "# File configurations (unchanged except for clarity)\n",
    "data_files = {\n",
    "    \"BAB_multi\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx\",\n",
    "        \"sheets\": {\n",
    "            \"BAB\": {\"sheet\": 0, \"header\": 18, \"paper\": \"Betting Against Beta (Frazzini and Pedersen, 2014)\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"BAB\", \"Global\": \"BAB\", \"Global Ex USA\": \"BAB\"}},\n",
    "            \"MKT\": {\"sheet\": 4, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"MKT\", \"Global\": \"MKT\", \"Global Ex USA\": \"MKT\"}},\n",
    "            \"SMB\": {\"sheet\": 5, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"SMB\", \"Global\": \"SMB\", \"Global Ex USA\": \"SMB\"}},\n",
    "            \"HML-FF\": {\"sheet\": 6, \"header\": 18, \"paper\": \"Fama-French Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-FF\", \"Global\": \"HML-FF\", \"Global Ex USA\": \"HML-FF\"}},\n",
    "            \"HML-D\": {\"sheet\": 7, \"header\": 18, \"paper\": \"The Devil's in HML's Details\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-D\", \"Global\": \"HML-D\", \"Global Ex USA\": \"HML-D\"}},\n",
    "            \"UMD\": {\"sheet\": 8, \"header\": 18, \"paper\": \"On Persistence in Mutual Fund Performance\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"UMD\", \"Global\": \"UMD\", \"Global Ex USA\": \"UMD\"}},\n",
    "            \"ME\": {\"sheet\": 9, \"header\": 18, \"paper\": \"AQR Factors\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"ME\", \"Global\": \"ME\", \"Global Ex USA\": \"ME\"}},\n",
    "            \"RF\": {\"sheet\": 10, \"header\": 18, \"paper\": None, \"columns\": {\"DATE\": \"DATE\", \"Risk Free Rate\": \"RF\"}}\n",
    "        }\n",
    "    },\n",
    "    # ... (other datasets unchanged)\n",
    "}\n",
    "\n",
    "def process_factors(file_config, sheet=0, is_com=False, parent_path=None):\n",
    "    file_path = parent_path if parent_path else file_config['path']\n",
    "    logger.info(f\"Processing {file_path} (sheet {sheet}) with is_com={is_com}\")\n",
    "    try:\n",
    "        # Read Excel\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet, header=file_config['header'])\n",
    "        logger.info(f\"Read {len(df)} rows with raw columns: {list(df.columns)}\")\n",
    "        \n",
    "        if is_com:\n",
    "            if 'columns' in file_config:\n",
    "                expected_cols = list(file_config['columns'].keys())\n",
    "                missing_cols = [col for col in expected_cols if col not in df.columns]\n",
    "                if missing_cols:\n",
    "                    logger.warning(f\"Missing columns in {file_path} (sheet {sheet}): {missing_cols}\")\n",
    "                df = df[[col for col in df.columns if col in expected_cols]]\n",
    "                df.columns = [file_config['columns'][col] for col in df.columns]\n",
    "            else:\n",
    "                logger.warning(f\"No column mapping provided for {file_path} (sheet {sheet}). Using default commodity columns.\")\n",
    "                df.columns = [\n",
    "                    'date', 'excess_return_eqwt', 'excess_spot_return_eqwt', 'ir_adjusted_carry_eqwt',\n",
    "                    'spot_return_eqwt', 'carry_eqwt', 'excess_return_long_short', 'excess_spot_return_long_short',\n",
    "                    'ir_adjusted_carry_long_short', 'aggregate_backwardation_contango', \n",
    "                    'state_backwardation_contango', 'state_inflation'\n",
    "                ]\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            df['associated_paper'] = file_config['paper'] if file_config['paper'] is not None else 'Unknown'\n",
    "            df = df.dropna(subset=['date'])\n",
    "            logger.debug(f\"After dropping NA dates, {len(df)} rows remain\")\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                min_date = df['date'].min().strftime('%Y-%m-%d')\n",
    "                existing = pd.read_sql(f\"SELECT date FROM aqr_cmdty_factors WHERE date >= '{min_date}'\", connection)\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(existing['date'])\n",
    "                logger.debug(f\"Existing commodity dates sample (first 5): {list(existing_keys)[:5]}\")\n",
    "            \n",
    "            df['date_str'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_new = df[~df['date_str'].isin(existing_keys)].drop(columns=['date_str'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                for chunk in [df_new[i:i+10000] for i in range(0, len(df_new), 10000)]:\n",
    "                    chunk.to_sql(\n",
    "                        'aqr_cmdty_factors',\n",
    "                        engine,\n",
    "                        if_exists='append',\n",
    "                        index=False,\n",
    "                        dtype={\n",
    "                            'date': DATE,\n",
    "                            'excess_return_eqwt': DECIMAL(15, 6),\n",
    "                            'excess_spot_return_eqwt': DECIMAL(15, 6),\n",
    "                            'ir_adjusted_carry_eqwt': DECIMAL(15, 6),\n",
    "                            'spot_return_eqwt': DECIMAL(15, 6),\n",
    "                            'carry_eqwt': DECIMAL(15, 6),\n",
    "                            'excess_return_long_short': DECIMAL(15, 6),\n",
    "                            'excess_spot_return_long_short': DECIMAL(15, 6),\n",
    "                            'ir_adjusted_carry_long_short': DECIMAL(15, 6),\n",
    "                            'aggregate_backwardation_contango': DECIMAL(15, 6),\n",
    "                            'state_backwardation_contango': VARCHAR(50),\n",
    "                            'state_inflation': VARCHAR(50),\n",
    "                            'associated_paper': VARCHAR(100)\n",
    "                        }\n",
    "                    )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into aqr_cmdty_factors from {file_path} (sheet {sheet})\")\n",
    "            else:\n",
    "                logger.info(f\"No new rows to load into aqr_cmdty_factors from {file_path} (sheet {sheet})\")\n",
    "                logger.debug(f\"Input date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "                logger.debug(f\"Database date range: {existing['date'].min() if not existing.empty else 'N/A'} to {existing['date'].max() if not existing.empty else 'N/A'}\")\n",
    "        else:\n",
    "            # Find date column\n",
    "            date_col = next(\n",
    "                (col for col in df.columns if isinstance(col, str) and ('DATE' in col.upper() or 'Date' in col)),\n",
    "                None\n",
    "            )\n",
    "            if date_col is None:\n",
    "                logger.warning(f\"No date column found in {file_path} (sheet {sheet}). Using first column.\")\n",
    "                date_col = df.columns[0]\n",
    "            \n",
    "            # Validate and rename columns\n",
    "            orig_cols = df.columns.tolist()\n",
    "            if 'columns' in file_config:\n",
    "                expected_cols = list(file_config['columns'].keys())\n",
    "                valid_cols = [col for col in expected_cols if col in df.columns]\n",
    "                missing_cols = [col for col in expected_cols if col not in df.columns]\n",
    "                if missing_cols:\n",
    "                    logger.warning(f\"Missing columns in {file_path} (sheet {sheet}): {missing_cols}\")\n",
    "                if not valid_cols:\n",
    "                    logger.error(f\"No valid columns found in {file_path} (sheet {sheet}). Skipping.\")\n",
    "                    return\n",
    "                if date_col not in valid_cols:\n",
    "                    valid_cols.append(date_col)\n",
    "                df = df[[col for col in df.columns if col in valid_cols]]\n",
    "                new_columns = ['date' if col == date_col else file_config['columns'].get(col, col) for col in df.columns]\n",
    "                df.columns = new_columns\n",
    "            \n",
    "            logger.info(f\"Columns after renaming: {list(df.columns)}\")\n",
    "            \n",
    "            # Parse dates\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            invalid_dates = df['date'].isna().sum()\n",
    "            if invalid_dates > 0:\n",
    "                logger.warning(f\"Dropped {invalid_dates} rows due to invalid dates in {file_path} (sheet {sheet})\")\n",
    "            df = df.dropna(subset=['date'])\n",
    "            logger.debug(f\"After dropping NA dates, {len(df)} rows remain\")\n",
    "            \n",
    "            # Melt DataFrame\n",
    "            value_vars = [col for col in df.columns if col != 'date']\n",
    "            df_long = df.melt(id_vars=['date'], value_vars=value_vars, var_name='factor', value_name='value')\n",
    "            df_long = df_long.dropna(subset=['value', 'date'])\n",
    "            logger.debug(f\"Rows after melting and dropping NA: {len(df_long)}\")\n",
    "            \n",
    "            # Assign asset class and region\n",
    "            file_path_for_check = parent_path if parent_path else file_config.get('path', '')\n",
    "            if 'TSMOM' in file_path_for_check:\n",
    "                df_long['asset_class'] = df_long['factor'].map({\n",
    "                    \"TSM-MA\": \"Multi-Asset\",\n",
    "                    \"TSM-Com\": \"Commodities\",\n",
    "                    \"TSM-EQ\": \"Equity\",\n",
    "                    \"TSM-FI\": \"Fixed Income\",\n",
    "                    \"TSM-FX\": \"Currencies\"\n",
    "                })\n",
    "                df_long['region'] = \"Global\"\n",
    "            elif 'Quality Minus Junk' in file_path_for_check:\n",
    "                df_long['asset_class'] = \"Equity\"\n",
    "                df_long['region'] = df_long['date'].apply(\n",
    "                    lambda x: \"USA\" if x < pd.Timestamp(\"1989-07-31\") else \"Global\"\n",
    "                )\n",
    "            elif 'Century' in file_path_for_check:\n",
    "                df_long['asset_class'] = df_long['factor'].str.extract(\n",
    "                    '(Stock Selection|Equity indices|Fixed income|Currencies|Commodities|All Macro|All asset classes)'\n",
    "                ).fillna('Equity')\n",
    "                df_long['region'] = df_long['factor'].apply(\n",
    "                    lambda x: 'US' if 'US' in x else 'Intl' if 'Intl' in x else 'Global'\n",
    "                )\n",
    "            else:  # BAB_multi\n",
    "                df_long['asset_class'] = \"Equity\" if 'Risk Free Rate' not in file_config['columns'].values() else \"Fixed Income\"\n",
    "                region_map = {}\n",
    "                for col in orig_cols:\n",
    "                    if col == date_col:\n",
    "                        continue\n",
    "                    factor = file_config['columns'].get(col, col)\n",
    "                    if col == 'USA':\n",
    "                        region_map[factor] = 'USA'\n",
    "                    elif col == 'Global':\n",
    "                        region_map[factor] = 'Global'\n",
    "                    elif col == 'Global Ex USA':\n",
    "                        region_map[factor] = 'Intl'\n",
    "                    elif col == 'Risk Free Rate':\n",
    "                        region_map[factor] = 'USA'\n",
    "                df_long['region'] = df_long['factor'].map(region_map)\n",
    "                df_long['factor'] = df_long.apply(\n",
    "                    lambda row: f\"{row['factor']}_{row['region']}\" if row['factor'] != 'RF' and row['region'] is not None else row['factor'], axis=1\n",
    "                )\n",
    "            \n",
    "            df_long['associated_paper'] = file_config['paper'] if file_config['paper'] is not None else 'Unknown'\n",
    "            df_long = df_long[['factor', 'date', 'associated_paper', 'asset_class', 'value', 'region']]\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                min_date = df_long['date'].min().strftime('%Y-%m-%d')\n",
    "                existing = pd.read_sql(\n",
    "                    f\"SELECT factor, date, associated_paper, asset_class FROM factor_returns WHERE date >= '{min_date}'\",\n",
    "                    connection\n",
    "                )\n",
    "                existing['asset_class'] = existing['asset_class'].fillna('Unknown')\n",
    "                existing['associated_paper'] = existing['associated_paper'].fillna('None')\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(tuple(row) for row in existing[['factor', 'date', 'associated_paper', 'asset_class']].values)\n",
    "                logger.debug(f\"Existing keys sample (first 5): {list(existing_keys)[:5]}\")\n",
    "            \n",
    "            df_long['date_str'] = df_long['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_long['asset_class'] = df_long['asset_class'].fillna('Unknown')\n",
    "            df_long['associated_paper'] = df_long['associated_paper'].fillna('None')\n",
    "            df_long['key'] = df_long.apply(\n",
    "                lambda row: (row['factor'], row['date_str'], row['associated_paper'], row['asset_class']), axis=1\n",
    "            )\n",
    "            logger.debug(f\"New keys sample (first 5): {df_long['key'].head().tolist()}\")\n",
    "            df_new = df_long[~df_long['key'].isin(existing_keys)].drop(columns=['date_str', 'key'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                for chunk in [df_new[i:i+10000] for i in range(0, len(df_new), 10000)]:\n",
    "                    chunk.to_sql(\n",
    "                        'factor_returns',\n",
    "                        engine,\n",
    "                        if_exists='append',\n",
    "                        index=False,\n",
    "                        dtype={\n",
    "                            'factor': VARCHAR(50),\n",
    "                            'date': DATE,\n",
    "                            'associated_paper': VARCHAR(100),\n",
    "                            'asset_class': VARCHAR(50),\n",
    "                            'value': DECIMAL(15, 6),\n",
    "                            'region': VARCHAR(50)\n",
    "                        }\n",
    "                    )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into factor_returns from {file_path} (sheet {sheet})\")\n",
    "            else:\n",
    "                logger.info(f\"No new rows to load into factor_returns from {file_path} (sheet {sheet})\")\n",
    "                logger.debug(f\"Input date range: {df_long['date'].min()} to {df_long['date'].max()}\")\n",
    "                logger.debug(f\"Database date range: {existing['date'].min() if not existing.empty else 'N/A'} to {existing['date'].max() if not existing.empty else 'N/A'}\")\n",
    "            \n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(f\"File not found: {file_path} (sheet {sheet}): {str(e)}\")\n",
    "    except pd.errors.ParserError as e:\n",
    "        logger.error(f\"Error parsing Excel file {file_path} (sheet {sheet}): {str(e)}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error processing {file_path} (sheet {sheet}): {type(e).__name__}: {str(e)}\")\n",
    "        raise  # Re-raise to see full stack trace during debugging\n",
    "\n",
    "# Main loop\n",
    "for key, config in data_files.items():\n",
    "    logger.info(f\"Processing dataset: {key}\")\n",
    "    if key == \"BAB_multi\":\n",
    "        for subkey, subconfig in config['sheets'].items():\n",
    "            process_factors(subconfig, sheet=subconfig['sheet'], parent_path=config['path'])\n",
    "    else:\n",
    "        is_com = (key == \"COM\")\n",
    "        process_factors(config, sheet=config['sheet'], is_com=is_com)\n",
    "\n",
    "logger.info(\"All data processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ff1e83d-aa87-4f97-a307-60d456e10e6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 11:56:49,654 - INFO - Processing dataset: BAB_multi\n",
      "2025-04-11 11:56:49,656 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet BAB Factors) with is_com=False\n",
      "2025-04-11 11:56:51,046 - INFO - Read 1128 rows with raw columns: ['12/31/1930', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', -0.000557986425086, 'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29']\n",
      "2025-04-11 11:56:51,047 - WARNING - No date column found in C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet BAB Factors). Using first column.\n",
      "2025-04-11 11:56:51,049 - WARNING - Missing columns in C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet BAB Factors): ['DATE', 'USA', 'Global', 'Global Ex USA']\n",
      "2025-04-11 11:56:51,049 - ERROR - No valid columns found in C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet BAB Factors). Skipping.\n",
      "2025-04-11 11:56:51,050 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet MKT) with is_com=False\n",
      "2025-04-11 11:56:51,644 - INFO - Read 1181 rows with raw columns: ['07/31/1926', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', 0.0283354011258, 'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29']\n",
      "2025-04-11 11:56:51,646 - WARNING - No date column found in C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet MKT). Using first column.\n",
      "2025-04-11 11:56:51,647 - WARNING - Missing columns in C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet MKT): ['DATE', 'USA', 'Global', 'Global Ex USA']\n",
      "2025-04-11 11:56:51,648 - ERROR - No valid columns found in C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet MKT). Skipping.\n",
      "2025-04-11 11:56:51,649 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet SMB) with is_com=False\n",
      "2025-04-11 11:56:52,325 - INFO - Read 1180 rows with raw columns: ['07/31/1926', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', -0.016588027537, 'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29']\n",
      "2025-04-11 11:56:52,327 - WARNING - No date column found in C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet SMB). Using first column.\n",
      "2025-04-11 11:56:52,328 - WARNING - Missing columns in C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet SMB): ['DATE', 'USA', 'Global', 'Global Ex USA']\n",
      "2025-04-11 11:56:52,329 - ERROR - No valid columns found in C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet SMB). Skipping.\n",
      "2025-04-11 11:56:52,329 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet HML FF) with is_com=False\n",
      "2025-04-11 11:56:53,011 - INFO - Read 1180 rows with raw columns: ['07/31/1926', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', -0.0271953118576, 'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29']\n",
      "2025-04-11 11:56:53,012 - WARNING - No date column found in C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet HML FF). Using first column.\n",
      "2025-04-11 11:56:53,013 - WARNING - Missing columns in C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet HML FF): ['DATE', 'USA', 'Global', 'Global Ex USA']\n",
      "2025-04-11 11:56:53,014 - ERROR - No valid columns found in C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet HML FF). Skipping.\n",
      "2025-04-11 11:56:53,015 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet HML Devil) with is_com=False\n",
      "2025-04-11 11:56:53,627 - INFO - Read 1181 rows with raw columns: ['07/31/1926', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', -0.0198557509772, 'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29']\n",
      "2025-04-11 11:56:53,627 - WARNING - No date column found in C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet HML Devil). Using first column.\n",
      "2025-04-11 11:56:53,629 - WARNING - Missing columns in C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet HML Devil): ['DATE', 'USA', 'Global', 'Global Ex USA']\n",
      "2025-04-11 11:56:53,630 - ERROR - No valid columns found in C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet HML Devil). Skipping.\n",
      "2025-04-11 11:56:53,630 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet UMD) with is_com=False\n",
      "2025-04-11 11:56:54,199 - INFO - Read 1175 rows with raw columns: ['01/31/1927', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', 0.0266643513295, 'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29']\n",
      "2025-04-11 11:56:54,201 - WARNING - No date column found in C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet UMD). Using first column.\n",
      "2025-04-11 11:56:54,202 - WARNING - Missing columns in C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet UMD): ['DATE', 'USA', 'Global', 'Global Ex USA']\n",
      "2025-04-11 11:56:54,203 - ERROR - No valid columns found in C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet UMD). Skipping.\n",
      "2025-04-11 11:56:54,204 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet ME(t-1)) with is_com=False\n",
      "2025-04-11 11:56:54,632 - INFO - Read 1181 rows with raw columns: ['07/31/1926', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 27892.9341875, 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29']\n",
      "2025-04-11 11:56:54,633 - WARNING - No date column found in C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet ME(t-1)). Using first column.\n",
      "2025-04-11 11:56:54,635 - WARNING - Missing columns in C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet ME(t-1)): ['DATE', 'USA', 'Global', 'Global Ex USA']\n",
      "2025-04-11 11:56:54,636 - ERROR - No valid columns found in C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet ME(t-1)). Skipping.\n",
      "2025-04-11 11:56:54,637 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet RF) with is_com=False\n",
      "2025-04-11 11:56:55,144 - INFO - Read 1183 rows with raw columns: ['DATE', 'Risk Free Rate']\n",
      "2025-04-11 11:56:55,146 - INFO - Columns after renaming: ['date', 'RF']\n",
      "2025-04-11 11:56:55,155 - DEBUG - After dropping NA dates, 1183 rows remain\n",
      "2025-04-11 11:56:55,161 - DEBUG - Rows after melting and dropping NA: 1183\n",
      "2025-04-11 11:56:55,271 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet RF): ProgrammingError: (pyodbc.ProgrammingError) ('42S22', \"[42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid column name 'factor_symbol'. (207) (SQLExecDirectW); [42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid column name 'portfolio'. (207)\")\n",
      "[SQL: SELECT factor_symbol, portfolio, region, date FROM factor_returns]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "2025-04-11 11:56:55,273 - INFO - Processing dataset: TSMOM\n",
      "2025-04-11 11:56:55,273 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet TSMOM Factors) with is_com=False\n",
      "2025-04-11 11:56:55,427 - INFO - Read 481 rows with raw columns: ['Unnamed: 0', 'TSMOM', 'TSMOM^CM', 'TSMOM^EQ', 'TSMOM^FI', 'TSMOM^FX']\n",
      "2025-04-11 11:56:55,428 - WARNING - No date column found in C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet TSMOM Factors). Using first column.\n",
      "2025-04-11 11:56:55,430 - INFO - Columns after renaming: ['date', 'TSM-MA', 'TSM-Com', 'TSM-EQ', 'TSM-FI', 'TSM-FX']\n",
      "2025-04-11 11:56:55,434 - DEBUG - After dropping NA dates, 481 rows remain\n",
      "2025-04-11 11:56:55,439 - DEBUG - Rows after melting and dropping NA: 2405\n",
      "2025-04-11 11:56:55,449 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet TSMOM Factors): ProgrammingError: (pyodbc.ProgrammingError) ('42S22', \"[42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid column name 'factor_symbol'. (207) (SQLExecDirectW); [42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid column name 'portfolio'. (207)\")\n",
      "[SQL: SELECT factor_symbol, portfolio, region, date FROM factor_returns]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "2025-04-11 11:56:55,450 - INFO - Processing dataset: QMJ\n",
      "2025-04-11 11:56:55,451 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 10 Portfolios Formed on Quality) with is_com=False\n",
      "2025-04-11 11:56:56,026 - INFO - Read 808 rows with raw columns: ['07/31/1957', -0.005016672241401992, 0.016438053192076186, -0.0018629379296232892, 0.004806585046341726, -0.005882511338651253, 0.017322414949695154, 0.0018166942388932648, 0.017135628005755674, 0.014401568183468263, 0.017518796894752758, 0.02253546913615475, 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22']\n",
      "2025-04-11 11:56:56,028 - WARNING - No date column found in C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 10 Portfolios Formed on Quality). Using first column.\n",
      "2025-04-11 11:56:56,029 - WARNING - Missing columns in C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 10 Portfolios Formed on Quality): ['DATE', 'P1 (low quality)', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10 (high quality)', 'P10-P1']\n",
      "2025-04-11 11:56:56,030 - ERROR - No valid columns found in C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 10 Portfolios Formed on Quality). Skipping.\n",
      "2025-04-11 11:56:56,031 - INFO - Processing dataset: Century\n",
      "2025-04-11 11:56:56,032 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx (sheet 0) with is_com=False\n",
      "2025-04-11 11:56:56,843 - INFO - Read 1182 rows with raw columns: ['Date', 'US Stock Selection Value', 'US Stock Selection Momentum', 'US Stock Selection Defensive', 'US Stock Selection Multi-style', 'Intl Stock Selection Value', 'Intl Stock Selection Momentum', 'Intl Stock Selection Defensive', 'Intl Stock Selection Multi-style', 'Equity indices Value', 'Equity indices Momentum', 'Equity indices Carry', 'Equity indices Defensive', 'Equity indices Multi-style', 'Fixed income Value', 'Fixed income Momentum', 'Fixed income Carry', 'Fixed income Defensive', 'Fixed income Multi-style', 'Currencies Value', 'Currencies Momentum', 'Currencies Carry', 'Currencies Multi-style', 'Commodities Value', 'Commodities Momentum', 'Commodities Carry', 'Commodities Multi-style', 'All Stock Selection Value', 'All Stock Selection Momentum', 'All Stock Selection Defensive', 'All Stock Selection Multi-style', 'All Macro Value', 'All Macro Momentum', 'All Macro Carry', 'All Macro Defensive', 'All Macro Multi-style', 'All asset classes Value', 'All asset classes Momentum', 'All asset classes Carry', 'All asset classes Defensive', 'All asset classes Multi-style', 'Equity indices Market', 'Fixed income Market', 'Commodities Market', 'All Macro Market']\n",
      "2025-04-11 11:56:56,846 - INFO - Columns after renaming: ['date', 'HML-FF-US', 'UMD-US', 'BAB-US', 'Multi-style-US', 'HML-FF-Intl', 'UMD-Intl', 'BAB-Intl', 'Multi-style-Intl', 'HML-Equity', 'UMD-Equity', 'Carry-Equity', 'BAB-Equity', 'Multi-style-Equity', 'HML-FI', 'UMD-FI', 'Carry-FI', 'BAB-FI', 'Multi-style-FI', 'HML-FX', 'UMD-FX', 'Carry-FX', 'Multi-style-FX', 'HML-COM', 'UMD-COM', 'Carry-COM', 'Multi-style-COM', 'HML-All-SS', 'UMD-All-SS', 'BAB-All-SS', 'Multi-style-All-SS', 'HML-All-Macro', 'UMD-All-Macro', 'Carry-All-Macro', 'BAB-All-Macro', 'Multi-style-All-Macro', 'HML-All', 'UMD-All', 'Carry-All', 'BAB-All', 'Multi-style-All', 'MKT-Equity', 'MKT-FI', 'MKT-COM', 'MKT-All-Macro']\n",
      "2025-04-11 11:56:56,851 - DEBUG - After dropping NA dates, 1182 rows remain\n",
      "2025-04-11 11:56:56,864 - DEBUG - Rows after melting and dropping NA: 46491\n",
      "2025-04-11 11:56:56,918 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx (sheet 0): ProgrammingError: (pyodbc.ProgrammingError) ('42S22', \"[42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid column name 'factor_symbol'. (207) (SQLExecDirectW); [42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid column name 'portfolio'. (207)\")\n",
      "[SQL: SELECT factor_symbol, portfolio, region, date FROM factor_returns]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "2025-04-11 11:56:56,920 - INFO - Processing dataset: COM\n",
      "2025-04-11 11:56:56,920 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx (sheet 0) with is_com=True\n",
      "2025-04-11 11:56:57,252 - INFO - Read 1776 rows with raw columns: ['Unnamed: 0', 'Excess return of equal-weight commodities portfolio', 'Excess spot return of equal-weight commodities portfolio', 'Interest rate adjusted carry of equal-weight commodities portfolio', 'Spot return of equal-weight commodities portfolio', 'Carry of equal-weight commodities portfolio', 'Excess return of long/short commodities portfolio', 'Excess spot return of long/short commodities portfolio', 'Interest rate adjusted carry of long/short commodities portfolio', 'Aggregate backwardation/contango', 'State of backwardation/contango', 'State of inflation']\n",
      "2025-04-11 11:56:57,253 - WARNING - Missing columns in C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx (sheet 0): ['Date']\n",
      "2025-04-11 11:56:57,255 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx (sheet 0): KeyError: 'date'\n",
      "2025-04-11 11:56:57,256 - INFO - All data processing complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import VARCHAR, DATE, DECIMAL\n",
    "import logging\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(), logging.FileHandler('load_aqr_data.log')]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Database connection\n",
    "engine = create_engine(\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/CWA_Fund_Database\"\n",
    "    \"?driver=ODBC+Driver+18+for+SQL+Server&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "# File configurations updated with sheet names and headers\n",
    "data_files = {\n",
    "    \"BAB_multi\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx\",\n",
    "        \"sheets\": {\n",
    "            \"BAB\": {\"sheet\": \"BAB Factors\", \"header\": 19, \"paper\": \"Betting Against Beta (Frazzini and Pedersen, 2014)\", \"factor_name\": \"Bet Against Beta\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"BAB\", \"Global\": \"BAB\", \"Global Ex USA\": \"BAB\"}},\n",
    "            \"MKT\": {\"sheet\": \"MKT\", \"header\": 19, \"paper\": \"Fama-French Factors\", \"factor_name\": \"Market\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"MKT\", \"Global\": \"MKT\", \"Global Ex USA\": \"MKT\"}},\n",
    "            \"SMB\": {\"sheet\": \"SMB\", \"header\": 19, \"paper\": \"Fama-French Factors\", \"factor_name\": \"Small Minus Big\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"SMB\", \"Global\": \"SMB\", \"Global Ex USA\": \"SMB\"}},\n",
    "            \"HML-FF\": {\"sheet\": \"HML FF\", \"header\": 19, \"paper\": \"Fama-French Factors\", \"factor_name\": \"High Minus Low - Fama French\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-FF\", \"Global\": \"HML-FF\", \"Global Ex USA\": \"HML-FF\"}},\n",
    "            \"HML-D\": {\"sheet\": \"HML Devil\", \"header\": 19, \"paper\": \"The Devil's in HML's Details\", \"factor_name\": \"High Minus Low - Devil/AQR\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-D\", \"Global\": \"HML-D\", \"Global Ex USA\": \"HML-D\"}},\n",
    "            \"UMD\": {\"sheet\": \"UMD\", \"header\": 19, \"paper\": \"On Persistence in Mutual Fund Performance\", \"factor_name\": \"Up Minus Down\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"UMD\", \"Global\": \"UMD\", \"Global Ex USA\": \"UMD\"}},\n",
    "            \"ME\": {\"sheet\": \"ME(t-1)\", \"header\": 19, \"paper\": \"AQR Factors\", \"factor_name\": \"Market Value of Equity\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"ME\", \"Global\": \"ME\", \"Global Ex USA\": \"ME\"}},\n",
    "            \"RF\": {\"sheet\": \"RF\", \"header\": 18, \"paper\": None, \"factor_name\": \"Risk Free\", \"columns\": {\"DATE\": \"DATE\", \"Risk Free Rate\": \"RF\"}}\n",
    "        }\n",
    "    },\n",
    "    \"TSMOM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx\",\n",
    "        \"sheet\": \"TSMOM Factors\",\n",
    "        \"header\": 17,\n",
    "        \"paper\": \"Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)\",\n",
    "        \"columns\": {\n",
    "            \"Unnamed: 0\": \"DATE\",\n",
    "            \"TSMOM\": \"TSM-MA\",\n",
    "            \"TSMOM^CM\": \"TSM-Com\",\n",
    "            \"TSMOM^EQ\": \"TSM-EQ\",\n",
    "            \"TSMOM^FI\": \"TSM-FI\",\n",
    "            \"TSMOM^FX\": \"TSM-FX\"\n",
    "        }\n",
    "    },\n",
    "    \"QMJ\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx\",\n",
    "        \"sheet\": \"10 Portfolios Formed on Quality\",\n",
    "        \"header\": 19,\n",
    "        \"paper\": \"Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)\",\n",
    "        \"columns\": {\n",
    "            \"DATE\": \"DATE\",\n",
    "            \"P1 (low quality)\": \"QMJ-P1-LQ\",\n",
    "            \"P2\": \"QMJ-P2\",\n",
    "            \"P3\": \"QMJ-P3\",\n",
    "            \"P4\": \"QMJ-P4\",\n",
    "            \"P5\": \"QMJ-P5\",\n",
    "            \"P6\": \"QMJ-P6\",\n",
    "            \"P7\": \"QMJ-P7\",\n",
    "            \"P8\": \"QMJ-P8\",\n",
    "            \"P9\": \"QMJ-P9\",\n",
    "            \"P10 (high quality)\": \"QMJ-P10-HQ\",\n",
    "            \"P10-P1\": \"QMJ\"\n",
    "        }\n",
    "    },\n",
    "    \"Century\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 18,\n",
    "        \"paper\": \"Century of Factor Premia Monthly-Ilmanen et al. (2021)\",\n",
    "        \"columns\": {\n",
    "            \"Date\": \"DATE\",\n",
    "            \"US Stock Selection Value\": \"HML-FF-US\", \"US Stock Selection Momentum\": \"UMD-US\", \n",
    "            \"US Stock Selection Defensive\": \"BAB-US\", \"US Stock Selection Multi-style\": \"Multi-style-US\",\n",
    "            \"Intl Stock Selection Value\": \"HML-FF-Intl\", \"Intl Stock Selection Momentum\": \"UMD-Intl\", \n",
    "            \"Intl Stock Selection Defensive\": \"BAB-Intl\", \"Intl Stock Selection Multi-style\": \"Multi-style-Intl\",\n",
    "            \"Equity indices Value\": \"HML-Equity\", \"Equity indices Momentum\": \"UMD-Equity\", \n",
    "            \"Equity indices Carry\": \"Carry-Equity\", \"Equity indices Defensive\": \"BAB-Equity\", \n",
    "            \"Equity indices Multi-style\": \"Multi-style-Equity\",\n",
    "            \"Fixed income Value\": \"HML-FI\", \"Fixed income Momentum\": \"UMD-FI\", \n",
    "            \"Fixed income Carry\": \"Carry-FI\", \"Fixed income Defensive\": \"BAB-FI\", \n",
    "            \"Fixed income Multi-style\": \"Multi-style-FI\",\n",
    "            \"Currencies Value\": \"HML-FX\", \"Currencies Momentum\": \"UMD-FX\", \n",
    "            \"Currencies Carry\": \"Carry-FX\", \"Currencies Multi-style\": \"Multi-style-FX\",\n",
    "            \"Commodities Value\": \"HML-COM\", \"Commodities Momentum\": \"UMD-COM\", \n",
    "            \"Commodities Carry\": \"Carry-COM\", \"Commodities Multi-style\": \"Multi-style-COM\",\n",
    "            \"All Stock Selection Value\": \"HML-All-SS\", \"All Stock Selection Momentum\": \"UMD-All-SS\", \n",
    "            \"All Stock Selection Defensive\": \"BAB-All-SS\", \"All Stock Selection Multi-style\": \"Multi-style-All-SS\",\n",
    "            \"All Macro Value\": \"HML-All-Macro\", \"All Macro Momentum\": \"UMD-All-Macro\", \n",
    "            \"All Macro Carry\": \"Carry-All-Macro\", \"All Macro Defensive\": \"BAB-All-Macro\", \n",
    "            \"All Macro Multi-style\": \"Multi-style-All-Macro\",\n",
    "            \"All asset classes Value\": \"HML-All\", \"All asset classes Momentum\": \"UMD-All\", \n",
    "            \"All asset classes Carry\": \"Carry-All\", \"All asset classes Defensive\": \"BAB-All\", \n",
    "            \"All asset classes Multi-style\": \"Multi-style-All\",\n",
    "            \"Equity indices Market\": \"MKT-Equity\", \"Fixed income Market\": \"MKT-FI\", \n",
    "            \"Commodities Market\": \"MKT-COM\", \"All Macro Market\": \"MKT-All-Macro\"\n",
    "        }\n",
    "    },\n",
    "    \"COM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 10,\n",
    "        \"paper\": \"Commodities for the Long Run\",\n",
    "        \"columns\": {\n",
    "            \"Date\": \"date\",\n",
    "            \"Excess return of equal-weight commodities portfolio\": \"excess_return_eqwt\",\n",
    "            \"Excess spot return of equal-weight commodities portfolio\": \"excess_spot_return_eqwt\",\n",
    "            \"Interest rate adjusted carry of equal-weight commodities portfolio\": \"ir_adjusted_carry_eqwt\",\n",
    "            \"Spot return of equal-weight commodities portfolio\": \"spot_return_eqwt\",\n",
    "            \"Carry of equal-weight commodities portfolio\": \"carry_eqwt\",\n",
    "            \"Excess return of long/short commodities portfolio\": \"excess_return_long_short\",\n",
    "            \"Excess spot return of long/short commodities portfolio\": \"excess_spot_return_long_short\",\n",
    "            \"Interest rate adjusted carry of long/short commodities portfolio\": \"ir_adjusted_carry_long_short\",\n",
    "            \"Aggregate backwardation/contango\": \"aggregate_backwardation_contango\",\n",
    "            \"State of backwardation/contango\": \"state_backwardation_contango\",\n",
    "            \"State of inflation\": \"state_inflation\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "def process_factors(file_config, sheet=0, is_com=False, parent_path=None):\n",
    "    file_path = parent_path if parent_path else file_config['path']\n",
    "    logger.info(f\"Processing {file_path} (sheet {sheet}) with is_com={is_com}\")\n",
    "    try:\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet, header=file_config['header'])\n",
    "        logger.info(f\"Read {len(df)} rows with raw columns: {list(df.columns)}\")\n",
    "        \n",
    "        if is_com:\n",
    "            expected_cols = list(file_config['columns'].keys())\n",
    "            missing_cols = [col for col in expected_cols if col not in df.columns]\n",
    "            if missing_cols:\n",
    "                logger.warning(f\"Missing columns in {file_path} (sheet {sheet}): {missing_cols}\")\n",
    "            df = df[[col for col in df.columns if col in expected_cols]]\n",
    "            df.columns = [file_config['columns'][col] for col in df.columns]\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            df['associated_paper'] = file_config['paper'] if file_config['paper'] is not None else 'Unknown'\n",
    "            df = df.dropna(subset=['date'])\n",
    "            logger.debug(f\"After dropping NA dates, {len(df)} rows remain\")\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                existing = pd.read_sql(\"SELECT date FROM aqr_cmdty_factors\", connection)\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(existing['date'])\n",
    "                logger.debug(f\"Existing commodity dates sample (first 5): {list(existing_keys)[:5]}\")\n",
    "            \n",
    "            df['date_str'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_new = df[~df['date_str'].isin(existing_keys)].drop(columns=['date_str'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                for chunk in [df_new[i:i+10000] for i in range(0, len(df_new), 10000)]:\n",
    "                    chunk.to_sql(\n",
    "                        'aqr_cmdty_factors',\n",
    "                        engine,\n",
    "                        if_exists='append',\n",
    "                        index=False,\n",
    "                        dtype={\n",
    "                            'date': DATE,\n",
    "                            'excess_return_eqwt': DECIMAL(15, 6),\n",
    "                            'excess_spot_return_eqwt': DECIMAL(15, 6),\n",
    "                            'ir_adjusted_carry_eqwt': DECIMAL(15, 6),\n",
    "                            'spot_return_eqwt': DECIMAL(15, 6),\n",
    "                            'carry_eqwt': DECIMAL(15, 6),\n",
    "                            'excess_return_long_short': DECIMAL(15, 6),\n",
    "                            'excess_spot_return_long_short': DECIMAL(15, 6),\n",
    "                            'ir_adjusted_carry_long_short': DECIMAL(15, 6),\n",
    "                            'aggregate_backwardation_contango': DECIMAL(15, 6),\n",
    "                            'state_backwardation_contango': VARCHAR(50),\n",
    "                            'state_inflation': VARCHAR(50),\n",
    "                            'associated_paper': VARCHAR(100)\n",
    "                        }\n",
    "                    )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into aqr_cmdty_factors from {file_path} (sheet {sheet})\")\n",
    "            else:\n",
    "                logger.info(f\"No new rows to load into aqr_cmdty_factors from {file_path} (sheet {sheet})\")\n",
    "                logger.debug(f\"Input date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "                logger.debug(f\"Database date range: {existing['date'].min() if not existing.empty else 'N/A'} to {existing['date'].max() if not existing.empty else 'N/A'}\")\n",
    "        else:\n",
    "            date_col = next(\n",
    "                (col for col in df.columns if isinstance(col, str) and ('DATE' in col.upper() or 'Date' in col)),\n",
    "                None\n",
    "            )\n",
    "            if date_col is None:\n",
    "                logger.warning(f\"No date column found in {file_path} (sheet {sheet}). Using first column.\")\n",
    "                date_col = df.columns[0]\n",
    "            \n",
    "            orig_cols = df.columns.tolist()\n",
    "            if 'columns' in file_config:\n",
    "                expected_cols = list(file_config['columns'].keys())\n",
    "                valid_cols = [col for col in expected_cols if col in df.columns]\n",
    "                missing_cols = [col for col in expected_cols if col not in df.columns]\n",
    "                if missing_cols:\n",
    "                    logger.warning(f\"Missing columns in {file_path} (sheet {sheet}): {missing_cols}\")\n",
    "                if not valid_cols:\n",
    "                    logger.error(f\"No valid columns found in {file_path} (sheet {sheet}). Skipping.\")\n",
    "                    return\n",
    "                if date_col not in valid_cols:\n",
    "                    valid_cols.append(date_col)\n",
    "                df = df[[col for col in df.columns if col in valid_cols]]\n",
    "                new_columns = ['date' if col == date_col else file_config['columns'].get(col, col) for col in df.columns]\n",
    "                df.columns = new_columns\n",
    "            \n",
    "            logger.info(f\"Columns after renaming: {list(df.columns)}\")\n",
    "            \n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            invalid_dates = df['date'].isna().sum()\n",
    "            if invalid_dates > 0:\n",
    "                logger.warning(f\"Dropped {invalid_dates} rows due to invalid dates in {file_path} (sheet {sheet})\")\n",
    "            df = df.dropna(subset=['date'])\n",
    "            logger.debug(f\"After dropping NA dates, {len(df)} rows remain\")\n",
    "            \n",
    "            value_vars = [col for col in df.columns if col != 'date']\n",
    "            df_long = df.melt(id_vars=['date'], value_vars=value_vars, var_name='factor_symbol', value_name='value')\n",
    "            df_long = df_long.dropna(subset=['value', 'date'])\n",
    "            logger.debug(f\"Rows after melting and dropping NA: {len(df_long)}\")\n",
    "            \n",
    "            # Assign columns based on table design\n",
    "            file_path_for_check = parent_path if parent_path else file_config.get('path', '')\n",
    "            if 'TSMOM' in file_path_for_check:\n",
    "                df_long['factor_symbol'] = df_long['factor_symbol']  # Keep as is (TSM-MA, etc.)\n",
    "                df_long['portfolio'] = 'TSMOM'  # Generic portfolio name for TSMOM factors\n",
    "                df_long['region'] = \"Global\"\n",
    "                df_long['factor_name'] = df_long['factor_symbol'].map({\n",
    "                    \"TSM-MA\": \"Time Series Momentum Multi-Asset\",\n",
    "                    \"TSM-Com\": \"Time Series Momentum Commodities\",\n",
    "                    \"TSM-EQ\": \"Time Series Momentum Equity\",\n",
    "                    \"TSM-FI\": \"Time Series Momentum Fixed Income\",\n",
    "                    \"TSM-FX\": \"Time Series Momentum Currencies\"\n",
    "                })\n",
    "            elif 'Quality Minus Junk' in file_path_for_check:\n",
    "                df_long['factor_symbol'] = df_long['factor_symbol'].apply(lambda x: \"QMJ\" if x == \"QMJ\" else x.split('-')[0])\n",
    "                df_long['portfolio'] = df_long['factor_symbol'].apply(lambda x: x if x != \"QMJ\" else \"P10-P1\")\n",
    "                df_long['region'] = df_long['date'].apply(lambda x: \"USA\" if x < pd.Timestamp(\"1989-07-31\") else \"Global\")\n",
    "                df_long['factor_name'] = df_long['factor_symbol'].apply(lambda x: \"Quality Minus Junk\" if x == \"QMJ\" else f\"Quality Portfolio {x.split('-')[1]}\")\n",
    "            elif 'Century' in file_path_for_check:\n",
    "                df_long['factor_symbol'] = df_long['factor_symbol'].apply(lambda x: x.split('-')[0])\n",
    "                df_long['portfolio'] = df_long['factor_symbol'].apply(lambda x: x)  # Use factor as portfolio for simplicity\n",
    "                df_long['region'] = df_long['factor_symbol'].apply(lambda x: 'US' if 'US' in x else 'Intl' if 'Intl' in x else 'Global')\n",
    "                df_long['factor_name'] = df_long['factor_symbol'].map({\n",
    "                    \"HML\": \"High Minus Low\", \"UMD\": \"Up Minus Down\", \"BAB\": \"Bet Against Beta\",\n",
    "                    \"MKT\": \"Market\", \"Carry\": \"Carry\", \"Multi-style\": \"Multi-style\"\n",
    "                }).fillna(df_long['factor_symbol'])\n",
    "            else:  # BAB_multi\n",
    "                df_long['factor_symbol'] = df_long['factor_symbol']  # Keep base factor (e.g., \"BAB\")\n",
    "                df_long['portfolio'] = file_config.get('sheet', 'Unknown')  # Use sheet name as portfolio\n",
    "                region_map = {}\n",
    "                for col in orig_cols:\n",
    "                    if col == date_col:\n",
    "                        continue\n",
    "                    factor = file_config['columns'].get(col, col)\n",
    "                    if col == 'USA':\n",
    "                        region_map[factor] = 'USA'\n",
    "                    elif col == 'Global':\n",
    "                        region_map[factor] = 'Global'\n",
    "                    elif col == 'Global Ex USA':\n",
    "                        region_map[factor] = 'Intl'\n",
    "                    elif col == 'Risk Free Rate':\n",
    "                        region_map[factor] = 'USA'\n",
    "                df_long['region'] = df_long['factor_symbol'].map(region_map)\n",
    "                df_long['factor_name'] = file_config.get('factor_name', df_long['factor_symbol'])\n",
    "            \n",
    "            df_long['associated_paper'] = file_config['paper'] if file_config['paper'] is not None else 'Unknown'\n",
    "            df_long = df_long[['factor_symbol', 'factor_name', 'portfolio', 'region', 'date', 'value', 'associated_paper']]\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                existing = pd.read_sql(\n",
    "                    \"SELECT factor_symbol, portfolio, region, date FROM factor_returns\",\n",
    "                    connection\n",
    "                )\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(tuple(row) for row in existing[['factor_symbol', 'portfolio', 'region', 'date']].values)\n",
    "                logger.debug(f\"Existing keys sample (first 5): {list(existing_keys)[:5]}\")\n",
    "                logger.debug(f\"Total existing keys: {len(existing_keys)}\")\n",
    "            \n",
    "            df_long['date_str'] = df_long['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_long['key'] = df_long.apply(\n",
    "                lambda row: (row['factor_symbol'], row['portfolio'], row['region'], row['date_str']), axis=1\n",
    "            )\n",
    "            logger.debug(f\"New keys sample (first 5): {df_long['key'].head().tolist()}\")\n",
    "            df_new = df_long[~df_long['key'].isin(existing_keys)].drop(columns=['date_str', 'key'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                logger.debug(f\"New rows to insert: {len(df_new)}. Sample (first 5): {df_new[['factor_symbol', 'portfolio', 'region', 'date']].head().to_dict('records')}\")\n",
    "                for chunk in [df_new[i:i+10000] for i in range(0, len(df_new), 10000)]:\n",
    "                    chunk.to_sql(\n",
    "                        'factor_returns',\n",
    "                        engine,\n",
    "                        if_exists='append',\n",
    "                        index=False,\n",
    "                        dtype={\n",
    "                            'factor_symbol': VARCHAR(20),\n",
    "                            'factor_name': VARCHAR(100),\n",
    "                            'portfolio': VARCHAR(100),\n",
    "                            'region': VARCHAR(50),\n",
    "                            'date': DATE,\n",
    "                            'value': DECIMAL(15, 6),\n",
    "                            'associated_paper': VARCHAR(150)\n",
    "                        }\n",
    "                    )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into factor_returns from {file_path} (sheet {sheet})\")\n",
    "            else:\n",
    "                logger.info(f\"No new rows to load into factor_returns from {file_path} (sheet {sheet})\")\n",
    "                logger.debug(f\"Input date range: {df_long['date'].min()} to {df_long['date'].max()}\")\n",
    "                logger.debug(f\"Database date range: {existing['date'].min() if not existing.empty else 'N/A'} to {existing['date'].max() if not existing.empty else 'N/A'}\")\n",
    "            \n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(f\"File not found: {file_path} (sheet {sheet}): {str(e)}\")\n",
    "    except pd.errors.ParserError as e:\n",
    "        logger.error(f\"Error parsing Excel file {file_path} (sheet {sheet}): {str(e)}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error processing {file_path} (sheet {sheet}): {type(e).__name__}: {str(e)}\")\n",
    "\n",
    "# Main loop\n",
    "for key, config in data_files.items():\n",
    "    logger.info(f\"Processing dataset: {key}\")\n",
    "    if key == \"BAB_multi\":\n",
    "        for subkey, subconfig in config['sheets'].items():\n",
    "            process_factors(subconfig, sheet=subconfig['sheet'], parent_path=config['path'])\n",
    "    else:\n",
    "        is_com = (key == \"COM\")\n",
    "        process_factors(config, sheet=config['sheet'], is_com=is_com)\n",
    "\n",
    "logger.info(\"All data processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fddf3e86-9fb3-4048-9c71-00f619d10b3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 179) (2007911644.py, line 179)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[26], line 179\u001b[1;36m\u001b[0m\n\u001b[1;33m    logger.debug(f\"Input date range: {df['date'].min()} to {df['date机床.max()}\")\u001b[0m\n\u001b[1;37m                                                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 179)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import VARCHAR, DATE, DECIMAL\n",
    "import logging\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(), logging.FileHandler('load_aqr_data.log')]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Database connection\n",
    "engine = create_engine(\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/CWA_Fund_Database\"\n",
    "    \"?driver=ODBC+Driver+18+for+SQL+Server&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "# File configurations\n",
    "data_files = {\n",
    "    \"BAB_multi\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx\",\n",
    "        \"sheets\": {\n",
    "            \"BAB\": {\"sheet\": \"BAB Factors\", \"header\": 18, \"paper\": \"Betting Against Beta (Frazzini and Pedersen, 2014)\", \"factor_name\": \"Bet Against Beta\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"BAB\", \"Global\": \"BAB\", \"Global Ex USA\": \"BAB\"}},\n",
    "            \"MKT\": {\"sheet\": \"MKT\", \"header\": 18, \"paper\": \"Fama-French Factors\", \"factor_name\": \"Market\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"MKT\", \"Global\": \"MKT\", \"Global Ex USA\": \"MKT\"}},\n",
    "            \"SMB\": {\"sheet\": \"SMB\", \"header\": 18, \"paper\": \"Fama-French Factors\", \"factor_name\": \"Small Minus Big\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"SMB\", \"Global\": \"SMB\", \"Global Ex USA\": \"SMB\"}},\n",
    "            \"HML-FF\": {\"sheet\": \"HML FF\", \"header\": 18, \"paper\": \"Fama-French Factors\", \"factor_name\": \"High Minus Low - Fama French\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-FF\", \"Global\": \"HML-FF\", \"Global Ex USA\": \"HML-FF\"}},\n",
    "            \"HML-D\": {\"sheet\": \"HML Devil\", \"header\": 18, \"paper\": \"The Devil's in HML's Details\", \"factor_name\": \"High Minus Low - Devil/AQR\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-D\", \"Global\": \"HML-D\", \"Global Ex USA\": \"HML-D\"}},\n",
    "            \"UMD\": {\"sheet\": \"UMD\", \"header\": 18, \"paper\": \"On Persistence in Mutual Fund Performance\", \"factor_name\": \"Up Minus Down\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"UMD\", \"Global\": \"UMD\", \"Global Ex USA\": \"UMD\"}},\n",
    "            \"ME\": {\"sheet\": \"ME(t-1)\", \"header\": 18, \"paper\": \"AQR Factors\", \"factor_name\": \"Market Value of Equity\", \"columns\": {\"DATE\": \"DATE\", \"USA\": \"ME\", \"Global\": \"ME\", \"Global Ex USA\": \"ME\"}},\n",
    "            \"RF\": {\"sheet\": \"RF\", \"header\": 17, \"paper\": None, \"factor_name\": \"Risk Free\", \"columns\": {\"DATE\": \"DATE\", \"Risk Free Rate\": \"RF\"}}\n",
    "        }\n",
    "    },\n",
    "    \"TSMOM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx\",\n",
    "        \"sheet\": \"TSMOM Factors\",\n",
    "        \"header\": 17,\n",
    "        \"paper\": \"Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)\",\n",
    "        \"columns\": {\n",
    "            \"Unnamed: 0\": \"DATE\",\n",
    "            \"TSMOM\": \"TSM-MA\",\n",
    "            \"TSMOM^CM\": \"TSM-Com\",\n",
    "            \"TSMOM^EQ\": \"TSM-EQ\",\n",
    "            \"TSMOM^FI\": \"TSM-FI\",\n",
    "            \"TSMOM^FX\": \"TSM-FX\"\n",
    "        }\n",
    "    },\n",
    "    \"QMJ\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx\",\n",
    "        \"sheet\": \"10 Portfolios Formed on Quality\",\n",
    "        \"header\": 18,\n",
    "        \"paper\": \"Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)\",\n",
    "        \"columns\": {\n",
    "            \"DATE\": \"DATE\",\n",
    "            \"P1 (low quality)\": \"QMJ-P1-LQ\",\n",
    "            \"P2\": \"QMJ-P2\",\n",
    "            \"P3\": \"QMJ-P3\",\n",
    "            \"P4\": \"QMJ-P4\",\n",
    "            \"P5\": \"QMJ-P5\",\n",
    "            \"P6\": \"QMJ-P6\",\n",
    "            \"P7\": \"QMJ-P7\",\n",
    "            \"P8\": \"QMJ-P8\",\n",
    "            \"P9\": \"QMJ-P9\",\n",
    "            \"P10 (high quality)\": \"QMJ-P10-HQ\",\n",
    "            \"P10-P1\": \"QMJ\"\n",
    "        }\n",
    "    },\n",
    "    \"Century\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 18,\n",
    "        \"paper\": \"Century of Factor Premia Monthly-Ilmanen et al. (2021)\",\n",
    "        \"columns\": {\n",
    "            \"Date\": \"DATE\",\n",
    "            \"US Stock Selection Value\": \"HML-FF-US\", \"US Stock Selection Momentum\": \"UMD-US\", \n",
    "            \"US Stock Selection Defensive\": \"BAB-US\", \"US Stock Selection Multi-style\": \"Multi-style-US\",\n",
    "            \"Intl Stock Selection Value\": \"HML-FF-Intl\", \"Intl Stock Selection Momentum\": \"UMD-Intl\", \n",
    "            \"Intl Stock Selection Defensive\": \"BAB-Intl\", \"Intl Stock Selection Multi-style\": \"Multi-style-Intl\",\n",
    "            \"Equity indices Value\": \"HML-Equity\", \"Equity indices Momentum\": \"UMD-Equity\", \n",
    "            \"Equity indices Carry\": \"Carry-Equity\", \"Equity indices Defensive\": \"BAB-Equity\", \n",
    "            \"Equity indices Multi-style\": \"Multi-style-Equity\",\n",
    "            \"Fixed income Value\": \"HML-FI\", \"Fixed income Momentum\": \"UMD-FI\", \n",
    "            \"Fixed income Carry\": \"Carry-FI\", \"Fixed income Defensive\": \"BAB-FI\", \n",
    "            \"Fixed income Multi-style\": \"Multi-style-FI\",\n",
    "            \"Currencies Value\": \"HML-FX\", \"Currencies Momentum\": \"UMD-FX\", \n",
    "            \"Currencies Carry\": \"Carry-FX\", \"Currencies Multi-style\": \"Multi-style-FX\",\n",
    "            \"Commodities Value\": \"HML-COM\", \"Commodities Momentum\": \"UMD-COM\", \n",
    "            \"Commodities Carry\": \"Carry-COM\", \"Commodities Multi-style\": \"Multi-style-COM\",\n",
    "            \"All Stock Selection Value\": \"HML-All-SS\", \"All Stock Selection Momentum\": \"UMD-All-SS\", \n",
    "            \"All Stock Selection Defensive\": \"BAB-All-SS\", \"All Stock Selection Multi-style\": \"Multi-style-All-SS\",\n",
    "            \"All Macro Value\": \"HML-All-Macro\", \"All Macro Momentum\": \"UMD-All-Macro\", \n",
    "            \"All Macro Carry\": \"Carry-All-Macro\", \"All Macro Defensive\": \"BAB-All-Macro\", \n",
    "            \"All Macro Multi-style\": \"Multi-style-All-Macro\",\n",
    "            \"All asset classes Value\": \"HML-All\", \"All asset classes Momentum\": \"UMD-All\", \n",
    "            \"All asset classes Carry\": \"Carry-All\", \"All asset classes Defensive\": \"BAB-All\", \n",
    "            \"All asset classes Multi-style\": \"Multi-style-All\",\n",
    "            \"Equity indices Market\": \"MKT-Equity\", \"Fixed income Market\": \"MKT-FI\", \n",
    "            \"Commodities Market\": \"MKT-COM\", \"All Macro Market\": \"MKT-All-Macro\"\n",
    "        }\n",
    "    },\n",
    "    \"COM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"header\": 10,\n",
    "        \"paper\": \"Commodities for the Long Run\",\n",
    "        \"columns\": {\n",
    "            \"Unnamed: 0\": \"date\",\n",
    "            \"Excess return of equal-weight commodities portfolio\": \"excess_return_eqwt\",\n",
    "            \"Excess spot return of equal-weight commodities portfolio\": \"excess_spot_return_eqwt\",\n",
    "            \"Interest rate adjusted carry of equal-weight commodities portfolio\": \"ir_adjusted_carry_eqwt\",\n",
    "            \"Spot return of equal-weight commodities portfolio\": \"spot_return_eqwt\",\n",
    "            \"Carry of equal-weight commodities portfolio\": \"carry_eqwt\",\n",
    "            \"Excess return of long/short commodities portfolio\": \"excess_return_long_short\",\n",
    "            \"Excess spot return of long/short commodities portfolio\": \"excess_spot_return_long_short\",\n",
    "            \"Interest rate adjusted carry of long/short commodities portfolio\": \"ir_adjusted_carry_long_short\",\n",
    "            \"Aggregate backwardation/contango\": \"aggregate_backwardation_contango\",\n",
    "            \"State of backwardation/contango\": \"state_backwardation_contango\",\n",
    "            \"State of inflation\": \"state_inflation\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "def process_factors(file_config, sheet=0, is_com=False, parent_path=None):\n",
    "    file_path = parent_path if parent_path else file_config['path']\n",
    "    logger.info(f\"Processing {file_path} (sheet {sheet}) with is_com={is_com}\")\n",
    "    try:\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet, header=file_config['header'])\n",
    "        logger.info(f\"Read {len(df)} rows with raw columns: {list(df.columns)}\")\n",
    "        \n",
    "        if is_com:\n",
    "            expected_cols = list(file_config['columns'].keys())\n",
    "            missing_cols = [col for col in expected_cols if col not in df.columns]\n",
    "            if missing_cols:\n",
    "                logger.warning(f\"Missing columns in {file_path} (sheet {sheet}): {missing_cols}\")\n",
    "            df = df[[col for col in df.columns if col in expected_cols]]\n",
    "            df.columns = [file_config['columns'][col] for col in df.columns]\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            df['associated_paper'] = file_config['paper'] if file_config['paper'] is not None else 'Unknown'\n",
    "            df = df.dropna(subset=['date'])\n",
    "            logger.debug(f\"After dropping NA dates, {len(df)} rows remain\")\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                existing = pd.read_sql(\"SELECT date FROM aqr_cmdty_factors\", connection)\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(existing['date'])\n",
    "                logger.debug(f\"Existing commodity dates sample (first 5): {list(existing_keys)[:5]}\")\n",
    "            \n",
    "            df['date_str'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_new = df[~df['date_str'].isin(existing_keys)].drop(columns=['date_str'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                for chunk in [df_new[i:i+10000] for i in range(0, len(df_new), 10000)]:\n",
    "                    chunk.to_sql(\n",
    "                        'aqr_cmdty_factors',\n",
    "                        engine,\n",
    "                        if_exists='append',\n",
    "                        index=False,\n",
    "                        dtype={\n",
    "                            'date': DATE,\n",
    "                            'excess_return_eqwt': DECIMAL(15, 6),\n",
    "                            'excess_spot_return_eqwt': DECIMAL(15, 6),\n",
    "                            'ir_adjusted_carry_eqwt': DECIMAL(15, 6),\n",
    "                            'spot_return_eqwt': DECIMAL(15, 6),\n",
    "                            'carry_eqwt': DECIMAL(15, 6),\n",
    "                            'excess_return_long_short': DECIMAL(15, 6),\n",
    "                            'excess_spot_return_long_short': DECIMAL(15, 6),\n",
    "                            'ir_adjusted_carry_long_short': DECIMAL(15, 6),\n",
    "                            'aggregate_backwardation_contango': DECIMAL(15, 6),\n",
    "                            'state_backwardation_contango': VARCHAR(50),\n",
    "                            'state_inflation': VARCHAR(50),\n",
    "                            'associated_paper': VARCHAR(100)\n",
    "                        }\n",
    "                    )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into aqr_cmdty_factors from {file_path} (sheet {sheet})\")\n",
    "            else:\n",
    "                logger.info(f\"No new rows to load into aqr_cmdty_factors from {file_path} (sheet {sheet})\")\n",
    "                logger.debug(f\"Input date range: {df['date'].min()} to {df['date机床.max()}\")\n",
    "                logger.debug(f\"Database date range: {existing['date'].min() if not existing.empty else 'N/A'} to {existing['date'].max() if not existing.empty else 'N/A'}\")\n",
    "        else:\n",
    "            date_col = next(\n",
    "                (col for col in df.columns if isinstance(col, str) and ('DATE' in col.upper() or 'Date' in col)),\n",
    "                None\n",
    "            )\n",
    "            if date_col is None:\n",
    "                logger.warning(f\"No date column found in {file_path} (sheet {sheet}). Using first column.\")\n",
    "                date_col = df.columns[0]\n",
    "            \n",
    "            orig_cols = df.columns.tolist()\n",
    "            if 'columns' in file_config:\n",
    "                expected_cols = list(file_config['columns'].keys())\n",
    "                valid_cols = [col for col in expected_cols if col in df.columns]\n",
    "                missing_cols = [col for col in expected_cols if col not in df.columns]\n",
    "                if missing_cols:\n",
    "                    logger.warning(f\"Missing columns in {file_path} (sheet {sheet}): {missing_cols}\")\n",
    "                if not valid_cols:\n",
    "                    logger.error(f\"No valid columns found in {file_path} (sheet {sheet}). Skipping.\")\n",
    "                    return\n",
    "                if date_col not in valid_cols:\n",
    "                    valid_cols.append(date_col)\n",
    "                df = df[[col for col in df.columns if col in valid_cols]]\n",
    "                new_columns = ['date' if col == date_col else file_config['columns'].get(col, col) for col in df.columns]\n",
    "                df.columns = new_columns\n",
    "            \n",
    "            logger.info(f\"Columns after renaming: {list(df.columns)}\")\n",
    "            \n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            invalid_dates = df['date'].isna().sum()\n",
    "            if invalid_dates > 0:\n",
    "                logger.warning(f\"Dropped {invalid_dates} rows due to invalid dates in {file_path} (sheet {sheet})\")\n",
    "            df = df.dropna(subset=['date'])\n",
    "            logger.debug(f\"After dropping NA dates, {len(df)} rows remain\")\n",
    "            \n",
    "            value_vars = [col for col in df.columns if col != 'date']\n",
    "            df_long = df.melt(id_vars=['date'], value_vars=value_vars, var_name='factor_symbol', value_name='value')\n",
    "            df_long = df_long.dropna(subset=['value', 'date'])\n",
    "            logger.debug(f\"Rows after melting and dropping NA: {len(df_long)}\")\n",
    "            \n",
    "            file_path_for_check = parent_path if parent_path else file_config.get('path', '')\n",
    "            if 'TSMOM' in file_path_for_check:\n",
    "                df_long['factor_symbol'] = df_long['factor_symbol']\n",
    "                df_long['portfolio'] = 'TSMOM'\n",
    "                df_long['region'] = \"Global\"\n",
    "                df_long['factor_name'] = df_long['factor_symbol'].map({\n",
    "                    \"TSM-MA\": \"Time Series Momentum Multi-Asset\",\n",
    "                    \"TSM-Com\": \"Time Series Momentum Commodities\",\n",
    "                    \"TSM-EQ\": \"Time Series Momentum Equity\",\n",
    "                    \"TSM-FI\": \"Time Series Momentum Fixed Income\",\n",
    "                    \"TSM-FX\": \"Time Series Momentum Currencies\"\n",
    "                })\n",
    "            elif 'Quality Minus Junk' in file_path_for_check:\n",
    "                df_long['factor_symbol'] = df_long['factor_symbol'].apply(lambda x: \"QMJ\" if x == \"QMJ\" else x.split('-')[0])\n",
    "                df_long['portfolio'] = df_long['factor_symbol'].apply(lambda x: x if x != \"QMJ\" else \"P10-P1\")\n",
    "                df_long['region'] = df_long['date'].apply(lambda x: \"USA\" if x < pd.Timestamp(\"1989-07-31\") else \"Global\")\n",
    "                df_long['factor_name'] = df_long['factor_symbol'].apply(lambda x: \"Quality Minus Junk\" if x == \"QMJ\" else f\"Quality Portfolio {x.split('-')[1]}\")\n",
    "            elif 'Century' in file_path_for_check:\n",
    "                df_long['factor_symbol'] = df_long['factor_symbol'].apply(lambda x: x.split('-')[0])\n",
    "                df_long['portfolio'] = df_long['factor_symbol'].apply(lambda x: x)\n",
    "                df_long['region'] = df_long['factor_symbol'].apply(lambda x: 'US' if 'US' in x else 'Intl' if 'Intl' in x else 'Global')\n",
    "                df_long['factor_name'] = df_long['factor_symbol'].map({\n",
    "                    \"HML\": \"High Minus Low\", \"UMD\": \"Up Minus Down\", \"BAB\": \"Bet Against Beta\",\n",
    "                    \"MKT\": \"Market\", \"Carry\": \"Carry\", \"Multi-style\": \"Multi-style\"\n",
    "                }).fillna(df_long['factor_symbol'])\n",
    "            else:  # BAB_multi\n",
    "                df_long['factor_symbol'] = df_long['factor_symbol']\n",
    "                df_long['portfolio'] = file_config.get('sheet', 'Unknown')\n",
    "                region_map = {}\n",
    "                for col in orig_cols:\n",
    "                    if col == date_col:\n",
    "                        continue\n",
    "                    factor = file_config['columns'].get(col, col)\n",
    "                    if col == 'USA':\n",
    "                        region_map[factor] = 'USA'\n",
    "                    elif col == 'Global':\n",
    "                        region_map[factor] = 'Global'\n",
    "                    elif col == 'Global Ex USA':\n",
    "                        region_map[factor] = 'Intl'\n",
    "                    elif col == 'Risk Free Rate':\n",
    "                        region_map[factor] = 'USA'\n",
    "                df_long['region'] = df_long['factor_symbol'].map(region_map)\n",
    "                df_long['factor_name'] = file_config.get('factor_name', df_long['factor_symbol'])\n",
    "            \n",
    "            df_long['associated_paper'] = file_config['paper'] if file_config['paper'] is not None else 'Unknown'\n",
    "            df_long = df_long[['factor_symbol', 'factor_name', 'portfolio', 'region', 'date', 'value', 'associated_paper']]\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                # Update query to match existing table columns\n",
    "                existing = pd.read_sql(\n",
    "                    \"SELECT factor, date, associated_paper, region FROM factor_returns\",\n",
    "                    connection\n",
    "                )\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                # Adjust key to match old table for now\n",
    "                existing_keys = set(tuple(row) for row in existing[['factor', 'date', 'associated_paper', 'region']].values)\n",
    "                logger.debug(f\"Existing keys sample (first 5): {list(existing_keys)[:5]}\")\n",
    "                logger.debug(f\"Total existing keys: {len(existing_keys)}\")\n",
    "            \n",
    "            df_long['date_str'] = df_long['date'].dt.strftime('%Y-%m-%d')\n",
    "            # Temporarily align with old table structure\n",
    "            df_long['factor'] = df_long['factor_symbol']  # Map to old 'factor' column\n",
    "            df_new = df_long[~df_long.apply(lambda row: (row['factor'], row['date_str'], row['associated_paper'], row['region']), axis=1).isin(existing_keys)]\n",
    "            df_new = df_new.drop(columns=['date_str', 'factor_symbol']).rename(columns={'factor': 'factor_symbol'})\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                logger.debug(f\"New rows to insert: {len(df_new)}. Sample (first 5): {df_new[['factor_symbol', 'portfolio', 'region', 'date']].head().to_dict('records')}\")\n",
    "                for chunk in [df_new[i:i+10000] for i in range(0, len(df_new), 10000)]:\n",
    "                    chunk.to_sql(\n",
    "                        'factor_returns',\n",
    "                        engine,\n",
    "                        if_exists='append',\n",
    "                        index=False,\n",
    "                        dtype={\n",
    "                            'factor_symbol': VARCHAR(20),\n",
    "                            'factor_name': VARCHAR(100),\n",
    "                            'portfolio': VARCHAR(100),\n",
    "                            'region': VARCHAR(50),\n",
    "                            'date': DATE,\n",
    "                            'value': DECIMAL(15, 6),\n",
    "                            'associated_paper': VARCHAR(150)\n",
    "                        }\n",
    "                    )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into factor_returns from {file_path} (sheet {sheet})\")\n",
    "            else:\n",
    "                logger.info(f\"No new rows to load into factor_returns from {file_path} (sheet {sheet})\")\n",
    "                logger.debug(f\"Input date range: {df_long['date'].min()} to {df_long['date'].max()}\")\n",
    "                logger.debug(f\"Database date range: {existing['date'].min() if not existing.empty else 'N/A'} to {existing['date'].max() if not existing.empty else 'N/A'}\")\n",
    "            \n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(f\"File not found: {file_path} (sheet {sheet}): {str(e)}\")\n",
    "    except pd.errors.ParserError as e:\n",
    "        logger.error(f\"Error parsing Excel file {file_path} (sheet {sheet}): {str(e)}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error processing {file_path} (sheet {sheet}): {type(e).__name__}: {str(e)}\")\n",
    "\n",
    "# Main loop\n",
    "for key, config in data_files.items():\n",
    "    logger.info(f\"Processing dataset: {key}\")\n",
    "    if key == \"BAB_multi\":\n",
    "        for subkey, subconfig in config['sheets'].items():\n",
    "            process_factors(subconfig, sheet=subconfig['sheet'], parent_path=config['path'])\n",
    "    else:\n",
    "        is_com = (key == \"COM\")\n",
    "        process_factors(config, sheet=config['sheet'], is_com=is_com)\n",
    "\n",
    "logger.info(\"All data processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9854b9de-6bd0-45a7-8f13-ee8e6cd559d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 12:33:07,576 - INFO - Processing dataset: BAB_multi\n",
      "2025-04-11 12:33:07,577 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet BAB Factors) with is_com=False\n",
      "2025-04-11 12:33:08,183 - INFO - Read 1129 rows with set columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-11 12:33:08,187 - INFO - Columns after renaming: ['date', 'BAB', 'BAB', 'BAB']\n",
      "2025-04-11 12:33:08,205 - DEBUG - After dropping NA dates, 1129 rows remain\n",
      "2025-04-11 12:33:08,216 - DEBUG - Rows after melting and dropping NA: 2039\n",
      "2025-04-11 12:33:10,854 - DEBUG - Existing keys sample (first 5): [('BAB_Intl', '2006-06-30', 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Intl'), ('UMD-COM', '1977-10-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global'), ('BAB-US', '2023-05-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'US'), ('HML-FI', '2019-07-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global'), ('Multi-style-All-SS', '1977-02-28', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global')]\n",
      "2025-04-11 12:33:10,857 - DEBUG - Total existing keys: 69934\n",
      "2025-04-11 12:33:10,959 - DEBUG - New keys sample (first 5): [('BAB', '1930-12-31', 'Betting Against Beta (Frazzini and Pedersen, 2014)', nan), ('BAB', '1931-01-31', 'Betting Against Beta (Frazzini and Pedersen, 2014)', nan), ('BAB', '1931-02-28', 'Betting Against Beta (Frazzini and Pedersen, 2014)', nan), ('BAB', '1931-03-31', 'Betting Against Beta (Frazzini and Pedersen, 2014)', nan), ('BAB', '1931-04-30', 'Betting Against Beta (Frazzini and Pedersen, 2014)', nan)]\n",
      "2025-04-11 12:33:11,090 - DEBUG - New rows to insert: 2039. Sample (first 5): [{'factor': 'BAB', 'date': Timestamp('1930-12-31 00:00:00'), 'region': nan}, {'factor': 'BAB', 'date': Timestamp('1931-01-31 00:00:00'), 'region': nan}, {'factor': 'BAB', 'date': Timestamp('1931-02-28 00:00:00'), 'region': nan}, {'factor': 'BAB', 'date': Timestamp('1931-03-31 00:00:00'), 'region': nan}, {'factor': 'BAB', 'date': Timestamp('1931-04-30 00:00:00'), 'region': nan}]\n",
      "2025-04-11 12:33:24,031 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet BAB Factors): ProgrammingError: (pyodbc.ProgrammingError) ('42S22', \"[42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid column name 'key'. (207) (SQLExecDirectW); [42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid column name 'key'. (207); [42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Statement(s) could not be prepared. (8180)\")\n",
      "[SQL: INSERT INTO factor_returns (factor, date, associated_paper, value, region, asset_class, [key]) VALUES (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?,  ... 6627 characters truncated ... ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?)]\n",
      "[parameters: ('BAB', datetime.datetime(1930, 12, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', -0.000557986425086, None, 'Equity', ('BAB', '1930-12-31', 'Betting Against Beta (Frazzini and Pedersen, 2014)', nan), 'BAB', datetime.datetime(1931, 1, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', -0.0224459497248, None, 'Equity', ('BAB', '1931-01-31', 'Betting Against Beta (Frazzini and Pedersen, 2014)', nan), 'BAB', datetime.datetime(1931, 2, 28, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', -0.0774228338726, None, 'Equity', ('BAB', '1931-02-28', 'Betting Against Beta (Frazzini and Pedersen, 2014)', nan), 'BAB', datetime.datetime(1931, 3, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 0.029235360405, None, 'Equity', ('BAB', '1931-03-31', 'Betting Against Beta (Frazzini and Pedersen, 2014)', nan), 'BAB', datetime.datetime(1931, 4, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', -0.0129855843188, None, 'Equity', ('BAB', '1931-04-30', 'Betting Against Beta (Frazzini and Pedersen, 2014)', nan), 'BAB', datetime.datetime(1931, 5, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', -0.00723995810474, None, 'Equity', ('BAB', '1931-05-31', 'Betting Against Beta (Frazzini and Pedersen, 2014)', nan), 'BAB', datetime.datetime(1931, 6, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', -0.0786521611949, None, 'Equity', ('BAB', '1931-06-30', 'Betting Against Beta (Frazzini and Pedersen, 2014)', nan), 'BAB' ... 1993 parameters truncated ... ('BAB', '1955-03-31', 'Betting Against Beta (Frazzini and Pedersen, 2014)', nan), 'BAB', datetime.datetime(1955, 4, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 0.0160703912929, None, 'Equity', ('BAB', '1955-04-30', 'Betting Against Beta (Frazzini and Pedersen, 2014)', nan), 'BAB', datetime.datetime(1955, 5, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 0.00100629987365, None, 'Equity', ('BAB', '1955-05-31', 'Betting Against Beta (Frazzini and Pedersen, 2014)', nan), 'BAB', datetime.datetime(1955, 6, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', -0.00508405627609, None, 'Equity', ('BAB', '1955-06-30', 'Betting Against Beta (Frazzini and Pedersen, 2014)', nan), 'BAB', datetime.datetime(1955, 7, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 0.0283168366225, None, 'Equity', ('BAB', '1955-07-31', 'Betting Against Beta (Frazzini and Pedersen, 2014)', nan), 'BAB', datetime.datetime(1955, 8, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', -0.013489692615, None, 'Equity', ('BAB', '1955-08-31', 'Betting Against Beta (Frazzini and Pedersen, 2014)', nan), 'BAB', datetime.datetime(1955, 9, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', -0.00404576425489, None, 'Equity', ('BAB', '1955-09-30', 'Betting Against Beta (Frazzini and Pedersen, 2014)', nan), 'BAB', datetime.datetime(1955, 10, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 0.000982636684195, None, 'Equity', ('BAB', '1955-10-31', 'Betting Against Beta (Frazzini and Pedersen, 2014)', nan))]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "2025-04-11 12:33:24,032 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet MKT) with is_com=False\n",
      "2025-04-11 12:33:24,465 - INFO - Read 1182 rows with set columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-11 12:33:24,466 - INFO - Columns after renaming: ['date', 'MKT', 'MKT', 'MKT']\n",
      "2025-04-11 12:33:24,475 - DEBUG - After dropping NA dates, 1182 rows remain\n",
      "2025-04-11 12:33:24,481 - DEBUG - Rows after melting and dropping NA: 2166\n",
      "2025-04-11 12:33:25,271 - DEBUG - Existing keys sample (first 5): [('BAB_Intl', '2006-06-30', 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Intl'), ('UMD-COM', '1977-10-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global'), ('BAB-US', '2023-05-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'US'), ('HML-FI', '2019-07-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global'), ('Multi-style-All-SS', '1977-02-28', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global')]\n",
      "2025-04-11 12:33:25,275 - DEBUG - Total existing keys: 69934\n",
      "2025-04-11 12:33:25,321 - DEBUG - New keys sample (first 5): [('MKT', '1926-07-31', 'Fama-French Factors', nan), ('MKT', '1926-08-31', 'Fama-French Factors', nan), ('MKT', '1926-09-30', 'Fama-French Factors', nan), ('MKT', '1926-10-31', 'Fama-French Factors', nan), ('MKT', '1926-11-30', 'Fama-French Factors', nan)]\n",
      "2025-04-11 12:33:25,408 - DEBUG - New rows to insert: 2166. Sample (first 5): [{'factor': 'MKT', 'date': Timestamp('1926-07-31 00:00:00'), 'region': nan}, {'factor': 'MKT', 'date': Timestamp('1926-08-31 00:00:00'), 'region': nan}, {'factor': 'MKT', 'date': Timestamp('1926-09-30 00:00:00'), 'region': nan}, {'factor': 'MKT', 'date': Timestamp('1926-10-31 00:00:00'), 'region': nan}, {'factor': 'MKT', 'date': Timestamp('1926-11-30 00:00:00'), 'region': nan}]\n",
      "2025-04-11 12:33:39,899 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet MKT): ProgrammingError: (pyodbc.ProgrammingError) ('42S22', \"[42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid column name 'key'. (207) (SQLExecDirectW); [42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid column name 'key'. (207); [42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Statement(s) could not be prepared. (8180)\")\n",
      "[SQL: INSERT INTO factor_returns (factor, date, associated_paper, value, region, asset_class, [key]) VALUES (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?,  ... 6627 characters truncated ... ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?)]\n",
      "[parameters: ('MKT', datetime.datetime(1926, 7, 31, 0, 0), 'Fama-French Factors', 0.0283354011258, None, 'Equity', ('MKT', '1926-07-31', 'Fama-French Factors', nan), 'MKT', datetime.datetime(1926, 8, 31, 0, 0), 'Fama-French Factors', 0.026245387407, None, 'Equity', ('MKT', '1926-08-31', 'Fama-French Factors', nan), 'MKT', datetime.datetime(1926, 9, 30, 0, 0), 'Fama-French Factors', 0.00328704461906, None, 'Equity', ('MKT', '1926-09-30', 'Fama-French Factors', nan), 'MKT', datetime.datetime(1926, 10, 31, 0, 0), 'Fama-French Factors', -0.0311033186019, None, 'Equity', ('MKT', '1926-10-31', 'Fama-French Factors', nan), 'MKT', datetime.datetime(1926, 11, 30, 0, 0), 'Fama-French Factors', 0.0243573891083, None, 'Equity', ('MKT', '1926-11-30', 'Fama-French Factors', nan), 'MKT', datetime.datetime(1926, 12, 31, 0, 0), 'Fama-French Factors', 0.0258814782775, None, 'Equity', ('MKT', '1926-12-31', 'Fama-French Factors', nan), 'MKT', datetime.datetime(1927, 1, 31, 0, 0), 'Fama-French Factors', -0.00135455042829, None, 'Equity', ('MKT', '1927-01-31', 'Fama-French Factors', nan), 'MKT' ... 1993 parameters truncated ... ('MKT', '1950-10-31', 'Fama-French Factors', nan), 'MKT', datetime.datetime(1950, 11, 30, 0, 0), 'Fama-French Factors', 0.0274219459779, None, 'Equity', ('MKT', '1950-11-30', 'Fama-French Factors', nan), 'MKT', datetime.datetime(1950, 12, 31, 0, 0), 'Fama-French Factors', 0.0552195983444, None, 'Equity', ('MKT', '1950-12-31', 'Fama-French Factors', nan), 'MKT', datetime.datetime(1951, 1, 31, 0, 0), 'Fama-French Factors', 0.0569623899476, None, 'Equity', ('MKT', '1951-01-31', 'Fama-French Factors', nan), 'MKT', datetime.datetime(1951, 2, 28, 0, 0), 'Fama-French Factors', 0.0141178425383, None, 'Equity', ('MKT', '1951-02-28', 'Fama-French Factors', nan), 'MKT', datetime.datetime(1951, 3, 31, 0, 0), 'Fama-French Factors', -0.0215394694888, None, 'Equity', ('MKT', '1951-03-31', 'Fama-French Factors', nan), 'MKT', datetime.datetime(1951, 4, 30, 0, 0), 'Fama-French Factors', 0.0485961573605, None, 'Equity', ('MKT', '1951-04-30', 'Fama-French Factors', nan), 'MKT', datetime.datetime(1951, 5, 31, 0, 0), 'Fama-French Factors', -0.0234152724597, None, 'Equity', ('MKT', '1951-05-31', 'Fama-French Factors', nan))]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "2025-04-11 12:33:39,900 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet SMB) with is_com=False\n",
      "2025-04-11 12:33:40,535 - INFO - Read 1181 rows with set columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-11 12:33:40,538 - INFO - Columns after renaming: ['date', 'SMB', 'SMB', 'SMB']\n",
      "2025-04-11 12:33:40,550 - DEBUG - After dropping NA dates, 1181 rows remain\n",
      "2025-04-11 12:33:40,559 - DEBUG - Rows after melting and dropping NA: 2151\n",
      "2025-04-11 12:33:41,541 - DEBUG - Existing keys sample (first 5): [('BAB_Intl', '2006-06-30', 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Intl'), ('UMD-COM', '1977-10-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global'), ('BAB-US', '2023-05-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'US'), ('HML-FI', '2019-07-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global'), ('Multi-style-All-SS', '1977-02-28', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global')]\n",
      "2025-04-11 12:33:41,542 - DEBUG - Total existing keys: 69934\n",
      "2025-04-11 12:33:41,613 - DEBUG - New keys sample (first 5): [('SMB', '1926-07-31', 'Fama-French Factors', nan), ('SMB', '1926-08-31', 'Fama-French Factors', nan), ('SMB', '1926-09-30', 'Fama-French Factors', nan), ('SMB', '1926-10-31', 'Fama-French Factors', nan), ('SMB', '1926-11-30', 'Fama-French Factors', nan)]\n",
      "2025-04-11 12:33:41,708 - DEBUG - New rows to insert: 2151. Sample (first 5): [{'factor': 'SMB', 'date': Timestamp('1926-07-31 00:00:00'), 'region': nan}, {'factor': 'SMB', 'date': Timestamp('1926-08-31 00:00:00'), 'region': nan}, {'factor': 'SMB', 'date': Timestamp('1926-09-30 00:00:00'), 'region': nan}, {'factor': 'SMB', 'date': Timestamp('1926-10-31 00:00:00'), 'region': nan}, {'factor': 'SMB', 'date': Timestamp('1926-11-30 00:00:00'), 'region': nan}]\n",
      "2025-04-11 12:33:53,745 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet SMB): ProgrammingError: (pyodbc.ProgrammingError) ('42S22', \"[42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid column name 'key'. (207) (SQLExecDirectW); [42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid column name 'key'. (207); [42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Statement(s) could not be prepared. (8180)\")\n",
      "[SQL: INSERT INTO factor_returns (factor, date, associated_paper, value, region, asset_class, [key]) VALUES (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?,  ... 6627 characters truncated ... ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?)]\n",
      "[parameters: ('SMB', datetime.datetime(1926, 7, 31, 0, 0), 'Fama-French Factors', -0.016588027537, None, 'Equity', ('SMB', '1926-07-31', 'Fama-French Factors', nan), 'SMB', datetime.datetime(1926, 8, 31, 0, 0), 'Fama-French Factors', -0.0139579314481, None, 'Equity', ('SMB', '1926-08-31', 'Fama-French Factors', nan), 'SMB', datetime.datetime(1926, 9, 30, 0, 0), 'Fama-French Factors', -0.0119792160085, None, 'Equity', ('SMB', '1926-09-30', 'Fama-French Factors', nan), 'SMB', datetime.datetime(1926, 10, 31, 0, 0), 'Fama-French Factors', 0.00510163415285, None, 'Equity', ('SMB', '1926-10-31', 'Fama-French Factors', nan), 'SMB', datetime.datetime(1926, 11, 30, 0, 0), 'Fama-French Factors', -0.0124207162797, None, 'Equity', ('SMB', '1926-11-30', 'Fama-French Factors', nan), 'SMB', datetime.datetime(1926, 12, 31, 0, 0), 'Fama-French Factors', -0.00841644602698, None, 'Equity', ('SMB', '1926-12-31', 'Fama-French Factors', nan), 'SMB', datetime.datetime(1927, 1, 31, 0, 0), 'Fama-French Factors', -0.00694753196658, None, 'Equity', ('SMB', '1927-01-31', 'Fama-French Factors', nan), 'SMB' ... 1993 parameters truncated ... ('SMB', '1950-10-31', 'Fama-French Factors', nan), 'SMB', datetime.datetime(1950, 11, 30, 0, 0), 'Fama-French Factors', -0.00389808281966, None, 'Equity', ('SMB', '1950-11-30', 'Fama-French Factors', nan), 'SMB', datetime.datetime(1950, 12, 31, 0, 0), 'Fama-French Factors', 0.018758581311, None, 'Equity', ('SMB', '1950-12-31', 'Fama-French Factors', nan), 'SMB', datetime.datetime(1951, 1, 31, 0, 0), 'Fama-French Factors', 0.0151695292084, None, 'Equity', ('SMB', '1951-01-31', 'Fama-French Factors', nan), 'SMB', datetime.datetime(1951, 2, 28, 0, 0), 'Fama-French Factors', 0.00241930874501, None, 'Equity', ('SMB', '1951-02-28', 'Fama-French Factors', nan), 'SMB', datetime.datetime(1951, 3, 31, 0, 0), 'Fama-French Factors', -0.00840651487657, None, 'Equity', ('SMB', '1951-03-31', 'Fama-French Factors', nan), 'SMB', datetime.datetime(1951, 4, 30, 0, 0), 'Fama-French Factors', -0.0119209581786, None, 'Equity', ('SMB', '1951-04-30', 'Fama-French Factors', nan), 'SMB', datetime.datetime(1951, 5, 31, 0, 0), 'Fama-French Factors', -0.00312338050807, None, 'Equity', ('SMB', '1951-05-31', 'Fama-French Factors', nan))]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "2025-04-11 12:33:53,746 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet HML FF) with is_com=False\n",
      "2025-04-11 12:33:54,248 - INFO - Read 1181 rows with set columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-11 12:33:54,251 - INFO - Columns after renaming: ['date', 'HML-FF', 'HML-FF', 'HML-FF']\n",
      "2025-04-11 12:33:54,265 - DEBUG - After dropping NA dates, 1181 rows remain\n",
      "2025-04-11 12:33:54,273 - DEBUG - Rows after melting and dropping NA: 2151\n",
      "2025-04-11 12:33:55,198 - DEBUG - Existing keys sample (first 5): [('BAB_Intl', '2006-06-30', 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Intl'), ('UMD-COM', '1977-10-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global'), ('BAB-US', '2023-05-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'US'), ('HML-FI', '2019-07-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global'), ('Multi-style-All-SS', '1977-02-28', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global')]\n",
      "2025-04-11 12:33:55,199 - DEBUG - Total existing keys: 69934\n",
      "2025-04-11 12:33:55,244 - DEBUG - New keys sample (first 5): [('HML-FF', '1926-07-31', 'Fama-French Factors', nan), ('HML-FF', '1926-08-31', 'Fama-French Factors', nan), ('HML-FF', '1926-09-30', 'Fama-French Factors', nan), ('HML-FF', '1926-10-31', 'Fama-French Factors', nan), ('HML-FF', '1926-11-30', 'Fama-French Factors', nan)]\n",
      "2025-04-11 12:33:55,292 - DEBUG - New rows to insert: 2151. Sample (first 5): [{'factor': 'HML-FF', 'date': Timestamp('1926-07-31 00:00:00'), 'region': nan}, {'factor': 'HML-FF', 'date': Timestamp('1926-08-31 00:00:00'), 'region': nan}, {'factor': 'HML-FF', 'date': Timestamp('1926-09-30 00:00:00'), 'region': nan}, {'factor': 'HML-FF', 'date': Timestamp('1926-10-31 00:00:00'), 'region': nan}, {'factor': 'HML-FF', 'date': Timestamp('1926-11-30 00:00:00'), 'region': nan}]\n",
      "2025-04-11 12:34:03,571 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet HML FF): ProgrammingError: (pyodbc.ProgrammingError) ('42S22', \"[42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid column name 'key'. (207) (SQLExecDirectW); [42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid column name 'key'. (207); [42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Statement(s) could not be prepared. (8180)\")\n",
      "[SQL: INSERT INTO factor_returns (factor, date, associated_paper, value, region, asset_class, [key]) VALUES (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?,  ... 6627 characters truncated ... ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?)]\n",
      "[parameters: ('HML-FF', datetime.datetime(1926, 7, 31, 0, 0), 'Fama-French Factors', -0.0271953118576, None, 'Equity', ('HML-FF', '1926-07-31', 'Fama-French Factors', nan), 'HML-FF', datetime.datetime(1926, 8, 31, 0, 0), 'Fama-French Factors', 0.0540767833315, None, 'Equity', ('HML-FF', '1926-08-31', 'Fama-French Factors', nan), 'HML-FF', datetime.datetime(1926, 9, 30, 0, 0), 'Fama-French Factors', -0.00507633146891, None, 'Equity', ('HML-FF', '1926-09-30', 'Fama-French Factors', nan), 'HML-FF', datetime.datetime(1926, 10, 31, 0, 0), 'Fama-French Factors', 0.0108136920398, None, 'Equity', ('HML-FF', '1926-10-31', 'Fama-French Factors', nan), 'HML-FF', datetime.datetime(1926, 11, 30, 0, 0), 'Fama-French Factors', 0.00213270988112, None, 'Equity', ('HML-FF', '1926-11-30', 'Fama-French Factors', nan), 'HML-FF', datetime.datetime(1926, 12, 31, 0, 0), 'Fama-French Factors', 0.0111346834639, None, 'Equity', ('HML-FF', '1926-12-31', 'Fama-French Factors', nan), 'HML-FF', datetime.datetime(1927, 1, 31, 0, 0), 'Fama-French Factors', 0.0516913187421, None, 'Equity', ('HML-FF', '1927-01-31', 'Fama-French Factors', nan), 'HML-FF' ... 1993 parameters truncated ... ('HML-FF', '1950-10-31', 'Fama-French Factors', nan), 'HML-FF', datetime.datetime(1950, 11, 30, 0, 0), 'Fama-French Factors', 0.0369767360283, None, 'Equity', ('HML-FF', '1950-11-30', 'Fama-French Factors', nan), 'HML-FF', datetime.datetime(1950, 12, 31, 0, 0), 'Fama-French Factors', 0.0792618189324, None, 'Equity', ('HML-FF', '1950-12-31', 'Fama-French Factors', nan), 'HML-FF', datetime.datetime(1951, 1, 31, 0, 0), 'Fama-French Factors', 0.0311926655481, None, 'Equity', ('HML-FF', '1951-01-31', 'Fama-French Factors', nan), 'HML-FF', datetime.datetime(1951, 2, 28, 0, 0), 'Fama-French Factors', -0.0233763233268, None, 'Equity', ('HML-FF', '1951-02-28', 'Fama-French Factors', nan), 'HML-FF', datetime.datetime(1951, 3, 31, 0, 0), 'Fama-French Factors', -0.0426035115557, None, 'Equity', ('HML-FF', '1951-03-31', 'Fama-French Factors', nan), 'HML-FF', datetime.datetime(1951, 4, 30, 0, 0), 'Fama-French Factors', 0.0244857103198, None, 'Equity', ('HML-FF', '1951-04-30', 'Fama-French Factors', nan), 'HML-FF', datetime.datetime(1951, 5, 31, 0, 0), 'Fama-French Factors', -0.0151233137672, None, 'Equity', ('HML-FF', '1951-05-31', 'Fama-French Factors', nan))]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "2025-04-11 12:34:03,572 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet HML Devil) with is_com=False\n",
      "2025-04-11 12:34:04,031 - INFO - Read 1182 rows with set columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-11 12:34:04,033 - INFO - Columns after renaming: ['date', 'HML-D', 'HML-D', 'HML-D']\n",
      "2025-04-11 12:34:04,043 - DEBUG - After dropping NA dates, 1182 rows remain\n",
      "2025-04-11 12:34:04,048 - DEBUG - Rows after melting and dropping NA: 2154\n",
      "2025-04-11 12:34:04,750 - DEBUG - Existing keys sample (first 5): [('BAB_Intl', '2006-06-30', 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Intl'), ('UMD-COM', '1977-10-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global'), ('BAB-US', '2023-05-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'US'), ('HML-FI', '2019-07-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global'), ('Multi-style-All-SS', '1977-02-28', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global')]\n",
      "2025-04-11 12:34:04,751 - DEBUG - Total existing keys: 69934\n",
      "2025-04-11 12:34:04,792 - DEBUG - New keys sample (first 5): [('HML-D', '1926-07-31', \"The Devil's in HML's Details\", nan), ('HML-D', '1926-08-31', \"The Devil's in HML's Details\", nan), ('HML-D', '1926-09-30', \"The Devil's in HML's Details\", nan), ('HML-D', '1926-10-31', \"The Devil's in HML's Details\", nan), ('HML-D', '1926-11-30', \"The Devil's in HML's Details\", nan)]\n",
      "2025-04-11 12:34:04,848 - DEBUG - New rows to insert: 2154. Sample (first 5): [{'factor': 'HML-D', 'date': Timestamp('1926-07-31 00:00:00'), 'region': nan}, {'factor': 'HML-D', 'date': Timestamp('1926-08-31 00:00:00'), 'region': nan}, {'factor': 'HML-D', 'date': Timestamp('1926-09-30 00:00:00'), 'region': nan}, {'factor': 'HML-D', 'date': Timestamp('1926-10-31 00:00:00'), 'region': nan}, {'factor': 'HML-D', 'date': Timestamp('1926-11-30 00:00:00'), 'region': nan}]\n",
      "2025-04-11 12:34:12,893 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet HML Devil): ProgrammingError: (pyodbc.ProgrammingError) ('42S22', \"[42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid column name 'key'. (207) (SQLExecDirectW); [42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid column name 'key'. (207); [42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Statement(s) could not be prepared. (8180)\")\n",
      "[SQL: INSERT INTO factor_returns (factor, date, associated_paper, value, region, asset_class, [key]) VALUES (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?,  ... 6627 characters truncated ... ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?)]\n",
      "[parameters: ('HML-D', datetime.datetime(1926, 7, 31, 0, 0), \"The Devil's in HML's Details\", -0.0198557509772, None, 'Equity', ('HML-D', '1926-07-31', \"The Devil's in HML's Details\", nan), 'HML-D', datetime.datetime(1926, 8, 31, 0, 0), \"The Devil's in HML's Details\", 0.0523514868609, None, 'Equity', ('HML-D', '1926-08-31', \"The Devil's in HML's Details\", nan), 'HML-D', datetime.datetime(1926, 9, 30, 0, 0), \"The Devil's in HML's Details\", -0.0233491305501, None, 'Equity', ('HML-D', '1926-09-30', \"The Devil's in HML's Details\", nan), 'HML-D', datetime.datetime(1926, 10, 31, 0, 0), \"The Devil's in HML's Details\", 0.00825290745545, None, 'Equity', ('HML-D', '1926-10-31', \"The Devil's in HML's Details\", nan), 'HML-D', datetime.datetime(1926, 11, 30, 0, 0), \"The Devil's in HML's Details\", 0.00202531611231, None, 'Equity', ('HML-D', '1926-11-30', \"The Devil's in HML's Details\", nan), 'HML-D', datetime.datetime(1926, 12, 31, 0, 0), \"The Devil's in HML's Details\", 0.0218206425858, None, 'Equity', ('HML-D', '1926-12-31', \"The Devil's in HML's Details\", nan), 'HML-D', datetime.datetime(1927, 1, 31, 0, 0), \"The Devil's in HML's Details\", 0.0404056052839, None, 'Equity', ('HML-D', '1927-01-31', \"The Devil's in HML's Details\", nan), 'HML-D' ... 1993 parameters truncated ... ('HML-D', '1950-10-31', \"The Devil's in HML's Details\", nan), 'HML-D', datetime.datetime(1950, 11, 30, 0, 0), \"The Devil's in HML's Details\", 0.0281361332044, None, 'Equity', ('HML-D', '1950-11-30', \"The Devil's in HML's Details\", nan), 'HML-D', datetime.datetime(1950, 12, 31, 0, 0), \"The Devil's in HML's Details\", 0.0639380056689, None, 'Equity', ('HML-D', '1950-12-31', \"The Devil's in HML's Details\", nan), 'HML-D', datetime.datetime(1951, 1, 31, 0, 0), \"The Devil's in HML's Details\", 0.0412424077737, None, 'Equity', ('HML-D', '1951-01-31', \"The Devil's in HML's Details\", nan), 'HML-D', datetime.datetime(1951, 2, 28, 0, 0), \"The Devil's in HML's Details\", -0.0175933573262, None, 'Equity', ('HML-D', '1951-02-28', \"The Devil's in HML's Details\", nan), 'HML-D', datetime.datetime(1951, 3, 31, 0, 0), \"The Devil's in HML's Details\", -0.0335661174488, None, 'Equity', ('HML-D', '1951-03-31', \"The Devil's in HML's Details\", nan), 'HML-D', datetime.datetime(1951, 4, 30, 0, 0), \"The Devil's in HML's Details\", 0.0115436989333, None, 'Equity', ('HML-D', '1951-04-30', \"The Devil's in HML's Details\", nan), 'HML-D', datetime.datetime(1951, 5, 31, 0, 0), \"The Devil's in HML's Details\", -0.0100897393966, None, 'Equity', ('HML-D', '1951-05-31', \"The Devil's in HML's Details\", nan))]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "2025-04-11 12:34:12,894 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet UMD) with is_com=False\n",
      "2025-04-11 12:34:13,353 - INFO - Read 1176 rows with set columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-11 12:34:13,356 - INFO - Columns after renaming: ['date', 'UMD', 'UMD', 'UMD']\n",
      "2025-04-11 12:34:13,369 - DEBUG - After dropping NA dates, 1176 rows remain\n",
      "2025-04-11 12:34:13,376 - DEBUG - Rows after melting and dropping NA: 2136\n",
      "2025-04-11 12:34:14,248 - DEBUG - Existing keys sample (first 5): [('BAB_Intl', '2006-06-30', 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Intl'), ('UMD-COM', '1977-10-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global'), ('BAB-US', '2023-05-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'US'), ('HML-FI', '2019-07-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global'), ('Multi-style-All-SS', '1977-02-28', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global')]\n",
      "2025-04-11 12:34:14,249 - DEBUG - Total existing keys: 69934\n",
      "2025-04-11 12:34:14,293 - DEBUG - New keys sample (first 5): [('UMD', '1927-01-31', 'On Persistence in Mutual Fund Performance', nan), ('UMD', '1927-02-28', 'On Persistence in Mutual Fund Performance', nan), ('UMD', '1927-03-31', 'On Persistence in Mutual Fund Performance', nan), ('UMD', '1927-04-30', 'On Persistence in Mutual Fund Performance', nan), ('UMD', '1927-05-31', 'On Persistence in Mutual Fund Performance', nan)]\n",
      "2025-04-11 12:34:14,363 - DEBUG - New rows to insert: 2136. Sample (first 5): [{'factor': 'UMD', 'date': Timestamp('1927-01-31 00:00:00'), 'region': nan}, {'factor': 'UMD', 'date': Timestamp('1927-02-28 00:00:00'), 'region': nan}, {'factor': 'UMD', 'date': Timestamp('1927-03-31 00:00:00'), 'region': nan}, {'factor': 'UMD', 'date': Timestamp('1927-04-30 00:00:00'), 'region': nan}, {'factor': 'UMD', 'date': Timestamp('1927-05-31 00:00:00'), 'region': nan}]\n",
      "2025-04-11 12:34:22,583 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet UMD): ProgrammingError: (pyodbc.ProgrammingError) ('42S22', \"[42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid column name 'key'. (207) (SQLExecDirectW); [42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid column name 'key'. (207); [42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Statement(s) could not be prepared. (8180)\")\n",
      "[SQL: INSERT INTO factor_returns (factor, date, associated_paper, value, region, asset_class, [key]) VALUES (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?,  ... 6627 characters truncated ... ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?)]\n",
      "[parameters: ('UMD', datetime.datetime(1927, 1, 31, 0, 0), 'On Persistence in Mutual Fund Performance', 0.0266643513295, None, 'Equity', ('UMD', '1927-01-31', 'On Persistence in Mutual Fund Performance', nan), 'UMD', datetime.datetime(1927, 2, 28, 0, 0), 'On Persistence in Mutual Fund Performance', -0.00926118462808, None, 'Equity', ('UMD', '1927-02-28', 'On Persistence in Mutual Fund Performance', nan), 'UMD', datetime.datetime(1927, 3, 31, 0, 0), 'On Persistence in Mutual Fund Performance', 0.0516508368413, None, 'Equity', ('UMD', '1927-03-31', 'On Persistence in Mutual Fund Performance', nan), 'UMD', datetime.datetime(1927, 4, 30, 0, 0), 'On Persistence in Mutual Fund Performance', 0.0306027318418, None, 'Equity', ('UMD', '1927-04-30', 'On Persistence in Mutual Fund Performance', nan), 'UMD', datetime.datetime(1927, 5, 31, 0, 0), 'On Persistence in Mutual Fund Performance', 0.0532634291197, None, 'Equity', ('UMD', '1927-05-31', 'On Persistence in Mutual Fund Performance', nan), 'UMD', datetime.datetime(1927, 6, 30, 0, 0), 'On Persistence in Mutual Fund Performance', 0.00654415415699, None, 'Equity', ('UMD', '1927-06-30', 'On Persistence in Mutual Fund Performance', nan), 'UMD', datetime.datetime(1927, 7, 31, 0, 0), 'On Persistence in Mutual Fund Performance', 0.0203867823485, None, 'Equity', ('UMD', '1927-07-31', 'On Persistence in Mutual Fund Performance', nan), 'UMD' ... 1993 parameters truncated ... ('UMD', '1951-04-30', 'On Persistence in Mutual Fund Performance', nan), 'UMD', datetime.datetime(1951, 5, 31, 0, 0), 'On Persistence in Mutual Fund Performance', -0.0105625379976, None, 'Equity', ('UMD', '1951-05-31', 'On Persistence in Mutual Fund Performance', nan), 'UMD', datetime.datetime(1951, 6, 30, 0, 0), 'On Persistence in Mutual Fund Performance', -0.0225001925169, None, 'Equity', ('UMD', '1951-06-30', 'On Persistence in Mutual Fund Performance', nan), 'UMD', datetime.datetime(1951, 7, 31, 0, 0), 'On Persistence in Mutual Fund Performance', 0.0706386130492, None, 'Equity', ('UMD', '1951-07-31', 'On Persistence in Mutual Fund Performance', nan), 'UMD', datetime.datetime(1951, 8, 31, 0, 0), 'On Persistence in Mutual Fund Performance', 0.00888902988211, None, 'Equity', ('UMD', '1951-08-31', 'On Persistence in Mutual Fund Performance', nan), 'UMD', datetime.datetime(1951, 9, 30, 0, 0), 'On Persistence in Mutual Fund Performance', 0.00354583277603, None, 'Equity', ('UMD', '1951-09-30', 'On Persistence in Mutual Fund Performance', nan), 'UMD', datetime.datetime(1951, 10, 31, 0, 0), 'On Persistence in Mutual Fund Performance', 0.00209302095975, None, 'Equity', ('UMD', '1951-10-31', 'On Persistence in Mutual Fund Performance', nan), 'UMD', datetime.datetime(1951, 11, 30, 0, 0), 'On Persistence in Mutual Fund Performance', 0.00430487335146, None, 'Equity', ('UMD', '1951-11-30', 'On Persistence in Mutual Fund Performance', nan))]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "2025-04-11 12:34:22,584 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet ME(t-1)) with is_com=False\n",
      "2025-04-11 12:34:23,012 - INFO - Read 1182 rows with set columns: ['DATE', 'AUT', 'HKG', 'ESP', 'GBR', 'ITA', 'DEU', 'DNK', 'NZL', 'NLD', 'USA', 'PRT', 'BEL', 'ISR', 'GRC', 'NOR', 'SGP', 'CHE', 'IRL', 'CAN', 'FIN', 'JPN', 'SWE', 'FRA', 'AUS', 'Global Ex USA', 'Global', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-11 12:34:23,014 - INFO - Columns after renaming: ['date', 'ME', 'ME', 'ME']\n",
      "2025-04-11 12:34:23,020 - DEBUG - After dropping NA dates, 1182 rows remain\n",
      "2025-04-11 12:34:23,026 - DEBUG - Rows after melting and dropping NA: 2210\n",
      "2025-04-11 12:34:23,538 - DEBUG - Existing keys sample (first 5): [('BAB_Intl', '2006-06-30', 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Intl'), ('UMD-COM', '1977-10-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global'), ('BAB-US', '2023-05-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'US'), ('HML-FI', '2019-07-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global'), ('Multi-style-All-SS', '1977-02-28', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global')]\n",
      "2025-04-11 12:34:23,541 - DEBUG - Total existing keys: 69934\n",
      "2025-04-11 12:34:23,580 - DEBUG - New keys sample (first 5): [('ME', '1926-07-31', 'AQR Factors', nan), ('ME', '1926-08-31', 'AQR Factors', nan), ('ME', '1926-09-30', 'AQR Factors', nan), ('ME', '1926-10-31', 'AQR Factors', nan), ('ME', '1926-11-30', 'AQR Factors', nan)]\n",
      "2025-04-11 12:34:23,633 - DEBUG - New rows to insert: 2210. Sample (first 5): [{'factor': 'ME', 'date': Timestamp('1926-07-31 00:00:00'), 'region': nan}, {'factor': 'ME', 'date': Timestamp('1926-08-31 00:00:00'), 'region': nan}, {'factor': 'ME', 'date': Timestamp('1926-09-30 00:00:00'), 'region': nan}, {'factor': 'ME', 'date': Timestamp('1926-10-31 00:00:00'), 'region': nan}, {'factor': 'ME', 'date': Timestamp('1926-11-30 00:00:00'), 'region': nan}]\n",
      "2025-04-11 12:34:32,116 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet ME(t-1)): ProgrammingError: (pyodbc.ProgrammingError) ('42S22', \"[42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid column name 'key'. (207) (SQLExecDirectW); [42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid column name 'key'. (207); [42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Statement(s) could not be prepared. (8180)\")\n",
      "[SQL: INSERT INTO factor_returns (factor, date, associated_paper, value, region, asset_class, [key]) VALUES (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?,  ... 6627 characters truncated ... ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?)]\n",
      "[parameters: ('ME', datetime.datetime(1926, 7, 31, 0, 0), 'AQR Factors', 27892.9341875, None, 'Equity', ('ME', '1926-07-31', 'AQR Factors', nan), 'ME', datetime.datetime(1926, 8, 31, 0, 0), 'AQR Factors', 28213.9693125, None, 'Equity', ('ME', '1926-08-31', 'AQR Factors', nan), 'ME', datetime.datetime(1926, 9, 30, 0, 0), 'AQR Factors', 29432.298, None, 'Equity', ('ME', '1926-09-30', 'AQR Factors', nan), 'ME', datetime.datetime(1926, 10, 31, 0, 0), 'AQR Factors', 29322.096875, None, 'Equity', ('ME', '1926-10-31', 'AQR Factors', nan), 'ME', datetime.datetime(1926, 11, 30, 0, 0), 'AQR Factors', 28528.5460625, None, 'Equity', ('ME', '1926-11-30', 'AQR Factors', nan), 'ME', datetime.datetime(1926, 12, 31, 0, 0), 'AQR Factors', 29322.369875, None, 'Equity', ('ME', '1926-12-31', 'AQR Factors', nan), 'ME', datetime.datetime(1927, 1, 31, 0, 0), 'AQR Factors', 30998.638875, None, 'Equity', ('ME', '1927-01-31', 'AQR Factors', nan), 'ME' ... 1993 parameters truncated ... ('ME', '1950-10-31', 'AQR Factors', nan), 'ME', datetime.datetime(1950, 11, 30, 0, 0), 'AQR Factors', 76834.580625, None, 'Equity', ('ME', '1950-11-30', 'AQR Factors', nan), 'ME', datetime.datetime(1950, 12, 31, 0, 0), 'AQR Factors', 77749.680375, None, 'Equity', ('ME', '1950-12-31', 'AQR Factors', nan), 'ME', datetime.datetime(1951, 1, 31, 0, 0), 'AQR Factors', 82822.6766875, None, 'Equity', ('ME', '1951-01-31', 'AQR Factors', nan), 'ME', datetime.datetime(1951, 2, 28, 0, 0), 'AQR Factors', 87669.0335, None, 'Equity', ('ME', '1951-02-28', 'AQR Factors', nan), 'ME', datetime.datetime(1951, 3, 31, 0, 0), 'AQR Factors', 88593.0031875, None, 'Equity', ('ME', '1951-03-31', 'AQR Factors', nan), 'ME', datetime.datetime(1951, 4, 30, 0, 0), 'AQR Factors', 86784.4641875, None, 'Equity', ('ME', '1951-04-30', 'AQR Factors', nan), 'ME', datetime.datetime(1951, 5, 31, 0, 0), 'AQR Factors', 91096.654, None, 'Equity', ('ME', '1951-05-31', 'AQR Factors', nan))]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "2025-04-11 12:34:32,117 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet RF) with is_com=False\n",
      "2025-04-11 12:34:32,822 - INFO - Read 1184 rows with set columns: ['DATE', 'Risk Free Rate']\n",
      "2025-04-11 12:34:32,823 - INFO - Columns after renaming: ['date', 'RF']\n",
      "C:\\Users\\JulianHeron\\AppData\\Local\\Temp\\ipykernel_21968\\2392414069.py:249: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
      "2025-04-11 12:34:32,837 - WARNING - Dropped 1 rows due to invalid dates in C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet RF)\n",
      "2025-04-11 12:34:32,841 - DEBUG - After dropping NA dates, 1183 rows remain\n",
      "2025-04-11 12:34:32,844 - DEBUG - Rows after melting and dropping NA: 1183\n",
      "2025-04-11 12:34:33,392 - DEBUG - Existing keys sample (first 5): [('BAB_Intl', '2006-06-30', 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Intl'), ('UMD-COM', '1977-10-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global'), ('BAB-US', '2023-05-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'US'), ('HML-FI', '2019-07-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global'), ('Multi-style-All-SS', '1977-02-28', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global')]\n",
      "2025-04-11 12:34:33,394 - DEBUG - Total existing keys: 69934\n",
      "2025-04-11 12:34:33,430 - DEBUG - New keys sample (first 5): [('RF', '1926-07-31', 'Unknown', nan), ('RF', '1926-08-31', 'Unknown', nan), ('RF', '1926-09-30', 'Unknown', nan), ('RF', '1926-10-31', 'Unknown', nan), ('RF', '1926-11-30', 'Unknown', nan)]\n",
      "2025-04-11 12:34:33,493 - DEBUG - New rows to insert: 1183. Sample (first 5): [{'factor': 'RF', 'date': Timestamp('1926-07-31 00:00:00'), 'region': nan}, {'factor': 'RF', 'date': Timestamp('1926-08-31 00:00:00'), 'region': nan}, {'factor': 'RF', 'date': Timestamp('1926-09-30 00:00:00'), 'region': nan}, {'factor': 'RF', 'date': Timestamp('1926-10-31 00:00:00'), 'region': nan}, {'factor': 'RF', 'date': Timestamp('1926-11-30 00:00:00'), 'region': nan}]\n",
      "2025-04-11 12:34:42,443 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet RF): ProgrammingError: (pyodbc.ProgrammingError) ('42S22', \"[42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid column name 'key'. (207) (SQLExecDirectW); [42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid column name 'key'. (207); [42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Statement(s) could not be prepared. (8180)\")\n",
      "[SQL: INSERT INTO factor_returns (factor, date, associated_paper, value, region, asset_class, [key]) VALUES (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?,  ... 6627 characters truncated ... ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?)]\n",
      "[parameters: ('RF', datetime.datetime(1926, 7, 31, 0, 0), 'Unknown', 0.0022, None, 'Equity', ('RF', '1926-07-31', 'Unknown', nan), 'RF', datetime.datetime(1926, 8, 31, 0, 0), 'Unknown', 0.0025, None, 'Equity', ('RF', '1926-08-31', 'Unknown', nan), 'RF', datetime.datetime(1926, 9, 30, 0, 0), 'Unknown', 0.0023, None, 'Equity', ('RF', '1926-09-30', 'Unknown', nan), 'RF', datetime.datetime(1926, 10, 31, 0, 0), 'Unknown', 0.0032, None, 'Equity', ('RF', '1926-10-31', 'Unknown', nan), 'RF', datetime.datetime(1926, 11, 30, 0, 0), 'Unknown', 0.0031, None, 'Equity', ('RF', '1926-11-30', 'Unknown', nan), 'RF', datetime.datetime(1926, 12, 31, 0, 0), 'Unknown', 0.0028000000000000004, None, 'Equity', ('RF', '1926-12-31', 'Unknown', nan), 'RF', datetime.datetime(1927, 1, 31, 0, 0), 'Unknown', 0.0025, None, 'Equity', ('RF', '1927-01-31', 'Unknown', nan), 'RF' ... 1993 parameters truncated ... ('RF', '1950-10-31', 'Unknown', nan), 'RF', datetime.datetime(1950, 11, 30, 0, 0), 'Unknown', 0.0011, None, 'Equity', ('RF', '1950-11-30', 'Unknown', nan), 'RF', datetime.datetime(1950, 12, 31, 0, 0), 'Unknown', 0.0011, None, 'Equity', ('RF', '1950-12-31', 'Unknown', nan), 'RF', datetime.datetime(1951, 1, 31, 0, 0), 'Unknown', 0.0013, None, 'Equity', ('RF', '1951-01-31', 'Unknown', nan), 'RF', datetime.datetime(1951, 2, 28, 0, 0), 'Unknown', 0.001, None, 'Equity', ('RF', '1951-02-28', 'Unknown', nan), 'RF', datetime.datetime(1951, 3, 31, 0, 0), 'Unknown', 0.0011, None, 'Equity', ('RF', '1951-03-31', 'Unknown', nan), 'RF', datetime.datetime(1951, 4, 30, 0, 0), 'Unknown', 0.0013, None, 'Equity', ('RF', '1951-04-30', 'Unknown', nan), 'RF', datetime.datetime(1951, 5, 31, 0, 0), 'Unknown', 0.0012, None, 'Equity', ('RF', '1951-05-31', 'Unknown', nan))]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "2025-04-11 12:34:42,444 - INFO - Processing dataset: TSMOM\n",
      "2025-04-11 12:34:42,445 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet TSMOM Factors) with is_com=False\n",
      "2025-04-11 12:34:42,613 - INFO - Read 481 rows with set columns: ['DATE', 'TSMOM', 'TSMOM^CM', 'TSMOM^EQ', 'TSMOM^FI', 'TSMOM^FX']\n",
      "2025-04-11 12:34:42,616 - INFO - Columns after renaming: ['date', 'TSM-MA', 'TSM-Com', 'TSM-EQ', 'TSM-FI', 'TSM-FX']\n",
      "2025-04-11 12:34:42,619 - DEBUG - After dropping NA dates, 481 rows remain\n",
      "2025-04-11 12:34:42,624 - DEBUG - Rows after melting and dropping NA: 2405\n",
      "2025-04-11 12:34:43,355 - DEBUG - Existing keys sample (first 5): [('BAB_Intl', '2006-06-30', 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Intl'), ('UMD-COM', '1977-10-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global'), ('BAB-US', '2023-05-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'US'), ('HML-FI', '2019-07-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global'), ('Multi-style-All-SS', '1977-02-28', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global')]\n",
      "2025-04-11 12:34:43,356 - DEBUG - Total existing keys: 69934\n",
      "2025-04-11 12:34:43,397 - DEBUG - New keys sample (first 5): [('TSM-MA', '1985-01-31', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', nan), ('TSM-MA', '1985-02-28', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', nan), ('TSM-MA', '1985-03-29', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', nan), ('TSM-MA', '1985-04-30', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', nan), ('TSM-MA', '1985-05-31', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', nan)]\n",
      "2025-04-11 12:34:43,448 - DEBUG - New rows to insert: 2405. Sample (first 5): [{'factor': 'TSM-MA', 'date': Timestamp('1985-01-31 00:00:00'), 'region': nan}, {'factor': 'TSM-MA', 'date': Timestamp('1985-02-28 00:00:00'), 'region': nan}, {'factor': 'TSM-MA', 'date': Timestamp('1985-03-29 00:00:00'), 'region': nan}, {'factor': 'TSM-MA', 'date': Timestamp('1985-04-30 00:00:00'), 'region': nan}, {'factor': 'TSM-MA', 'date': Timestamp('1985-05-31 00:00:00'), 'region': nan}]\n",
      "2025-04-11 12:34:56,252 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet TSMOM Factors): ProgrammingError: (pyodbc.ProgrammingError) ('42S22', \"[42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid column name 'key'. (207) (SQLExecDirectW); [42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid column name 'key'. (207); [42S22] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Statement(s) could not be prepared. (8180)\")\n",
      "[SQL: INSERT INTO factor_returns (factor, date, associated_paper, value, region, asset_class, [key]) VALUES (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?,  ... 6627 characters truncated ... ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?)]\n",
      "[parameters: ('TSM-MA', datetime.datetime(1985, 1, 31, 0, 0), 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', 0.0430656840875, None, 'Equity', ('TSM-MA', '1985-01-31', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', nan), 'TSM-MA', datetime.datetime(1985, 2, 28, 0, 0), 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', 0.0381283572367, None, 'Equity', ('TSM-MA', '1985-02-28', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', nan), 'TSM-MA', datetime.datetime(1985, 3, 29, 0, 0), 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', -0.0527186264907, None, 'Equity', ('TSM-MA', '1985-03-29', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', nan), 'TSM-MA', datetime.datetime(1985, 4, 30, 0, 0), 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', 0.0396339206576, None, 'Equity', ('TSM-MA', '1985-04-30', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', nan), 'TSM-MA', datetime.datetime(1985, 5, 31, 0, 0), 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', 0.0639184945413, None, 'Equity', ('TSM-MA', '1985-05-31', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', nan), 'TSM-MA', datetime.datetime(1985, 6, 28, 0, 0), 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', 0.010832082759, None, 'Equity', ('TSM-MA', '1985-06-28', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', nan), 'TSM-MA', datetime.datetime(1985, 7, 31, 0, 0), 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', -0.030555858881, None, 'Equity', ('TSM-MA', '1985-07-31', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', nan), 'TSM-MA' ... 1993 parameters truncated ... ('TSM-MA', '2009-04-30', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', nan), 'TSM-MA', datetime.datetime(2009, 5, 29, 0, 0), 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', -0.0736745472226, None, 'Equity', ('TSM-MA', '2009-05-29', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', nan), 'TSM-MA', datetime.datetime(2009, 6, 30, 0, 0), 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', 0.0150275030951, None, 'Equity', ('TSM-MA', '2009-06-30', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', nan), 'TSM-MA', datetime.datetime(2009, 7, 31, 0, 0), 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', -0.0338408708629, None, 'Equity', ('TSM-MA', '2009-07-31', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', nan), 'TSM-MA', datetime.datetime(2009, 8, 31, 0, 0), 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', 0.0206192928564, None, 'Equity', ('TSM-MA', '2009-08-31', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', nan), 'TSM-MA', datetime.datetime(2009, 9, 30, 0, 0), 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', 0.00888006360212, None, 'Equity', ('TSM-MA', '2009-09-30', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', nan), 'TSM-MA', datetime.datetime(2009, 10, 30, 0, 0), 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', -0.0230531475503, None, 'Equity', ('TSM-MA', '2009-10-30', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', nan), 'TSM-MA', datetime.datetime(2009, 11, 30, 0, 0), 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', 0.0434429528637, None, 'Equity', ('TSM-MA', '2009-11-30', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', nan))]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "2025-04-11 12:34:56,253 - INFO - Processing dataset: QMJ\n",
      "2025-04-11 12:34:56,253 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 10 Portfolios Formed on Quality) with is_com=False\n",
      "2025-04-11 12:34:56,731 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 10 Portfolios Formed on Quality): ValueError: Length mismatch: Expected axis has 23 elements, new values have 12 elements\n",
      "2025-04-11 12:34:56,732 - INFO - Processing dataset: Century\n",
      "2025-04-11 12:34:56,733 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx (sheet 0) with is_com=False\n",
      "2025-04-11 12:34:57,426 - INFO - Read 1183 rows with set columns: ['DATE', 'US Stock Selection Value', 'US Stock Selection Momentum', 'US Stock Selection Defensive', 'US Stock Selection Multi-style', 'Intl Stock Selection Value', 'Intl Stock Selection Momentum', 'Intl Stock Selection Defensive', 'Intl Stock Selection Multi-style', 'Equity indices Value', 'Equity indices Momentum', 'Equity indices Carry', 'Equity indices Defensive', 'Equity indices Multi-style', 'Fixed income Value', 'Fixed income Momentum', 'Fixed income Carry', 'Fixed income Defensive', 'Fixed income Multi-style', 'Currencies Value', 'Currencies Momentum', 'Currencies Carry', 'Currencies Multi-style', 'Commodities Value', 'Commodities Momentum', 'Commodities Carry', 'Commodities Multi-style', 'All Stock Selection Value', 'All Stock Selection Momentum', 'All Stock Selection Defensive', 'All Stock Selection Multi-style', 'All Macro Value', 'All Macro Momentum', 'All Macro Carry', 'All Macro Defensive', 'All Macro Multi-style', 'All asset classes Value', 'All asset classes Momentum', 'All asset classes Carry', 'All asset classes Defensive', 'All asset classes Multi-style', 'Equity indices Market', 'Fixed income Market', 'Commodities Market', 'All Macro Market']\n",
      "2025-04-11 12:34:57,430 - INFO - Columns after renaming: ['date', 'HML-FF-US', 'UMD-US', 'BAB-US', 'Multi-style-US', 'HML-FF-Intl', 'UMD-Intl', 'BAB-Intl', 'Multi-style-Intl', 'HML-Equity', 'UMD-Equity', 'Carry-Equity', 'BAB-Equity', 'Multi-style-Equity', 'HML-FI', 'UMD-FI', 'Carry-FI', 'BAB-FI', 'Multi-style-FI', 'HML-FX', 'UMD-FX', 'Carry-FX', 'Multi-style-FX', 'HML-COM', 'UMD-COM', 'Carry-COM', 'Multi-style-COM', 'HML-All-SS', 'UMD-All-SS', 'BAB-All-SS', 'Multi-style-All-SS', 'HML-All-Macro', 'UMD-All-Macro', 'Carry-All-Macro', 'BAB-All-Macro', 'Multi-style-All-Macro', 'HML-All', 'UMD-All', 'Carry-All', 'BAB-All', 'Multi-style-All', 'MKT-Equity', 'MKT-FI', 'MKT-COM', 'MKT-All-Macro']\n",
      "C:\\Users\\JulianHeron\\AppData\\Local\\Temp\\ipykernel_21968\\2392414069.py:249: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
      "2025-04-11 12:34:57,434 - WARNING - Dropped 1 rows due to invalid dates in C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx (sheet 0)\n",
      "2025-04-11 12:34:57,438 - DEBUG - After dropping NA dates, 1182 rows remain\n",
      "2025-04-11 12:34:57,459 - DEBUG - Rows after melting and dropping NA: 46491\n",
      "2025-04-11 12:34:58,200 - DEBUG - Existing keys sample (first 5): [('BAB_Intl', '2006-06-30', 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Intl'), ('UMD-COM', '1977-10-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global'), ('BAB-US', '2023-05-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'US'), ('HML-FI', '2019-07-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global'), ('Multi-style-All-SS', '1977-02-28', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global')]\n",
      "2025-04-11 12:34:58,202 - DEBUG - Total existing keys: 69934\n",
      "2025-04-11 12:34:59,082 - DEBUG - New keys sample (first 5): [('HML-FF-US', '1926-07-30', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'US'), ('HML-FF-US', '1926-08-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'US'), ('HML-FF-US', '1926-09-30', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'US'), ('HML-FF-US', '1926-10-29', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'US'), ('HML-FF-US', '1926-11-30', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'US')]\n",
      "2025-04-11 12:34:59,152 - INFO - No new rows to load into factor_returns from C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx (sheet 0)\n",
      "2025-04-11 12:34:59,154 - DEBUG - Input date range: 1926-07-30 00:00:00 to 2024-12-31 00:00:00\n",
      "2025-04-11 12:34:59,167 - DEBUG - Database date range: 1926-07-30 to 2025-01-31\n",
      "2025-04-11 12:34:59,221 - INFO - Processing dataset: COM\n",
      "2025-04-11 12:34:59,224 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx (sheet 0) with is_com=True\n",
      "2025-04-11 12:34:59,546 - INFO - Read 1776 rows with set columns: ['DATE', 'Excess return of equal-weight commodities portfolio', 'Excess spot return of equal-weight commodities portfolio', 'Interest rate adjusted carry of equal-weight commodities portfolio', 'Spot return of equal-weight commodities portfolio', 'Carry of equal-weight commodities portfolio', 'Excess return of long/short commodities portfolio', 'Excess spot return of long/short commodities portfolio', 'Interest rate adjusted carry of long/short commodities portfolio', 'Aggregate backwardation/contango', 'State of backwardation/contango', 'State of inflation']\n",
      "2025-04-11 12:34:59,551 - DEBUG - After dropping NA dates, 1776 rows remain\n",
      "2025-04-11 12:34:59,564 - DEBUG - Existing commodity dates sample (first 5): ['1903-11-30', '1887-07-29', '2000-03-31', '1967-05-31', '1912-04-30']\n",
      "2025-04-11 12:34:59,568 - INFO - No new rows to load into aqr_cmdty_factors from C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx (sheet 0)\n",
      "2025-04-11 12:34:59,570 - DEBUG - Input date range: 1877-02-28 00:00:00 to 2025-01-31 00:00:00\n",
      "2025-04-11 12:34:59,571 - DEBUG - Database date range: 1877-02-28 to 2025-01-31\n",
      "2025-04-11 12:34:59,572 - INFO - All data processing complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import VARCHAR, DATE, DECIMAL\n",
    "import logging\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(), logging.FileHandler('load_aqr_data.log')]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Database connection\n",
    "engine = create_engine(\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/CWA_Fund_Database\"\n",
    "    \"?driver=ODBC+Driver+18+for+SQL+Server&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "# File configurations with explicit headers\n",
    "data_files = {\n",
    "    \"BAB_multi\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx\",\n",
    "        \"sheets\": {\n",
    "            \"BAB\": {\n",
    "                \"sheet\": \"BAB Factors\",\n",
    "                \"start_row\": 19,  # Data starts on row 20 (0-based 19)\n",
    "                \"paper\": \"Betting Against Beta (Frazzini and Pedersen, 2014)\",\n",
    "                \"headers\": [\"DATE\", \"AUS\", \"AUT\", \"BEL\", \"CAN\", \"CHE\", \"DEU\", \"DNK\", \"ESP\", \"FIN\", \"FRA\", \"GBR\", \"GRC\", \"HKG\", \"IRL\", \"ISR\", \"ITA\", \"JPN\", \"NLD\", \"NOR\", \"NZL\", \"PRT\", \"SGP\", \"SWE\", \"USA\", \"Global\", \"Global Ex USA\", \"Europe\", \"North America\", \"Pacific\"],\n",
    "                \"columns\": {\"DATE\": \"DATE\", \"USA\": \"BAB\", \"Global\": \"BAB\", \"Global Ex USA\": \"BAB\"}\n",
    "            },\n",
    "            \"MKT\": {\n",
    "                \"sheet\": \"MKT\",\n",
    "                \"start_row\": 19,\n",
    "                \"paper\": \"Fama-French Factors\",\n",
    "                \"headers\": [\"DATE\", \"AUS\", \"AUT\", \"BEL\", \"CAN\", \"CHE\", \"DEU\", \"DNK\", \"ESP\", \"FIN\", \"FRA\", \"GBR\", \"GRC\", \"HKG\", \"IRL\", \"ISR\", \"ITA\", \"JPN\", \"NLD\", \"NOR\", \"NZL\", \"PRT\", \"SGP\", \"SWE\", \"USA\", \"Global\", \"Global Ex USA\", \"Europe\", \"North America\", \"Pacific\"],\n",
    "                \"columns\": {\"DATE\": \"DATE\", \"USA\": \"MKT\", \"Global\": \"MKT\", \"Global Ex USA\": \"MKT\"}\n",
    "            },\n",
    "            \"SMB\": {\n",
    "                \"sheet\": \"SMB\",\n",
    "                \"start_row\": 19,\n",
    "                \"paper\": \"Fama-French Factors\",\n",
    "                \"headers\": [\"DATE\", \"AUS\", \"AUT\", \"BEL\", \"CAN\", \"CHE\", \"DEU\", \"DNK\", \"ESP\", \"FIN\", \"FRA\", \"GBR\", \"GRC\", \"HKG\", \"IRL\", \"ISR\", \"ITA\", \"JPN\", \"NLD\", \"NOR\", \"NZL\", \"PRT\", \"SGP\", \"SWE\", \"USA\", \"Global\", \"Global Ex USA\", \"Europe\", \"North America\", \"Pacific\"],\n",
    "                \"columns\": {\"DATE\": \"DATE\", \"USA\": \"SMB\", \"Global\": \"SMB\", \"Global Ex USA\": \"SMB\"}\n",
    "            },\n",
    "            \"HML-FF\": {\n",
    "                \"sheet\": \"HML FF\",\n",
    "                \"start_row\": 19,\n",
    "                \"paper\": \"Fama-French Factors\",\n",
    "                \"headers\": [\"DATE\", \"AUS\", \"AUT\", \"BEL\", \"CAN\", \"CHE\", \"DEU\", \"DNK\", \"ESP\", \"FIN\", \"FRA\", \"GBR\", \"GRC\", \"HKG\", \"IRL\", \"ISR\", \"ITA\", \"JPN\", \"NLD\", \"NOR\", \"NZL\", \"PRT\", \"SGP\", \"SWE\", \"USA\", \"Global\", \"Global Ex USA\", \"Europe\", \"North America\", \"Pacific\"],\n",
    "                \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-FF\", \"Global\": \"HML-FF\", \"Global Ex USA\": \"HML-FF\"}\n",
    "            },\n",
    "            \"HML-D\": {\n",
    "                \"sheet\": \"HML Devil\",\n",
    "                \"start_row\": 19,\n",
    "                \"paper\": \"The Devil's in HML's Details\",\n",
    "                \"headers\": [\"DATE\", \"AUS\", \"AUT\", \"BEL\", \"CAN\", \"CHE\", \"DEU\", \"DNK\", \"ESP\", \"FIN\", \"FRA\", \"GBR\", \"GRC\", \"HKG\", \"IRL\", \"ISR\", \"ITA\", \"JPN\", \"NLD\", \"NOR\", \"NZL\", \"PRT\", \"SGP\", \"SWE\", \"USA\", \"Global\", \"Global Ex USA\", \"Europe\", \"North America\", \"Pacific\"],\n",
    "                \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-D\", \"Global\": \"HML-D\", \"Global Ex USA\": \"HML-D\"}\n",
    "            },\n",
    "            \"UMD\": {\n",
    "                \"sheet\": \"UMD\",\n",
    "                \"start_row\": 19,\n",
    "                \"paper\": \"On Persistence in Mutual Fund Performance\",\n",
    "                \"headers\": [\"DATE\", \"AUS\", \"AUT\", \"BEL\", \"CAN\", \"CHE\", \"DEU\", \"DNK\", \"ESP\", \"FIN\", \"FRA\", \"GBR\", \"GRC\", \"HKG\", \"IRL\", \"ISR\", \"ITA\", \"JPN\", \"NLD\", \"NOR\", \"NZL\", \"PRT\", \"SGP\", \"SWE\", \"USA\", \"Global\", \"Global Ex USA\", \"Europe\", \"North America\", \"Pacific\"],\n",
    "                \"columns\": {\"DATE\": \"DATE\", \"USA\": \"UMD\", \"Global\": \"UMD\", \"Global Ex USA\": \"UMD\"}\n",
    "            },\n",
    "            \"ME\": {\n",
    "                \"sheet\": \"ME(t-1)\",\n",
    "                \"start_row\": 19,\n",
    "                \"paper\": \"AQR Factors\",\n",
    "                \"headers\": [\"DATE\", \"AUT\", \"HKG\", \"ESP\", \"GBR\", \"ITA\", \"DEU\", \"DNK\", \"NZL\", \"NLD\", \"USA\", \"PRT\", \"BEL\", \"ISR\", \"GRC\", \"NOR\", \"SGP\", \"CHE\", \"IRL\", \"CAN\", \"FIN\", \"JPN\", \"SWE\", \"FRA\", \"AUS\", \"Global Ex USA\", \"Global\", \"Europe\", \"North America\", \"Pacific\"],\n",
    "                \"columns\": {\"DATE\": \"DATE\", \"USA\": \"ME\", \"Global\": \"ME\", \"Global Ex USA\": \"ME\"}\n",
    "            },\n",
    "            \"RF\": {\n",
    "                \"sheet\": \"RF\",\n",
    "                \"start_row\": 18,\n",
    "                \"paper\": None,\n",
    "                \"headers\": [\"DATE\", \"Risk Free Rate\"],\n",
    "                \"columns\": {\"DATE\": \"DATE\", \"Risk Free Rate\": \"RF\"}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"TSMOM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx\",\n",
    "        \"sheet\": \"TSMOM Factors\",\n",
    "        \"start_row\": 18,\n",
    "        \"paper\": \"Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)\",\n",
    "        \"headers\": [\"DATE\", \"TSMOM\", \"TSMOM^CM\", \"TSMOM^EQ\", \"TSMOM^FI\", \"TSMOM^FX\"],\n",
    "        \"columns\": {\n",
    "            \"DATE\": \"DATE\",\n",
    "            \"TSMOM\": \"TSM-MA\",\n",
    "            \"TSMOM^CM\": \"TSM-Com\",\n",
    "            \"TSMOM^EQ\": \"TSM-EQ\",\n",
    "            \"TSMOM^FI\": \"TSM-FI\",\n",
    "            \"TSMOM^FX\": \"TSM-FX\"\n",
    "        }\n",
    "    },\n",
    "    \"QMJ\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx\",\n",
    "        \"sheet\": \"10 Portfolios Formed on Quality\",\n",
    "        \"start_row\": 19,\n",
    "        \"paper\": \"Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)\",\n",
    "        \"headers\": [\"DATE\", \"P1 (low quality)\", \"P2\", \"P3\", \"P4\", \"P5\", \"P6\", \"P7\", \"P8\", \"P9\", \"P10 (high quality)\", \"P10-P1\"],\n",
    "        \"columns\": {\n",
    "            \"DATE\": \"DATE\",\n",
    "            \"P1 (low quality)\": \"QMJ-P1-LQ\",\n",
    "            \"P2\": \"QMJ-P2\",\n",
    "            \"P3\": \"QMJ-P3\",\n",
    "            \"P4\": \"QMJ-P4\",\n",
    "            \"P5\": \"QMJ-P5\",\n",
    "            \"P6\": \"QMJ-P6\",\n",
    "            \"P7\": \"QMJ-P7\",\n",
    "            \"P8\": \"QMJ-P8\",\n",
    "            \"P9\": \"QMJ-P9\",\n",
    "            \"P10 (high quality)\": \"QMJ-P10-HQ\",\n",
    "            \"P10-P1\": \"QMJ\"\n",
    "        }\n",
    "    },\n",
    "    \"Century\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"start_row\": 18,\n",
    "        \"paper\": \"Century of Factor Premia Monthly-Ilmanen et al. (2021)\",\n",
    "        \"headers\": [\"DATE\", \"US Stock Selection Value\", \"US Stock Selection Momentum\", \"US Stock Selection Defensive\", \"US Stock Selection Multi-style\", \"Intl Stock Selection Value\", \"Intl Stock Selection Momentum\", \"Intl Stock Selection Defensive\", \"Intl Stock Selection Multi-style\", \"Equity indices Value\", \"Equity indices Momentum\", \"Equity indices Carry\", \"Equity indices Defensive\", \"Equity indices Multi-style\", \"Fixed income Value\", \"Fixed income Momentum\", \"Fixed income Carry\", \"Fixed income Defensive\", \"Fixed income Multi-style\", \"Currencies Value\", \"Currencies Momentum\", \"Currencies Carry\", \"Currencies Multi-style\", \"Commodities Value\", \"Commodities Momentum\", \"Commodities Carry\", \"Commodities Multi-style\", \"All Stock Selection Value\", \"All Stock Selection Momentum\", \"All Stock Selection Defensive\", \"All Stock Selection Multi-style\", \"All Macro Value\", \"All Macro Momentum\", \"All Macro Carry\", \"All Macro Defensive\", \"All Macro Multi-style\", \"All asset classes Value\", \"All asset classes Momentum\", \"All asset classes Carry\", \"All asset classes Defensive\", \"All asset classes Multi-style\", \"Equity indices Market\", \"Fixed income Market\", \"Commodities Market\", \"All Macro Market\"],\n",
    "        \"columns\": {\n",
    "            \"DATE\": \"DATE\",\n",
    "            \"US Stock Selection Value\": \"HML-FF-US\", \"US Stock Selection Momentum\": \"UMD-US\", \n",
    "            \"US Stock Selection Defensive\": \"BAB-US\", \"US Stock Selection Multi-style\": \"Multi-style-US\",\n",
    "            \"Intl Stock Selection Value\": \"HML-FF-Intl\", \"Intl Stock Selection Momentum\": \"UMD-Intl\", \n",
    "            \"Intl Stock Selection Defensive\": \"BAB-Intl\", \"Intl Stock Selection Multi-style\": \"Multi-style-Intl\",\n",
    "            \"Equity indices Value\": \"HML-Equity\", \"Equity indices Momentum\": \"UMD-Equity\", \n",
    "            \"Equity indices Carry\": \"Carry-Equity\", \"Equity indices Defensive\": \"BAB-Equity\", \n",
    "            \"Equity indices Multi-style\": \"Multi-style-Equity\",\n",
    "            \"Fixed income Value\": \"HML-FI\", \"Fixed income Momentum\": \"UMD-FI\", \n",
    "            \"Fixed income Carry\": \"Carry-FI\", \"Fixed income Defensive\": \"BAB-FI\", \n",
    "            \"Fixed income Multi-style\": \"Multi-style-FI\",\n",
    "            \"Currencies Value\": \"HML-FX\", \"Currencies Momentum\": \"UMD-FX\", \n",
    "            \"Currencies Carry\": \"Carry-FX\", \"Currencies Multi-style\": \"Multi-style-FX\",\n",
    "            \"Commodities Value\": \"HML-COM\", \"Commodities Momentum\": \"UMD-COM\", \n",
    "            \"Commodities Carry\": \"Carry-COM\", \"Commodities Multi-style\": \"Multi-style-COM\",\n",
    "            \"All Stock Selection Value\": \"HML-All-SS\", \"All Stock Selection Momentum\": \"UMD-All-SS\", \n",
    "            \"All Stock Selection Defensive\": \"BAB-All-SS\", \"All Stock Selection Multi-style\": \"Multi-style-All-SS\",\n",
    "            \"All Macro Value\": \"HML-All-Macro\", \"All Macro Momentum\": \"UMD-All-Macro\", \n",
    "            \"All Macro Carry\": \"Carry-All-Macro\", \"All Macro Defensive\": \"BAB-All-Macro\", \n",
    "            \"All Macro Multi-style\": \"Multi-style-All-Macro\",\n",
    "            \"All asset classes Value\": \"HML-All\", \"All asset classes Momentum\": \"UMD-All\", \n",
    "            \"All asset classes Carry\": \"Carry-All\", \"All asset classes Defensive\": \"BAB-All\", \n",
    "            \"All asset classes Multi-style\": \"Multi-style-All\",\n",
    "            \"Equity indices Market\": \"MKT-Equity\", \"Fixed income Market\": \"MKT-FI\", \n",
    "            \"Commodities Market\": \"MKT-COM\", \"All Macro Market\": \"MKT-All-Macro\"\n",
    "        }\n",
    "    },\n",
    "    \"COM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"start_row\": 11,\n",
    "        \"paper\": \"Commodities for the Long Run\",\n",
    "        \"headers\": [\"DATE\", \"Excess return of equal-weight commodities portfolio\", \"Excess spot return of equal-weight commodities portfolio\", \"Interest rate adjusted carry of equal-weight commodities portfolio\", \"Spot return of equal-weight commodities portfolio\", \"Carry of equal-weight commodities portfolio\", \"Excess return of long/short commodities portfolio\", \"Excess spot return of long/short commodities portfolio\", \"Interest rate adjusted carry of long/short commodities portfolio\", \"Aggregate backwardation/contango\", \"State of backwardation/contango\", \"State of inflation\"],\n",
    "        \"columns\": {\n",
    "            \"DATE\": \"date\",\n",
    "            \"Excess return of equal-weight commodities portfolio\": \"excess_return_eqwt\",\n",
    "            \"Excess spot return of equal-weight commodities portfolio\": \"excess_spot_return_eqwt\",\n",
    "            \"Interest rate adjusted carry of equal-weight commodities portfolio\": \"ir_adjusted_carry_eqwt\",\n",
    "            \"Spot return of equal-weight commodities portfolio\": \"spot_return_eqwt\",\n",
    "            \"Carry of equal-weight commodities portfolio\": \"carry_eqwt\",\n",
    "            \"Excess return of long/short commodities portfolio\": \"excess_return_long_short\",\n",
    "            \"Excess spot return of long/short commodities portfolio\": \"excess_spot_return_long_short\",\n",
    "            \"Interest rate adjusted carry of long/short commodities portfolio\": \"ir_adjusted_carry_long_short\",\n",
    "            \"Aggregate backwardation/contango\": \"aggregate_backwardation_contango\",\n",
    "            \"State of backwardation/contango\": \"state_backwardation_contango\",\n",
    "            \"State of inflation\": \"state_inflation\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "def process_factors(file_config, sheet=0, is_com=False, parent_path=None):\n",
    "    file_path = parent_path if parent_path else file_config['path']\n",
    "    logger.info(f\"Processing {file_path} (sheet {sheet}) with is_com={is_com}\")\n",
    "    try:\n",
    "        # Read Excel without headers, then set them\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet, header=None, skiprows=file_config['start_row'])\n",
    "        df.columns = file_config['headers']\n",
    "        logger.info(f\"Read {len(df)} rows with set columns: {list(df.columns)}\")\n",
    "        \n",
    "        if is_com:\n",
    "            expected_cols = list(file_config['columns'].keys())\n",
    "            df = df[expected_cols]\n",
    "            df.columns = [file_config['columns'][col] for col in df.columns]\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            df['associated_paper'] = file_config['paper'] if file_config['paper'] is not None else 'Unknown'\n",
    "            df = df.dropna(subset=['date'])\n",
    "            logger.debug(f\"After dropping NA dates, {len(df)} rows remain\")\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                existing = pd.read_sql(\"SELECT date FROM aqr_cmdty_factors\", connection)\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(existing['date'])\n",
    "                logger.debug(f\"Existing commodity dates sample (first 5): {list(existing_keys)[:5]}\")\n",
    "            \n",
    "            df['date_str'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_new = df[~df['date_str'].isin(existing_keys)].drop(columns=['date_str'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                for chunk in [df_new[i:i+10000] for i in range(0, len(df_new), 10000)]:\n",
    "                    chunk.to_sql(\n",
    "                        'aqr_cmdty_factors',\n",
    "                        engine,\n",
    "                        if_exists='append',\n",
    "                        index=False,\n",
    "                        dtype={\n",
    "                            'date': DATE,\n",
    "                            'excess_return_eqwt': DECIMAL(15, 6),\n",
    "                            'excess_spot_return_eqwt': DECIMAL(15, 6),\n",
    "                            'ir_adjusted_carry_eqwt': DECIMAL(15, 6),\n",
    "                            'spot_return_eqwt': DECIMAL(15, 6),\n",
    "                            'carry_eqwt': DECIMAL(15, 6),\n",
    "                            'excess_return_long_short': DECIMAL(15, 6),\n",
    "                            'excess_spot_return_long_short': DECIMAL(15, 6),\n",
    "                            'ir_adjusted_carry_long_short': DECIMAL(15, 6),\n",
    "                            'aggregate_backwardation_contango': DECIMAL(15, 6),\n",
    "                            'state_backwardation_contango': VARCHAR(50),\n",
    "                            'state_inflation': VARCHAR(50),\n",
    "                            'associated_paper': VARCHAR(100)\n",
    "                        }\n",
    "                    )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into aqr_cmdty_factors from {file_path} (sheet {sheet})\")\n",
    "            else:\n",
    "                logger.info(f\"No new rows to load into aqr_cmdty_factors from {file_path} (sheet {sheet})\")\n",
    "                logger.debug(f\"Input date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "                logger.debug(f\"Database date range: {existing['date'].min() if not existing.empty else 'N/A'} to {existing['date'].max() if not existing.empty else 'N/A'}\")\n",
    "        else:\n",
    "            date_col = 'DATE'\n",
    "            orig_cols = df.columns.tolist()\n",
    "            if 'columns' in file_config:\n",
    "                expected_cols = list(file_config['columns'].keys())\n",
    "                valid_cols = [col for col in expected_cols if col in df.columns]\n",
    "                if not valid_cols:\n",
    "                    logger.error(f\"No valid columns found in {file_path} (sheet {sheet}). Skipping.\")\n",
    "                    return\n",
    "                if date_col not in valid_cols:\n",
    "                    valid_cols.append(date_col)\n",
    "                df = df[valid_cols]\n",
    "                new_columns = ['date' if col == date_col else file_config['columns'].get(col, col) for col in df.columns]\n",
    "                df.columns = new_columns\n",
    "            \n",
    "            logger.info(f\"Columns after renaming: {list(df.columns)}\")\n",
    "            \n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            invalid_dates = df['date'].isna().sum()\n",
    "            if invalid_dates > 0:\n",
    "                logger.warning(f\"Dropped {invalid_dates} rows due to invalid dates in {file_path} (sheet {sheet})\")\n",
    "            df = df.dropna(subset=['date'])\n",
    "            logger.debug(f\"After dropping NA dates, {len(df)} rows remain\")\n",
    "            \n",
    "            value_vars = [col for col in df.columns if col != 'date']\n",
    "            df_long = df.melt(id_vars=['date'], value_vars=value_vars, var_name='factor', value_name='value')\n",
    "            df_long = df_long.dropna(subset=['value', 'date'])\n",
    "            logger.debug(f\"Rows after melting and dropping NA: {len(df_long)}\")\n",
    "            \n",
    "            file_path_for_check = parent_path if parent_path else file_config.get('path', '')\n",
    "            if 'TSMOM' in file_path_for_check:\n",
    "                df_long['asset_class'] = df_long['factor'].map({\n",
    "                    \"TSM-MA\": \"Multi-Asset\",\n",
    "                    \"TSM-Com\": \"Commodities\",\n",
    "                    \"TSM-EQ\": \"Equity\",\n",
    "                    \"TSM-FI\": \"Fixed Income\",\n",
    "                    \"TSM-FX\": \"Currencies\"\n",
    "                })\n",
    "                df_long['region'] = \"Global\"\n",
    "            elif 'Quality Minus Junk' in file_path_for_check:\n",
    "                df_long['asset_class'] = \"Equity\"\n",
    "                df_long['region'] = df_long['date'].apply(lambda x: \"USA\" if x < pd.Timestamp(\"1989-07-31\") else \"Global\")\n",
    "            elif 'Century' in file_path_for_check:\n",
    "                df_long['asset_class'] = df_long['factor'].str.extract(\n",
    "                    '(Stock Selection|Equity indices|Fixed income|Currencies|Commodities|All Macro|All asset classes)'\n",
    "                ).fillna('Equity')\n",
    "                df_long['region'] = df_long['factor'].apply(lambda x: 'US' if 'US' in x else 'Intl' if 'Intl' in x else 'Global')\n",
    "            else:  # BAB_multi\n",
    "                df_long['asset_class'] = \"Equity\" if 'Risk Free Rate' not in file_config['columns'].values() else \"Fixed Income\"\n",
    "                region_map = {\n",
    "                    \"BAB\": {\"USA\": \"USA\", \"Global\": \"Global\", \"Global Ex USA\": \"Intl\"},\n",
    "                    \"MKT\": {\"USA\": \"USA\", \"Global\": \"Global\", \"Global Ex USA\": \"Intl\"},\n",
    "                    \"SMB\": {\"USA\": \"USA\", \"Global\": \"Global\", \"Global Ex USA\": \"Intl\"},\n",
    "                    \"HML-FF\": {\"USA\": \"USA\", \"Global\": \"Global\", \"Global Ex USA\": \"Intl\"},\n",
    "                    \"HML-D\": {\"USA\": \"USA\", \"Global\": \"Global\", \"Global Ex USA\": \"Intl\"},\n",
    "                    \"UMD\": {\"USA\": \"USA\", \"Global\": \"Global\", \"Global Ex USA\": \"Intl\"},\n",
    "                    \"ME\": {\"USA\": \"USA\", \"Global\": \"Global\", \"Global Ex USA\": \"Intl\"},\n",
    "                    \"RF\": {\"Risk Free Rate\": \"USA\"}\n",
    "                }.get(df_long['factor'].iloc[0], {})\n",
    "                df_long['region'] = df_long['factor'].map(region_map)\n",
    "            \n",
    "            df_long['associated_paper'] = file_config['paper'] if file_config['paper'] is not None else 'Unknown'\n",
    "            df_long = df_long[['factor', 'date', 'associated_paper', 'value', 'region', 'asset_class']]\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                existing = pd.read_sql(\n",
    "                    \"SELECT factor, date, associated_paper, region FROM factor_returns\",\n",
    "                    connection\n",
    "                )\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(tuple(row) for row in existing[['factor', 'date', 'associated_paper', 'region']].values)\n",
    "                logger.debug(f\"Existing keys sample (first 5): {list(existing_keys)[:5]}\")\n",
    "                logger.debug(f\"Total existing keys: {len(existing_keys)}\")\n",
    "            \n",
    "            df_long['date_str'] = df_long['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_long['key'] = df_long.apply(\n",
    "                lambda row: (row['factor'], row['date_str'], row['associated_paper'], row['region']), axis=1\n",
    "            )\n",
    "            logger.debug(f\"New keys sample (first 5): {df_long['key'].head().tolist()}\")\n",
    "            df_new = df_long[~df_long['key'].isin(existing_keys)].drop(columns=['date_str'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                logger.debug(f\"New rows to insert: {len(df_new)}. Sample (first 5): {df_new[['factor', 'date', 'region']].head().to_dict('records')}\")\n",
    "                for chunk in [df_new[i:i+10000] for i in range(0, len(df_new), 10000)]:\n",
    "                    chunk.to_sql(\n",
    "                        'factor_returns',\n",
    "                        engine,\n",
    "                        if_exists='append',\n",
    "                        index=False,\n",
    "                        dtype={\n",
    "                            'factor': VARCHAR(50),\n",
    "                            'date': DATE,\n",
    "                            'associated_paper': VARCHAR(100),\n",
    "                            'value': DECIMAL(15, 6),\n",
    "                            'region': VARCHAR(50),\n",
    "                            'asset_class': VARCHAR(50)\n",
    "                        }\n",
    "                    )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into factor_returns from {file_path} (sheet {sheet})\")\n",
    "            else:\n",
    "                logger.info(f\"No new rows to load into factor_returns from {file_path} (sheet {sheet})\")\n",
    "                logger.debug(f\"Input date range: {df_long['date'].min()} to {df_long['date'].max()}\")\n",
    "                logger.debug(f\"Database date range: {existing['date'].min() if not existing.empty else 'N/A'} to {existing['date'].max() if not existing.empty else 'N/A'}\")\n",
    "            \n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(f\"File not found: {file_path} (sheet {sheet}): {str(e)}\")\n",
    "    except pd.errors.ParserError as e:\n",
    "        logger.error(f\"Error parsing Excel file {file_path} (sheet {sheet}): {str(e)}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error processing {file_path} (sheet {sheet}): {type(e).__name__}: {str(e)}\")\n",
    "\n",
    "# Main loop\n",
    "for key, config in data_files.items():\n",
    "    logger.info(f\"Processing dataset: {key}\")\n",
    "    if key == \"BAB_multi\":\n",
    "        for subkey, subconfig in config['sheets'].items():\n",
    "            process_factors(subconfig, sheet=subconfig['sheet'], parent_path=config['path'])\n",
    "    else:\n",
    "        is_com = (key == \"COM\")\n",
    "        process_factors(config, sheet=config['sheet'], is_com=is_com)\n",
    "\n",
    "logger.info(\"All data processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e45841cf-6fda-4140-b079-e8a5f0421d65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 12:51:40,263 - INFO - Processing dataset: BAB_multi\n",
      "2025-04-11 12:51:40,265 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet BAB Factors) with is_com=False\n",
      "2025-04-11 12:51:40,572 - INFO - Read 1129 rows with set columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-11 12:51:40,575 - INFO - Columns after renaming: ['date', 'BAB', 'BAB', 'BAB']\n",
      "2025-04-11 12:51:40,586 - DEBUG - After dropping NA dates, 1129 rows remain\n",
      "2025-04-11 12:51:40,588 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet BAB Factors): ValueError: Length of values (4) does not match length of index (1129)\n",
      "2025-04-11 12:51:40,589 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet MKT) with is_com=False\n",
      "2025-04-11 12:51:41,007 - INFO - Read 1182 rows with set columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-11 12:51:41,008 - INFO - Columns after renaming: ['date', 'MKT', 'MKT', 'MKT']\n",
      "2025-04-11 12:51:41,017 - DEBUG - After dropping NA dates, 1182 rows remain\n",
      "2025-04-11 12:51:41,020 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet MKT): ValueError: Length of values (4) does not match length of index (1182)\n",
      "2025-04-11 12:51:41,021 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet SMB) with is_com=False\n",
      "2025-04-11 12:51:41,447 - INFO - Read 1181 rows with set columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-11 12:51:41,450 - INFO - Columns after renaming: ['date', 'SMB', 'SMB', 'SMB']\n",
      "2025-04-11 12:51:41,459 - DEBUG - After dropping NA dates, 1181 rows remain\n",
      "2025-04-11 12:51:41,461 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet SMB): ValueError: Length of values (4) does not match length of index (1181)\n",
      "2025-04-11 12:51:41,461 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet HML FF) with is_com=False\n",
      "2025-04-11 12:51:41,889 - INFO - Read 1181 rows with set columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-11 12:51:41,891 - INFO - Columns after renaming: ['date', 'HML-FF', 'HML-FF', 'HML-FF']\n",
      "2025-04-11 12:51:41,900 - DEBUG - After dropping NA dates, 1181 rows remain\n",
      "2025-04-11 12:51:41,901 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet HML FF): ValueError: Length of values (4) does not match length of index (1181)\n",
      "2025-04-11 12:51:41,903 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet HML Devil) with is_com=False\n",
      "2025-04-11 12:51:42,312 - INFO - Read 1182 rows with set columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-11 12:51:42,315 - INFO - Columns after renaming: ['date', 'HML-D', 'HML-D', 'HML-D']\n",
      "2025-04-11 12:51:42,323 - DEBUG - After dropping NA dates, 1182 rows remain\n",
      "2025-04-11 12:51:42,326 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet HML Devil): ValueError: Length of values (4) does not match length of index (1182)\n",
      "2025-04-11 12:51:42,327 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet UMD) with is_com=False\n",
      "2025-04-11 12:51:42,904 - INFO - Read 1176 rows with set columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-11 12:51:42,906 - INFO - Columns after renaming: ['date', 'UMD', 'UMD', 'UMD']\n",
      "2025-04-11 12:51:42,918 - DEBUG - After dropping NA dates, 1176 rows remain\n",
      "2025-04-11 12:51:42,921 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet UMD): ValueError: Length of values (4) does not match length of index (1176)\n",
      "2025-04-11 12:51:42,922 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet ME(t-1)) with is_com=False\n",
      "2025-04-11 12:51:43,447 - INFO - Read 1182 rows with set columns: ['DATE', 'AUT', 'HKG', 'ESP', 'GBR', 'ITA', 'DEU', 'DNK', 'NZL', 'NLD', 'USA', 'PRT', 'BEL', 'ISR', 'GRC', 'NOR', 'SGP', 'CHE', 'IRL', 'CAN', 'FIN', 'JPN', 'SWE', 'FRA', 'AUS', 'Global Ex USA', 'Global', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-11 12:51:43,450 - INFO - Columns after renaming: ['date', 'ME', 'ME', 'ME']\n",
      "2025-04-11 12:51:43,459 - DEBUG - After dropping NA dates, 1182 rows remain\n",
      "2025-04-11 12:51:43,462 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet ME(t-1)): ValueError: Length of values (4) does not match length of index (1182)\n",
      "2025-04-11 12:51:43,463 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet RF) with is_com=False\n",
      "2025-04-11 12:51:43,946 - INFO - Read 1184 rows with set columns: ['DATE', 'Risk Free Rate']\n",
      "2025-04-11 12:51:43,948 - INFO - Columns after renaming: ['date', 'RF']\n",
      "C:\\Users\\JulianHeron\\AppData\\Local\\Temp\\ipykernel_21968\\3141653370.py:260: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
      "2025-04-11 12:51:43,952 - WARNING - Dropped 1 rows due to invalid dates in C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet RF)\n",
      "2025-04-11 12:51:43,955 - DEBUG - After dropping NA dates, 1183 rows remain\n",
      "2025-04-11 12:51:43,957 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet RF): ValueError: Length of values (2) does not match length of index (1183)\n",
      "2025-04-11 12:51:43,959 - INFO - Processing dataset: TSMOM\n",
      "2025-04-11 12:51:43,959 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet TSMOM Factors) with is_com=False\n",
      "2025-04-11 12:51:44,143 - INFO - Read 481 rows with set columns: ['DATE', 'TSMOM', 'TSMOM^CM', 'TSMOM^EQ', 'TSMOM^FI', 'TSMOM^FX']\n",
      "2025-04-11 12:51:44,146 - INFO - Columns after renaming: ['date', 'TSM-MA', 'TSM-Com', 'TSM-EQ', 'TSM-FI', 'TSM-FX']\n",
      "2025-04-11 12:51:44,149 - DEBUG - After dropping NA dates, 481 rows remain\n",
      "2025-04-11 12:51:44,151 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet TSMOM Factors): ValueError: Length of values (6) does not match length of index (481)\n",
      "2025-04-11 12:51:44,152 - INFO - Processing dataset: QMJ\n",
      "2025-04-11 12:51:44,153 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 10 Portfolios Formed on Quality) with is_com=False\n",
      "2025-04-11 12:51:44,572 - INFO - Read 809 rows with set columns: ['DATE', 'P1 (low quality)', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10 (high quality)', 'P10-P1', 'P1 (low quality).1', 'P2.1', 'P3.1', 'P4.1', 'P5.1', 'P6.1', 'P7.1', 'P8.1', 'P9.1', 'P10 (high quality).1', 'P10-P1.1']\n",
      "2025-04-11 12:51:44,574 - INFO - Columns after renaming: ['date', 'QMJ-P1-LQ', 'QMJ-P2', 'QMJ-P3', 'QMJ-P4', 'QMJ-P5', 'QMJ-P6', 'QMJ-P7', 'QMJ-P8', 'QMJ-P9', 'QMJ-P10-HQ', 'QMJ', 'QMJ-P1-LQ', 'QMJ-P2', 'QMJ-P3', 'QMJ-P4', 'QMJ-P5', 'QMJ-P6', 'QMJ-P7', 'QMJ-P8', 'QMJ-P9', 'QMJ-P10-HQ', 'QMJ']\n",
      "2025-04-11 12:51:44,584 - DEBUG - After dropping NA dates, 809 rows remain\n",
      "2025-04-11 12:51:44,598 - DEBUG - Rows after melting and dropping NA: 13574\n",
      "2025-04-11 12:51:45,358 - DEBUG - Existing keys sample (first 5): [('BAB_Intl', '2006-06-30', 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Intl'), ('UMD-COM', '1977-10-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global'), ('BAB-US', '2023-05-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'US'), ('HML-FI', '2019-07-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global'), ('Multi-style-All-SS', '1977-02-28', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'Global')]\n",
      "2025-04-11 12:51:45,360 - DEBUG - Total existing keys: 69934\n",
      "2025-04-11 12:51:45,619 - DEBUG - New keys sample (first 5): [('QMJ-P1-LQ', '1957-07-31', 'Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)', 'USA'), ('QMJ-P1-LQ', '1957-08-31', 'Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)', 'USA'), ('QMJ-P1-LQ', '1957-09-30', 'Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)', 'USA'), ('QMJ-P1-LQ', '1957-10-31', 'Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)', 'USA'), ('QMJ-P1-LQ', '1957-11-30', 'Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)', 'USA')]\n",
      "2025-04-11 12:51:45,671 - INFO - No new rows to load into factor_returns from C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 10 Portfolios Formed on Quality)\n",
      "2025-04-11 12:51:45,672 - DEBUG - Input date range: 1957-07-31 00:00:00 to 2024-11-30 00:00:00\n",
      "2025-04-11 12:51:45,684 - DEBUG - Database date range: 1926-07-30 to 2025-01-31\n",
      "2025-04-11 12:51:45,719 - INFO - Processing dataset: Century\n",
      "2025-04-11 12:51:45,720 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx (sheet 0) with is_com=False\n",
      "2025-04-11 12:51:46,378 - INFO - Read 1183 rows with set columns: ['DATE', 'US Stock Selection Value', 'US Stock Selection Momentum', 'US Stock Selection Defensive', 'US Stock Selection Multi-style', 'Intl Stock Selection Value', 'Intl Stock Selection Momentum', 'Intl Stock Selection Defensive', 'Intl Stock Selection Multi-style', 'Equity indices Value', 'Equity indices Momentum', 'Equity indices Carry', 'Equity indices Defensive', 'Equity indices Multi-style', 'Fixed income Value', 'Fixed income Momentum', 'Fixed income Carry', 'Fixed income Defensive', 'Fixed income Multi-style', 'Currencies Value', 'Currencies Momentum', 'Currencies Carry', 'Currencies Multi-style', 'Commodities Value', 'Commodities Momentum', 'Commodities Carry', 'Commodities Multi-style', 'All Stock Selection Value', 'All Stock Selection Momentum', 'All Stock Selection Defensive', 'All Stock Selection Multi-style', 'All Macro Value', 'All Macro Momentum', 'All Macro Carry', 'All Macro Defensive', 'All Macro Multi-style', 'All asset classes Value', 'All asset classes Momentum', 'All asset classes Carry', 'All asset classes Defensive', 'All asset classes Multi-style', 'Equity indices Market', 'Fixed income Market', 'Commodities Market', 'All Macro Market']\n",
      "2025-04-11 12:51:46,381 - INFO - Columns after renaming: ['date', 'HML-FF-US', 'UMD-US', 'BAB-US', 'Multi-style-US', 'HML-FF-Intl', 'UMD-Intl', 'BAB-Intl', 'Multi-style-Intl', 'HML-Equity', 'UMD-Equity', 'Carry-Equity', 'BAB-Equity', 'Multi-style-Equity', 'HML-FI', 'UMD-FI', 'Carry-FI', 'BAB-FI', 'Multi-style-FI', 'HML-FX', 'UMD-FX', 'Carry-FX', 'Multi-style-FX', 'HML-COM', 'UMD-COM', 'Carry-COM', 'Multi-style-COM', 'HML-All-SS', 'UMD-All-SS', 'BAB-All-SS', 'Multi-style-All-SS', 'HML-All-Macro', 'UMD-All-Macro', 'Carry-All-Macro', 'BAB-All-Macro', 'Multi-style-All-Macro', 'HML-All', 'UMD-All', 'Carry-All', 'BAB-All', 'Multi-style-All', 'MKT-Equity', 'MKT-FI', 'MKT-COM', 'MKT-All-Macro']\n",
      "C:\\Users\\JulianHeron\\AppData\\Local\\Temp\\ipykernel_21968\\3141653370.py:260: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
      "2025-04-11 12:51:46,385 - WARNING - Dropped 1 rows due to invalid dates in C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx (sheet 0)\n",
      "2025-04-11 12:51:46,389 - DEBUG - After dropping NA dates, 1182 rows remain\n",
      "2025-04-11 12:51:46,391 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx (sheet 0): ValueError: Length of values (45) does not match length of index (1182)\n",
      "2025-04-11 12:51:46,392 - INFO - Processing dataset: COM\n",
      "2025-04-11 12:51:46,393 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx (sheet 0) with is_com=True\n",
      "2025-04-11 12:51:46,726 - INFO - Read 1776 rows with set columns: ['DATE', 'Excess return of equal-weight commodities portfolio', 'Excess spot return of equal-weight commodities portfolio', 'Interest rate adjusted carry of equal-weight commodities portfolio', 'Spot return of equal-weight commodities portfolio', 'Carry of equal-weight commodities portfolio', 'Excess return of long/short commodities portfolio', 'Excess spot return of long/short commodities portfolio', 'Interest rate adjusted carry of long/short commodities portfolio', 'Aggregate backwardation/contango', 'State of backwardation/contango', 'State of inflation']\n",
      "2025-04-11 12:51:46,734 - DEBUG - After dropping NA dates, 1776 rows remain\n",
      "2025-04-11 12:51:46,747 - DEBUG - Existing commodity dates sample (first 5): ['1903-11-30', '1887-07-29', '2000-03-31', '1967-05-31', '1912-04-30']\n",
      "2025-04-11 12:51:46,752 - INFO - No new rows to load into aqr_cmdty_factors from C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx (sheet 0)\n",
      "2025-04-11 12:51:46,754 - DEBUG - Input date range: 1877-02-28 00:00:00 to 2025-01-31 00:00:00\n",
      "2025-04-11 12:51:46,755 - DEBUG - Database date range: 1877-02-28 to 2025-01-31\n",
      "2025-04-11 12:51:46,756 - INFO - All data processing complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import VARCHAR, DATE, DECIMAL\n",
    "import logging\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(), logging.FileHandler('load_aqr_data.log')]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Database connection\n",
    "engine = create_engine(\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/CWA_Fund_Database\"\n",
    "    \"?driver=ODBC+Driver+18+for+SQL+Server&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "# File configurations with explicit headers\n",
    "data_files = {\n",
    "    \"BAB_multi\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx\",\n",
    "        \"sheets\": {\n",
    "            \"BAB\": {\n",
    "                \"sheet\": \"BAB Factors\",\n",
    "                \"start_row\": 19,\n",
    "                \"paper\": \"Betting Against Beta (Frazzini and Pedersen, 2014)\",\n",
    "                \"headers\": [\"DATE\", \"AUS\", \"AUT\", \"BEL\", \"CAN\", \"CHE\", \"DEU\", \"DNK\", \"ESP\", \"FIN\", \"FRA\", \"GBR\", \"GRC\", \"HKG\", \"IRL\", \"ISR\", \"ITA\", \"JPN\", \"NLD\", \"NOR\", \"NZL\", \"PRT\", \"SGP\", \"SWE\", \"USA\", \"Global\", \"Global Ex USA\", \"Europe\", \"North America\", \"Pacific\"],\n",
    "                \"columns\": {\"DATE\": \"DATE\", \"USA\": \"BAB\", \"Global\": \"BAB\", \"Global Ex USA\": \"BAB\"}\n",
    "            },\n",
    "            \"MKT\": {\n",
    "                \"sheet\": \"MKT\",\n",
    "                \"start_row\": 19,\n",
    "                \"paper\": \"Fama-French Factors\",\n",
    "                \"headers\": [\"DATE\", \"AUS\", \"AUT\", \"BEL\", \"CAN\", \"CHE\", \"DEU\", \"DNK\", \"ESP\", \"FIN\", \"FRA\", \"GBR\", \"GRC\", \"HKG\", \"IRL\", \"ISR\", \"ITA\", \"JPN\", \"NLD\", \"NOR\", \"NZL\", \"PRT\", \"SGP\", \"SWE\", \"USA\", \"Global\", \"Global Ex USA\", \"Europe\", \"North America\", \"Pacific\"],\n",
    "                \"columns\": {\"DATE\": \"DATE\", \"USA\": \"MKT\", \"Global\": \"MKT\", \"Global Ex USA\": \"MKT\"}\n",
    "            },\n",
    "            \"SMB\": {\n",
    "                \"sheet\": \"SMB\",\n",
    "                \"start_row\": 19,\n",
    "                \"paper\": \"Fama-French Factors\",\n",
    "                \"headers\": [\"DATE\", \"AUS\", \"AUT\", \"BEL\", \"CAN\", \"CHE\", \"DEU\", \"DNK\", \"ESP\", \"FIN\", \"FRA\", \"GBR\", \"GRC\", \"HKG\", \"IRL\", \"ISR\", \"ITA\", \"JPN\", \"NLD\", \"NOR\", \"NZL\", \"PRT\", \"SGP\", \"SWE\", \"USA\", \"Global\", \"Global Ex USA\", \"Europe\", \"North America\", \"Pacific\"],\n",
    "                \"columns\": {\"DATE\": \"DATE\", \"USA\": \"SMB\", \"Global\": \"SMB\", \"Global Ex USA\": \"SMB\"}\n",
    "            },\n",
    "            \"HML-FF\": {\n",
    "                \"sheet\": \"HML FF\",\n",
    "                \"start_row\": 19,\n",
    "                \"paper\": \"Fama-French Factors\",\n",
    "                \"headers\": [\"DATE\", \"AUS\", \"AUT\", \"BEL\", \"CAN\", \"CHE\", \"DEU\", \"DNK\", \"ESP\", \"FIN\", \"FRA\", \"GBR\", \"GRC\", \"HKG\", \"IRL\", \"ISR\", \"ITA\", \"JPN\", \"NLD\", \"NOR\", \"NZL\", \"PRT\", \"SGP\", \"SWE\", \"USA\", \"Global\", \"Global Ex USA\", \"Europe\", \"North America\", \"Pacific\"],\n",
    "                \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-FF\", \"Global\": \"HML-FF\", \"Global Ex USA\": \"HML-FF\"}\n",
    "            },\n",
    "            \"HML-D\": {\n",
    "                \"sheet\": \"HML Devil\",\n",
    "                \"start_row\": 19,\n",
    "                \"paper\": \"The Devil's in HML's Details\",\n",
    "                \"headers\": [\"DATE\", \"AUS\", \"AUT\", \"BEL\", \"CAN\", \"CHE\", \"DEU\", \"DNK\", \"ESP\", \"FIN\", \"FRA\", \"GBR\", \"GRC\", \"HKG\", \"IRL\", \"ISR\", \"ITA\", \"JPN\", \"NLD\", \"NOR\", \"NZL\", \"PRT\", \"SGP\", \"SWE\", \"USA\", \"Global\", \"Global Ex USA\", \"Europe\", \"North America\", \"Pacific\"],\n",
    "                \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-D\", \"Global\": \"HML-D\", \"Global Ex USA\": \"HML-D\"}\n",
    "            },\n",
    "            \"UMD\": {\n",
    "                \"sheet\": \"UMD\",\n",
    "                \"start_row\": 19,\n",
    "                \"paper\": \"On Persistence in Mutual Fund Performance\",\n",
    "                \"headers\": [\"DATE\", \"AUS\", \"AUT\", \"BEL\", \"CAN\", \"CHE\", \"DEU\", \"DNK\", \"ESP\", \"FIN\", \"FRA\", \"GBR\", \"GRC\", \"HKG\", \"IRL\", \"ISR\", \"ITA\", \"JPN\", \"NLD\", \"NOR\", \"NZL\", \"PRT\", \"SGP\", \"SWE\", \"USA\", \"Global\", \"Global Ex USA\", \"Europe\", \"North America\", \"Pacific\"],\n",
    "                \"columns\": {\"DATE\": \"DATE\", \"USA\": \"UMD\", \"Global\": \"UMD\", \"Global Ex USA\": \"UMD\"}\n",
    "            },\n",
    "            \"ME\": {\n",
    "                \"sheet\": \"ME(t-1)\",\n",
    "                \"start_row\": 19,\n",
    "                \"paper\": \"AQR Factors\",\n",
    "                \"headers\": [\"DATE\", \"AUT\", \"HKG\", \"ESP\", \"GBR\", \"ITA\", \"DEU\", \"DNK\", \"NZL\", \"NLD\", \"USA\", \"PRT\", \"BEL\", \"ISR\", \"GRC\", \"NOR\", \"SGP\", \"CHE\", \"IRL\", \"CAN\", \"FIN\", \"JPN\", \"SWE\", \"FRA\", \"AUS\", \"Global Ex USA\", \"Global\", \"Europe\", \"North America\", \"Pacific\"],\n",
    "                \"columns\": {\"DATE\": \"DATE\", \"USA\": \"ME\", \"Global\": \"ME\", \"Global Ex USA\": \"ME\"}\n",
    "            },\n",
    "            \"RF\": {\n",
    "                \"sheet\": \"RF\",\n",
    "                \"start_row\": 18,\n",
    "                \"paper\": None,\n",
    "                \"headers\": [\"DATE\", \"Risk Free Rate\"],\n",
    "                \"columns\": {\"DATE\": \"DATE\", \"Risk Free Rate\": \"RF\"}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"TSMOM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx\",\n",
    "        \"sheet\": \"TSMOM Factors\",\n",
    "        \"start_row\": 18,\n",
    "        \"paper\": \"Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)\",\n",
    "        \"headers\": [\"DATE\", \"TSMOM\", \"TSMOM^CM\", \"TSMOM^EQ\", \"TSMOM^FI\", \"TSMOM^FX\"],\n",
    "        \"columns\": {\n",
    "            \"DATE\": \"DATE\",\n",
    "            \"TSMOM\": \"TSM-MA\",\n",
    "            \"TSMOM^CM\": \"TSM-Com\",\n",
    "            \"TSMOM^EQ\": \"TSM-EQ\",\n",
    "            \"TSMOM^FI\": \"TSM-FI\",\n",
    "            \"TSMOM^FX\": \"TSM-FX\"\n",
    "        }\n",
    "    },\n",
    "    \"QMJ\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx\",\n",
    "        \"sheet\": \"10 Portfolios Formed on Quality\",\n",
    "        \"start_row\": 19,\n",
    "        \"paper\": \"Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)\",\n",
    "        \"headers\": [\"DATE\", \"P1 (low quality)\", \"P2\", \"P3\", \"P4\", \"P5\", \"P6\", \"P7\", \"P8\", \"P9\", \"P10 (high quality)\", \"P10-P1\", \"P1 (low quality).1\", \"P2.1\", \"P3.1\", \"P4.1\", \"P5.1\", \"P6.1\", \"P7.1\", \"P8.1\", \"P9.1\", \"P10 (high quality).1\", \"P10-P1.1\"],\n",
    "        \"columns\": {\n",
    "            \"DATE\": \"DATE\",\n",
    "            \"P1 (low quality)\": \"QMJ-P1-LQ\",\n",
    "            \"P2\": \"QMJ-P2\",\n",
    "            \"P3\": \"QMJ-P3\",\n",
    "            \"P4\": \"QMJ-P4\",\n",
    "            \"P5\": \"QMJ-P5\",\n",
    "            \"P6\": \"QMJ-P6\",\n",
    "            \"P7\": \"QMJ-P7\",\n",
    "            \"P8\": \"QMJ-P8\",\n",
    "            \"P9\": \"QMJ-P9\",\n",
    "            \"P10 (high quality)\": \"QMJ-P10-HQ\",\n",
    "            \"P10-P1\": \"QMJ\",\n",
    "            \"P1 (low quality).1\": \"QMJ-P1-LQ\",\n",
    "            \"P2.1\": \"QMJ-P2\",\n",
    "            \"P3.1\": \"QMJ-P3\",\n",
    "            \"P4.1\": \"QMJ-P4\",\n",
    "            \"P5.1\": \"QMJ-P5\",\n",
    "            \"P6.1\": \"QMJ-P6\",\n",
    "            \"P7.1\": \"QMJ-P7\",\n",
    "            \"P8.1\": \"QMJ-P8\",\n",
    "            \"P9.1\": \"QMJ-P9\",\n",
    "            \"P10 (high quality).1\": \"QMJ-P10-HQ\",\n",
    "            \"P10-P1.1\": \"QMJ\"\n",
    "        }\n",
    "    },\n",
    "    \"Century\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"start_row\": 18,\n",
    "        \"paper\": \"Century of Factor Premia Monthly-Ilmanen et al. (2021)\",\n",
    "        \"headers\": [\"DATE\", \"US Stock Selection Value\", \"US Stock Selection Momentum\", \"US Stock Selection Defensive\", \"US Stock Selection Multi-style\", \"Intl Stock Selection Value\", \"Intl Stock Selection Momentum\", \"Intl Stock Selection Defensive\", \"Intl Stock Selection Multi-style\", \"Equity indices Value\", \"Equity indices Momentum\", \"Equity indices Carry\", \"Equity indices Defensive\", \"Equity indices Multi-style\", \"Fixed income Value\", \"Fixed income Momentum\", \"Fixed income Carry\", \"Fixed income Defensive\", \"Fixed income Multi-style\", \"Currencies Value\", \"Currencies Momentum\", \"Currencies Carry\", \"Currencies Multi-style\", \"Commodities Value\", \"Commodities Momentum\", \"Commodities Carry\", \"Commodities Multi-style\", \"All Stock Selection Value\", \"All Stock Selection Momentum\", \"All Stock Selection Defensive\", \"All Stock Selection Multi-style\", \"All Macro Value\", \"All Macro Momentum\", \"All Macro Carry\", \"All Macro Defensive\", \"All Macro Multi-style\", \"All asset classes Value\", \"All asset classes Momentum\", \"All asset classes Carry\", \"All asset classes Defensive\", \"All asset classes Multi-style\", \"Equity indices Market\", \"Fixed income Market\", \"Commodities Market\", \"All Macro Market\"],\n",
    "        \"columns\": {\n",
    "            \"DATE\": \"DATE\",\n",
    "            \"US Stock Selection Value\": \"HML-FF-US\", \"US Stock Selection Momentum\": \"UMD-US\", \n",
    "            \"US Stock Selection Defensive\": \"BAB-US\", \"US Stock Selection Multi-style\": \"Multi-style-US\",\n",
    "            \"Intl Stock Selection Value\": \"HML-FF-Intl\", \"Intl Stock Selection Momentum\": \"UMD-Intl\", \n",
    "            \"Intl Stock Selection Defensive\": \"BAB-Intl\", \"Intl Stock Selection Multi-style\": \"Multi-style-Intl\",\n",
    "            \"Equity indices Value\": \"HML-Equity\", \"Equity indices Momentum\": \"UMD-Equity\", \n",
    "            \"Equity indices Carry\": \"Carry-Equity\", \"Equity indices Defensive\": \"BAB-Equity\", \n",
    "            \"Equity indices Multi-style\": \"Multi-style-Equity\",\n",
    "            \"Fixed income Value\": \"HML-FI\", \"Fixed income Momentum\": \"UMD-FI\", \n",
    "            \"Fixed income Carry\": \"Carry-FI\", \"Fixed income Defensive\": \"BAB-FI\", \n",
    "            \"Fixed income Multi-style\": \"Multi-style-FI\",\n",
    "            \"Currencies Value\": \"HML-FX\", \"Currencies Momentum\": \"UMD-FX\", \n",
    "            \"Currencies Carry\": \"Carry-FX\", \"Currencies Multi-style\": \"Multi-style-FX\",\n",
    "            \"Commodities Value\": \"HML-COM\", \"Commodities Momentum\": \"UMD-COM\", \n",
    "            \"Commodities Carry\": \"Carry-COM\", \"Commodities Multi-style\": \"Multi-style-COM\",\n",
    "            \"All Stock Selection Value\": \"HML-All-SS\", \"All Stock Selection Momentum\": \"UMD-All-SS\", \n",
    "            \"All Stock Selection Defensive\": \"BAB-All-SS\", \"All Stock Selection Multi-style\": \"Multi-style-All-SS\",\n",
    "            \"All Macro Value\": \"HML-All-Macro\", \"All Macro Momentum\": \"UMD-All-Macro\", \n",
    "            \"All Macro Carry\": \"Carry-All-Macro\", \"All Macro Defensive\": \"BAB-All-Macro\", \n",
    "            \"All Macro Multi-style\": \"Multi-style-All-Macro\",\n",
    "            \"All asset classes Value\": \"HML-All\", \"All asset classes Momentum\": \"UMD-All\", \n",
    "            \"All asset classes Carry\": \"Carry-All\", \"All asset classes Defensive\": \"BAB-All\", \n",
    "            \"All asset classes Multi-style\": \"Multi-style-All\",\n",
    "            \"Equity indices Market\": \"MKT-Equity\", \"Fixed income Market\": \"MKT-FI\", \n",
    "            \"Commodities Market\": \"MKT-COM\", \"All Macro Market\": \"MKT-All-Macro\"\n",
    "        }\n",
    "    },\n",
    "    \"COM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"start_row\": 11,\n",
    "        \"paper\": \"Commodities for the Long Run\",\n",
    "        \"headers\": [\"DATE\", \"Excess return of equal-weight commodities portfolio\", \"Excess spot return of equal-weight commodities portfolio\", \"Interest rate adjusted carry of equal-weight commodities portfolio\", \"Spot return of equal-weight commodities portfolio\", \"Carry of equal-weight commodities portfolio\", \"Excess return of long/short commodities portfolio\", \"Excess spot return of long/short commodities portfolio\", \"Interest rate adjusted carry of long/short commodities portfolio\", \"Aggregate backwardation/contango\", \"State of backwardation/contango\", \"State of inflation\"],\n",
    "        \"columns\": {\n",
    "            \"DATE\": \"date\",\n",
    "            \"Excess return of equal-weight commodities portfolio\": \"excess_return_eqwt\",\n",
    "            \"Excess spot return of equal-weight commodities portfolio\": \"excess_spot_return_eqwt\",\n",
    "            \"Interest rate adjusted carry of equal-weight commodities portfolio\": \"ir_adjusted_carry_eqwt\",\n",
    "            \"Spot return of equal-weight commodities portfolio\": \"spot_return_eqwt\",\n",
    "            \"Carry of equal-weight commodities portfolio\": \"carry_eqwt\",\n",
    "            \"Excess return of long/short commodities portfolio\": \"excess_return_long_short\",\n",
    "            \"Excess spot return of long/short commodities portfolio\": \"excess_spot_return_long_short\",\n",
    "            \"Interest rate adjusted carry of long/short commodities portfolio\": \"ir_adjusted_carry_long_short\",\n",
    "            \"Aggregate backwardation/contango\": \"aggregate_backwardation_contango\",\n",
    "            \"State of backwardation/contango\": \"state_backwardation_contango\",\n",
    "            \"State of inflation\": \"state_inflation\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "def process_factors(file_config, sheet=0, is_com=False, parent_path=None):\n",
    "    file_path = parent_path if parent_path else file_config['path']\n",
    "    logger.info(f\"Processing {file_path} (sheet {sheet}) with is_com={is_com}\")\n",
    "    try:\n",
    "        # Read Excel without headers, then set them\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet, header=None, skiprows=file_config['start_row'])\n",
    "        df.columns = file_config['headers']\n",
    "        logger.info(f\"Read {len(df)} rows with set columns: {list(df.columns)}\")\n",
    "        \n",
    "        if is_com:\n",
    "            expected_cols = list(file_config['columns'].keys())\n",
    "            df = df[expected_cols]\n",
    "            df.columns = [file_config['columns'][col] for col in df.columns]\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            df['associated_paper'] = file_config['paper'] if file_config['paper'] is not None else 'Unknown'\n",
    "            df = df.dropna(subset=['date'])\n",
    "            logger.debug(f\"After dropping NA dates, {len(df)} rows remain\")\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                existing = pd.read_sql(\"SELECT date FROM aqr_cmdty_factors\", connection)\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(existing['date'])\n",
    "                logger.debug(f\"Existing commodity dates sample (first 5): {list(existing_keys)[:5]}\")\n",
    "            \n",
    "            df['date_str'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_new = df[~df['date_str'].isin(existing_keys)].drop(columns=['date_str'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                for chunk in [df_new[i:i+10000] for i in range(0, len(df_new), 10000)]:\n",
    "                    chunk.to_sql(\n",
    "                        'aqr_cmdty_factors',\n",
    "                        engine,\n",
    "                        if_exists='append',\n",
    "                        index=False,\n",
    "                        dtype={\n",
    "                            'date': DATE,\n",
    "                            'excess_return_eqwt': DECIMAL(15, 6),\n",
    "                            'excess_spot_return_eqwt': DECIMAL(15, 6),\n",
    "                            'ir_adjusted_carry_eqwt': DECIMAL(15, 6),\n",
    "                            'spot_return_eqwt': DECIMAL(15, 6),\n",
    "                            'carry_eqwt': DECIMAL(15, 6),\n",
    "                            'excess_return_long_short': DECIMAL(15, 6),\n",
    "                            'excess_spot_return_long_short': DECIMAL(15, 6),\n",
    "                            'ir_adjusted_carry_long_short': DECIMAL(15, 6),\n",
    "                            'aggregate_backwardation_contango': DECIMAL(15, 6),\n",
    "                            'state_backwardation_contango': VARCHAR(50),\n",
    "                            'state_inflation': VARCHAR(50),\n",
    "                            'associated_paper': VARCHAR(100)\n",
    "                        }\n",
    "                    )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into aqr_cmdty_factors from {file_path} (sheet {sheet})\")\n",
    "            else:\n",
    "                logger.info(f\"No new rows to load into aqr_cmdty_factors from {file_path} (sheet {sheet})\")\n",
    "                logger.debug(f\"Input date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "                logger.debug(f\"Database date range: {existing['date'].min() if not existing.empty else 'N/A'} to {existing['date'].max() if not existing.empty else 'N/A'}\")\n",
    "        else:\n",
    "            date_col = 'DATE'\n",
    "            orig_cols = df.columns.tolist()\n",
    "            if 'columns' in file_config:\n",
    "                expected_cols = list(file_config['columns'].keys())\n",
    "                valid_cols = [col for col in expected_cols if col in df.columns]\n",
    "                if not valid_cols:\n",
    "                    logger.error(f\"No valid columns found in {file_path} (sheet {sheet}). Skipping.\")\n",
    "                    return\n",
    "                if date_col not in valid_cols:\n",
    "                    valid_cols.append(date_col)\n",
    "                df = df[valid_cols]\n",
    "                new_columns = ['date' if col == date_col else file_config['columns'].get(col, col) for col in df.columns]\n",
    "                df.columns = new_columns\n",
    "            \n",
    "            logger.info(f\"Columns after renaming: {list(df.columns)}\")\n",
    "            \n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            invalid_dates = df['date'].isna().sum()\n",
    "            if invalid_dates > 0:\n",
    "                logger.warning(f\"Dropped {invalid_dates} rows due to invalid dates in {file_path} (sheet {sheet})\")\n",
    "            df = df.dropna(subset=['date'])\n",
    "            logger.debug(f\"After dropping NA dates, {len(df)} rows remain\")\n",
    "            \n",
    "            # Assign region before melting\n",
    "            file_path_for_check = parent_path if parent_path else file_config.get('path', '')\n",
    "            if 'TSMOM' in file_path_for_check:\n",
    "                df['region'] = \"Global\"\n",
    "                df['asset_class'] = df.columns.map({\n",
    "                    \"date\": None,\n",
    "                    \"TSM-MA\": \"Multi-Asset\",\n",
    "                    \"TSM-Com\": \"Commodities\",\n",
    "                    \"TSM-EQ\": \"Equity\",\n",
    "                    \"TSM-FI\": \"Fixed Income\",\n",
    "                    \"TSM-FX\": \"Currencies\"\n",
    "                }).fillna(\"Unknown\")\n",
    "            elif 'Quality Minus Junk' in file_path_for_check:\n",
    "                df['region'] = df['date'].apply(lambda x: \"USA\" if x < pd.Timestamp(\"1989-07-31\") else \"Global\")\n",
    "                df['asset_class'] = \"Equity\"\n",
    "            elif 'Century' in file_path_for_check:\n",
    "                df['region'] = df.columns.map(lambda x: 'US' if 'US' in x else 'Intl' if 'Intl' in x else 'Global').fillna(\"Global\")\n",
    "                df['asset_class'] = df.columns.str.extract(\n",
    "                    '(Stock Selection|Equity indices|Fixed income|Currencies|Commodities|All Macro|All asset classes)'\n",
    "                )[0].fillna('Equity')\n",
    "            else:  # BAB_multi\n",
    "                df['region'] = df.columns.map({\n",
    "                    \"DATE\": None,\n",
    "                    \"USA\": \"USA\",\n",
    "                    \"Global\": \"Global\",\n",
    "                    \"Global Ex USA\": \"Intl\",\n",
    "                    \"Risk Free Rate\": \"USA\"\n",
    "                }).fillna(None)\n",
    "                df['asset_class'] = \"Equity\" if \"Risk Free Rate\" not in df.columns else \"Fixed Income\"\n",
    "            \n",
    "            value_vars = [col for col in df.columns if col != 'date' and col not in ['region', 'asset_class']]\n",
    "            df_long = df.melt(id_vars=['date', 'region', 'asset_class'], value_vars=value_vars, var_name='factor', value_name='value')\n",
    "            df_long = df_long.dropna(subset=['value', 'date'])\n",
    "            logger.debug(f\"Rows after melting and dropping NA: {len(df_long)}\")\n",
    "            \n",
    "            df_long['associated_paper'] = file_config['paper'] if file_config['paper'] is not None else 'Unknown'\n",
    "            df_long = df_long[['factor', 'date', 'associated_paper', 'value', 'region', 'asset_class']]\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                existing = pd.read_sql(\n",
    "                    \"SELECT factor, date, associated_paper, region FROM factor_returns\",\n",
    "                    connection\n",
    "                )\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(tuple(row) for row in existing[['factor', 'date', 'associated_paper', 'region']].values)\n",
    "                logger.debug(f\"Existing keys sample (first 5): {list(existing_keys)[:5]}\")\n",
    "                logger.debug(f\"Total existing keys: {len(existing_keys)}\")\n",
    "            \n",
    "            df_long['date_str'] = df_long['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_long['key'] = df_long.apply(\n",
    "                lambda row: (row['factor'], row['date_str'], row['associated_paper'], row['region'] if pd.notna(row['region']) else 'Unknown'), axis=1\n",
    "            )\n",
    "            logger.debug(f\"New keys sample (first 5): {df_long['key'].head().tolist()}\")\n",
    "            df_new = df_long[~df_long['key'].isin(existing_keys)].drop(columns=['key', 'date_str'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                logger.debug(f\"New rows to insert: {len(df_new)}. Sample (first 5): {df_new[['factor', 'date', 'region']].head().to_dict('records')}\")\n",
    "                for chunk in [df_new[i:i+10000] for i in range(0, len(df_new), 10000)]:\n",
    "                    chunk.to_sql(\n",
    "                        'factor_returns',\n",
    "                        engine,\n",
    "                        if_exists='append',\n",
    "                        index=False,\n",
    "                        dtype={\n",
    "                            'factor': VARCHAR(50),\n",
    "                            'date': DATE,\n",
    "                            'associated_paper': VARCHAR(100),\n",
    "                            'value': DECIMAL(15, 6),\n",
    "                            'region': VARCHAR(50),\n",
    "                            'asset_class': VARCHAR(50)\n",
    "                        }\n",
    "                    )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into factor_returns from {file_path} (sheet {sheet})\")\n",
    "            else:\n",
    "                logger.info(f\"No new rows to load into factor_returns from {file_path} (sheet {sheet})\")\n",
    "                logger.debug(f\"Input date range: {df_long['date'].min()} to {df_long['date'].max()}\")\n",
    "                logger.debug(f\"Database date range: {existing['date'].min() if not existing.empty else 'N/A'} to {existing['date'].max() if not existing.empty else 'N/A'}\")\n",
    "            \n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(f\"File not found: {file_path} (sheet {sheet}): {str(e)}\")\n",
    "    except pd.errors.ParserError as e:\n",
    "        logger.error(f\"Error parsing Excel file {file_path} (sheet {sheet}): {str(e)}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error processing {file_path} (sheet {sheet}): {type(e).__name__}: {str(e)}\")\n",
    "\n",
    "# Main loop\n",
    "for key, config in data_files.items():\n",
    "    logger.info(f\"Processing dataset: {key}\")\n",
    "    if key == \"BAB_multi\":\n",
    "        for subkey, subconfig in config['sheets'].items():\n",
    "            process_factors(subconfig, sheet=subconfig['sheet'], parent_path=config['path'])\n",
    "    else:\n",
    "        is_com = (key == \"COM\")\n",
    "        process_factors(config, sheet=config['sheet'], is_com=is_com)\n",
    "\n",
    "logger.info(\"All data processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c46d2680-d92f-4032-8144-112b7914ef07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:07:25,108 - INFO - Processing dataset: BAB_multi\n",
      "2025-04-11 13:07:25,110 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet BAB Factors) with is_com=False\n",
      "2025-04-11 13:07:26,145 - INFO - Read 1129 rows with set columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-11 13:07:26,149 - INFO - Columns after renaming: ['date', 'BAB', 'BAB', 'BAB']\n",
      "2025-04-11 13:07:26,174 - DEBUG - After dropping NA dates, 1129 rows remain\n",
      "2025-04-11 13:07:26,205 - DEBUG - Rows after melting and dropping NA: 2039\n",
      "2025-04-11 13:07:26,545 - DEBUG - Existing keys sample (first 5): []\n",
      "2025-04-11 13:07:26,546 - DEBUG - Total existing keys: 0\n",
      "2025-04-11 13:07:26,567 - DEBUG - New keys sample (first 5): [('BAB', '1930-12-31', 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Unknown'), ('BAB', '1931-01-31', 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Unknown'), ('BAB', '1931-02-28', 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Unknown'), ('BAB', '1931-03-31', 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Unknown'), ('BAB', '1931-04-30', 'Betting Against Beta (Frazzini and Pedersen, 2014)', 'Unknown')]\n",
      "2025-04-11 13:07:26,570 - DEBUG - New rows to insert: 2039. Sample (first 5): [{'factor': 'BAB', 'date': Timestamp('1930-12-31 00:00:00'), 'region': nan}, {'factor': 'BAB', 'date': Timestamp('1931-01-31 00:00:00'), 'region': nan}, {'factor': 'BAB', 'date': Timestamp('1931-02-28 00:00:00'), 'region': nan}, {'factor': 'BAB', 'date': Timestamp('1931-03-31 00:00:00'), 'region': nan}, {'factor': 'BAB', 'date': Timestamp('1931-04-30 00:00:00'), 'region': nan}]\n",
      "2025-04-11 13:07:28,370 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet BAB Factors): IntegrityError: (pyodbc.IntegrityError) ('23000', \"[23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Violation of PRIMARY KEY constraint 'PK__factor_r__C3CBC7054E79A6D5'. Cannot insert duplicate key in object 'dbo.factor_returns'. The duplicate key value is (BAB, 1987-02-28, Betting Against Beta (Frazzini and Pedersen, 2014)). (2627) (SQLExecDirectW); [23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]The statement has been terminated. (3621)\")\n",
      "[SQL: INSERT INTO factor_returns (factor, date, associated_paper, value, region, asset_class) VALUES (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ... 6723 characters truncated ... , (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?)]\n",
      "[parameters: ('BAB', datetime.datetime(2018, 3, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 0.024726359719057713, None, 'Equity', 'BAB', datetime.datetime(2018, 4, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 0.0007799553393408837, None, 'Equity', 'BAB', datetime.datetime(2018, 5, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 0.0061733720885607715, None, 'Equity', 'BAB', datetime.datetime(2018, 6, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 0.023681918622375155, None, 'Equity', 'BAB', datetime.datetime(2018, 7, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', -0.003681432428082633, None, 'Equity', 'BAB', datetime.datetime(2018, 8, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', -0.012114392481366903, None, 'Equity', 'BAB', datetime.datetime(2018, 9, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', -0.006209095953888497, None, 'Equity', 'BAB', datetime.datetime(2018, 10, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 0.02111187283759784, None, 'Equity', 'BAB', datetime.datetime(2018, 11, 30, 0, 0) ... 1994 parameters truncated ... None, 'Equity', 'BAB', datetime.datetime(2008, 9, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', -0.04015145002280483, None, 'Equity', 'BAB', datetime.datetime(2008, 10, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', -0.06507843668705648, None, 'Equity', 'BAB', datetime.datetime(2008, 11, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', -0.025706387072742018, None, 'Equity', 'BAB', datetime.datetime(2008, 12, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', -0.04223042725213571, None, 'Equity', 'BAB', datetime.datetime(2009, 1, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', 0.053884771313794676, None, 'Equity', 'BAB', datetime.datetime(2009, 2, 28, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', -0.0013600102720203353, None, 'Equity', 'BAB', datetime.datetime(2009, 3, 31, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', -0.043388589580733355, None, 'Equity', 'BAB', datetime.datetime(2009, 4, 30, 0, 0), 'Betting Against Beta (Frazzini and Pedersen, 2014)', -0.07292510221661865, None, 'Equity')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-04-11 13:07:28,371 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet MKT) with is_com=False\n",
      "2025-04-11 13:07:29,472 - INFO - Read 1182 rows with set columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-11 13:07:29,476 - INFO - Columns after renaming: ['date', 'MKT', 'MKT', 'MKT']\n",
      "2025-04-11 13:07:29,495 - DEBUG - After dropping NA dates, 1182 rows remain\n",
      "2025-04-11 13:07:29,509 - DEBUG - Rows after melting and dropping NA: 2166\n",
      "2025-04-11 13:07:29,570 - DEBUG - Existing keys sample (first 5): [('BAB', '1989-02-28', 'Betting Against Beta (Frazzini and Pedersen, 2014)', None), ('BAB', '2003-09-30', 'Betting Against Beta (Frazzini and Pedersen, 2014)', None), ('BAB', '1946-09-30', 'Betting Against Beta (Frazzini and Pedersen, 2014)', None), ('BAB', '1954-04-30', 'Betting Against Beta (Frazzini and Pedersen, 2014)', None), ('BAB', '1996-06-30', 'Betting Against Beta (Frazzini and Pedersen, 2014)', None)]\n",
      "2025-04-11 13:07:29,573 - DEBUG - Total existing keys: 1047\n",
      "2025-04-11 13:07:29,734 - DEBUG - New keys sample (first 5): [('MKT', '1926-07-31', 'Fama-French Factors', 'Unknown'), ('MKT', '1926-08-31', 'Fama-French Factors', 'Unknown'), ('MKT', '1926-09-30', 'Fama-French Factors', 'Unknown'), ('MKT', '1926-10-31', 'Fama-French Factors', 'Unknown'), ('MKT', '1926-11-30', 'Fama-French Factors', 'Unknown')]\n",
      "2025-04-11 13:07:29,761 - DEBUG - New rows to insert: 2166. Sample (first 5): [{'factor': 'MKT', 'date': Timestamp('1926-07-31 00:00:00'), 'region': nan}, {'factor': 'MKT', 'date': Timestamp('1926-08-31 00:00:00'), 'region': nan}, {'factor': 'MKT', 'date': Timestamp('1926-09-30 00:00:00'), 'region': nan}, {'factor': 'MKT', 'date': Timestamp('1926-10-31 00:00:00'), 'region': nan}, {'factor': 'MKT', 'date': Timestamp('1926-11-30 00:00:00'), 'region': nan}]\n",
      "2025-04-11 13:07:31,462 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet MKT): IntegrityError: (pyodbc.IntegrityError) ('23000', \"[23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Violation of PRIMARY KEY constraint 'PK__factor_r__C3CBC7054E79A6D5'. Cannot insert duplicate key in object 'dbo.factor_returns'. The duplicate key value is (MKT, 1984-01-31, Fama-French Factors). (2627) (SQLExecDirectW); [23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]The statement has been terminated. (3621)\")\n",
      "[SQL: INSERT INTO factor_returns (factor, date, associated_paper, value, region, asset_class) VALUES (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ... 6723 characters truncated ... , (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?)]\n",
      "[parameters: ('MKT', datetime.datetime(2013, 10, 31, 0, 0), 'Fama-French Factors', 0.040744699841014996, None, 'Equity', 'MKT', datetime.datetime(2013, 11, 30, 0, 0), 'Fama-French Factors', 0.02651336571903575, None, 'Equity', 'MKT', datetime.datetime(2013, 12, 31, 0, 0), 'Fama-French Factors', 0.026990113917166176, None, 'Equity', 'MKT', datetime.datetime(2014, 1, 31, 0, 0), 'Fama-French Factors', -0.030288442319910888, None, 'Equity', 'MKT', datetime.datetime(2014, 2, 28, 0, 0), 'Fama-French Factors', 0.04681951057275386, None, 'Equity', 'MKT', datetime.datetime(2014, 3, 31, 0, 0), 'Fama-French Factors', 0.004226895440435092, None, 'Equity', 'MKT', datetime.datetime(2014, 4, 30, 0, 0), 'Fama-French Factors', 0.0010398803443404372, None, 'Equity', 'MKT', datetime.datetime(2014, 5, 31, 0, 0), 'Fama-French Factors', 0.020276557704712726, None, 'Equity', 'MKT', datetime.datetime(2014, 6, 30, 0, 0) ... 1994 parameters truncated ... None, 'Equity', 'MKT', datetime.datetime(2001, 3, 31, 0, 0), 'Fama-French Factors', -0.07494531599005091, None, 'Equity', 'MKT', datetime.datetime(2001, 4, 30, 0, 0), 'Fama-French Factors', 0.07508485497454191, None, 'Equity', 'MKT', datetime.datetime(2001, 5, 31, 0, 0), 'Fama-French Factors', -0.010474514368770739, None, 'Equity', 'MKT', datetime.datetime(2001, 6, 30, 0, 0), 'Fama-French Factors', -0.02931420942914372, None, 'Equity', 'MKT', datetime.datetime(2001, 7, 31, 0, 0), 'Fama-French Factors', -0.026175716039357342, None, 'Equity', 'MKT', datetime.datetime(2001, 8, 31, 0, 0), 'Fama-French Factors', -0.0468346643449563, None, 'Equity', 'MKT', datetime.datetime(2001, 9, 30, 0, 0), 'Fama-French Factors', -0.09906583041804193, None, 'Equity', 'MKT', datetime.datetime(2001, 10, 31, 0, 0), 'Fama-French Factors', 0.026689513188864582, None, 'Equity')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-04-11 13:07:31,463 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet SMB) with is_com=False\n",
      "2025-04-11 13:07:32,599 - INFO - Read 1181 rows with set columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-11 13:07:32,611 - INFO - Columns after renaming: ['date', 'SMB', 'SMB', 'SMB']\n",
      "2025-04-11 13:07:32,628 - DEBUG - After dropping NA dates, 1181 rows remain\n",
      "2025-04-11 13:07:32,639 - DEBUG - Rows after melting and dropping NA: 2151\n",
      "2025-04-11 13:07:32,745 - DEBUG - Existing keys sample (first 5): [('MKT', '1955-11-30', 'Fama-French Factors', None), ('MKT', '2012-11-30', 'Fama-French Factors', None), ('MKT', '1968-04-30', 'Fama-French Factors', None), ('MKT', '1956-10-31', 'Fama-French Factors', None), ('BAB', '1945-04-30', 'Betting Against Beta (Frazzini and Pedersen, 2014)', None)]\n",
      "2025-04-11 13:07:32,746 - DEBUG - Total existing keys: 2094\n",
      "2025-04-11 13:07:32,871 - DEBUG - New keys sample (first 5): [('SMB', '1926-07-31', 'Fama-French Factors', 'Unknown'), ('SMB', '1926-08-31', 'Fama-French Factors', 'Unknown'), ('SMB', '1926-09-30', 'Fama-French Factors', 'Unknown'), ('SMB', '1926-10-31', 'Fama-French Factors', 'Unknown'), ('SMB', '1926-11-30', 'Fama-French Factors', 'Unknown')]\n",
      "2025-04-11 13:07:32,897 - DEBUG - New rows to insert: 2151. Sample (first 5): [{'factor': 'SMB', 'date': Timestamp('1926-07-31 00:00:00'), 'region': nan}, {'factor': 'SMB', 'date': Timestamp('1926-08-31 00:00:00'), 'region': nan}, {'factor': 'SMB', 'date': Timestamp('1926-09-30 00:00:00'), 'region': nan}, {'factor': 'SMB', 'date': Timestamp('1926-10-31 00:00:00'), 'region': nan}, {'factor': 'SMB', 'date': Timestamp('1926-11-30 00:00:00'), 'region': nan}]\n",
      "2025-04-11 13:07:34,377 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet SMB): IntegrityError: (pyodbc.IntegrityError) ('23000', \"[23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Violation of PRIMARY KEY constraint 'PK__factor_r__C3CBC7054E79A6D5'. Cannot insert duplicate key in object 'dbo.factor_returns'. The duplicate key value is (SMB, 1984-07-31, Fama-French Factors). (2627) (SQLExecDirectW); [23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]The statement has been terminated. (3621)\")\n",
      "[SQL: INSERT INTO factor_returns (factor, date, associated_paper, value, region, asset_class) VALUES (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ... 6723 characters truncated ... , (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?)]\n",
      "[parameters: ('SMB', datetime.datetime(2013, 10, 31, 0, 0), 'Fama-French Factors', -0.015588468883991955, None, 'Equity', 'SMB', datetime.datetime(2013, 11, 30, 0, 0), 'Fama-French Factors', 0.01065483414815262, None, 'Equity', 'SMB', datetime.datetime(2013, 12, 31, 0, 0), 'Fama-French Factors', -0.0010166842544921284, None, 'Equity', 'SMB', datetime.datetime(2014, 1, 31, 0, 0), 'Fama-French Factors', 0.007428787828202504, None, 'Equity', 'SMB', datetime.datetime(2014, 2, 28, 0, 0), 'Fama-French Factors', 0.0018911095129556061, None, 'Equity', 'SMB', datetime.datetime(2014, 3, 31, 0, 0), 'Fama-French Factors', -0.007537377322076746, None, 'Equity', 'SMB', datetime.datetime(2014, 4, 30, 0, 0), 'Fama-French Factors', -0.036172693683151236, None, 'Equity', 'SMB', datetime.datetime(2014, 5, 31, 0, 0), 'Fama-French Factors', -0.01391237448379029, None, 'Equity', 'SMB', datetime.datetime(2014, 6, 30, 0, 0) ... 1994 parameters truncated ... None, 'Equity', 'SMB', datetime.datetime(2001, 10, 31, 0, 0), 'Fama-French Factors', 0.04437886535965284, None, 'Equity', 'SMB', datetime.datetime(2001, 11, 30, 0, 0), 'Fama-French Factors', -0.0007389383728429238, None, 'Equity', 'SMB', datetime.datetime(2001, 12, 31, 0, 0), 'Fama-French Factors', 0.023116268340654826, None, 'Equity', 'SMB', datetime.datetime(2002, 1, 31, 0, 0), 'Fama-French Factors', 0.021369157183437584, None, 'Equity', 'SMB', datetime.datetime(2002, 2, 28, 0, 0), 'Fama-French Factors', -0.010535330167321437, None, 'Equity', 'SMB', datetime.datetime(2002, 3, 31, 0, 0), 'Fama-French Factors', 0.023330221817805488, None, 'Equity', 'SMB', datetime.datetime(2002, 4, 30, 0, 0), 'Fama-French Factors', 0.034445536190484724, None, 'Equity', 'SMB', datetime.datetime(2002, 5, 31, 0, 0), 'Fama-French Factors', -0.010465487612244091, None, 'Equity')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-04-11 13:07:34,378 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet HML FF) with is_com=False\n",
      "2025-04-11 13:07:35,487 - INFO - Read 1181 rows with set columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-11 13:07:35,490 - INFO - Columns after renaming: ['date', 'HML-FF', 'HML-FF', 'HML-FF']\n",
      "2025-04-11 13:07:35,515 - DEBUG - After dropping NA dates, 1181 rows remain\n",
      "2025-04-11 13:07:35,542 - DEBUG - Rows after melting and dropping NA: 2151\n",
      "2025-04-11 13:07:35,723 - DEBUG - Existing keys sample (first 5): [('SMB', '2000-06-30', 'Fama-French Factors', None), ('SMB', '2002-01-31', 'Fama-French Factors', None), ('MKT', '1955-11-30', 'Fama-French Factors', None), ('MKT', '2012-11-30', 'Fama-French Factors', None), ('MKT', '1968-04-30', 'Fama-French Factors', None)]\n",
      "2025-04-11 13:07:35,724 - DEBUG - Total existing keys: 3141\n",
      "2025-04-11 13:07:35,805 - DEBUG - New keys sample (first 5): [('HML-FF', '1926-07-31', 'Fama-French Factors', 'Unknown'), ('HML-FF', '1926-08-31', 'Fama-French Factors', 'Unknown'), ('HML-FF', '1926-09-30', 'Fama-French Factors', 'Unknown'), ('HML-FF', '1926-10-31', 'Fama-French Factors', 'Unknown'), ('HML-FF', '1926-11-30', 'Fama-French Factors', 'Unknown')]\n",
      "2025-04-11 13:07:35,825 - DEBUG - New rows to insert: 2151. Sample (first 5): [{'factor': 'HML-FF', 'date': Timestamp('1926-07-31 00:00:00'), 'region': nan}, {'factor': 'HML-FF', 'date': Timestamp('1926-08-31 00:00:00'), 'region': nan}, {'factor': 'HML-FF', 'date': Timestamp('1926-09-30 00:00:00'), 'region': nan}, {'factor': 'HML-FF', 'date': Timestamp('1926-10-31 00:00:00'), 'region': nan}, {'factor': 'HML-FF', 'date': Timestamp('1926-11-30 00:00:00'), 'region': nan}]\n",
      "2025-04-11 13:07:38,341 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet HML FF): IntegrityError: (pyodbc.IntegrityError) ('23000', \"[23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Violation of PRIMARY KEY constraint 'PK__factor_r__C3CBC7054E79A6D5'. Cannot insert duplicate key in object 'dbo.factor_returns'. The duplicate key value is (HML-FF, 1984-07-31, Fama-French Factors). (2627) (SQLExecDirectW); [23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]The statement has been terminated. (3621)\")\n",
      "[SQL: INSERT INTO factor_returns (factor, date, associated_paper, value, region, asset_class) VALUES (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ... 6723 characters truncated ... , (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?)]\n",
      "[parameters: ('HML-FF', datetime.datetime(2013, 10, 31, 0, 0), 'Fama-French Factors', 0.008126275592922588, None, 'Equity', 'HML-FF', datetime.datetime(2013, 11, 30, 0, 0), 'Fama-French Factors', -0.006213918038464201, None, 'Equity', 'HML-FF', datetime.datetime(2013, 12, 31, 0, 0), 'Fama-French Factors', 0.0005835877582695357, None, 'Equity', 'HML-FF', datetime.datetime(2014, 1, 31, 0, 0), 'Fama-French Factors', -0.009251287117120475, None, 'Equity', 'HML-FF', datetime.datetime(2014, 2, 28, 0, 0), 'Fama-French Factors', -0.006413256078610271, None, 'Equity', 'HML-FF', datetime.datetime(2014, 3, 31, 0, 0), 'Fama-French Factors', 0.03169030874251517, None, 'Equity', 'HML-FF', datetime.datetime(2014, 4, 30, 0, 0), 'Fama-French Factors', 0.01364073711053479, None, 'Equity', 'HML-FF', datetime.datetime(2014, 5, 31, 0, 0), 'Fama-French Factors', -0.0026271462733967656, None, 'Equity', 'HML-FF', datetime.datetime(2014, 6, 30, 0, 0) ... 1994 parameters truncated ... None, 'Equity', 'HML-FF', datetime.datetime(2001, 10, 31, 0, 0), 'Fama-French Factors', -0.043722538653486104, None, 'Equity', 'HML-FF', datetime.datetime(2001, 11, 30, 0, 0), 'Fama-French Factors', -0.01613061192627387, None, 'Equity', 'HML-FF', datetime.datetime(2001, 12, 31, 0, 0), 'Fama-French Factors', 0.011513742700095602, None, 'Equity', 'HML-FF', datetime.datetime(2002, 1, 31, 0, 0), 'Fama-French Factors', 0.03356734390736426, None, 'Equity', 'HML-FF', datetime.datetime(2002, 2, 28, 0, 0), 'Fama-French Factors', 0.024212788104121793, None, 'Equity', 'HML-FF', datetime.datetime(2002, 3, 31, 0, 0), 'Fama-French Factors', 0.006571864421787964, None, 'Equity', 'HML-FF', datetime.datetime(2002, 4, 30, 0, 0), 'Fama-French Factors', 0.05046657745144843, None, 'Equity', 'HML-FF', datetime.datetime(2002, 5, 31, 0, 0), 'Fama-French Factors', 0.03897095652699924, None, 'Equity')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-04-11 13:07:38,342 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet HML Devil) with is_com=False\n",
      "2025-04-11 13:07:39,289 - INFO - Read 1182 rows with set columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-11 13:07:39,300 - INFO - Columns after renaming: ['date', 'HML-D', 'HML-D', 'HML-D']\n",
      "2025-04-11 13:07:39,315 - DEBUG - After dropping NA dates, 1182 rows remain\n",
      "2025-04-11 13:07:39,332 - DEBUG - Rows after melting and dropping NA: 2154\n",
      "2025-04-11 13:07:39,434 - DEBUG - Existing keys sample (first 5): [('HML-FF', '1928-01-31', 'Fama-French Factors', None), ('HML-FF', '1937-02-28', 'Fama-French Factors', None), ('SMB', '2000-06-30', 'Fama-French Factors', None), ('HML-FF', '1947-05-31', 'Fama-French Factors', None), ('HML-FF', '1980-11-30', 'Fama-French Factors', None)]\n",
      "2025-04-11 13:07:39,434 - DEBUG - Total existing keys: 4188\n",
      "2025-04-11 13:07:39,473 - DEBUG - New keys sample (first 5): [('HML-D', '1926-07-31', \"The Devil's in HML's Details\", 'Unknown'), ('HML-D', '1926-08-31', \"The Devil's in HML's Details\", 'Unknown'), ('HML-D', '1926-09-30', \"The Devil's in HML's Details\", 'Unknown'), ('HML-D', '1926-10-31', \"The Devil's in HML's Details\", 'Unknown'), ('HML-D', '1926-11-30', \"The Devil's in HML's Details\", 'Unknown')]\n",
      "2025-04-11 13:07:39,484 - DEBUG - New rows to insert: 2154. Sample (first 5): [{'factor': 'HML-D', 'date': Timestamp('1926-07-31 00:00:00'), 'region': nan}, {'factor': 'HML-D', 'date': Timestamp('1926-08-31 00:00:00'), 'region': nan}, {'factor': 'HML-D', 'date': Timestamp('1926-09-30 00:00:00'), 'region': nan}, {'factor': 'HML-D', 'date': Timestamp('1926-10-31 00:00:00'), 'region': nan}, {'factor': 'HML-D', 'date': Timestamp('1926-11-30 00:00:00'), 'region': nan}]\n",
      "2025-04-11 13:07:41,560 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet HML Devil): IntegrityError: (pyodbc.IntegrityError) ('23000', \"[23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Violation of PRIMARY KEY constraint 'PK__factor_r__C3CBC7054E79A6D5'. Cannot insert duplicate key in object 'dbo.factor_returns'. The duplicate key value is (HML-D, 1984-07-31, The Devil's in HML's Details). (2627) (SQLExecDirectW); [23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]The statement has been terminated. (3621)\")\n",
      "[SQL: INSERT INTO factor_returns (factor, date, associated_paper, value, region, asset_class) VALUES (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ... 6723 characters truncated ... , (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?)]\n",
      "[parameters: ('HML-D', datetime.datetime(2013, 10, 31, 0, 0), \"The Devil's in HML's Details\", 0.0072444105281305295, None, 'Equity', 'HML-D', datetime.datetime(2013, 11, 30, 0, 0), \"The Devil's in HML's Details\", -0.005184703242705693, None, 'Equity', 'HML-D', datetime.datetime(2013, 12, 31, 0, 0), \"The Devil's in HML's Details\", -0.005092753300083641, None, 'Equity', 'HML-D', datetime.datetime(2014, 1, 31, 0, 0), \"The Devil's in HML's Details\", -0.009014270054341142, None, 'Equity', 'HML-D', datetime.datetime(2014, 2, 28, 0, 0), \"The Devil's in HML's Details\", -0.009496538155720964, None, 'Equity', 'HML-D', datetime.datetime(2014, 3, 31, 0, 0), \"The Devil's in HML's Details\", 0.03441581628966687, None, 'Equity', 'HML-D', datetime.datetime(2014, 4, 30, 0, 0), \"The Devil's in HML's Details\", 0.024334649355976432, None, 'Equity', 'HML-D', datetime.datetime(2014, 5, 31, 0, 0), \"The Devil's in HML's Details\", -0.0043872889196122904, None, 'Equity', 'HML-D', datetime.datetime(2014, 6, 30, 0, 0) ... 1994 parameters truncated ... None, 'Equity', 'HML-D', datetime.datetime(2001, 9, 30, 0, 0), \"The Devil's in HML's Details\", -0.031155186944991396, None, 'Equity', 'HML-D', datetime.datetime(2001, 10, 31, 0, 0), \"The Devil's in HML's Details\", 0.007021243301153898, None, 'Equity', 'HML-D', datetime.datetime(2001, 11, 30, 0, 0), \"The Devil's in HML's Details\", 0.03149142164443875, None, 'Equity', 'HML-D', datetime.datetime(2001, 12, 31, 0, 0), \"The Devil's in HML's Details\", 0.007743100314369627, None, 'Equity', 'HML-D', datetime.datetime(2002, 1, 31, 0, 0), \"The Devil's in HML's Details\", 0.00634064776393236, None, 'Equity', 'HML-D', datetime.datetime(2002, 2, 28, 0, 0), \"The Devil's in HML's Details\", -0.0009196778618448396, None, 'Equity', 'HML-D', datetime.datetime(2002, 3, 31, 0, 0), \"The Devil's in HML's Details\", 0.02380782970640389, None, 'Equity', 'HML-D', datetime.datetime(2002, 4, 30, 0, 0), \"The Devil's in HML's Details\", 0.015381715521180367, None, 'Equity')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-04-11 13:07:41,561 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet UMD) with is_com=False\n",
      "2025-04-11 13:07:42,631 - INFO - Read 1176 rows with set columns: ['DATE', 'AUS', 'AUT', 'BEL', 'CAN', 'CHE', 'DEU', 'DNK', 'ESP', 'FIN', 'FRA', 'GBR', 'GRC', 'HKG', 'IRL', 'ISR', 'ITA', 'JPN', 'NLD', 'NOR', 'NZL', 'PRT', 'SGP', 'SWE', 'USA', 'Global', 'Global Ex USA', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-11 13:07:42,634 - INFO - Columns after renaming: ['date', 'UMD', 'UMD', 'UMD']\n",
      "2025-04-11 13:07:42,661 - DEBUG - After dropping NA dates, 1176 rows remain\n",
      "2025-04-11 13:07:42,675 - DEBUG - Rows after melting and dropping NA: 2136\n",
      "2025-04-11 13:07:42,825 - DEBUG - Existing keys sample (first 5): [('HML-FF', '1980-11-30', 'Fama-French Factors', None), ('BAB', '1957-07-31', 'Betting Against Beta (Frazzini and Pedersen, 2014)', None), ('BAB', '1972-06-30', 'Betting Against Beta (Frazzini and Pedersen, 2014)', None), ('MKT', '1987-06-30', 'Fama-French Factors', None), ('MKT', '2011-01-31', 'Fama-French Factors', None)]\n",
      "2025-04-11 13:07:42,827 - DEBUG - Total existing keys: 5235\n",
      "2025-04-11 13:07:42,969 - DEBUG - New keys sample (first 5): [('UMD', '1927-01-31', 'On Persistence in Mutual Fund Performance', 'Unknown'), ('UMD', '1927-02-28', 'On Persistence in Mutual Fund Performance', 'Unknown'), ('UMD', '1927-03-31', 'On Persistence in Mutual Fund Performance', 'Unknown'), ('UMD', '1927-04-30', 'On Persistence in Mutual Fund Performance', 'Unknown'), ('UMD', '1927-05-31', 'On Persistence in Mutual Fund Performance', 'Unknown')]\n",
      "2025-04-11 13:07:43,018 - DEBUG - New rows to insert: 2136. Sample (first 5): [{'factor': 'UMD', 'date': Timestamp('1927-01-31 00:00:00'), 'region': nan}, {'factor': 'UMD', 'date': Timestamp('1927-02-28 00:00:00'), 'region': nan}, {'factor': 'UMD', 'date': Timestamp('1927-03-31 00:00:00'), 'region': nan}, {'factor': 'UMD', 'date': Timestamp('1927-04-30 00:00:00'), 'region': nan}, {'factor': 'UMD', 'date': Timestamp('1927-05-31 00:00:00'), 'region': nan}]\n",
      "2025-04-11 13:07:44,859 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet UMD): IntegrityError: (pyodbc.IntegrityError) ('23000', \"[23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Violation of PRIMARY KEY constraint 'PK__factor_r__C3CBC7054E79A6D5'. Cannot insert duplicate key in object 'dbo.factor_returns'. The duplicate key value is (UMD, 1985-01-31, On Persistence in Mutual Fund Performance). (2627) (SQLExecDirectW); [23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]The statement has been terminated. (3621)\")\n",
      "[SQL: INSERT INTO factor_returns (factor, date, associated_paper, value, region, asset_class) VALUES (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ... 6723 characters truncated ... , (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?)]\n",
      "[parameters: ('UMD', datetime.datetime(2014, 4, 30, 0, 0), 'On Persistence in Mutual Fund Performance', -0.04315077904847455, None, 'Equity', 'UMD', datetime.datetime(2014, 5, 31, 0, 0), 'On Persistence in Mutual Fund Performance', 0.012067091700408518, None, 'Equity', 'UMD', datetime.datetime(2014, 6, 30, 0, 0), 'On Persistence in Mutual Fund Performance', 0.006253928654609622, None, 'Equity', 'UMD', datetime.datetime(2014, 7, 31, 0, 0), 'On Persistence in Mutual Fund Performance', -0.0006523035900165526, None, 'Equity', 'UMD', datetime.datetime(2014, 8, 31, 0, 0), 'On Persistence in Mutual Fund Performance', 0.009703868011299879, None, 'Equity', 'UMD', datetime.datetime(2014, 9, 30, 0, 0), 'On Persistence in Mutual Fund Performance', 0.01127236580703486, None, 'Equity', 'UMD', datetime.datetime(2014, 10, 31, 0, 0), 'On Persistence in Mutual Fund Performance', -0.0016423145212227802, None, 'Equity', 'UMD', datetime.datetime(2014, 11, 30, 0, 0), 'On Persistence in Mutual Fund Performance', 0.00907903172393267, None, 'Equity', 'UMD', datetime.datetime(2014, 12, 31, 0, 0) ... 1994 parameters truncated ... None, 'Equity', 'UMD', datetime.datetime(2002, 9, 30, 0, 0), 'On Persistence in Mutual Fund Performance', 0.09455445968723777, None, 'Equity', 'UMD', datetime.datetime(2002, 10, 31, 0, 0), 'On Persistence in Mutual Fund Performance', -0.05297015142448799, None, 'Equity', 'UMD', datetime.datetime(2002, 11, 30, 0, 0), 'On Persistence in Mutual Fund Performance', -0.11395292591341677, None, 'Equity', 'UMD', datetime.datetime(2002, 12, 31, 0, 0), 'On Persistence in Mutual Fund Performance', 0.09656001282528576, None, 'Equity', 'UMD', datetime.datetime(2003, 1, 31, 0, 0), 'On Persistence in Mutual Fund Performance', 0.01048439611252955, None, 'Equity', 'UMD', datetime.datetime(2003, 2, 28, 0, 0), 'On Persistence in Mutual Fund Performance', 0.03626111195157964, None, 'Equity', 'UMD', datetime.datetime(2003, 3, 31, 0, 0), 'On Persistence in Mutual Fund Performance', 0.018182495745141906, None, 'Equity', 'UMD', datetime.datetime(2003, 4, 30, 0, 0), 'On Persistence in Mutual Fund Performance', -0.09211410115601056, None, 'Equity')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-04-11 13:07:44,860 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet ME(t-1)) with is_com=False\n",
      "2025-04-11 13:07:46,024 - INFO - Read 1182 rows with set columns: ['DATE', 'AUT', 'HKG', 'ESP', 'GBR', 'ITA', 'DEU', 'DNK', 'NZL', 'NLD', 'USA', 'PRT', 'BEL', 'ISR', 'GRC', 'NOR', 'SGP', 'CHE', 'IRL', 'CAN', 'FIN', 'JPN', 'SWE', 'FRA', 'AUS', 'Global Ex USA', 'Global', 'Europe', 'North America', 'Pacific']\n",
      "2025-04-11 13:07:46,029 - INFO - Columns after renaming: ['date', 'ME', 'ME', 'ME']\n",
      "2025-04-11 13:07:46,051 - DEBUG - After dropping NA dates, 1182 rows remain\n",
      "2025-04-11 13:07:46,059 - DEBUG - Rows after melting and dropping NA: 2210\n",
      "2025-04-11 13:07:46,302 - DEBUG - Existing keys sample (first 5): [('HML-FF', '1980-11-30', 'Fama-French Factors', None), ('BAB', '1957-07-31', 'Betting Against Beta (Frazzini and Pedersen, 2014)', None), ('BAB', '1972-06-30', 'Betting Against Beta (Frazzini and Pedersen, 2014)', None), ('MKT', '1987-06-30', 'Fama-French Factors', None), ('UMD', '1931-09-30', 'On Persistence in Mutual Fund Performance', None)]\n",
      "2025-04-11 13:07:46,303 - DEBUG - Total existing keys: 6282\n",
      "2025-04-11 13:07:46,480 - DEBUG - New keys sample (first 5): [('ME', '1926-07-31', 'AQR Factors', 'Unknown'), ('ME', '1926-08-31', 'AQR Factors', 'Unknown'), ('ME', '1926-09-30', 'AQR Factors', 'Unknown'), ('ME', '1926-10-31', 'AQR Factors', 'Unknown'), ('ME', '1926-11-30', 'AQR Factors', 'Unknown')]\n",
      "2025-04-11 13:07:46,495 - DEBUG - New rows to insert: 2210. Sample (first 5): [{'factor': 'ME', 'date': Timestamp('1926-07-31 00:00:00'), 'region': nan}, {'factor': 'ME', 'date': Timestamp('1926-08-31 00:00:00'), 'region': nan}, {'factor': 'ME', 'date': Timestamp('1926-09-30 00:00:00'), 'region': nan}, {'factor': 'ME', 'date': Timestamp('1926-10-31 00:00:00'), 'region': nan}, {'factor': 'ME', 'date': Timestamp('1926-11-30 00:00:00'), 'region': nan}]\n",
      "2025-04-11 13:07:48,340 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet ME(t-1)): IntegrityError: (pyodbc.IntegrityError) ('23000', \"[23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Violation of PRIMARY KEY constraint 'PK__factor_r__C3CBC7054E79A6D5'. Cannot insert duplicate key in object 'dbo.factor_returns'. The duplicate key value is (ME, 1982-03-31, AQR Factors). (2627) (SQLExecDirectW); [23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]The statement has been terminated. (3621)\")\n",
      "[SQL: INSERT INTO factor_returns (factor, date, associated_paper, value, region, asset_class) VALUES (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ... 6723 characters truncated ... , (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?)]\n",
      "[parameters: ('ME', datetime.datetime(2013, 10, 31, 0, 0), 'AQR Factors', 22025042.496611033, None, 'Equity', 'ME', datetime.datetime(2013, 11, 30, 0, 0), 'AQR Factors', 22861634.48946448, None, 'Equity', 'ME', datetime.datetime(2013, 12, 31, 0, 0), 'AQR Factors', 23435136.39110338, None, 'Equity', 'ME', datetime.datetime(2014, 1, 31, 0, 0), 'AQR Factors', 24059414.51842615, None, 'Equity', 'ME', datetime.datetime(2014, 2, 28, 0, 0), 'AQR Factors', 23353985.84743171, None, 'Equity', 'ME', datetime.datetime(2014, 3, 31, 0, 0), 'AQR Factors', 24409683.84168286, None, 'Equity', 'ME', datetime.datetime(2014, 4, 30, 0, 0), 'AQR Factors', 24513849.445184622, None, 'Equity', 'ME', datetime.datetime(2014, 5, 31, 0, 0), 'AQR Factors', 24377841.6124672, None, 'Equity', 'ME', datetime.datetime(2014, 6, 30, 0, 0) ... 1994 parameters truncated ... None, 'Equity', 'ME', datetime.datetime(1999, 5, 31, 0, 0), 'AQR Factors', 26527101.931955345, None, 'Equity', 'ME', datetime.datetime(1999, 6, 30, 0, 0), 'AQR Factors', 25766215.92625363, None, 'Equity', 'ME', datetime.datetime(1999, 7, 31, 0, 0), 'AQR Factors', 27215758.178556606, None, 'Equity', 'ME', datetime.datetime(1999, 8, 31, 0, 0), 'AQR Factors', 27240690.506904326, None, 'Equity', 'ME', datetime.datetime(1999, 9, 30, 0, 0), 'AQR Factors', 27329477.49193398, None, 'Equity', 'ME', datetime.datetime(1999, 10, 31, 0, 0), 'AQR Factors', 27265598.20936404, None, 'Equity', 'ME', datetime.datetime(1999, 11, 30, 0, 0), 'AQR Factors', 28819903.467325125, None, 'Equity', 'ME', datetime.datetime(1999, 12, 31, 0, 0), 'AQR Factors', 30411519.247075036, None, 'Equity')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-04-11 13:07:48,341 - INFO - Processing C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet RF) with is_com=False\n",
      "2025-04-11 13:07:49,629 - INFO - Read 1184 rows with set columns: ['DATE', 'Risk Free Rate']\n",
      "2025-04-11 13:07:49,631 - INFO - Columns after renaming: ['date', 'RF']\n",
      "C:\\Users\\JulianHeron\\AppData\\Local\\Temp\\ipykernel_21968\\3722488965.py:260: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
      "2025-04-11 13:07:49,643 - WARNING - Dropped 1 rows due to invalid dates in C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet RF)\n",
      "2025-04-11 13:07:49,646 - DEBUG - After dropping NA dates, 1183 rows remain\n",
      "2025-04-11 13:07:49,657 - DEBUG - Rows after melting and dropping NA: 1183\n",
      "2025-04-11 13:07:49,916 - DEBUG - Existing keys sample (first 5): [('HML-FF', '1980-11-30', 'Fama-French Factors', None), ('BAB', '1957-07-31', 'Betting Against Beta (Frazzini and Pedersen, 2014)', None), ('ME', '2012-06-30', 'AQR Factors', None), ('BAB', '1972-06-30', 'Betting Against Beta (Frazzini and Pedersen, 2014)', None), ('MKT', '1987-06-30', 'Fama-French Factors', None)]\n",
      "2025-04-11 13:07:49,928 - DEBUG - Total existing keys: 7329\n",
      "2025-04-11 13:07:50,002 - DEBUG - New keys sample (first 5): [('RF', '1926-07-31', 'Unknown', 'Unknown'), ('RF', '1926-08-31', 'Unknown', 'Unknown'), ('RF', '1926-09-30', 'Unknown', 'Unknown'), ('RF', '1926-10-31', 'Unknown', 'Unknown'), ('RF', '1926-11-30', 'Unknown', 'Unknown')]\n",
      "2025-04-11 13:07:50,044 - DEBUG - New rows to insert: 1183. Sample (first 5): [{'factor': 'RF', 'date': Timestamp('1926-07-31 00:00:00'), 'region': nan}, {'factor': 'RF', 'date': Timestamp('1926-08-31 00:00:00'), 'region': nan}, {'factor': 'RF', 'date': Timestamp('1926-09-30 00:00:00'), 'region': nan}, {'factor': 'RF', 'date': Timestamp('1926-10-31 00:00:00'), 'region': nan}, {'factor': 'RF', 'date': Timestamp('1926-11-30 00:00:00'), 'region': nan}]\n",
      "2025-04-11 13:07:52,164 - INFO - Loaded 1183 new rows into factor_returns from C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx (sheet RF)\n",
      "2025-04-11 13:07:52,167 - INFO - Processing dataset: TSMOM\n",
      "2025-04-11 13:07:52,168 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet TSMOM Factors) with is_com=False\n",
      "2025-04-11 13:07:52,484 - INFO - Read 481 rows with set columns: ['DATE', 'TSMOM', 'TSMOM^CM', 'TSMOM^EQ', 'TSMOM^FI', 'TSMOM^FX']\n",
      "2025-04-11 13:07:52,487 - INFO - Columns after renaming: ['date', 'TSM-MA', 'TSM-Com', 'TSM-EQ', 'TSM-FI', 'TSM-FX']\n",
      "2025-04-11 13:07:52,501 - DEBUG - After dropping NA dates, 481 rows remain\n",
      "2025-04-11 13:07:52,509 - DEBUG - Rows after melting and dropping NA: 2405\n",
      "2025-04-11 13:07:53,141 - DEBUG - Existing keys sample (first 5): [('RF', '1982-12-31', 'Unknown', None), ('HML-FF', '1980-11-30', 'Fama-French Factors', None), ('RF', '1983-07-31', 'Unknown', None), ('BAB', '1957-07-31', 'Betting Against Beta (Frazzini and Pedersen, 2014)', None), ('ME', '2012-06-30', 'AQR Factors', None)]\n",
      "2025-04-11 13:07:53,142 - DEBUG - Total existing keys: 8512\n",
      "2025-04-11 13:07:53,240 - DEBUG - New keys sample (first 5): [('TSM-MA', '1985-01-31', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', 'Unknown'), ('TSM-MA', '1985-02-28', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', 'Unknown'), ('TSM-MA', '1985-03-29', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', 'Unknown'), ('TSM-MA', '1985-04-30', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', 'Unknown'), ('TSM-MA', '1985-05-31', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', 'Unknown')]\n",
      "2025-04-11 13:07:53,267 - DEBUG - New rows to insert: 2405. Sample (first 5): [{'factor': 'TSM-MA', 'date': Timestamp('1985-01-31 00:00:00'), 'region': nan}, {'factor': 'TSM-MA', 'date': Timestamp('1985-02-28 00:00:00'), 'region': nan}, {'factor': 'TSM-MA', 'date': Timestamp('1985-03-29 00:00:00'), 'region': nan}, {'factor': 'TSM-MA', 'date': Timestamp('1985-04-30 00:00:00'), 'region': nan}, {'factor': 'TSM-MA', 'date': Timestamp('1985-05-31 00:00:00'), 'region': nan}]\n",
      "2025-04-11 13:07:57,247 - INFO - Loaded 2405 new rows into factor_returns from C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx (sheet TSMOM Factors)\n",
      "2025-04-11 13:07:57,250 - INFO - Processing dataset: QMJ\n",
      "2025-04-11 13:07:57,251 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 10 Portfolios Formed on Quality) with is_com=False\n",
      "2025-04-11 13:07:58,298 - INFO - Read 809 rows with set columns: ['DATE', 'P1 (low quality)', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10 (high quality)', 'P10-P1', 'P1 (low quality).1', 'P2.1', 'P3.1', 'P4.1', 'P5.1', 'P6.1', 'P7.1', 'P8.1', 'P9.1', 'P10 (high quality).1', 'P10-P1.1']\n",
      "2025-04-11 13:07:58,301 - INFO - Columns after renaming: ['date', 'QMJ_P1', 'QMJ_P2', 'QMJ_P3', 'QMJ_P4', 'QMJ_P5', 'QMJ_P6', 'QMJ_P7', 'QMJ_P8', 'QMJ_P9', 'QMJ_P10', 'QMJ', 'QMJ_P1', 'QMJ_P2', 'QMJ_P3', 'QMJ_P4', 'QMJ_P5', 'QMJ_P6', 'QMJ_P7', 'QMJ_P8', 'QMJ_P9', 'QMJ_P10', 'QMJ']\n",
      "2025-04-11 13:07:58,316 - DEBUG - After dropping NA dates, 809 rows remain\n",
      "2025-04-11 13:07:58,328 - DEBUG - Rows after melting and dropping NA: 13574\n",
      "2025-04-11 13:07:58,741 - DEBUG - Existing keys sample (first 5): [('RF', '1982-12-31', 'Unknown', None), ('HML-FF', '1980-11-30', 'Fama-French Factors', None), ('TSM-FX', '2024-12-31', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', None), ('RF', '1983-07-31', 'Unknown', None), ('BAB', '1957-07-31', 'Betting Against Beta (Frazzini and Pedersen, 2014)', None)]\n",
      "2025-04-11 13:07:58,746 - DEBUG - Total existing keys: 10917\n",
      "2025-04-11 13:07:59,565 - DEBUG - New keys sample (first 5): [('QMJ_P1', '1957-07-31', 'Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)', 'USA'), ('QMJ_P1', '1957-08-31', 'Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)', 'USA'), ('QMJ_P1', '1957-09-30', 'Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)', 'USA'), ('QMJ_P1', '1957-10-31', 'Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)', 'USA'), ('QMJ_P1', '1957-11-30', 'Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)', 'USA')]\n",
      "2025-04-11 13:07:59,625 - DEBUG - New rows to insert: 13574. Sample (first 5): [{'factor': 'QMJ_P1', 'date': Timestamp('1957-07-31 00:00:00'), 'region': 'USA'}, {'factor': 'QMJ_P1', 'date': Timestamp('1957-08-31 00:00:00'), 'region': 'USA'}, {'factor': 'QMJ_P1', 'date': Timestamp('1957-09-30 00:00:00'), 'region': 'USA'}, {'factor': 'QMJ_P1', 'date': Timestamp('1957-10-31 00:00:00'), 'region': 'USA'}, {'factor': 'QMJ_P1', 'date': Timestamp('1957-11-30 00:00:00'), 'region': 'USA'}]\n",
      "2025-04-11 13:08:00,917 - ERROR - Unexpected error processing C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx (sheet 10 Portfolios Formed on Quality): IntegrityError: (pyodbc.IntegrityError) ('23000', \"[23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Violation of PRIMARY KEY constraint 'PK__factor_r__C3CBC7054E79A6D5'. Cannot insert duplicate key in object 'dbo.factor_returns'. The duplicate key value is (QMJ_P1, 1989-07-31, Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)). (2627) (SQLExecDirectW); [23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]The statement has been terminated. (3621)\")\n",
      "[SQL: INSERT INTO factor_returns (factor, date, associated_paper, value, region, asset_class) VALUES (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ... 6723 characters truncated ... , (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?)]\n",
      "[parameters: ('QMJ_P1', datetime.datetime(2015, 9, 30, 0, 0), 'Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)', -0.12076591604740565, 'Global', 'Equity', 'QMJ_P1', datetime.datetime(2015, 10, 31, 0, 0), 'Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)', 0.05916116023492199, 'Global', 'Equity', 'QMJ_P1', datetime.datetime(2015, 11, 30, 0, 0), 'Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)', -0.021569708880523637, 'Global', 'Equity', 'QMJ_P1', datetime.datetime(2015, 12, 31, 0, 0), 'Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)', -0.05185553764310499, 'Global', 'Equity', 'QMJ_P1', datetime.datetime(2016, 1, 31, 0, 0), 'Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)', -0.17865720769848717, 'Global', 'Equity', 'QMJ_P1', datetime.datetime(2016, 2, 29, 0, 0), 'Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)', 0.002655302069975409, 'Global', 'Equity', 'QMJ_P1', datetime.datetime(2016, 3, 31, 0, 0), 'Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)', 0.09718948952934528, 'Global', 'Equity', 'QMJ_P1', datetime.datetime(2016, 4, 30, 0, 0), 'Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)', 0.09202647132157513, 'Global', 'Equity', 'QMJ_P1', datetime.datetime(2016, 5, 31, 0, 0) ... 1994 parameters truncated ... 'Global', 'Equity', 'QMJ_P1', datetime.datetime(2008, 9, 30, 0, 0), 'Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)', -0.1587076263157002, 'Global', 'Equity', 'QMJ_P1', datetime.datetime(2008, 10, 31, 0, 0), 'Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)', -0.3101494440191087, 'Global', 'Equity', 'QMJ_P1', datetime.datetime(2008, 11, 30, 0, 0), 'Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)', -0.12790467665176206, 'Global', 'Equity', 'QMJ_P1', datetime.datetime(2008, 12, 31, 0, 0), 'Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)', 0.04017804470872002, 'Global', 'Equity', 'QMJ_P1', datetime.datetime(2009, 1, 31, 0, 0), 'Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)', -0.07102075178671474, 'Global', 'Equity', 'QMJ_P1', datetime.datetime(2009, 2, 28, 0, 0), 'Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)', -0.13929468578485352, 'Global', 'Equity', 'QMJ_P1', datetime.datetime(2009, 3, 31, 0, 0), 'Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)', 0.1403976624451895, 'Global', 'Equity', 'QMJ_P1', datetime.datetime(2009, 4, 30, 0, 0), 'Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)', 0.20158746685015724, 'Global', 'Equity')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-04-11 13:08:00,919 - INFO - Processing dataset: Century\n",
      "2025-04-11 13:08:00,920 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx (sheet 0) with is_com=False\n",
      "2025-04-11 13:08:02,692 - INFO - Read 1183 rows with set columns: ['DATE', 'US Stock Selection Value', 'US Stock Selection Momentum', 'US Stock Selection Defensive', 'US Stock Selection Multi-style', 'Intl Stock Selection Value', 'Intl Stock Selection Momentum', 'Intl Stock Selection Defensive', 'Intl Stock Selection Multi-style', 'Equity indices Value', 'Equity indices Momentum', 'Equity indices Carry', 'Equity indices Defensive', 'Equity indices Multi-style', 'Fixed income Value', 'Fixed income Momentum', 'Fixed income Carry', 'Fixed income Defensive', 'Fixed income Multi-style', 'Currencies Value', 'Currencies Momentum', 'Currencies Carry', 'Currencies Multi-style', 'Commodities Value', 'Commodities Momentum', 'Commodities Carry', 'Commodities Multi-style', 'All Stock Selection Value', 'All Stock Selection Momentum', 'All Stock Selection Defensive', 'All Stock Selection Multi-style', 'All Macro Value', 'All Macro Momentum', 'All Macro Carry', 'All Macro Defensive', 'All Macro Multi-style', 'All asset classes Value', 'All asset classes Momentum', 'All asset classes Carry', 'All asset classes Defensive', 'All asset classes Multi-style', 'Equity indices Market', 'Fixed income Market', 'Commodities Market', 'All Macro Market']\n",
      "2025-04-11 13:08:02,697 - INFO - Columns after renaming: ['date', 'HML-FF-US', 'UMD-US', 'BAB-US', 'Multi-style-US', 'HML-FF-Intl', 'UMD-Intl', 'BAB-Intl', 'Multi-style-Intl', 'HML-Equity', 'UMD-Equity', 'Carry-Equity', 'BAB-Equity', 'Multi-style-Equity', 'HML-FI', 'UMD-FI', 'Carry-FI', 'BAB-FI', 'Multi-style-FI', 'HML-FX', 'UMD-FX', 'Carry-FX', 'Multi-style-FX', 'HML-COM', 'UMD-COM', 'Carry-COM', 'Multi-style-COM', 'HML-All-SS', 'UMD-All-SS', 'BAB-All-SS', 'Multi-style-All-SS', 'HML-All-Macro', 'UMD-All-Macro', 'Carry-All-Macro', 'BAB-All-Macro', 'Multi-style-All-Macro', 'HML-All', 'UMD-All', 'Carry-All', 'BAB-All', 'Multi-style-All', 'MKT-Equity', 'MKT-FI', 'MKT-COM', 'MKT-All-Macro']\n",
      "C:\\Users\\JulianHeron\\AppData\\Local\\Temp\\ipykernel_21968\\3722488965.py:260: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
      "2025-04-11 13:08:02,704 - WARNING - Dropped 1 rows due to invalid dates in C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx (sheet 0)\n",
      "2025-04-11 13:08:02,709 - DEBUG - After dropping NA dates, 1182 rows remain\n",
      "2025-04-11 13:08:02,771 - DEBUG - Rows after melting and dropping NA: 46491\n",
      "2025-04-11 13:08:03,280 - DEBUG - Existing keys sample (first 5): [('RF', '1982-12-31', 'Unknown', None), ('HML-FF', '1980-11-30', 'Fama-French Factors', None), ('TSM-FX', '2024-12-31', 'Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)', None), ('RF', '1983-07-31', 'Unknown', None), ('QMJ_P1', '1960-08-31', 'Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)', 'USA')]\n",
      "2025-04-11 13:08:03,282 - DEBUG - Total existing keys: 11615\n",
      "2025-04-11 13:08:06,865 - DEBUG - New keys sample (first 5): [('HML-FF-US', '1926-07-30', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'US'), ('HML-FF-US', '1926-08-31', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'US'), ('HML-FF-US', '1926-09-30', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'US'), ('HML-FF-US', '1926-10-29', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'US'), ('HML-FF-US', '1926-11-30', 'Century of Factor Premia Monthly-Ilmanen et al. (2021)', 'US')]\n",
      "2025-04-11 13:08:06,959 - DEBUG - New rows to insert: 46491. Sample (first 5): [{'factor': 'HML-FF-US', 'date': Timestamp('1926-07-30 00:00:00'), 'region': 'US'}, {'factor': 'HML-FF-US', 'date': Timestamp('1926-08-31 00:00:00'), 'region': 'US'}, {'factor': 'HML-FF-US', 'date': Timestamp('1926-09-30 00:00:00'), 'region': 'US'}, {'factor': 'HML-FF-US', 'date': Timestamp('1926-10-29 00:00:00'), 'region': 'US'}, {'factor': 'HML-FF-US', 'date': Timestamp('1926-11-30 00:00:00'), 'region': 'US'}]\n",
      "2025-04-11 13:08:30,087 - INFO - Loaded 46491 new rows into factor_returns from C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx (sheet 0)\n",
      "2025-04-11 13:08:30,095 - INFO - Processing dataset: COM\n",
      "2025-04-11 13:08:30,096 - INFO - Processing C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx (sheet 0) with is_com=True\n",
      "2025-04-11 13:08:30,771 - INFO - Read 1776 rows with set columns: ['DATE', 'Excess return of equal-weight commodities portfolio', 'Excess spot return of equal-weight commodities portfolio', 'Interest rate adjusted carry of equal-weight commodities portfolio', 'Spot return of equal-weight commodities portfolio', 'Carry of equal-weight commodities portfolio', 'Excess return of long/short commodities portfolio', 'Excess spot return of long/short commodities portfolio', 'Interest rate adjusted carry of long/short commodities portfolio', 'Aggregate backwardation/contango', 'State of backwardation/contango', 'State of inflation']\n",
      "2025-04-11 13:08:30,790 - DEBUG - After dropping NA dates, 1776 rows remain\n",
      "2025-04-11 13:08:30,825 - DEBUG - Existing commodity dates sample (first 5): ['1903-11-30', '1887-07-29', '2000-03-31', '1967-05-31', '1912-04-30']\n",
      "2025-04-11 13:08:30,838 - INFO - No new rows to load into aqr_cmdty_factors from C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx (sheet 0)\n",
      "2025-04-11 13:08:30,845 - DEBUG - Input date range: 1877-02-28 00:00:00 to 2025-01-31 00:00:00\n",
      "2025-04-11 13:08:30,849 - DEBUG - Database date range: 1877-02-28 to 2025-01-31\n",
      "2025-04-11 13:08:30,859 - INFO - All data processing complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import VARCHAR, DATE, DECIMAL\n",
    "import logging\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(), logging.FileHandler('load_aqr_data.log')]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Database connection\n",
    "engine = create_engine(\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/CWA_Fund_Database\"\n",
    "    \"?driver=ODBC+Driver+18+for+SQL+Server&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "# File configurations with explicit headers\n",
    "data_files = {\n",
    "    \"BAB_multi\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\OneDrive - Credentialed Wealth Advisors\\Documents\\AQR_Factor_Checks\\Betting_Against_Beta_Equity_Factors_Monthly.xlsx\",\n",
    "        \"sheets\": {\n",
    "            \"BAB\": {\n",
    "                \"sheet\": \"BAB Factors\",\n",
    "                \"start_row\": 19,\n",
    "                \"paper\": \"Betting Against Beta (Frazzini and Pedersen, 2014)\",\n",
    "                \"headers\": [\"DATE\", \"AUS\", \"AUT\", \"BEL\", \"CAN\", \"CHE\", \"DEU\", \"DNK\", \"ESP\", \"FIN\", \"FRA\", \"GBR\", \"GRC\", \"HKG\", \"IRL\", \"ISR\", \"ITA\", \"JPN\", \"NLD\", \"NOR\", \"NZL\", \"PRT\", \"SGP\", \"SWE\", \"USA\", \"Global\", \"Global Ex USA\", \"Europe\", \"North America\", \"Pacific\"],\n",
    "                \"columns\": {\"DATE\": \"DATE\", \"USA\": \"BAB\", \"Global\": \"BAB\", \"Global Ex USA\": \"BAB\"}\n",
    "            },\n",
    "            \"MKT\": {\n",
    "                \"sheet\": \"MKT\",\n",
    "                \"start_row\": 19,\n",
    "                \"paper\": \"Fama-French Factors\",\n",
    "                \"headers\": [\"DATE\", \"AUS\", \"AUT\", \"BEL\", \"CAN\", \"CHE\", \"DEU\", \"DNK\", \"ESP\", \"FIN\", \"FRA\", \"GBR\", \"GRC\", \"HKG\", \"IRL\", \"ISR\", \"ITA\", \"JPN\", \"NLD\", \"NOR\", \"NZL\", \"PRT\", \"SGP\", \"SWE\", \"USA\", \"Global\", \"Global Ex USA\", \"Europe\", \"North America\", \"Pacific\"],\n",
    "                \"columns\": {\"DATE\": \"DATE\", \"USA\": \"MKT\", \"Global\": \"MKT\", \"Global Ex USA\": \"MKT\"}\n",
    "            },\n",
    "            \"SMB\": {\n",
    "                \"sheet\": \"SMB\",\n",
    "                \"start_row\": 19,\n",
    "                \"paper\": \"Fama-French Factors\",\n",
    "                \"headers\": [\"DATE\", \"AUS\", \"AUT\", \"BEL\", \"CAN\", \"CHE\", \"DEU\", \"DNK\", \"ESP\", \"FIN\", \"FRA\", \"GBR\", \"GRC\", \"HKG\", \"IRL\", \"ISR\", \"ITA\", \"JPN\", \"NLD\", \"NOR\", \"NZL\", \"PRT\", \"SGP\", \"SWE\", \"USA\", \"Global\", \"Global Ex USA\", \"Europe\", \"North America\", \"Pacific\"],\n",
    "                \"columns\": {\"DATE\": \"DATE\", \"USA\": \"SMB\", \"Global\": \"SMB\", \"Global Ex USA\": \"SMB\"}\n",
    "            },\n",
    "            \"HML-FF\": {\n",
    "                \"sheet\": \"HML FF\",\n",
    "                \"start_row\": 19,\n",
    "                \"paper\": \"Fama-French Factors\",\n",
    "                \"headers\": [\"DATE\", \"AUS\", \"AUT\", \"BEL\", \"CAN\", \"CHE\", \"DEU\", \"DNK\", \"ESP\", \"FIN\", \"FRA\", \"GBR\", \"GRC\", \"HKG\", \"IRL\", \"ISR\", \"ITA\", \"JPN\", \"NLD\", \"NOR\", \"NZL\", \"PRT\", \"SGP\", \"SWE\", \"USA\", \"Global\", \"Global Ex USA\", \"Europe\", \"North America\", \"Pacific\"],\n",
    "                \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-FF\", \"Global\": \"HML-FF\", \"Global Ex USA\": \"HML-FF\"}\n",
    "            },\n",
    "            \"HML-D\": {\n",
    "                \"sheet\": \"HML Devil\",\n",
    "                \"start_row\": 19,\n",
    "                \"paper\": \"The Devil's in HML's Details\",\n",
    "                \"headers\": [\"DATE\", \"AUS\", \"AUT\", \"BEL\", \"CAN\", \"CHE\", \"DEU\", \"DNK\", \"ESP\", \"FIN\", \"FRA\", \"GBR\", \"GRC\", \"HKG\", \"IRL\", \"ISR\", \"ITA\", \"JPN\", \"NLD\", \"NOR\", \"NZL\", \"PRT\", \"SGP\", \"SWE\", \"USA\", \"Global\", \"Global Ex USA\", \"Europe\", \"North America\", \"Pacific\"],\n",
    "                \"columns\": {\"DATE\": \"DATE\", \"USA\": \"HML-D\", \"Global\": \"HML-D\", \"Global Ex USA\": \"HML-D\"}\n",
    "            },\n",
    "            \"UMD\": {\n",
    "                \"sheet\": \"UMD\",\n",
    "                \"start_row\": 19,\n",
    "                \"paper\": \"On Persistence in Mutual Fund Performance\",\n",
    "                \"headers\": [\"DATE\", \"AUS\", \"AUT\", \"BEL\", \"CAN\", \"CHE\", \"DEU\", \"DNK\", \"ESP\", \"FIN\", \"FRA\", \"GBR\", \"GRC\", \"HKG\", \"IRL\", \"ISR\", \"ITA\", \"JPN\", \"NLD\", \"NOR\", \"NZL\", \"PRT\", \"SGP\", \"SWE\", \"USA\", \"Global\", \"Global Ex USA\", \"Europe\", \"North America\", \"Pacific\"],\n",
    "                \"columns\": {\"DATE\": \"DATE\", \"USA\": \"UMD\", \"Global\": \"UMD\", \"Global Ex USA\": \"UMD\"}\n",
    "            },\n",
    "            \"ME\": {\n",
    "                \"sheet\": \"ME(t-1)\",\n",
    "                \"start_row\": 19,\n",
    "                \"paper\": \"AQR Factors\",\n",
    "                \"headers\": [\"DATE\", \"AUT\", \"HKG\", \"ESP\", \"GBR\", \"ITA\", \"DEU\", \"DNK\", \"NZL\", \"NLD\", \"USA\", \"PRT\", \"BEL\", \"ISR\", \"GRC\", \"NOR\", \"SGP\", \"CHE\", \"IRL\", \"CAN\", \"FIN\", \"JPN\", \"SWE\", \"FRA\", \"AUS\", \"Global Ex USA\", \"Global\", \"Europe\", \"North America\", \"Pacific\"],\n",
    "                \"columns\": {\"DATE\": \"DATE\", \"USA\": \"ME\", \"Global\": \"ME\", \"Global Ex USA\": \"ME\"}\n",
    "            },\n",
    "            \"RF\": {\n",
    "                \"sheet\": \"RF\",\n",
    "                \"start_row\": 18,\n",
    "                \"paper\": None,\n",
    "                \"headers\": [\"DATE\", \"Risk Free Rate\"],\n",
    "                \"columns\": {\"DATE\": \"DATE\", \"Risk Free Rate\": \"RF\"}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"TSMOM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Time Series Momentum Factors Monthly.xlsx\",\n",
    "        \"sheet\": \"TSMOM Factors\",\n",
    "        \"start_row\": 18,\n",
    "        \"paper\": \"Time Series Momentum (Moskowitz, Ooi, and Pedersen, 2012)\",\n",
    "        \"headers\": [\"DATE\", \"TSMOM\", \"TSMOM^CM\", \"TSMOM^EQ\", \"TSMOM^FI\", \"TSMOM^FX\"],\n",
    "        \"columns\": {\n",
    "            \"DATE\": \"DATE\",\n",
    "            \"TSMOM\": \"TSM-MA\",\n",
    "            \"TSMOM^CM\": \"TSM-Com\",\n",
    "            \"TSMOM^EQ\": \"TSM-EQ\",\n",
    "            \"TSMOM^FI\": \"TSM-FI\",\n",
    "            \"TSMOM^FX\": \"TSM-FX\"\n",
    "        }\n",
    "    },\n",
    "    \"QMJ\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Quality Minus Junk 10 QualitySorted Portfolios Monthly.xlsx\",\n",
    "        \"sheet\": \"10 Portfolios Formed on Quality\",\n",
    "        \"start_row\": 19,\n",
    "        \"paper\": \"Quality Minus Junk (Asness, Frazzini and Pedersen, 2014)\",\n",
    "        \"headers\": [\"DATE\", \"P1 (low quality)\", \"P2\", \"P3\", \"P4\", \"P5\", \"P6\", \"P7\", \"P8\", \"P9\", \"P10 (high quality)\", \"P10-P1\", \"P1 (low quality).1\", \"P2.1\", \"P3.1\", \"P4.1\", \"P5.1\", \"P6.1\", \"P7.1\", \"P8.1\", \"P9.1\", \"P10 (high quality).1\", \"P10-P1.1\"],\n",
    "        \"columns\": {\n",
    "            \"DATE\": \"DATE\",\n",
    "            \"P1 (low quality)\": \"QMJ_P1\",\n",
    "            \"P2\": \"QMJ_P2\",\n",
    "            \"P3\": \"QMJ_P3\",\n",
    "            \"P4\": \"QMJ_P4\",\n",
    "            \"P5\": \"QMJ_P5\",\n",
    "            \"P6\": \"QMJ_P6\",\n",
    "            \"P7\": \"QMJ_P7\",\n",
    "            \"P8\": \"QMJ_P8\",\n",
    "            \"P9\": \"QMJ_P9\",\n",
    "            \"P10 (high quality)\": \"QMJ_P10\",\n",
    "            \"P10-P1\": \"QMJ\",\n",
    "            \"P1 (low quality).1\": \"QMJ_P1\",\n",
    "            \"P2.1\": \"QMJ_P2\",\n",
    "            \"P3.1\": \"QMJ_P3\",\n",
    "            \"P4.1\": \"QMJ_P4\",\n",
    "            \"P5.1\": \"QMJ_P5\",\n",
    "            \"P6.1\": \"QMJ_P6\",\n",
    "            \"P7.1\": \"QMJ_P7\",\n",
    "            \"P8.1\": \"QMJ_P8\",\n",
    "            \"P9.1\": \"QMJ_P9\",\n",
    "            \"P10 (high quality).1\": \"QMJ_P10\",\n",
    "            \"P10-P1.1\": \"QMJ\"\n",
    "        }\n",
    "    },\n",
    "    \"Century\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Century of Factor Premia Monthly (1).xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"start_row\": 18,\n",
    "        \"paper\": \"Century of Factor Premia Monthly-Ilmanen et al. (2021)\",\n",
    "        \"headers\": [\"DATE\", \"US Stock Selection Value\", \"US Stock Selection Momentum\", \"US Stock Selection Defensive\", \"US Stock Selection Multi-style\", \"Intl Stock Selection Value\", \"Intl Stock Selection Momentum\", \"Intl Stock Selection Defensive\", \"Intl Stock Selection Multi-style\", \"Equity indices Value\", \"Equity indices Momentum\", \"Equity indices Carry\", \"Equity indices Defensive\", \"Equity indices Multi-style\", \"Fixed income Value\", \"Fixed income Momentum\", \"Fixed income Carry\", \"Fixed income Defensive\", \"Fixed income Multi-style\", \"Currencies Value\", \"Currencies Momentum\", \"Currencies Carry\", \"Currencies Multi-style\", \"Commodities Value\", \"Commodities Momentum\", \"Commodities Carry\", \"Commodities Multi-style\", \"All Stock Selection Value\", \"All Stock Selection Momentum\", \"All Stock Selection Defensive\", \"All Stock Selection Multi-style\", \"All Macro Value\", \"All Macro Momentum\", \"All Macro Carry\", \"All Macro Defensive\", \"All Macro Multi-style\", \"All asset classes Value\", \"All asset classes Momentum\", \"All asset classes Carry\", \"All asset classes Defensive\", \"All asset classes Multi-style\", \"Equity indices Market\", \"Fixed income Market\", \"Commodities Market\", \"All Macro Market\"],\n",
    "        \"columns\": {\n",
    "            \"DATE\": \"DATE\",\n",
    "            \"US Stock Selection Value\": \"HML-FF-US\", \"US Stock Selection Momentum\": \"UMD-US\", \n",
    "            \"US Stock Selection Defensive\": \"BAB-US\", \"US Stock Selection Multi-style\": \"Multi-style-US\",\n",
    "            \"Intl Stock Selection Value\": \"HML-FF-Intl\", \"Intl Stock Selection Momentum\": \"UMD-Intl\", \n",
    "            \"Intl Stock Selection Defensive\": \"BAB-Intl\", \"Intl Stock Selection Multi-style\": \"Multi-style-Intl\",\n",
    "            \"Equity indices Value\": \"HML-Equity\", \"Equity indices Momentum\": \"UMD-Equity\", \n",
    "            \"Equity indices Carry\": \"Carry-Equity\", \"Equity indices Defensive\": \"BAB-Equity\", \n",
    "            \"Equity indices Multi-style\": \"Multi-style-Equity\",\n",
    "            \"Fixed income Value\": \"HML-FI\", \"Fixed income Momentum\": \"UMD-FI\", \n",
    "            \"Fixed income Carry\": \"Carry-FI\", \"Fixed income Defensive\": \"BAB-FI\", \n",
    "            \"Fixed income Multi-style\": \"Multi-style-FI\",\n",
    "            \"Currencies Value\": \"HML-FX\", \"Currencies Momentum\": \"UMD-FX\", \n",
    "            \"Currencies Carry\": \"Carry-FX\", \"Currencies Multi-style\": \"Multi-style-FX\",\n",
    "            \"Commodities Value\": \"HML-COM\", \"Commodities Momentum\": \"UMD-COM\", \n",
    "            \"Commodities Carry\": \"Carry-COM\", \"Commodities Multi-style\": \"Multi-style-COM\",\n",
    "            \"All Stock Selection Value\": \"HML-All-SS\", \"All Stock Selection Momentum\": \"UMD-All-SS\", \n",
    "            \"All Stock Selection Defensive\": \"BAB-All-SS\", \"All Stock Selection Multi-style\": \"Multi-style-All-SS\",\n",
    "            \"All Macro Value\": \"HML-All-Macro\", \"All Macro Momentum\": \"UMD-All-Macro\", \n",
    "            \"All Macro Carry\": \"Carry-All-Macro\", \"All Macro Defensive\": \"BAB-All-Macro\", \n",
    "            \"All Macro Multi-style\": \"Multi-style-All-Macro\",\n",
    "            \"All asset classes Value\": \"HML-All\", \"All asset classes Momentum\": \"UMD-All\", \n",
    "            \"All asset classes Carry\": \"Carry-All\", \"All asset classes Defensive\": \"BAB-All\", \n",
    "            \"All asset classes Multi-style\": \"Multi-style-All\",\n",
    "            \"Equity indices Market\": \"MKT-Equity\", \"Fixed income Market\": \"MKT-FI\", \n",
    "            \"Commodities Market\": \"MKT-COM\", \"All Macro Market\": \"MKT-All-Macro\"\n",
    "        }\n",
    "    },\n",
    "    \"COM\": {\n",
    "        \"path\": r\"C:\\Users\\JulianHeron\\Downloads\\Commodities for the Long Run Index Level Data Monthly.xlsx\",\n",
    "        \"sheet\": 0,\n",
    "        \"start_row\": 11,\n",
    "        \"paper\": \"Commodities for the Long Run\",\n",
    "        \"headers\": [\"DATE\", \"Excess return of equal-weight commodities portfolio\", \"Excess spot return of equal-weight commodities portfolio\", \"Interest rate adjusted carry of equal-weight commodities portfolio\", \"Spot return of equal-weight commodities portfolio\", \"Carry of equal-weight commodities portfolio\", \"Excess return of long/short commodities portfolio\", \"Excess spot return of long/short commodities portfolio\", \"Interest rate adjusted carry of long/short commodities portfolio\", \"Aggregate backwardation/contango\", \"State of backwardation/contango\", \"State of inflation\"],\n",
    "        \"columns\": {\n",
    "            \"DATE\": \"date\",\n",
    "            \"Excess return of equal-weight commodities portfolio\": \"excess_return_eqwt\",\n",
    "            \"Excess spot return of equal-weight commodities portfolio\": \"excess_spot_return_eqwt\",\n",
    "            \"Interest rate adjusted carry of equal-weight commodities portfolio\": \"ir_adjusted_carry_eqwt\",\n",
    "            \"Spot return of equal-weight commodities portfolio\": \"spot_return_eqwt\",\n",
    "            \"Carry of equal-weight commodities portfolio\": \"carry_eqwt\",\n",
    "            \"Excess return of long/short commodities portfolio\": \"excess_return_long_short\",\n",
    "            \"Excess spot return of long/short commodities portfolio\": \"excess_spot_return_long_short\",\n",
    "            \"Interest rate adjusted carry of long/short commodities portfolio\": \"ir_adjusted_carry_long_short\",\n",
    "            \"Aggregate backwardation/contango\": \"aggregate_backwardation_contango\",\n",
    "            \"State of backwardation/contango\": \"state_backwardation_contango\",\n",
    "            \"State of inflation\": \"state_inflation\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "def process_factors(file_config, sheet=0, is_com=False, parent_path=None):\n",
    "    file_path = parent_path if parent_path else file_config['path']\n",
    "    logger.info(f\"Processing {file_path} (sheet {sheet}) with is_com={is_com}\")\n",
    "    try:\n",
    "        # Read Excel without headers, then set them\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet, header=None, skiprows=file_config['start_row'])\n",
    "        df.columns = file_config['headers']\n",
    "        logger.info(f\"Read {len(df)} rows with set columns: {list(df.columns)}\")\n",
    "        \n",
    "        if is_com:\n",
    "            expected_cols = list(file_config['columns'].keys())\n",
    "            df = df[expected_cols]\n",
    "            df.columns = [file_config['columns'][col] for col in df.columns]\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            df['associated_paper'] = file_config['paper'] if file_config['paper'] is not None else 'Unknown'\n",
    "            df = df.dropna(subset=['date'])\n",
    "            logger.debug(f\"After dropping NA dates, {len(df)} rows remain\")\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                existing = pd.read_sql(\"SELECT date FROM aqr_cmdty_factors\", connection)\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(existing['date'])\n",
    "                logger.debug(f\"Existing commodity dates sample (first 5): {list(existing_keys)[:5]}\")\n",
    "            \n",
    "            df['date_str'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_new = df[~df['date_str'].isin(existing_keys)].drop(columns=['date_str'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                for chunk in [df_new[i:i+10000] for i in range(0, len(df_new), 10000)]:\n",
    "                    chunk.to_sql(\n",
    "                        'aqr_cmdty_factors',\n",
    "                        engine,\n",
    "                        if_exists='append',\n",
    "                        index=False,\n",
    "                        dtype={\n",
    "                            'date': DATE,\n",
    "                            'excess_return_eqwt': DECIMAL(15, 6),\n",
    "                            'excess_spot_return_eqwt': DECIMAL(15, 6),\n",
    "                            'ir_adjusted_carry_eqwt': DECIMAL(15, 6),\n",
    "                            'spot_return_eqwt': DECIMAL(15, 6),\n",
    "                            'carry_eqwt': DECIMAL(15, 6),\n",
    "                            'excess_return_long_short': DECIMAL(15, 6),\n",
    "                            'excess_spot_return_long_short': DECIMAL(15, 6),\n",
    "                            'ir_adjusted_carry_long_short': DECIMAL(15, 6),\n",
    "                            'aggregate_backwardation_contango': DECIMAL(15, 6),\n",
    "                            'state_backwardation_contango': VARCHAR(50),\n",
    "                            'state_inflation': VARCHAR(50),\n",
    "                            'associated_paper': VARCHAR(100)\n",
    "                        }\n",
    "                    )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into aqr_cmdty_factors from {file_path} (sheet {sheet})\")\n",
    "            else:\n",
    "                logger.info(f\"No new rows to load into aqr_cmdty_factors from {file_path} (sheet {sheet})\")\n",
    "                logger.debug(f\"Input date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "                logger.debug(f\"Database date range: {existing['date'].min() if not existing.empty else 'N/A'} to {existing['date'].max() if not existing.empty else 'N/A'}\")\n",
    "        else:\n",
    "            date_col = 'DATE'\n",
    "            orig_cols = df.columns.tolist()\n",
    "            if 'columns' in file_config:\n",
    "                expected_cols = list(file_config['columns'].keys())\n",
    "                valid_cols = [col for col in expected_cols if col in df.columns]\n",
    "                if not valid_cols:\n",
    "                    logger.error(f\"No valid columns found in {file_path} (sheet {sheet}). Skipping.\")\n",
    "                    return\n",
    "                if date_col not in valid_cols:\n",
    "                    valid_cols.append(date_col)\n",
    "                df = df[valid_cols]\n",
    "                new_columns = ['date' if col == date_col else file_config['columns'].get(col, col) for col in df.columns]\n",
    "                df.columns = new_columns\n",
    "            \n",
    "            logger.info(f\"Columns after renaming: {list(df.columns)}\")\n",
    "            \n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "            invalid_dates = df['date'].isna().sum()\n",
    "            if invalid_dates > 0:\n",
    "                logger.warning(f\"Dropped {invalid_dates} rows due to invalid dates in {file_path} (sheet {sheet})\")\n",
    "            df = df.dropna(subset=['date'])\n",
    "            logger.debug(f\"After dropping NA dates, {len(df)} rows remain\")\n",
    "            \n",
    "            # Melt the DataFrame\n",
    "            value_vars = [col for col in df.columns if col != 'date']\n",
    "            df_long = df.melt(id_vars=['date'], value_vars=value_vars, var_name='factor', value_name='value', col_level=0)\n",
    "            df_long = df_long.dropna(subset=['value', 'date'])\n",
    "            logger.debug(f\"Rows after melting and dropping NA: {len(df_long)}\")\n",
    "            \n",
    "            # Assign region and asset_class post-melt\n",
    "            file_path_for_check = parent_path if parent_path else file_config.get('path', '')\n",
    "            if 'TSMOM' in file_path_for_check:\n",
    "                df_long['region'] = \"Global\"\n",
    "                df_long['asset_class'] = df_long['factor'].map({\n",
    "                    \"TSM-MA\": \"Multi-Asset\",\n",
    "                    \"TSM-Com\": \"Commodities\",\n",
    "                    \"TSM-EQ\": \"Equity\",\n",
    "                    \"TSM-FI\": \"Fixed Income\",\n",
    "                    \"TSM-FX\": \"Currencies\"\n",
    "                })\n",
    "            elif 'Quality Minus Junk' in file_path_for_check:\n",
    "                df_long['region'] = df_long['date'].apply(lambda x: \"USA\" if x < pd.Timestamp(\"1989-07-31\") else \"Global\")\n",
    "                df_long['asset_class'] = \"Equity\"\n",
    "            elif 'Century' in file_path_for_check:\n",
    "                df_long['region'] = df_long['factor'].apply(lambda x: 'US' if 'US' in x else 'Intl' if 'Intl' in x else 'Global')\n",
    "                df_long['asset_class'] = df_long['factor'].str.extract(\n",
    "                    '(Stock Selection|Equity indices|Fixed income|Currencies|Commodities|All Macro|All asset classes)'\n",
    "                ).fillna('Equity')\n",
    "            else:  # BAB_multi\n",
    "                region_map = {\n",
    "                    \"USA\": \"USA\",\n",
    "                    \"Global\": \"Global\",\n",
    "                    \"Global Ex USA\": \"Intl\",\n",
    "                    \"Risk Free Rate\": \"USA\"\n",
    "                }\n",
    "                df_long['region'] = df_long['factor'].map(region_map)\n",
    "                df_long['asset_class'] = \"Equity\" if \"Risk Free Rate\" not in orig_cols else \"Fixed Income\"\n",
    "            \n",
    "            df_long['associated_paper'] = file_config['paper'] if file_config['paper'] is not None else 'Unknown'\n",
    "            df_long = df_long[['factor', 'date', 'associated_paper', 'value', 'region', 'asset_class']]\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                existing = pd.read_sql(\n",
    "                    \"SELECT factor, date, associated_paper, region FROM factor_returns\",\n",
    "                    connection\n",
    "                )\n",
    "                existing['date'] = pd.to_datetime(existing['date']).dt.strftime('%Y-%m-%d')\n",
    "                existing_keys = set(tuple(row) for row in existing[['factor', 'date', 'associated_paper', 'region']].values)\n",
    "                logger.debug(f\"Existing keys sample (first 5): {list(existing_keys)[:5]}\")\n",
    "                logger.debug(f\"Total existing keys: {len(existing_keys)}\")\n",
    "            \n",
    "            df_long['date_str'] = df_long['date'].dt.strftime('%Y-%m-%d')\n",
    "            df_long['key'] = df_long.apply(\n",
    "                lambda row: (row['factor'], row['date_str'], row['associated_paper'], row['region'] if pd.notna(row['region']) else 'Unknown'), axis=1\n",
    "            )\n",
    "            logger.debug(f\"New keys sample (first 5): {df_long['key'].head().tolist()}\")\n",
    "            df_new = df_long[~df_long['key'].isin(existing_keys)].drop(columns=['key', 'date_str'])\n",
    "            \n",
    "            if not df_new.empty:\n",
    "                logger.debug(f\"New rows to insert: {len(df_new)}. Sample (first 5): {df_new[['factor', 'date', 'region']].head().to_dict('records')}\")\n",
    "                for chunk in [df_new[i:i+10000] for i in range(0, len(df_new), 10000)]:\n",
    "                    chunk.to_sql(\n",
    "                        'factor_returns',\n",
    "                        engine,\n",
    "                        if_exists='append',\n",
    "                        index=False,\n",
    "                        dtype={\n",
    "                            'factor': VARCHAR(50),\n",
    "                            'date': DATE,\n",
    "                            'associated_paper': VARCHAR(100),\n",
    "                            'value': DECIMAL(15, 6),\n",
    "                            'region': VARCHAR(50),\n",
    "                            'asset_class': VARCHAR(50)\n",
    "                        }\n",
    "                    )\n",
    "                logger.info(f\"Loaded {len(df_new)} new rows into factor_returns from {file_path} (sheet {sheet})\")\n",
    "            else:\n",
    "                logger.info(f\"No new rows to load into factor_returns from {file_path} (sheet {sheet})\")\n",
    "                logger.debug(f\"Input date range: {df_long['date'].min()} to {df_long['date'].max()}\")\n",
    "                logger.debug(f\"Database date range: {existing['date'].min() if not existing.empty else 'N/A'} to {existing['date'].max() if not existing.empty else 'N/A'}\")\n",
    "            \n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(f\"File not found: {file_path} (sheet {sheet}): {str(e)}\")\n",
    "    except pd.errors.ParserError as e:\n",
    "        logger.error(f\"Error parsing Excel file {file_path} (sheet {sheet}): {str(e)}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error processing {file_path} (sheet {sheet}): {type(e).__name__}: {str(e)}\")\n",
    "\n",
    "# Main loop\n",
    "for key, config in data_files.items():\n",
    "    logger.info(f\"Processing dataset: {key}\")\n",
    "    if key == \"BAB_multi\":\n",
    "        for subkey, subconfig in config['sheets'].items():\n",
    "            process_factors(subconfig, sheet=subconfig['sheet'], parent_path=config['path'])\n",
    "    else:\n",
    "        is_com = (key == \"COM\")\n",
    "        process_factors(config, sheet=config['sheet'], is_com=is_com)\n",
    "\n",
    "logger.info(\"All data processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9ab829-1d5c-4680-935d-f38d492f8bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec348de1-1729-491e-a788-024bcf448692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c5aed3-0597-4756-9cc3-547a95e9d0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76f0721-f394-438c-b639-bf6743ad214c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d253a822-bbfd-4eaf-bfc6-eb0f755a8dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12638682-af79-4a03-9939-f5e78bc1845a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fb7107-8b8c-4f0f-9026-2c3371c28921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a35af68-c04e-4b70-b32b-9babc15e3998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c261e018-4c92-4846-960b-5754a3cac7f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd00d67-6d76-4175-93b2-729a980110fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f0ce7f-31e7-4eb6-b00d-a0789effe00c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dca8690-1303-409c-9786-8af693a2bfe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae3b9c5-7dcd-4696-aa41-fcadfa4b0669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Database Administration)",
   "language": "python",
   "name": "databaseadminenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
