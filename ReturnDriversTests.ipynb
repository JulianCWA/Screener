{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f9c575c-9298-483f-8e37-39066aeed117",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw index_fund values before normalization: ['0', '1', '1', '1', '1']\n",
      "Index_fund values after normalization: [0, 1, 1, 1, 1]\n",
      "IJH index_fund after normalization: [1]\n",
      "Columns after initializing scores: ['SymbolCUSIP', 'ProductName', 'fund_family', 'investment_strategy', 'FS_insight', 'index_fund', 'inverse_fund', 'leveraged_fund', 'socially_responsible_fund', 'synthetic_replication_fund', 'fund_of_funds', 'ycharts_url', 'YC_Category_ID', 'CWA_Broad_Category_ID', 'YC_Global_Category_ID', 'YC_Broad_Asset_Class_ID', 'currency_hedged_fund', 'CWA_Broad_Category_Name', 'Category_Name', 'Global_Category_Name', 'YC_Broad_Asset_Class_Name', 'score_Index Based', 'score_Factor/Smart Beta', 'score_Active Discretionary', 'score_Quant/Systematic', 'score_Multi-Strategy', 'keyword_score_Index Based', 'meaningful_score_Index Based', 'assist_score_Index Based', 'boolean_score_Index Based', 'fundfamily_score_Index Based', 'keyword_score_Factor/Smart Beta', 'meaningful_score_Factor/Smart Beta', 'assist_score_Factor/Smart Beta', 'boolean_score_Factor/Smart Beta', 'fundfamily_score_Factor/Smart Beta', 'keyword_score_Active Discretionary', 'meaningful_score_Active Discretionary', 'assist_score_Active Discretionary', 'boolean_score_Active Discretionary', 'fundfamily_score_Active Discretionary', 'keyword_score_Quant/Systematic', 'meaningful_score_Quant/Systematic', 'assist_score_Quant/Systematic', 'boolean_score_Quant/Systematic', 'fundfamily_score_Quant/Systematic', 'keyword_score_Multi-Strategy', 'meaningful_score_Multi-Strategy', 'assist_score_Multi-Strategy', 'boolean_score_Multi-Strategy', 'fundfamily_score_Multi-Strategy', 'matched_keywords_Index Based', 'matched_keywords_Factor/Smart Beta', 'matched_keywords_Active Discretionary', 'matched_keywords_Quant/Systematic', 'matched_keywords_Multi-Strategy']\n",
      "Assist category pattern 'Muni' matches for YC_Category:\n",
      "    SymbolCUSIP                 Category_Name\n",
      "164         VOX                Communications\n",
      "415        DFCA  Muni California Intermediate\n",
      "416         PWZ          Muni California Long\n",
      "417        AVMU          Muni National Interm\n",
      "418         ITM          Muni National Interm\n",
      "Assist category pattern 'US Municipal Fixed Income' matches for YC_Global_Category:\n",
      "    SymbolCUSIP       Global_Category_Name\n",
      "415        DFCA  US Municipal Fixed Income\n",
      "416         PWZ  US Municipal Fixed Income\n",
      "417        AVMU  US Municipal Fixed Income\n",
      "418         ITM  US Municipal Fixed Income\n",
      "419        MUST  US Municipal Fixed Income\n",
      "Assist category exact 'Commodity' matches for CWA_Broad_Category:\n",
      "   SymbolCUSIP CWA_Broad_Category_Name\n",
      "26        FAAR               Commodity\n",
      "42        CMDY               Commodity\n",
      "43        NBCM               Commodity\n",
      "44        CERY               Commodity\n",
      "45        EDGH               Commodity\n",
      "Assist category exact 'Commodities Broad Basket' matches for YC_Category:\n",
      "   SymbolCUSIP             Category_Name\n",
      "26        FAAR  Commodities Broad Basket\n",
      "42        CMDY  Commodities Broad Basket\n",
      "43        NBCM  Commodities Broad Basket\n",
      "44        CERY  Commodities Broad Basket\n",
      "45        EDGH  Commodities Broad Basket\n",
      "Assist category exact 'Commodities Focused' matches for YC_Category:\n",
      "   SymbolCUSIP        Category_Name\n",
      "46        AAAU  Commodities Focused\n",
      "47        GLDM  Commodities Focused\n",
      "48         DBE  Commodities Focused\n",
      "49        CPER  Commodities Focused\n",
      "50        CORN  Commodities Focused\n",
      "Assist category exact 'Commodities Broad Basket' matches for YC_Global_Category:\n",
      "   SymbolCUSIP      Global_Category_Name\n",
      "26        FAAR  Commodities Broad Basket\n",
      "42        CMDY  Commodities Broad Basket\n",
      "43        NBCM  Commodities Broad Basket\n",
      "44        CERY  Commodities Broad Basket\n",
      "45        EDGH  Commodities Broad Basket\n",
      "Assist category exact 'Commodities Specified' matches for YC_Global_Category:\n",
      "   SymbolCUSIP   Global_Category_Name\n",
      "46        AAAU  Commodities Specified\n",
      "47        GLDM  Commodities Specified\n",
      "48         DBE  Commodities Specified\n",
      "49        CPER  Commodities Specified\n",
      "50        CORN  Commodities Specified\n",
      "Assist category exact 'Long/Short Equity' matches for YC_Global_Category:\n",
      "     SymbolCUSIP Global_Category_Name\n",
      "29          FTLS    Long/Short Equity\n",
      "30          FFLS    Long/Short Equity\n",
      "31          CLSE    Long/Short Equity\n",
      "32          LBAY    Long/Short Equity\n",
      "1171        LSEQ    Long/Short Equity\n",
      "Assist category exact 'inflation-protected bond' matches for YC_Category:\n",
      "    SymbolCUSIP             Category_Name\n",
      "469        LTPZ  Inflation-Protected Bond\n",
      "470         TIP  Inflation-Protected Bond\n",
      "471        TIPZ  Inflation-Protected Bond\n",
      "472        TDTF  Inflation-Protected Bond\n",
      "473        LDRI  Inflation-Protected Bond\n",
      "Assist category exact 'Nontraditional' matches for CWA_Broad_Category:\n",
      "    SymbolCUSIP CWA_Broad_Category_Name\n",
      "27         VEGA          Nontraditional\n",
      "28         BUYW          Nontraditional\n",
      "141        SIXH          Nontraditional\n",
      "142        DISO          Nontraditional\n",
      "143        JPMO          Nontraditional\n",
      "Assist category exact 'Nontraditional Equity' matches for YC_Broad_Asset_Class:\n",
      "    SymbolCUSIP YC_Broad_Asset_Class_Name\n",
      "141        SIXH     Nontraditional Equity\n",
      "142        DISO     Nontraditional Equity\n",
      "143        JPMO     Nontraditional Equity\n",
      "144        XOMO     Nontraditional Equity\n",
      "145        PYPY     Nontraditional Equity\n",
      "Assist category exact 'Sector/Industry' matches for CWA_Broad_Category:\n",
      "    SymbolCUSIP CWA_Broad_Category_Name\n",
      "140        GMET         Sector/Industry\n",
      "163        BLOK         Sector/Industry\n",
      "164         VOX         Sector/Industry\n",
      "165         VCR         Sector/Industry\n",
      "166        IEDI         Sector/Industry\n",
      "Results exported to C:\\Users\\JulianHeron\\Software Projects\\Return_Drivers_V1.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Grok Attempt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# Adjustable scaling factor for fund family distribution\n",
    "FUND_FAMILY_SCALE_FACTOR = 5  # Adjust this value to change the influence of fund family data\n",
    "\n",
    "# Database connection\n",
    "connection_string = (\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/\"\n",
    "    \"CWA_Fund_Database?driver=ODBC+Driver+18+for+SQL+Server\"\n",
    "    \"&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Define keywords for each category\n",
    "keywords = {\n",
    "    \"Index Based\": [\"index fund\", \"tracks\", \"replicates\", \"indexed\", \"underlying index\", \"thematic\", \"passive\",\n",
    "                    \"economic characteristics that are substantially\", \"bond index\", \"market-cap weighted\",\n",
    "                    \"low tracking error\", \"high correlation\", \"benchmark\", \"low-cost\", \"broad market exposure\",\n",
    "                    \"aggregate bond\", \"mirrors\", \"equal-weighted\", \"beta\", \"value index\", \"growth index\"],\n",
    "    \"Factor/Smart Beta\": [\"rules-based\", \"factor-based\", \"factor tilt\", \"multi-factor\", \"factor investing\", \"momentum\",\n",
    "                          \"low volatility\", \"low vol\", \"value factor\", \"quality\", \"quality factor\", \"free cash flow\",\n",
    "                          \"fcf\", \"objective\", \"relatively\", \"go up\", \"certain fundamental metrics\", \"momentum index\",\n",
    "                          \"quality index\", \"relatively lower valuations\", \"factors\", \"minimum volatility\",\n",
    "                          \"high dividend yield\", \"enhanced index\", \"revenue weighted\", \"dividend weighted\",\n",
    "                          \"enhanced returns\", \"fundamental weighting\", \"yield weighted\", \"low volatility\", \"rotation\",\n",
    "                          \"rules based methodology\", \"cash cows\", \"alphaDEX\", \"ranked\", \"lower volatility\",\n",
    "                          \"tilt\", \"optimized\", \"component securities\", \"economic characteristics\", \"free cash flow yield\",\n",
    "                          \"high dividend yields\", \"ranking system\", \"consistently increased dividends\", \"dividend\",\n",
    "                          \"dividends\", \"strong cash\", \"low debt\", \"increasing earnings\", \"earnings\", \"rising dividend\",\n",
    "                          \"achievers\", \"volatility weighted\", \"long/cash\", \"low beta\", \"low size\"],\n",
    "    \"Active Discretionary\": [\"actively managed\", \"actively-managed\", \"manager believes\", \"manager's judgment\",\n",
    "                             \"active bottom‑up\", \"active strategy\", \"discretionary\", \"active management\",\n",
    "                             \"active-management\", \"machine learning\", \"ai\", \"research-driven\", \"fundamental\",\n",
    "                             \"strategically\", \"tactical allocation\", \"active\", \"rotation\", \"judgment\", \"analysis\",\n",
    "                             \"outperform\", \"selection\", \"tactical\", \"trend-following\", \"trend following\", \"Bottom-Up Approach\"\n",
    "                            \"the advisor\", \"advisor considers\", \"long-term\", \"appraisal\"],\n",
    "    \"Quant/Systematic\": [\"quantitative\", \"algorithm-driven\", \"systematic\", \"levered\", \"algorithm\", \"implied volatility\",\n",
    "                        \"data-driven\", \"back-tested\", \"long-short\", \"model-based\", \"rotation\", \"statistical\",\n",
    "                        \"rules-driven\", \"trend-following\", \"trend following\", \"tactical\", \"machine learning\", \"ai\",\n",
    "                        \"long/short\"],\n",
    "    \"Multi-Strategy\": [\"multi-strategy\", \"multi-asset\", \"hybrid strategy\", \"multi-manager\", \"dynamic allocation\",\n",
    "                      \"absolute return\", \"blended\", \"combination\", \"hybrid\", \"flexible\", \"alternative\"]\n",
    "}\n",
    "\n",
    "# Direct mapping keywords (added to existing keywords)\n",
    "direct_mappings = {\n",
    "    \"Active Discretionary\": [\"Active Management\", \"Actively Managed\", \"Discretionary\", \"Active Strategy\", \"Active\",\n",
    "                             \"Active Bottom-Up\", \"Active-Management\", \"Actively-Managed\", \"Actively\",\n",
    "                             \"Actively Allocates\", \"Active Allocation\", \"Active Trading\", \"Trading Actively\",\n",
    "                             \"Actively Trading\"],\n",
    "    \"Factor/Smart Beta\": [\"Rules-Based\", \"Factor-Based\", \"Multi-Factor\"],\n",
    "    \"Quant/Systematic\": []\n",
    "}\n",
    "\n",
    "# Update keywords with direct mappings\n",
    "for category, terms in direct_mappings.items():\n",
    "    keywords[category].extend(terms)\n",
    "\n",
    "# Convert keywords to lowercase for matching\n",
    "keywords = {cat: [term.lower() for term in terms] for cat, terms in keywords.items()}\n",
    "\n",
    "# Define meaningful categories for direct classification\n",
    "meaningful_categories = {\n",
    "    \"Index Based\": {\n",
    "        \"YC_Category\": [\"Target Maturity\", \"Digital Assets\", \"Single Currency\", \"Muni Target Maturity\"],\n",
    "        \"CWA_Broad_Category\": [\"Currency\", \"Digital Asset\", \"Single Stock\"],\n",
    "        \"YC_Global_Category\": [\"Currency\"]\n",
    "    },\n",
    "    \"Quant/Systematic\": {\n",
    "        \"CWA_Broad_Category\": [\"Defined Outcome\", \"Trading/Tactical\"],\n",
    "        \"YC_Global_Category\": [\"Defined Outcome\", \"Trading Tools\", \"Systematic Trend\"],\n",
    "        \"YC_Category\": [\"Trading--Inverse Commodities\", \"Trading--Inverse Debt\", \"Trading--Inverse Equity\",\n",
    "                        \"Trading--Leveraged Commodities\", \"Trading--Leveraged Debt\", \"Trading--Leveraged Equity\",\n",
    "                        \"Trading—Miscellaneous\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Simplified assist categories using pattern matching for \"Target-Date\" and \"Muni\"\n",
    "assist_categories = [\n",
    "    # Pattern-based rules\n",
    "    {\n",
    "        \"pattern\": \"Target-Date\",\n",
    "        \"cat_type\": \"YC_Category\",\n",
    "        \"actions\": {\"remove\": [\"Factor/Smart Beta\", \"Quant/Systematic\"]}\n",
    "    },\n",
    "    {\n",
    "        \"pattern\": \"Target Date\",\n",
    "        \"cat_type\": \"CWA_Broad_Category\",\n",
    "        \"actions\": {\"remove\": [\"Factor/Smart Beta\", \"Quant/Systematic\"]}\n",
    "    },\n",
    "    {\n",
    "        \"pattern\": \"Target Date\",\n",
    "        \"cat_type\": \"YC_Global_Category\",\n",
    "        \"actions\": {\"remove\": [\"Factor/Smart Beta\", \"Quant/Systematic\"]}\n",
    "    },\n",
    "    {\n",
    "        \"pattern\": \"Muni\",\n",
    "        \"cat_type\": \"YC_Category\",\n",
    "        \"actions\": {\"remove\": [\"Multi-Strategy\", \"Quant/Systematic\"]}\n",
    "    },\n",
    "    {\n",
    "        \"pattern\": \"US Municipal Fixed Income\",\n",
    "        \"cat_type\": \"YC_Global_Category\",\n",
    "        \"actions\": {\"remove\": [\"Multi-Strategy\", \"Quant/Systematic\"]}\n",
    "    },\n",
    "    # Exact match rules (non-patterned categories)\n",
    "    {\n",
    "        \"exact\": \"Commodity\",\n",
    "        \"cat_type\": \"CWA_Broad_Category\",\n",
    "        \"actions\": {\"remove\": [\"Factor/Smart Beta\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Commodities Broad Basket\",\n",
    "        \"cat_type\": \"YC_Category\",\n",
    "        \"actions\": {\"remove\": [\"Factor/Smart Beta\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Commodities Focused\",\n",
    "        \"cat_type\": \"YC_Category\",\n",
    "        \"actions\": {\"remove\": [\"Factor/Smart Beta\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Commodities Broad Basket\",\n",
    "        \"cat_type\": \"YC_Global_Category\",\n",
    "        \"actions\": {\"remove\": [\"Factor/Smart Beta\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Commodities Specified\",\n",
    "        \"cat_type\": \"YC_Global_Category\",\n",
    "        \"actions\": {\"remove\": [\"Factor/Smart Beta\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Long/Short Equity\",\n",
    "        \"cat_type\": \"YC_Global_Category\",\n",
    "        \"actions\": {\"boost\": [\"Active Discretionary\", \"Quant/Systematic\"],\n",
    "                    \"remove\": [\"Multi-Strategy\", \"Factor/Smart Beta\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"inflation-protected bond\",\n",
    "        \"cat_type\": \"YC_Category\",\n",
    "        \"actions\": {\"boost\": [\"Active Discretionary\", \"Index Based\"],\n",
    "                    \"remove\": [\"Multi-Strategy\", \"Factor/Smart Beta\", \"Quant/Systematic\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Nontraditional\",\n",
    "        \"cat_type\": \"CWA_Broad_Category\",\n",
    "        \"actions\": {\"boost\": [\"Active Discretionary\", \"Factor/Smart Beta\", \"Quant/Systematic\"],\n",
    "                    \"remove\": [\"Index Based\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Nontraditional Equity\",\n",
    "        \"cat_type\": \"YC_Broad_Asset_Class\",\n",
    "        \"actions\": {\"boost\": [\"Active Discretionary\", \"Factor/Smart Beta\", \"Quant/Systematic\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Sector/Industry\",\n",
    "        \"cat_type\": \"CWA_Broad_Category\",\n",
    "        \"actions\": {\"boost\": [\"Active Discretionary\", \"Index Based\", \"Factor/Smart Beta\"]}\n",
    "    }\n",
    "]\n",
    "\n",
    "# Load data from database (select only ID columns)\n",
    "query_funds = \"\"\"\n",
    "SELECT SymbolCUSIP, ProductName, fund_family, investment_strategy, FS_insight, index_fund,\n",
    "       inverse_fund, leveraged_fund, socially_responsible_fund, synthetic_replication_fund,\n",
    "       fund_of_funds, ycharts_url, YC_Category_ID, CWA_Broad_Category_ID,\n",
    "       YC_Global_Category_ID, YC_Broad_Asset_Class_ID,\n",
    "       currency_hedged_fund\n",
    "FROM Funds_to_Screen\n",
    "\"\"\"\n",
    "funds_df = pd.read_sql(query_funds, engine)\n",
    "\n",
    "# Load category mappings with exact column names from your prompt\n",
    "category_mappings = {\n",
    "    \"CWA_Broad_Category\": pd.read_sql(\"SELECT ID, CWA_Broad_Category_Name FROM CWA_Broad_Category_List\", engine),\n",
    "    \"YC_Category\": pd.read_sql(\"SELECT ID, Category_Name FROM YC_Category_List\", engine),\n",
    "    \"YC_Global_Category\": pd.read_sql(\"SELECT ID, Global_Category_Name FROM YC_Global_Category_List\", engine),\n",
    "    \"YC_Broad_Asset_Class\": pd.read_sql(\"SELECT ID, YC_Broad_Asset_Class_Name FROM YC_Broad_Asset_Class_List\", engine)\n",
    "}\n",
    "\n",
    "# Merge category names into funds_df using the ID columns, drop 'ID' after each merge\n",
    "funds_df = funds_df.merge(category_mappings[\"CWA_Broad_Category\"], left_on=\"CWA_Broad_Category_ID\", right_on=\"ID\", how=\"left\").drop(columns=[\"ID\"])\n",
    "funds_df = funds_df.merge(category_mappings[\"YC_Category\"], left_on=\"YC_Category_ID\", right_on=\"ID\", how=\"left\").drop(columns=[\"ID\"])\n",
    "funds_df = funds_df.merge(category_mappings[\"YC_Global_Category\"], left_on=\"YC_Global_Category_ID\", right_on=\"ID\", how=\"left\").drop(columns=[\"ID\"])\n",
    "funds_df = funds_df.merge(category_mappings[\"YC_Broad_Asset_Class\"], left_on=\"YC_Broad_Asset_Class_ID\", right_on=\"ID\", how=\"left\").drop(columns=[\"ID\"])\n",
    "\n",
    "# Normalize Boolean fields (True/False and 1/0 to 1/0) and add debugging\n",
    "boolean_cols = [\"index_fund\", \"inverse_fund\", \"leveraged_fund\", \"socially_responsible_fund\",\n",
    "               \"synthetic_replication_fund\", \"fund_of_funds\", \"currency_hedged_fund\"]\n",
    "# Debug raw values before normalization\n",
    "print(\"Raw index_fund values before normalization:\", funds_df[\"index_fund\"].head().tolist())\n",
    "# Normalize with broader type handling\n",
    "for col in boolean_cols:\n",
    "    funds_df[col] = funds_df[col].apply(lambda x: 1 if str(x).lower() in ['true', '1', 'yes'] else 0)\n",
    "# Debug after normalization\n",
    "print(\"Index_fund values after normalization:\", funds_df[\"index_fund\"].head().tolist())\n",
    "# Specifically check IJH\n",
    "print(\"IJH index_fund after normalization:\", funds_df[funds_df[\"SymbolCUSIP\"] == \"IJH\"][\"index_fund\"].values)\n",
    "\n",
    "# Initialize dictionaries to track scoring components\n",
    "categories = [\"Index Based\", \"Factor/Smart Beta\", \"Active Discretionary\", \"Quant/Systematic\", \"Multi-Strategy\"]\n",
    "\n",
    "# Initialize final score columns\n",
    "for cat in categories:\n",
    "    score_col = f\"score_{cat}\"\n",
    "    funds_df[score_col] = 0.0\n",
    "\n",
    "# Initialize intermediate score columns for each component\n",
    "for cat in categories:\n",
    "    funds_df[f\"keyword_score_{cat}\"] = 0.0\n",
    "    funds_df[f\"meaningful_score_{cat}\"] = 0.0\n",
    "    funds_df[f\"assist_score_{cat}\"] = 0.0\n",
    "    funds_df[f\"boolean_score_{cat}\"] = 0.0\n",
    "    funds_df[f\"fundfamily_score_{cat}\"] = 0.0\n",
    "\n",
    "# Initialize columns to track matched keywords (concatenate matched keywords as strings)\n",
    "for cat in categories:\n",
    "    funds_df[f\"matched_keywords_{cat}\"] = \"\"\n",
    "\n",
    "# Debugging: Print columns to confirm score columns are created\n",
    "print(\"Columns after initializing scores:\", funds_df.columns.tolist())\n",
    "\n",
    "# Function to count keywords and return matched keywords\n",
    "def count_keywords(text, keyword_list):\n",
    "    if pd.isna(text):\n",
    "        return 0, \"\"\n",
    "    text = text.lower()\n",
    "    matches = [keyword for keyword in keyword_list if re.search(r'\\b' + re.escape(keyword) + r'\\b', text)]\n",
    "    return len(matches), \"; \".join(matches)\n",
    "\n",
    "# Apply scoring based on keywords and track matched keywords\n",
    "text_columns = [\"ProductName\", \"investment_strategy\", \"FS_insight\"]\n",
    "for cat, kw_list in keywords.items():\n",
    "    score_col = f\"keyword_score_{cat}\"\n",
    "    matched_col = f\"matched_keywords_{cat}\"\n",
    "    for text_col in text_columns:\n",
    "        counts_and_matches = funds_df[text_col].apply(lambda x: count_keywords(x, kw_list))\n",
    "        funds_df[score_col] += counts_and_matches.apply(lambda x: x[0])\n",
    "        funds_df[matched_col] = funds_df[matched_col] + \"; \" + counts_and_matches.apply(lambda x: x[1])\n",
    "    # Clean up matched keywords column (remove duplicate semicolons, trim)\n",
    "    funds_df[matched_col] = funds_df[matched_col].str.replace(r'\\s*;\\s*;\\s*', '; ', regex=True).str.strip('; ')\n",
    "\n",
    "# Apply meaningful category rules\n",
    "for cat, mappings in meaningful_categories.items():\n",
    "    score_col = f\"meaningful_score_{cat}\"\n",
    "    for map_type, values in mappings.items():\n",
    "        col_name = {\n",
    "            \"CWA_Broad_Category\": \"CWA_Broad_Category_Name\",\n",
    "            \"YC_Category\": \"Category_Name\",\n",
    "            \"YC_Global_Category\": \"Global_Category_Name\"\n",
    "        }[map_type]\n",
    "        funds_df.loc[funds_df[col_name].isin(values), score_col] += 10  # High score for direct match\n",
    "\n",
    "# Apply assist category rules with pattern matching\n",
    "for rule in assist_categories:\n",
    "    cat_type = rule[\"cat_type\"]\n",
    "    col_name = {\n",
    "        \"CWA_Broad_Category\": \"CWA_Broad_Category_Name\",\n",
    "        \"YC_Category\": \"Category_Name\",\n",
    "        \"YC_Global_Category\": \"Global_Category_Name\",\n",
    "        \"YC_Broad_Asset_Class\": \"YC_Broad_Asset_Class_Name\"\n",
    "    }[cat_type]\n",
    "    actions = rule[\"actions\"]\n",
    "\n",
    "    if \"pattern\" in rule:\n",
    "        pattern = rule[\"pattern\"]\n",
    "        mask = funds_df[col_name].fillna(\"\").str.contains(pattern, case=False, na=False)\n",
    "        matches = funds_df[mask][[\"SymbolCUSIP\", col_name]]\n",
    "        if not matches.empty:\n",
    "            print(f\"Assist category pattern '{pattern}' matches for {cat_type}:\")\n",
    "            print(matches.head())\n",
    "    else:\n",
    "        exact_value = rule[\"exact\"]\n",
    "        mask = funds_df[col_name].fillna(\"\").str.contains(exact_value, case=False, na=False)\n",
    "        matches = funds_df[mask][[\"SymbolCUSIP\", col_name]]\n",
    "        if not matches.empty:\n",
    "            print(f\"Assist category exact '{exact_value}' matches for {cat_type}:\")\n",
    "            print(matches.head())\n",
    "\n",
    "    if \"remove\" in actions:\n",
    "        for remove_cat in actions[\"remove\"]:\n",
    "            score_col = f\"assist_score_{remove_cat}\"\n",
    "            funds_df.loc[mask, score_col] = -float('inf')\n",
    "    if \"boost\" in actions:\n",
    "        for boost_cat in actions[\"boost\"]:\n",
    "            score_col = f\"assist_score_{boost_cat}\"\n",
    "            funds_df.loc[mask, score_col] += 5\n",
    "\n",
    "# Reset any assist scores not explicitly set to 0 (avoid incorrect leftovers like 0.25)\n",
    "for cat in categories:\n",
    "    score_col = f\"assist_score_{cat}\"\n",
    "    funds_df[score_col] = funds_df[score_col].replace(0.25, 0)  # Explicitly correct erroneous 0.25 values\n",
    "\n",
    "# Apply Boolean rules and track contributions\n",
    "# Rule 1: Categorize as Index Based\n",
    "mask_index = (funds_df[\"index_fund\"] == 1) & (\n",
    "    (funds_df[\"inverse_fund\"] == 1) |\n",
    "    (funds_df[\"leveraged_fund\"] == 1) |\n",
    "    (funds_df[\"socially_responsible_fund\"] == 1) |\n",
    "    (funds_df[\"synthetic_replication_fund\"] == 1)\n",
    ")\n",
    "funds_df.loc[mask_index, \"boolean_score_Index Based\"] += 20  # High score for direct categorization\n",
    "\n",
    "# Rule 2: Remove Active Discretionary and Quant/Systematic if index_fund = True\n",
    "mask_remove = funds_df[\"index_fund\"] == 1\n",
    "funds_df.loc[mask_remove, \"boolean_score_Active Discretionary\"] = -float('inf')\n",
    "funds_df.loc[mask_remove, \"boolean_score_Quant/Systematic\"] = -float('inf')\n",
    "\n",
    "# Rule 3: Boost Index Based and Factor/Smart Beta if index_fund = True\n",
    "funds_df.loc[mask_remove, \"boolean_score_Index Based\"] += 5\n",
    "funds_df.loc[mask_remove, \"boolean_score_Factor/Smart Beta\"] += 5\n",
    "\n",
    "# Rule 4: Remove Index Based if index_fund = False\n",
    "funds_df.loc[funds_df[\"index_fund\"] == 0, \"boolean_score_Index Based\"] = -float('inf')\n",
    "\n",
    "# Rule 5: Remove Active Discretionary and Quant/Systematic if index_fund and fund_of_funds = True\n",
    "mask_remove2 = (funds_df[\"index_fund\"] == 1) & (funds_df[\"fund_of_funds\"] == 1)\n",
    "funds_df.loc[mask_remove2, \"boolean_score_Active Discretionary\"] = -float('inf')\n",
    "funds_df.loc[mask_remove2, \"boolean_score_Quant/Systematic\"] = -float('inf')\n",
    "\n",
    "# Rule 6: Boost Active Discretionary, Quant/Systematic, Multi-Strategy if fund_of_funds = True\n",
    "mask_boost = funds_df[\"fund_of_funds\"] == 1\n",
    "funds_df.loc[mask_boost, \"boolean_score_Active Discretionary\"] += 5\n",
    "funds_df.loc[mask_boost, \"boolean_score_Quant/Systematic\"] += 5\n",
    "funds_df.loc[mask_boost, \"boolean_score_Multi-Strategy\"] += 5\n",
    "\n",
    "# Rule 7: Boost Active Discretionary and Index Based if currency_hedged_fund = True\n",
    "mask_currency = funds_df[\"currency_hedged_fund\"] == 1\n",
    "funds_df.loc[mask_currency, \"boolean_score_Active Discretionary\"] += 5\n",
    "funds_df.loc[mask_currency, \"boolean_score_Index Based\"] += 5\n",
    "\n",
    "# Rule 8: Remove Factor/Smart Beta if currency_hedged_fund = True\n",
    "funds_df.loc[mask_currency, \"boolean_score_Factor/Smart Beta\"] = -float('inf')\n",
    "\n",
    "# Merge FundFamilyData and apply as a weighted factor\n",
    "fund_family_df = pd.read_sql(\"SELECT FundFamilyName, Dist_Index, Dist_Active, Dist_Rules_Based, Dist_Quant, Dist_Multi FROM FundFamilyData\", engine)\n",
    "funds_df = funds_df.merge(fund_family_df, left_on=\"fund_family\", right_on=\"FundFamilyName\", how=\"left\")\n",
    "funds_df[\"Dist_Index\"] = funds_df[\"Dist_Index\"].fillna(0) / 100\n",
    "funds_df[\"Dist_Active\"] = funds_df[\"Dist_Active\"].fillna(0) / 100\n",
    "funds_df[\"Dist_Rules_Based\"] = funds_df[\"Dist_Rules_Based\"].fillna(0) / 100\n",
    "funds_df[\"Dist_Quant\"] = funds_df[\"Dist_Quant\"].fillna(0) / 100\n",
    "funds_df[\"Dist_Multi\"] = funds_df[\"Dist_Multi\"].fillna(0) / 100\n",
    "\n",
    "# Apply fund family scoring\n",
    "funds_df[\"fundfamily_score_Index Based\"] += funds_df[\"Dist_Index\"] * FUND_FAMILY_SCALE_FACTOR\n",
    "funds_df[\"fundfamily_score_Active Discretionary\"] += funds_df[\"Dist_Active\"] * FUND_FAMILY_SCALE_FACTOR\n",
    "funds_df[\"fundfamily_score_Factor/Smart Beta\"] += funds_df[\"Dist_Rules_Based\"] * FUND_FAMILY_SCALE_FACTOR\n",
    "funds_df[\"fundfamily_score_Quant/Systematic\"] += funds_df[\"Dist_Quant\"] * FUND_FAMILY_SCALE_FACTOR\n",
    "funds_df[\"fundfamily_score_Multi-Strategy\"] += funds_df[\"Dist_Multi\"] * FUND_FAMILY_SCALE_FACTOR\n",
    "\n",
    "# Sum all intermediate scores into final scores\n",
    "for cat in categories:\n",
    "    score_col = f\"score_{cat}\"\n",
    "    funds_df[score_col] = (\n",
    "        funds_df[f\"keyword_score_{cat}\"] +\n",
    "        funds_df[f\"meaningful_score_{cat}\"] +\n",
    "        funds_df[f\"assist_score_{cat}\"] +\n",
    "        funds_df[f\"boolean_score_{cat}\"] +\n",
    "        funds_df[f\"fundfamily_score_{cat}\"]\n",
    "    )\n",
    "\n",
    "# Determine final category with tiebreaker based on keyword scores\n",
    "score_columns = [f\"score_{cat}\" for cat in categories]\n",
    "# Initial idxmax\n",
    "funds_df[\"Return_Driver\"] = funds_df[score_columns].idxmax(axis=1).apply(\n",
    "    lambda x: x.replace(\"score_\", \"\") if pd.notnull(x) else \"None\"\n",
    ")\n",
    "# Apply tiebreaker: if scores are tied, prefer category with higher keyword score\n",
    "for idx in funds_df.index:\n",
    "    scores = funds_df.loc[idx, score_columns]\n",
    "    max_score = scores.max()\n",
    "    tied_categories = [col for col, score in scores.items() if score == max_score]\n",
    "    if len(tied_categories) > 1:\n",
    "        # Find category with highest keyword score among tied categories\n",
    "        keyword_scores = {col: funds_df.loc[idx, f\"keyword_score_{col.replace('score_', '')}\"] for col in tied_categories}\n",
    "        max_keyword_score = max(keyword_scores.values())\n",
    "        best_tied_category = max(keyword_scores, key=keyword_scores.get)\n",
    "        funds_df.loc[idx, \"Return_Driver\"] = best_tied_category.replace(\"score_\", \"\")\n",
    "\n",
    "# Export to Excel with all details in the specified order\n",
    "output_columns = (\n",
    "    # Primary identifiers and results\n",
    "    [\"SymbolCUSIP\", \"ProductName\", \"fund_family\", \"Return_Driver\", \"ycharts_url\"] +\n",
    "    \n",
    "    # Final scores for each category\n",
    "    [f\"score_{cat}\" for cat in categories] +\n",
    "    \n",
    "    # Intermediate scores for each scoring component\n",
    "    [f\"keyword_score_{cat}\" for cat in categories] +\n",
    "    [f\"meaningful_score_{cat}\" for cat in categories] +\n",
    "    [f\"assist_score_{cat}\" for cat in categories] +\n",
    "    [f\"boolean_score_{cat}\" for cat in categories] +\n",
    "    [f\"fundfamily_score_{cat}\" for cat in categories] +\n",
    "    \n",
    "    # Everything else (inputs, matched keywords, etc.)\n",
    "    [f\"matched_keywords_{cat}\" for cat in categories] +\n",
    "    [\"CWA_Broad_Category_Name\", \"Category_Name\", \"Global_Category_Name\", \"YC_Broad_Asset_Class_Name\"] +\n",
    "    [\"index_fund\", \"inverse_fund\", \"leveraged_fund\", \"socially_responsible_fund\", \"synthetic_replication_fund\", \"fund_of_funds\", \"currency_hedged_fund\"] +\n",
    "    [\"Dist_Index\", \"Dist_Active\", \"Dist_Rules_Based\", \"Dist_Quant\", \"Dist_Multi\"]\n",
    ")\n",
    "\n",
    "funds_df[output_columns].to_excel(output_path, index=False)\n",
    "print(f\"Results exported to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88ebee99-3e67-4b7b-830e-464b48b12511",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw index_fund values before normalization: ['0', '1', '1', '1', '1']\n",
      "Index_fund values after normalization: [0, 1, 1, 1, 1]\n",
      "VLUE index_fund after normalization: [1]\n",
      "Columns after initializing scores: ['SymbolCUSIP', 'ProductName', 'fund_family', 'investment_strategy', 'FS_insight', 'index_fund', 'inverse_fund', 'leveraged_fund', 'socially_responsible_fund', 'synthetic_replication_fund', 'fund_of_funds', 'ycharts_url', 'YC_Category_ID', 'CWA_Broad_Category_ID', 'YC_Global_Category_ID', 'YC_Broad_Asset_Class_ID', 'currency_hedged_fund', 'CWA_Broad_Category_Name', 'Category_Name', 'Global_Category_Name', 'YC_Broad_Asset_Class_Name', 'score_index_based', 'score_rules_based', 'score_active_discretionary', 'score_quant_systematic', 'score_multi_strategy', 'keyword_score_index_based', 'meaningful_score_index_based', 'assist_score_index_based', 'boolean_score_index_based', 'fundfamily_score_index_based', 'keyword_score_rules_based', 'meaningful_score_rules_based', 'assist_score_rules_based', 'boolean_score_rules_based', 'fundfamily_score_rules_based', 'keyword_score_active_discretionary', 'meaningful_score_active_discretionary', 'assist_score_active_discretionary', 'boolean_score_active_discretionary', 'fundfamily_score_active_discretionary', 'keyword_score_quant_systematic', 'meaningful_score_quant_systematic', 'assist_score_quant_systematic', 'boolean_score_quant_systematic', 'fundfamily_score_quant_systematic', 'keyword_score_multi_strategy', 'meaningful_score_multi_strategy', 'assist_score_multi_strategy', 'boolean_score_multi_strategy', 'fundfamily_score_multi_strategy', 'matched_keywords_index_based', 'matched_keywords_rules_based', 'matched_keywords_active_discretionary', 'matched_keywords_quant_systematic', 'matched_keywords_multi_strategy']\n",
      "Meaningful category matches for Index Based, YC_Category:\n",
      "     SymbolCUSIP   Category_Name\n",
      "163         BLOK  Digital Assets\n",
      "223         SPBC  Digital Assets\n",
      "1827        BLCN  Digital Assets\n",
      "1828        LEGR  Digital Assets\n",
      "1829        BCDF  Digital Assets\n",
      "Meaningful category matches for Index Based, CWA_Broad_Category:\n",
      "    SymbolCUSIP CWA_Broad_Category_Name\n",
      "415        DFCA            Single Stock\n",
      "416         PWZ            Single Stock\n",
      "436         PZT            Single Stock\n",
      "437        CALI            Single Stock\n",
      "582       AAZYX            Single Stock\n",
      "Meaningful category matches for Quant Systematic, CWA_Broad_Category:\n",
      "     SymbolCUSIP CWA_Broad_Category_Name\n",
      "5583        RSBT        Trading/Tactical\n",
      "5584        RSST        Trading/Tactical\n",
      "5585        RSBY        Trading/Tactical\n",
      "Meaningful category matches for Quant Systematic, YC_Global_Category:\n",
      "     SymbolCUSIP Global_Category_Name\n",
      "59           ZSL        Trading Tools\n",
      "60          KOLD        Trading Tools\n",
      "232         RSSY        Trading Tools\n",
      "1258         SCO        Trading Tools\n",
      "1259         GLL        Trading Tools\n",
      "Meaningful category matches for Quant Systematic, YC_Category:\n",
      "     SymbolCUSIP                 Category_Name\n",
      "59           ZSL  Trading--Inverse Commodities\n",
      "60          KOLD  Trading--Inverse Commodities\n",
      "232         RSSY     Trading--Leveraged Equity\n",
      "1258         SCO  Trading--Inverse Commodities\n",
      "1259         GLL  Trading--Inverse Commodities\n",
      "Assist category pattern 'Muni' matches for YC_Category:\n",
      "    SymbolCUSIP                 Category_Name\n",
      "164         VOX                Communications\n",
      "415        DFCA  Muni California Intermediate\n",
      "416         PWZ          Muni California Long\n",
      "417        AVMU          Muni National Interm\n",
      "418         ITM          Muni National Interm\n",
      "Assist category pattern 'US Municipal Fixed Income' matches for YC_Global_Category:\n",
      "    SymbolCUSIP       Global_Category_Name\n",
      "415        DFCA  US Municipal Fixed Income\n",
      "416         PWZ  US Municipal Fixed Income\n",
      "417        AVMU  US Municipal Fixed Income\n",
      "418         ITM  US Municipal Fixed Income\n",
      "419        MUST  US Municipal Fixed Income\n",
      "Assist category exact 'Commodity' matches for CWA_Broad_Category:\n",
      "   SymbolCUSIP CWA_Broad_Category_Name\n",
      "26        FAAR               Commodity\n",
      "42        CMDY               Commodity\n",
      "43        NBCM               Commodity\n",
      "44        CERY               Commodity\n",
      "45        EDGH               Commodity\n",
      "Assist category exact 'Commodities Broad Basket' matches for YC_Category:\n",
      "   SymbolCUSIP             Category_Name\n",
      "26        FAAR  Commodities Broad Basket\n",
      "42        CMDY  Commodities Broad Basket\n",
      "43        NBCM  Commodities Broad Basket\n",
      "44        CERY  Commodities Broad Basket\n",
      "45        EDGH  Commodities Broad Basket\n",
      "Assist category exact 'Commodities Focused' matches for YC_Category:\n",
      "   SymbolCUSIP        Category_Name\n",
      "46        AAAU  Commodities Focused\n",
      "47        GLDM  Commodities Focused\n",
      "48         DBE  Commodities Focused\n",
      "49        CPER  Commodities Focused\n",
      "50        CORN  Commodities Focused\n",
      "Assist category exact 'Commodities Broad Basket' matches for YC_Global_Category:\n",
      "   SymbolCUSIP      Global_Category_Name\n",
      "26        FAAR  Commodities Broad Basket\n",
      "42        CMDY  Commodities Broad Basket\n",
      "43        NBCM  Commodities Broad Basket\n",
      "44        CERY  Commodities Broad Basket\n",
      "45        EDGH  Commodities Broad Basket\n",
      "Assist category exact 'Commodities Specified' matches for YC_Global_Category:\n",
      "   SymbolCUSIP   Global_Category_Name\n",
      "46        AAAU  Commodities Specified\n",
      "47        GLDM  Commodities Specified\n",
      "48         DBE  Commodities Specified\n",
      "49        CPER  Commodities Specified\n",
      "50        CORN  Commodities Specified\n",
      "Assist category exact 'Long/Short Equity' matches for YC_Global_Category:\n",
      "     SymbolCUSIP Global_Category_Name\n",
      "29          FTLS    Long/Short Equity\n",
      "30          FFLS    Long/Short Equity\n",
      "31          CLSE    Long/Short Equity\n",
      "32          LBAY    Long/Short Equity\n",
      "1171        LSEQ    Long/Short Equity\n",
      "Assist category exact 'inflation-protected bond' matches for YC_Category:\n",
      "    SymbolCUSIP             Category_Name\n",
      "469        LTPZ  Inflation-Protected Bond\n",
      "470         TIP  Inflation-Protected Bond\n",
      "471        TIPZ  Inflation-Protected Bond\n",
      "472        TDTF  Inflation-Protected Bond\n",
      "473        LDRI  Inflation-Protected Bond\n",
      "Assist category exact 'Nontraditional' matches for CWA_Broad_Category:\n",
      "    SymbolCUSIP CWA_Broad_Category_Name\n",
      "27         VEGA          Nontraditional\n",
      "28         BUYW          Nontraditional\n",
      "141        SIXH          Nontraditional\n",
      "142        DISO          Nontraditional\n",
      "143        JPMO          Nontraditional\n",
      "Assist category exact 'Nontraditional Equity' matches for YC_Broad_Asset_Class:\n",
      "    SymbolCUSIP YC_Broad_Asset_Class_Name\n",
      "141        SIXH     Nontraditional Equity\n",
      "142        DISO     Nontraditional Equity\n",
      "143        JPMO     Nontraditional Equity\n",
      "144        XOMO     Nontraditional Equity\n",
      "145        PYPY     Nontraditional Equity\n",
      "Assist category exact 'Sector/Industry' matches for CWA_Broad_Category:\n",
      "    SymbolCUSIP CWA_Broad_Category_Name\n",
      "140        GMET         Sector/Industry\n",
      "163        BLOK         Sector/Industry\n",
      "164         VOX         Sector/Industry\n",
      "165         VCR         Sector/Industry\n",
      "166        IEDI         Sector/Industry\n",
      "Excel output skipped (write_to_excel=False). Data written to database.\n"
     ]
    }
   ],
   "source": [
    "# Likely final classification of Return Drivers via Grok\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.sql import text\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# Adjustable scaling factor for fund family distribution\n",
    "FUND_FAMILY_SCALE_FACTOR = 5  # Adjust this value to change the influence of fund family data\n",
    "\n",
    "# Adjustable toggle for Excel output (default off)\n",
    "write_to_excel = False  # Set to True to generate Excel output, False to skip\n",
    "\n",
    "# Define output path for Excel (if used)\n",
    "output_path = r\"C:\\Users\\JulianHeron\\Software Projects\\Return_Drivers_V1.xlsx\"\n",
    "\n",
    "# Database connection\n",
    "connection_string = (\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/\"\n",
    "    \"CWA_Fund_Database?driver=ODBC+Driver+18+for+SQL+Server\"\n",
    "    \"&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Define keywords for each category\n",
    "keywords = {\n",
    "    \"Index Based\": [\"index fund\", \"tracks\", \"replicates\", \"indexed\", \"underlying index\", \"thematic\", \"passive\",\n",
    "                    \"economic characteristics that are substantially\", \"bond index\", \"market-cap weighted\",\n",
    "                    \"low tracking error\", \"high correlation\", \"benchmark\", \"low-cost\", \"broad market exposure\",\n",
    "                    \"aggregate bond\", \"mirrors\", \"equal-weighted\", \"beta\", \"value index\", \"growth index\"],\n",
    "    \"Rules Based\": [\"rules-based\", \"factor-based\", \"factor tilt\", \"multi-factor\", \"factor investing\", \"momentum\",\n",
    "                    \"low volatility\", \"low vol\", \"value factor\", \"quality\", \"quality factor\", \"free cash flow\",\n",
    "                    \"fcf\", \"objective\", \"relatively\", \"go up\", \"certain fundamental metrics\", \"momentum index\",\n",
    "                    \"quality index\", \"relatively lower valuations\", \"factors\", \"minimum volatility\",\n",
    "                    \"high dividend yield\", \"enhanced index\", \"revenue weighted\", \"dividend weighted\",\n",
    "                    \"enhanced returns\", \"fundamental weighting\", \"yield weighted\", \"low volatility\", \"rotation\",\n",
    "                    \"rules based methodology\", \"cash cows\", \"alphaDEX\", \"ranked\", \"lower volatility\",\n",
    "                    \"tilt\", \"optimized\", \"component securities\", \"economic characteristics\", \"free cash flow yield\",\n",
    "                    \"high dividend yields\", \"ranking system\", \"consistently increased dividends\", \"dividend\",\n",
    "                    \"dividends\", \"strong cash\", \"low debt\", \"increasing earnings\", \"earnings\", \"rising dividend\",\n",
    "                    \"achievers\", \"volatility weighted\", \"long/cash\", \"low beta\", \"low size\"],\n",
    "    \"Active Discretionary\": [\"actively managed\", \"actively-managed\", \"manager believes\", \"manager's judgment\",\n",
    "                             \"active bottom‑up\", \"active strategy\", \"discretionary\", \"active management\",\n",
    "                             \"active-management\", \"machine learning\", \"ai\", \"research-driven\", \"fundamental\",\n",
    "                             \"strategically\", \"tactical allocation\", \"active\", \"rotation\", \"judgment\", \"analysis\",\n",
    "                             \"outperform\", \"selection\", \"tactical\", \"trend-following\", \"trend following\", \"Bottom-Up Approach\"\n",
    "                            \"the advisor\", \"advisor considers\", \"long-term\", \"appraisal\"],\n",
    "    \"Quant Systematic\": [\"quantitative\", \"algorithm-driven\", \"systematic\", \"levered\", \"algorithm\", \"implied volatility\",\n",
    "                        \"data-driven\", \"back-tested\", \"long-short\", \"model-based\", \"rotation\", \"statistical\",\n",
    "                        \"rules-driven\", \"trend-following\", \"trend following\", \"tactical\", \"machine learning\", \"ai\",\n",
    "                        \"long/short\"],\n",
    "    \"Multi Strategy\": [\"multi-strategy\", \"multi-asset\", \"hybrid strategy\", \"multi-manager\", \"dynamic allocation\",\n",
    "                      \"absolute return\", \"blended\", \"combination\", \"hybrid\", \"flexible\", \"alternative\"]\n",
    "}\n",
    "\n",
    "# Direct mapping keywords (added to existing keywords)\n",
    "direct_mappings = {\n",
    "    \"Active Discretionary\": [\"Active Management\", \"Actively Managed\", \"Discretionary\", \"Active Strategy\", \"Active\",\n",
    "                             \"Active Bottom-Up\", \"Active-Management\", \"Actively-Managed\", \"Actively\",\n",
    "                             \"Actively Allocates\", \"Active Allocation\", \"Active Trading\", \"Trading Actively\",\n",
    "                             \"Actively Trading\"],\n",
    "    \"Rules Based\": [\"Rules-Based\", \"Factor-Based\", \"Multi-Factor\"],\n",
    "    \"Quant Systematic\": []\n",
    "}\n",
    "\n",
    "# Update keywords with direct mappings\n",
    "for category, terms in direct_mappings.items():\n",
    "    keywords[category].extend(terms)\n",
    "\n",
    "# Convert keywords to lowercase for matching\n",
    "keywords = {cat: [term.lower() for term in terms] for cat, terms in keywords.items()}\n",
    "\n",
    "# Define meaningful categories for direct classification\n",
    "meaningful_categories = {\n",
    "    \"Index Based\": {\n",
    "        \"YC_Category\": [\"Target Maturity\", \"Digital Assets\", \"Single Currency\", \"Muni Target Maturity\"],\n",
    "        \"CWA_Broad_Category\": [\"Currency\", \"Digital Asset\", \"Single Stock\"],\n",
    "        \"YC_Global_Category\": [\"Currency\"]\n",
    "    },\n",
    "    \"Quant Systematic\": {\n",
    "        \"CWA_Broad_Category\": [\"Defined Outcome\", \"Trading/Tactical\"],\n",
    "        \"YC_Global_Category\": [\"Defined Outcome\", \"Trading Tools\", \"Systematic Trend\"],\n",
    "        \"YC_Category\": [\"Trading--Inverse Commodities\", \"Trading--Inverse Debt\", \"Trading--Inverse Equity\",\n",
    "                        \"Trading--Leveraged Commodities\", \"Trading--Leveraged Debt\", \"Trading--Leveraged Equity\",\n",
    "                        \"Trading—Miscellaneous\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Simplified assist categories using pattern matching for \"Target-Date\" and \"Muni\"\n",
    "assist_categories = [\n",
    "    # Pattern-based rules\n",
    "    {\n",
    "        \"pattern\": \"Target-Date\",\n",
    "        \"cat_type\": \"YC_Category\",\n",
    "        \"actions\": {\"remove\": [\"Rules Based\", \"Quant Systematic\"]}\n",
    "    },\n",
    "    {\n",
    "        \"pattern\": \"Target Date\",\n",
    "        \"cat_type\": \"CWA_Broad_Category\",\n",
    "        \"actions\": {\"remove\": [\"Rules Based\", \"Quant Systematic\"]}\n",
    "    },\n",
    "    {\n",
    "        \"pattern\": \"Target Date\",\n",
    "        \"cat_type\": \"YC_Global_Category\",\n",
    "        \"actions\": {\"remove\": [\"Rules Based\", \"Quant Systematic\"]}\n",
    "    },\n",
    "    {\n",
    "        \"pattern\": \"Muni\",\n",
    "        \"cat_type\": \"YC_Category\",\n",
    "        \"actions\": {\"remove\": [\"Multi Strategy\", \"Quant Systematic\"]}\n",
    "    },\n",
    "    {\n",
    "        \"pattern\": \"US Municipal Fixed Income\",\n",
    "        \"cat_type\": \"YC_Global_Category\",\n",
    "        \"actions\": {\"remove\": [\"Multi Strategy\", \"Quant Systematic\"]}\n",
    "    },\n",
    "    # Exact match rules (non-patterned categories)\n",
    "    {\n",
    "        \"exact\": \"Commodity\",\n",
    "        \"cat_type\": \"CWA_Broad_Category\",\n",
    "        \"actions\": {\"remove\": [\"Rules Based\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Commodities Broad Basket\",\n",
    "        \"cat_type\": \"YC_Category\",\n",
    "        \"actions\": {\"remove\": [\"Rules Based\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Commodities Focused\",\n",
    "        \"cat_type\": \"YC_Category\",\n",
    "        \"actions\": {\"remove\": [\"Rules Based\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Commodities Broad Basket\",\n",
    "        \"cat_type\": \"YC_Global_Category\",\n",
    "        \"actions\": {\"remove\": [\"Rules Based\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Commodities Specified\",\n",
    "        \"cat_type\": \"YC_Global_Category\",\n",
    "        \"actions\": {\"remove\": [\"Rules Based\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Long/Short Equity\",\n",
    "        \"cat_type\": \"YC_Global_Category\",\n",
    "        \"actions\": {\"boost\": [\"Active Discretionary\", \"Quant Systematic\"],\n",
    "                    \"remove\": [\"Multi Strategy\", \"Rules Based\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"inflation-protected bond\",\n",
    "        \"cat_type\": \"YC_Category\",\n",
    "        \"actions\": {\"boost\": [\"Active Discretionary\", \"Index Based\"],\n",
    "                    \"remove\": [\"Multi Strategy\", \"Rules Based\", \"Quant Systematic\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Nontraditional\",\n",
    "        \"cat_type\": \"CWA_Broad_Category\",\n",
    "        \"actions\": {\"boost\": [\"Active Discretionary\", \"Rules Based\", \"Quant Systematic\"],\n",
    "                    \"remove\": [\"Index Based\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Nontraditional Equity\",\n",
    "        \"cat_type\": \"YC_Broad_Asset_Class\",\n",
    "        \"actions\": {\"boost\": [\"Active Discretionary\", \"Rules Based\", \"Quant Systematic\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Sector/Industry\",\n",
    "        \"cat_type\": \"CWA_Broad_Category\",\n",
    "        \"actions\": {\"boost\": [\"Active Discretionary\", \"Index Based\", \"Rules Based\"]}\n",
    "    }\n",
    "]\n",
    "\n",
    "# Load data from database (select only ID columns along with necessary fields)\n",
    "query_funds = \"\"\"\n",
    "SELECT SymbolCUSIP, ProductName, fund_family, investment_strategy, FS_insight, index_fund,\n",
    "       inverse_fund, leveraged_fund, socially_responsible_fund, synthetic_replication_fund,\n",
    "       fund_of_funds, ycharts_url, YC_Category_ID, CWA_Broad_Category_ID,\n",
    "       YC_Global_Category_ID, YC_Broad_Asset_Class_ID,\n",
    "       currency_hedged_fund\n",
    "FROM Funds_to_Screen\n",
    "\"\"\"\n",
    "funds_df = pd.read_sql(query_funds, engine)\n",
    "\n",
    "# Load category mappings with exact column names from your schema\n",
    "category_mappings = {\n",
    "    \"CWA_Broad_Category\": pd.read_sql(\"SELECT ID, CWA_Broad_Category_Name FROM CWA_Broad_Category_List\", engine),\n",
    "    \"YC_Category\": pd.read_sql(\"SELECT ID, Category_Name FROM YC_Category_List\", engine),\n",
    "    \"YC_Global_Category\": pd.read_sql(\"SELECT ID, Global_Category_Name FROM YC_Global_Category_List\", engine),\n",
    "    \"YC_Broad_Asset_Class\": pd.read_sql(\"SELECT ID, YC_Broad_Asset_Class_Name FROM YC_Broad_Asset_Class_List\", engine)\n",
    "}\n",
    "\n",
    "# Merge category names into funds_df using the ID columns, drop 'ID' after each merge\n",
    "funds_df = funds_df.merge(category_mappings[\"CWA_Broad_Category\"], left_on=\"CWA_Broad_Category_ID\", right_on=\"ID\", how=\"left\").drop(columns=[\"ID\"])\n",
    "funds_df = funds_df.merge(category_mappings[\"YC_Category\"], left_on=\"YC_Category_ID\", right_on=\"ID\", how=\"left\").drop(columns=[\"ID\"])\n",
    "funds_df = funds_df.merge(category_mappings[\"YC_Global_Category\"], left_on=\"YC_Global_Category_ID\", right_on=\"ID\", how=\"left\").drop(columns=[\"ID\"])\n",
    "funds_df = funds_df.merge(category_mappings[\"YC_Broad_Asset_Class\"], left_on=\"YC_Broad_Asset_Class_ID\", right_on=\"ID\", how=\"left\").drop(columns=[\"ID\"])\n",
    "\n",
    "# Normalize Boolean fields (True/False and 1/0 to 1/0) and add debugging\n",
    "boolean_cols = [\"index_fund\", \"inverse_fund\", \"leveraged_fund\", \"socially_responsible_fund\",\n",
    "               \"synthetic_replication_fund\", \"fund_of_funds\", \"currency_hedged_fund\"]\n",
    "# Debug raw values before normalization\n",
    "print(\"Raw index_fund values before normalization:\", funds_df[\"index_fund\"].head().tolist())\n",
    "# Normalize with broader type handling\n",
    "for col in boolean_cols:\n",
    "    funds_df[col] = funds_df[col].apply(lambda x: 1 if str(x).lower() in ['true', '1', 'yes'] else 0)\n",
    "# Debug after normalization\n",
    "print(\"Index_fund values after normalization:\", funds_df[\"index_fund\"].head().tolist())\n",
    "# Specifically check a few funds\n",
    "print(\"VLUE index_fund after normalization:\", funds_df[funds_df[\"SymbolCUSIP\"] == \"VLUE\"][\"index_fund\"].values)\n",
    "\n",
    "# Define categories with new names\n",
    "categories = [\"Index Based\", \"Rules Based\", \"Active Discretionary\", \"Quant Systematic\", \"Multi Strategy\"]\n",
    "category_mapping = {\n",
    "    \"Index Based\": \"index_based\",\n",
    "    \"Rules Based\": \"rules_based\",\n",
    "    \"Active Discretionary\": \"active_discretionary\",\n",
    "    \"Quant Systematic\": \"quant_systematic\",\n",
    "    \"Multi Strategy\": \"multi_strategy\"\n",
    "}\n",
    "\n",
    "# Initialize dictionaries to track scoring components\n",
    "for cat in categories:\n",
    "    db_cat = category_mapping[cat]\n",
    "    score_col = f\"score_{db_cat}\"\n",
    "    funds_df[score_col] = 0.0\n",
    "\n",
    "# Initialize intermediate score columns for each component\n",
    "for cat in categories:\n",
    "    db_cat = category_mapping[cat]\n",
    "    funds_df[f\"keyword_score_{db_cat}\"] = 0.0\n",
    "    funds_df[f\"meaningful_score_{db_cat}\"] = 0.0\n",
    "    funds_df[f\"assist_score_{db_cat}\"] = 0.0\n",
    "    funds_df[f\"boolean_score_{db_cat}\"] = 0.0\n",
    "    funds_df[f\"fundfamily_score_{db_cat}\"] = 0.0\n",
    "\n",
    "# Initialize columns to track matched keywords (concatenate matched keywords as strings)\n",
    "for cat in categories:\n",
    "    db_cat = category_mapping[cat]\n",
    "    funds_df[f\"matched_keywords_{db_cat}\"] = \"\"\n",
    "\n",
    "# Debugging: Print columns to confirm score columns are created\n",
    "print(\"Columns after initializing scores:\", funds_df.columns.tolist())\n",
    "\n",
    "# Function to count keywords and return matched keywords\n",
    "def count_keywords(text, keyword_list):\n",
    "    if pd.isna(text):\n",
    "        return 0, \"\"\n",
    "    text = text.lower()\n",
    "    matches = [keyword for keyword in keyword_list if re.search(r'\\b' + re.escape(keyword) + r'\\b', text)]\n",
    "    return len(matches), \"; \".join(matches)\n",
    "\n",
    "# Apply scoring based on keywords and track matched keywords\n",
    "text_columns = [\"ProductName\", \"investment_strategy\", \"FS_insight\"]\n",
    "for cat, kw_list in keywords.items():\n",
    "    db_cat = category_mapping[cat]\n",
    "    score_col = f\"keyword_score_{db_cat}\"\n",
    "    matched_col = f\"matched_keywords_{db_cat}\"\n",
    "    for text_col in text_columns:\n",
    "        counts_and_matches = funds_df[text_col].apply(lambda x: count_keywords(x, kw_list))\n",
    "        funds_df[score_col] += counts_and_matches.apply(lambda x: x[0])\n",
    "        funds_df[matched_col] = funds_df[matched_col] + \"; \" + counts_and_matches.apply(lambda x: x[1])\n",
    "    # Clean up matched keywords column (remove duplicate semicolons, trim)\n",
    "    funds_df[matched_col] = funds_df[matched_col].str.replace(r'\\s*;\\s*;\\s*', '; ', regex=True).str.strip('; ')\n",
    "\n",
    "# Apply meaningful category rules\n",
    "for cat, mappings in meaningful_categories.items():\n",
    "    db_cat = category_mapping[cat]\n",
    "    score_col = f\"meaningful_score_{db_cat}\"\n",
    "    for map_type, values in mappings.items():\n",
    "        col_name = {\n",
    "            \"CWA_Broad_Category\": \"CWA_Broad_Category_Name\",\n",
    "            \"YC_Category\": \"Category_Name\",\n",
    "            \"YC_Global_Category\": \"Global_Category_Name\"\n",
    "        }[map_type]\n",
    "        matches = funds_df[funds_df[col_name].isin(values)][[\"SymbolCUSIP\", col_name]]\n",
    "        if not matches.empty:\n",
    "            print(f\"Meaningful category matches for {cat}, {map_type}:\")\n",
    "            print(matches.head())\n",
    "        funds_df.loc[funds_df[col_name].isin(values), score_col] += 10  # High score for direct match\n",
    "\n",
    "# Apply assist category rules with pattern matching\n",
    "for rule in assist_categories:\n",
    "    cat_type = rule[\"cat_type\"]\n",
    "    col_name = {\n",
    "        \"CWA_Broad_Category\": \"CWA_Broad_Category_Name\",\n",
    "        \"YC_Category\": \"Category_Name\",\n",
    "        \"YC_Global_Category\": \"Global_Category_Name\",\n",
    "        \"YC_Broad_Asset_Class\": \"YC_Broad_Asset_Class_Name\"\n",
    "    }[cat_type]\n",
    "    actions = rule[\"actions\"]\n",
    "\n",
    "    if \"pattern\" in rule:\n",
    "        pattern = rule[\"pattern\"]\n",
    "        mask = funds_df[col_name].fillna(\"\").str.contains(pattern, case=False, na=False)\n",
    "        matches = funds_df[mask][[\"SymbolCUSIP\", col_name]]\n",
    "        if not matches.empty:\n",
    "            print(f\"Assist category pattern '{pattern}' matches for {cat_type}:\")\n",
    "            print(matches.head())\n",
    "    else:\n",
    "        exact_value = rule[\"exact\"]\n",
    "        mask = funds_df[col_name].fillna(\"\").str.contains(exact_value, case=False, na=False)\n",
    "        matches = funds_df[mask][[\"SymbolCUSIP\", col_name]]\n",
    "        if not matches.empty:\n",
    "            print(f\"Assist category exact '{exact_value}' matches for {cat_type}:\")\n",
    "            print(matches.head())\n",
    "\n",
    "    if \"remove\" in actions:\n",
    "        for remove_cat in actions[\"remove\"]:\n",
    "            db_remove_cat = category_mapping[remove_cat]\n",
    "            score_col = f\"assist_score_{db_remove_cat}\"\n",
    "            funds_df.loc[mask, score_col] = -float('inf')\n",
    "    if \"boost\" in actions:\n",
    "        for boost_cat in actions[\"boost\"]:\n",
    "            db_boost_cat = category_mapping[boost_cat]\n",
    "            score_col = f\"assist_score_{db_boost_cat}\"\n",
    "            funds_df.loc[mask, score_col] += 5\n",
    "\n",
    "# Reset any assist scores not explicitly set to 0 (avoid incorrect leftovers like 0.25)\n",
    "for cat in categories:\n",
    "    db_cat = category_mapping[cat]\n",
    "    score_col = f\"assist_score_{db_cat}\"\n",
    "    funds_df[score_col] = funds_df[score_col].replace(0.25, 0)\n",
    "\n",
    "# Apply Boolean rules and track contributions\n",
    "mask_index = (funds_df[\"index_fund\"] == 1) & (\n",
    "    (funds_df[\"inverse_fund\"] == 1) |\n",
    "    (funds_df[\"leveraged_fund\"] == 1) |\n",
    "    (funds_df[\"socially_responsible_fund\"] == 1) |\n",
    "    (funds_df[\"synthetic_replication_fund\"] == 1)\n",
    ")\n",
    "funds_df.loc[mask_index, \"boolean_score_index_based\"] += 20\n",
    "\n",
    "mask_remove = funds_df[\"index_fund\"] == 1\n",
    "funds_df.loc[mask_remove, \"boolean_score_active_discretionary\"] = -float('inf')\n",
    "funds_df.loc[mask_remove, \"boolean_score_quant_systematic\"] = -float('inf')\n",
    "\n",
    "funds_df.loc[mask_remove, \"boolean_score_index_based\"] += 5\n",
    "funds_df.loc[mask_remove, \"boolean_score_rules_based\"] += 5\n",
    "\n",
    "funds_df.loc[funds_df[\"index_fund\"] == 0, \"boolean_score_index_based\"] = -float('inf')\n",
    "\n",
    "mask_remove2 = (funds_df[\"index_fund\"] == 1) & (funds_df[\"fund_of_funds\"] == 1)\n",
    "funds_df.loc[mask_remove2, \"boolean_score_active_discretionary\"] = -float('inf')\n",
    "funds_df.loc[mask_remove2, \"boolean_score_quant_systematic\"] = -float('inf')\n",
    "\n",
    "mask_boost = funds_df[\"fund_of_funds\"] == 1\n",
    "funds_df.loc[mask_boost, \"boolean_score_active_discretionary\"] += 5\n",
    "funds_df.loc[mask_boost, \"boolean_score_quant_systematic\"] += 5\n",
    "funds_df.loc[mask_boost, \"boolean_score_multi_strategy\"] += 5\n",
    "\n",
    "mask_currency = funds_df[\"currency_hedged_fund\"] == 1\n",
    "funds_df.loc[mask_currency, \"boolean_score_active_discretionary\"] += 5\n",
    "funds_df.loc[mask_currency, \"boolean_score_index_based\"] += 5\n",
    "\n",
    "funds_df.loc[mask_currency, \"boolean_score_rules_based\"] = -float('inf')\n",
    "\n",
    "# Merge FundFamilyData and apply as a weighted factor\n",
    "fund_family_df = pd.read_sql(\"SELECT FundFamilyName, Dist_Index, Dist_Active, Dist_Rules_Based, Dist_Quant, Dist_Multi FROM FundFamilyData\", engine)\n",
    "funds_df = funds_df.merge(fund_family_df, left_on=\"fund_family\", right_on=\"FundFamilyName\", how=\"left\")\n",
    "funds_df[\"Dist_Index\"] = funds_df[\"Dist_Index\"].fillna(0) / 100\n",
    "funds_df[\"Dist_Active\"] = funds_df[\"Dist_Active\"].fillna(0) / 100\n",
    "funds_df[\"Dist_Rules_Based\"] = funds_df[\"Dist_Rules_Based\"].fillna(0) / 100\n",
    "funds_df[\"Dist_Quant\"] = funds_df[\"Dist_Quant\"].fillna(0) / 100\n",
    "funds_df[\"Dist_Multi\"] = funds_df[\"Dist_Multi\"].fillna(0) / 100\n",
    "\n",
    "funds_df[\"fundfamily_score_index_based\"] += funds_df[\"Dist_Index\"] * FUND_FAMILY_SCALE_FACTOR\n",
    "funds_df[\"fundfamily_score_active_discretionary\"] += funds_df[\"Dist_Active\"] * FUND_FAMILY_SCALE_FACTOR\n",
    "funds_df[\"fundfamily_score_rules_based\"] += funds_df[\"Dist_Rules_Based\"] * FUND_FAMILY_SCALE_FACTOR\n",
    "funds_df[\"fundfamily_score_quant_systematic\"] += funds_df[\"Dist_Quant\"] * FUND_FAMILY_SCALE_FACTOR\n",
    "funds_df[\"fundfamily_score_multi_strategy\"] += funds_df[\"Dist_Multi\"] * FUND_FAMILY_SCALE_FACTOR\n",
    "\n",
    "# Sum all intermediate scores into final scores\n",
    "for cat in categories:\n",
    "    db_cat = category_mapping[cat]\n",
    "    score_col = f\"score_{db_cat}\"\n",
    "    funds_df[score_col] = (\n",
    "        funds_df[f\"keyword_score_{db_cat}\"] +\n",
    "        funds_df[f\"meaningful_score_{db_cat}\"] +\n",
    "        funds_df[f\"assist_score_{db_cat}\"] +\n",
    "        funds_df[f\"boolean_score_{db_cat}\"] +\n",
    "        funds_df[f\"fundfamily_score_{db_cat}\"]\n",
    "    )\n",
    "\n",
    "# Determine final category with tiebreaker based on keyword scores\n",
    "score_columns = [f\"score_{category_mapping[cat]}\" for cat in categories]\n",
    "# Initial idxmax\n",
    "funds_df[\"Return_Driver\"] = funds_df[score_columns].idxmax(axis=1).apply(\n",
    "    lambda x: category_mapping.get(x.replace(\"score_\", \"\"), \"None\") if pd.notnull(x) else \"None\"\n",
    ")\n",
    "# Apply tiebreaker: if scores are tied, prefer category with higher keyword score\n",
    "for idx in funds_df.index:\n",
    "    scores = funds_df.loc[idx, score_columns]\n",
    "    max_score = scores.max()\n",
    "    tied_categories = [col for col, score in scores.items() if score == max_score]\n",
    "    if len(tied_categories) > 1:\n",
    "        # Find category with highest keyword score among tied categories\n",
    "        keyword_scores = {col: funds_df.loc[idx, f\"keyword_score_{col.replace('score_', '')}\"] for col in tied_categories}\n",
    "        max_keyword_score = max(keyword_scores.values())\n",
    "        best_tied_category = max(keyword_scores, key=keyword_scores.get)\n",
    "        funds_df.loc[idx, \"Return_Driver\"] = best_tied_category.replace(\"score_\", \"\")\n",
    "\n",
    "\n",
    "\n",
    "# Write scores and Return_Driver to the database\n",
    "with engine.connect() as conn:\n",
    "    for cat in categories:\n",
    "        db_cat = category_mapping[cat]\n",
    "        score_col = f\"score_{db_cat}\"\n",
    "        # Replace -inf, inf, and NaN with None (NULL in SQL) to avoid invalid float errors\n",
    "        funds_df[score_col] = funds_df[score_col].replace([np.inf, -np.inf, np.nan], None)\n",
    "        # Define the SQL query with named parameters\n",
    "        update_query = text(f\"\"\"\n",
    "            UPDATE Funds_to_Screen\n",
    "            SET {db_cat} = df.{score_col}\n",
    "            FROM Funds_to_Screen fts\n",
    "            JOIN (SELECT :symbol_cusip AS SymbolCUSIP, :score AS {score_col}) df\n",
    "            ON fts.SymbolCUSIP = df.SymbolCUSIP\n",
    "        \"\"\")\n",
    "        # Prepare data for update\n",
    "        score_data = [(row[\"SymbolCUSIP\"], row[score_col]) for _, row in funds_df.iterrows()]\n",
    "        # Execute the update for each row individually using parameter binding\n",
    "        for sym, score in score_data:\n",
    "            # Skip if score is None (already converted from inf/-inf/nan)\n",
    "            if score is None:\n",
    "                params = {\"symbol_cusip\": sym, \"score\": None}\n",
    "            else:\n",
    "                params = {\"symbol_cusip\": sym, \"score\": float(score)}  # Ensure float for SQL Server\n",
    "            conn.execute(update_query, params)\n",
    "        conn.commit()  # Commit after each category update\n",
    "\n",
    "    # Update the Return_Driver column\n",
    "    update_driver_query = text(\"\"\"\n",
    "        UPDATE Funds_to_Screen\n",
    "        SET return_driver = df.Return_Driver\n",
    "        FROM Funds_to_Screen fts\n",
    "        JOIN (SELECT :symbol_cusip AS SymbolCUSIP, :return_driver AS Return_Driver) df\n",
    "        ON fts.SymbolCUSIP = df.SymbolCUSIP\n",
    "    \"\"\")\n",
    "    driver_data = [(row[\"SymbolCUSIP\"], row[\"Return_Driver\"]) for _, row in funds_df.iterrows()]\n",
    "    for sym, driver in driver_data:\n",
    "        conn.execute(update_driver_query, {\"symbol_cusip\": sym, \"return_driver\": driver})\n",
    "    conn.commit()  # Commit after Return_Driver updates\n",
    "\n",
    "# Export to Excel if toggled on (default off)\n",
    "if write_to_excel:\n",
    "    output_columns = (\n",
    "        [\"SymbolCUSIP\", \"ProductName\", \"fund_family\", \"Return_Driver\", \"ycharts_url\"] +\n",
    "        [f\"score_{category_mapping[cat]}\" for cat in categories] +\n",
    "        [f\"keyword_score_{category_mapping[cat]}\" for cat in categories] +\n",
    "        [f\"meaningful_score_{category_mapping[cat]}\" for cat in categories] +\n",
    "        [f\"assist_score_{category_mapping[cat]}\" for cat in categories] +\n",
    "        [f\"boolean_score_{category_mapping[cat]}\" for cat in categories] +\n",
    "        [f\"fundfamily_score_{category_mapping[cat]}\" for cat in categories] +\n",
    "        [f\"matched_keywords_{category_mapping[cat]}\" for cat in categories] +\n",
    "        [\"CWA_Broad_Category_Name\", \"Category_Name\", \"Global_Category_Name\", \"YC_Broad_Asset_Class_Name\"] +\n",
    "        [\"index_fund\", \"inverse_fund\", \"leveraged_fund\", \"socially_responsible_fund\", \"synthetic_replication_fund\", \"fund_of_funds\", \"currency_hedged_fund\"] +\n",
    "        [\"Dist_Index\", \"Dist_Active\", \"Dist_Rules_Based\", \"Dist_Quant\", \"Dist_Multi\"]\n",
    "    )\n",
    "    funds_df[output_columns].to_excel(output_path, index=False)\n",
    "    print(f\"Results exported to {output_path}\")\n",
    "else:\n",
    "    print(\"Excel output skipped (write_to_excel=False). Data written to database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa90bef-cabe-4894-a11a-3407cf909097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First attempt at overlay classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d5a9a0-cab6-41d5-bd33-e0c97130ba30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49456836-1b9d-4c1d-8834-ca344c90cc29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bc7702-d354-4e4a-bb2a-08cedb6abff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a1fcdc-d182-4d6f-9d2e-1a7794ec566d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13725102-bef6-4a04-897f-4cfe02fe20f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff78f42-db40-43bc-95b8-241c6f8f2683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd23300b-6ba8-4cb1-800e-ec317f5942ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ef8b4a-b6ff-4ce0-b43c-0803e5e9f705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "602b4e7f-9912-4985-9dad-3de35c6f6823",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 12:40:01,138 - INFO - Found 5586 funds needing cash_long updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection successful\n",
      "Requesting Cash Long for 5586 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 12:40:04,228 - WARNING - No cash_long in results for AMPD: {}\n",
      "2025-03-03 12:40:06,157 - WARNING - No cash_long in results for VMOT: {}\n",
      "2025-03-03 12:40:13,983 - INFO - Null value in cash_long for HSBH: [None, None]\n",
      "2025-03-03 12:40:13,988 - INFO - Null value in cash_long for AZNH: [None, None]\n",
      "2025-03-03 12:40:14,259 - INFO - Null value in cash_long for SHEH: [None, None]\n",
      "2025-03-03 12:40:16,162 - WARNING - No cash_long in results for PP: {}\n",
      "2025-03-03 12:40:17,679 - WARNING - No cash_long in results for VCAR: {}\n",
      "2025-03-03 12:40:46,893 - INFO - Null value in cash_long for PSQA: [None, None]\n",
      "2025-03-03 12:40:56,488 - INFO - Null value in cash_long for APDOX: [None, None]\n",
      "2025-03-03 12:41:05,993 - WARNING - No cash_long in results for OFIYX: {}\n",
      "2025-03-03 12:41:45,892 - WARNING - No cash_long in results for TWIO: {}\n",
      "2025-03-03 12:41:52,126 - INFO - Null value in cash_long for HGER: [None, None]\n",
      "2025-03-03 12:41:53,009 - INFO - Null value in cash_long for IAUM: [None, None]\n",
      "2025-03-03 12:41:58,896 - WARNING - No cash_long in results for DFNV: {}\n",
      "2025-03-03 12:42:01,048 - INFO - Null value in cash_long for BCIM: [None, None]\n",
      "2025-03-03 12:42:01,061 - WARNING - No cash_long in results for DFRA: {}\n",
      "2025-03-03 12:42:27,357 - WARNING - No cash_long in results for TTAI: {}\n",
      "2025-03-03 12:42:36,137 - WARNING - No cash_long in results for IQDE: {}\n",
      "2025-03-03 12:42:45,241 - WARNING - No cash_long in results for QYLE: {}\n",
      "2025-03-03 12:42:45,243 - WARNING - No cash_long in results for XYLE: {}\n",
      "2025-03-03 12:42:49,717 - WARNING - No cash_long in results for NUSI: {}\n",
      "2025-03-03 12:42:50,590 - WARNING - No cash_long in results for FYLG: {}\n",
      "2025-03-03 12:42:52,144 - WARNING - No cash_long in results for HYLG: {}\n",
      "2025-03-03 12:42:53,863 - WARNING - No cash_long in results for EMCC: {}\n",
      "2025-03-03 12:42:54,235 - WARNING - No cash_long in results for GPOW: {}\n",
      "2025-03-03 12:42:54,237 - WARNING - No cash_long in results for OCTA: {}\n",
      "2025-03-03 12:42:54,526 - WARNING - No cash_long in results for GCLN: {}\n",
      "2025-03-03 12:42:57,683 - WARNING - No cash_long in results for MJUS: {}\n",
      "2025-03-03 12:42:58,279 - WARNING - No cash_long in results for GREI: {}\n",
      "2025-03-03 12:43:24,585 - WARNING - No cash_long in results for TTAC: {}\n",
      "2025-03-03 12:43:29,280 - WARNING - No cash_long in results for NETZ: {}\n",
      "2025-03-03 12:43:33,576 - INFO - Null value in cash_long for FMCE: [None, None]\n",
      "2025-03-03 12:43:40,576 - WARNING - No cash_long in results for USCF: {}\n",
      "2025-03-03 12:44:02,728 - WARNING - No cash_long in results for HYMU: {}\n",
      "2025-03-03 12:44:03,005 - WARNING - No cash_long in results for IMSI: {}\n",
      "2025-03-03 12:44:18,411 - WARNING - No cash_long in results for WBND: {}\n",
      "2025-03-03 12:44:23,065 - INFO - Null value in cash_long for PSQO: [None, None]\n",
      "2025-03-03 12:44:23,117 - WARNING - No cash_long in results for DFHY: {}\n",
      "2025-03-03 12:44:25,508 - WARNING - No cash_long in results for ISDB: {}\n",
      "2025-03-03 12:44:33,871 - WARNING - No cash_long in results for ABQYX: {}\n",
      "2025-03-03 12:44:35,280 - WARNING - No cash_long in results for JIEIX: {}\n",
      "2025-03-03 12:44:49,062 - WARNING - No cash_long in results for MAYHX: {}\n",
      "2025-03-03 12:45:12,874 - WARNING - No cash_long in results for FGTBX: {}\n",
      "2025-03-03 12:45:24,912 - WARNING - No cash_long in results for FSMZX: {}\n",
      "2025-03-03 12:45:34,857 - WARNING - No cash_long in results for AMCYX: {}\n",
      "2025-03-03 12:45:41,903 - WARNING - No cash_long in results for JGIFX: {}\n",
      "2025-03-03 12:45:55,711 - WARNING - No cash_long in results for FPPJX: {}\n",
      "2025-03-03 12:45:59,291 - WARNING - No cash_long in results for MUIBX: {}\n",
      "2025-03-03 12:46:06,831 - WARNING - No cash_long in results for NHYMX: {}\n",
      "2025-03-03 12:46:16,544 - WARNING - No cash_long in results for PYHIX: {}\n",
      "2025-03-03 12:46:43,937 - INFO - Inserting 5536 rows for cash_long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating cash_long for 5536 funds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 12:46:45,224 - INFO - Found 5586 funds needing cash_net updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary for cash_long:\n",
      "  Funds Needing Update: 5586\n",
      "  Data Fetched: 5536\n",
      "  Inserted: 5536\n",
      "  No Data: 50\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n",
      "Requesting Cash Net for 5586 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 12:46:47,288 - WARNING - No cash_net in results for AMPD: {}\n",
      "2025-03-03 12:46:48,598 - WARNING - No cash_net in results for VMOT: {}\n",
      "2025-03-03 12:46:53,184 - INFO - Null value in cash_net for SHEH: [None, None]\n",
      "2025-03-03 12:46:53,187 - INFO - Null value in cash_net for HSBH: [None, None]\n",
      "2025-03-03 12:46:54,887 - INFO - Null value in cash_net for AZNH: [None, None]\n",
      "2025-03-03 12:46:55,362 - WARNING - No cash_net in results for PP: {}\n",
      "2025-03-03 12:46:58,209 - WARNING - No cash_net in results for VCAR: {}\n",
      "2025-03-03 12:47:21,935 - INFO - Null value in cash_net for PSQA: [None, None]\n",
      "2025-03-03 12:47:23,375 - INFO - Null value in cash_net for APDOX: [None, None]\n",
      "2025-03-03 12:47:32,047 - WARNING - No cash_net in results for OFIYX: {}\n",
      "2025-03-03 12:47:48,606 - WARNING - No cash_net in results for DFNV: {}\n",
      "2025-03-03 12:47:49,944 - WARNING - No cash_net in results for DFRA: {}\n",
      "2025-03-03 12:47:51,454 - WARNING - No cash_net in results for TWIO: {}\n",
      "2025-03-03 12:47:54,558 - INFO - Null value in cash_net for HGER: [None, None]\n",
      "2025-03-03 12:47:54,688 - INFO - Null value in cash_net for IAUM: [None, None]\n",
      "2025-03-03 12:47:54,971 - INFO - Null value in cash_net for BCIM: [None, None]\n",
      "2025-03-03 12:48:06,515 - WARNING - No cash_net in results for TTAI: {}\n",
      "2025-03-03 12:48:10,102 - WARNING - No cash_net in results for IQDE: {}\n",
      "2025-03-03 12:48:20,875 - WARNING - No cash_net in results for XYLE: {}\n",
      "2025-03-03 12:48:22,875 - WARNING - No cash_net in results for EMCC: {}\n",
      "2025-03-03 12:48:23,106 - WARNING - No cash_net in results for QYLE: {}\n",
      "2025-03-03 12:48:23,123 - WARNING - No cash_net in results for NUSI: {}\n",
      "2025-03-03 12:48:23,296 - WARNING - No cash_net in results for HYLG: {}\n",
      "2025-03-03 12:48:26,087 - WARNING - No cash_net in results for FYLG: {}\n",
      "2025-03-03 12:48:28,878 - WARNING - No cash_net in results for OCTA: {}\n",
      "2025-03-03 12:48:29,165 - WARNING - No cash_net in results for GPOW: {}\n",
      "2025-03-03 12:48:31,099 - WARNING - No cash_net in results for GCLN: {}\n",
      "2025-03-03 12:48:31,828 - WARNING - No cash_net in results for MJUS: {}\n",
      "2025-03-03 12:48:31,836 - WARNING - No cash_net in results for GREI: {}\n",
      "2025-03-03 12:48:57,679 - WARNING - No cash_net in results for TTAC: {}\n",
      "2025-03-03 12:49:00,864 - WARNING - No cash_net in results for NETZ: {}\n",
      "2025-03-03 12:49:04,289 - INFO - Null value in cash_net for FMCE: [None, None]\n",
      "2025-03-03 12:49:10,116 - WARNING - No cash_net in results for USCF: {}\n",
      "2025-03-03 12:49:24,543 - WARNING - No cash_net in results for HYMU: {}\n",
      "2025-03-03 12:49:24,780 - WARNING - No cash_net in results for IMSI: {}\n",
      "2025-03-03 12:49:37,701 - WARNING - No cash_net in results for WBND: {}\n",
      "2025-03-03 12:49:41,671 - WARNING - No cash_net in results for DFHY: {}\n",
      "2025-03-03 12:49:41,899 - INFO - Null value in cash_net for PSQO: [None, None]\n",
      "2025-03-03 12:49:44,507 - WARNING - No cash_net in results for ISDB: {}\n",
      "2025-03-03 12:49:48,608 - WARNING - No cash_net in results for ABQYX: {}\n",
      "2025-03-03 12:49:48,701 - WARNING - No cash_net in results for JIEIX: {}\n",
      "2025-03-03 12:50:01,882 - WARNING - No cash_net in results for MAYHX: {}\n",
      "2025-03-03 12:50:20,795 - WARNING - No cash_net in results for FGTBX: {}\n",
      "2025-03-03 12:50:30,086 - WARNING - No cash_net in results for FSMZX: {}\n",
      "2025-03-03 12:50:36,376 - WARNING - No cash_net in results for AMCYX: {}\n",
      "2025-03-03 12:50:42,971 - WARNING - No cash_net in results for JGIFX: {}\n",
      "2025-03-03 12:50:51,257 - WARNING - No cash_net in results for FPPJX: {}\n",
      "2025-03-03 12:50:56,894 - WARNING - No cash_net in results for MUIBX: {}\n",
      "2025-03-03 12:50:58,818 - WARNING - No cash_net in results for NHYMX: {}\n",
      "2025-03-03 12:51:15,924 - WARNING - No cash_net in results for PYHIX: {}\n",
      "2025-03-03 12:51:35,397 - INFO - Inserting 5536 rows for cash_net\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating cash_net for 5536 funds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 12:51:36,388 - INFO - Found 5586 funds needing cash_short updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary for cash_net:\n",
      "  Funds Needing Update: 5586\n",
      "  Data Fetched: 5536\n",
      "  Inserted: 5536\n",
      "  No Data: 50\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n",
      "Requesting Cash Short for 5586 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 12:51:39,858 - WARNING - No cash_short in results for AMPD: {}\n",
      "2025-03-03 12:51:39,901 - WARNING - No cash_short in results for VMOT: {}\n",
      "2025-03-03 12:51:44,448 - INFO - Null value in cash_short for HSBH: [None, None]\n",
      "2025-03-03 12:51:47,294 - INFO - Null value in cash_short for AZNH: [None, None]\n",
      "2025-03-03 12:51:47,420 - WARNING - No cash_short in results for VCAR: {}\n",
      "2025-03-03 12:51:47,421 - WARNING - No cash_short in results for PP: {}\n",
      "2025-03-03 12:51:49,233 - INFO - Null value in cash_short for SHEH: [None, None]\n",
      "2025-03-03 12:52:05,277 - INFO - Null value in cash_short for PSQA: [None, None]\n",
      "2025-03-03 12:52:10,534 - INFO - Null value in cash_short for APDOX: [None, None]\n",
      "2025-03-03 12:52:16,504 - WARNING - No cash_short in results for OFIYX: {}\n",
      "2025-03-03 12:52:40,621 - WARNING - No cash_short in results for TWIO: {}\n",
      "2025-03-03 12:52:45,147 - WARNING - No cash_short in results for DFRA: {}\n",
      "2025-03-03 12:52:48,173 - WARNING - No cash_short in results for DFNV: {}\n",
      "2025-03-03 12:52:49,195 - INFO - Null value in cash_short for HGER: [None, None]\n",
      "2025-03-03 12:52:53,795 - INFO - Null value in cash_short for BCIM: [None, None]\n",
      "2025-03-03 12:52:55,205 - INFO - Null value in cash_short for IAUM: [None, None]\n",
      "2025-03-03 12:53:07,165 - WARNING - No cash_short in results for TTAI: {}\n",
      "2025-03-03 12:53:08,822 - WARNING - No cash_short in results for IQDE: {}\n",
      "2025-03-03 12:53:15,709 - WARNING - No cash_short in results for QYLE: {}\n",
      "2025-03-03 12:53:15,923 - WARNING - No cash_short in results for XYLE: {}\n",
      "2025-03-03 12:53:18,588 - WARNING - No cash_short in results for EMCC: {}\n",
      "2025-03-03 12:53:20,312 - WARNING - No cash_short in results for NUSI: {}\n",
      "2025-03-03 12:53:20,605 - WARNING - No cash_short in results for FYLG: {}\n",
      "2025-03-03 12:53:20,755 - WARNING - No cash_short in results for HYLG: {}\n",
      "2025-03-03 12:53:23,697 - WARNING - No cash_short in results for GCLN: {}\n",
      "2025-03-03 12:53:25,401 - WARNING - No cash_short in results for MJUS: {}\n",
      "2025-03-03 12:53:26,739 - WARNING - No cash_short in results for OCTA: {}\n",
      "2025-03-03 12:53:26,883 - WARNING - No cash_short in results for GPOW: {}\n",
      "2025-03-03 12:53:27,163 - WARNING - No cash_short in results for GREI: {}\n",
      "2025-03-03 12:53:49,569 - WARNING - No cash_short in results for TTAC: {}\n",
      "2025-03-03 12:53:52,790 - WARNING - No cash_short in results for NETZ: {}\n",
      "2025-03-03 12:54:00,988 - INFO - Null value in cash_short for FMCE: [None, None]\n",
      "2025-03-03 12:54:01,752 - WARNING - No cash_short in results for USCF: {}\n",
      "2025-03-03 12:54:18,592 - WARNING - No cash_short in results for IMSI: {}\n",
      "2025-03-03 12:54:18,602 - WARNING - No cash_short in results for HYMU: {}\n",
      "2025-03-03 12:54:33,894 - WARNING - No cash_short in results for WBND: {}\n",
      "2025-03-03 12:54:36,848 - INFO - Null value in cash_short for PSQO: [None, None]\n",
      "2025-03-03 12:54:38,545 - WARNING - No cash_short in results for DFHY: {}\n",
      "2025-03-03 12:54:40,323 - WARNING - No cash_short in results for ISDB: {}\n",
      "2025-03-03 12:54:44,431 - WARNING - No cash_short in results for ABQYX: {}\n",
      "2025-03-03 12:54:44,447 - WARNING - No cash_short in results for JIEIX: {}\n",
      "2025-03-03 12:54:54,884 - WARNING - No cash_short in results for MAYHX: {}\n",
      "2025-03-03 12:55:16,685 - WARNING - No cash_short in results for FGTBX: {}\n",
      "2025-03-03 12:55:25,233 - WARNING - No cash_short in results for FSMZX: {}\n",
      "2025-03-03 12:55:34,318 - WARNING - No cash_short in results for AMCYX: {}\n",
      "2025-03-03 12:55:39,240 - WARNING - No cash_short in results for JGIFX: {}\n",
      "2025-03-03 12:55:49,924 - WARNING - No cash_short in results for FPPJX: {}\n",
      "2025-03-03 12:55:51,231 - WARNING - No cash_short in results for MUIBX: {}\n",
      "2025-03-03 12:55:56,036 - WARNING - No cash_short in results for NHYMX: {}\n",
      "2025-03-03 12:56:08,296 - WARNING - No cash_short in results for PYHIX: {}\n",
      "2025-03-03 12:56:26,288 - INFO - Inserting 5536 rows for cash_short\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating cash_short for 5536 funds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 12:56:27,268 - INFO - Found 5586 funds needing stock_long updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary for cash_short:\n",
      "  Funds Needing Update: 5586\n",
      "  Data Fetched: 5536\n",
      "  Inserted: 5536\n",
      "  No Data: 50\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n",
      "Requesting Stock Long for 5586 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 12:56:29,842 - WARNING - No stock_long in results for AMPD: {}\n",
      "2025-03-03 12:56:30,597 - WARNING - No stock_long in results for VMOT: {}\n",
      "2025-03-03 12:56:36,900 - INFO - Null value in stock_long for HSBH: [None, None]\n",
      "2025-03-03 12:56:37,671 - INFO - Null value in stock_long for SHEH: [None, None]\n",
      "2025-03-03 12:56:39,101 - INFO - Null value in stock_long for AZNH: [None, None]\n",
      "2025-03-03 12:56:40,126 - WARNING - No stock_long in results for PP: {}\n",
      "2025-03-03 12:56:40,339 - WARNING - No stock_long in results for VCAR: {}\n",
      "2025-03-03 12:56:58,421 - INFO - Null value in stock_long for PSQA: [None, None]\n",
      "2025-03-03 12:57:03,825 - INFO - Null value in stock_long for APDOX: [None, None]\n",
      "2025-03-03 12:57:12,081 - WARNING - No stock_long in results for OFIYX: {}\n",
      "2025-03-03 12:57:22,080 - WARNING - No stock_long in results for TWIO: {}\n",
      "2025-03-03 12:57:24,089 - WARNING - No stock_long in results for DFNV: {}\n",
      "2025-03-03 12:57:24,698 - WARNING - No stock_long in results for DFRA: {}\n",
      "2025-03-03 12:57:27,749 - INFO - Null value in stock_long for HGER: [None, None]\n",
      "2025-03-03 12:57:29,751 - INFO - Null value in stock_long for IAUM: [None, None]\n",
      "2025-03-03 12:57:32,520 - INFO - Null value in stock_long for BCIM: [None, None]\n",
      "2025-03-03 12:57:43,145 - WARNING - No stock_long in results for TTAI: {}\n",
      "2025-03-03 12:57:45,624 - WARNING - No stock_long in results for IQDE: {}\n",
      "2025-03-03 12:57:56,313 - WARNING - No stock_long in results for XYLE: {}\n",
      "2025-03-03 12:57:57,951 - WARNING - No stock_long in results for QYLE: {}\n",
      "2025-03-03 12:57:59,640 - WARNING - No stock_long in results for EMCC: {}\n",
      "2025-03-03 12:57:59,648 - WARNING - No stock_long in results for NUSI: {}\n",
      "2025-03-03 12:58:04,298 - WARNING - No stock_long in results for HYLG: {}\n",
      "2025-03-03 12:58:07,384 - WARNING - No stock_long in results for GPOW: {}\n",
      "2025-03-03 12:58:07,384 - WARNING - No stock_long in results for OCTA: {}\n",
      "2025-03-03 12:58:07,613 - WARNING - No stock_long in results for GREI: {}\n",
      "2025-03-03 12:58:07,779 - WARNING - No stock_long in results for GCLN: {}\n",
      "2025-03-03 12:58:10,180 - WARNING - No stock_long in results for FYLG: {}\n",
      "2025-03-03 12:58:12,432 - WARNING - No stock_long in results for MJUS: {}\n",
      "2025-03-03 12:58:31,506 - WARNING - No stock_long in results for TTAC: {}\n",
      "2025-03-03 12:58:34,895 - WARNING - No stock_long in results for NETZ: {}\n",
      "2025-03-03 12:58:38,235 - INFO - Null value in stock_long for FMCE: [None, None]\n",
      "2025-03-03 12:58:42,121 - WARNING - No stock_long in results for USCF: {}\n",
      "2025-03-03 12:58:57,439 - WARNING - No stock_long in results for IMSI: {}\n",
      "2025-03-03 12:58:59,015 - WARNING - No stock_long in results for HYMU: {}\n",
      "2025-03-03 12:59:11,641 - WARNING - No stock_long in results for WBND: {}\n",
      "2025-03-03 12:59:20,852 - INFO - Null value in stock_long for PSQO: [None, None]\n",
      "2025-03-03 12:59:21,273 - WARNING - No stock_long in results for DFHY: {}\n",
      "2025-03-03 12:59:22,105 - WARNING - No stock_long in results for ISDB: {}\n",
      "2025-03-03 12:59:28,340 - WARNING - No stock_long in results for ABQYX: {}\n",
      "2025-03-03 12:59:29,080 - WARNING - No stock_long in results for JIEIX: {}\n",
      "2025-03-03 12:59:39,914 - WARNING - No stock_long in results for MAYHX: {}\n",
      "2025-03-03 12:59:58,208 - WARNING - No stock_long in results for FGTBX: {}\n",
      "2025-03-03 13:00:09,840 - WARNING - No stock_long in results for FSMZX: {}\n",
      "2025-03-03 13:00:16,865 - WARNING - No stock_long in results for AMCYX: {}\n",
      "2025-03-03 13:00:20,320 - WARNING - No stock_long in results for JGIFX: {}\n",
      "2025-03-03 13:00:28,712 - WARNING - No stock_long in results for FPPJX: {}\n",
      "2025-03-03 13:00:30,071 - WARNING - No stock_long in results for MUIBX: {}\n",
      "2025-03-03 13:00:33,049 - WARNING - No stock_long in results for NHYMX: {}\n",
      "2025-03-03 13:00:48,348 - WARNING - No stock_long in results for PYHIX: {}\n",
      "2025-03-03 13:01:06,672 - INFO - Inserting 5536 rows for stock_long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating stock_long for 5536 funds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 13:01:07,614 - INFO - Found 5586 funds needing stock_net updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary for stock_long:\n",
      "  Funds Needing Update: 5586\n",
      "  Data Fetched: 5536\n",
      "  Inserted: 5536\n",
      "  No Data: 50\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n",
      "Requesting Stock Net for 5586 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 13:01:10,555 - WARNING - No stock_net in results for AMPD: {}\n",
      "2025-03-03 13:01:12,288 - WARNING - No stock_net in results for VMOT: {}\n",
      "2025-03-03 13:01:18,817 - INFO - Null value in stock_net for SHEH: [None, None]\n",
      "2025-03-03 13:01:19,485 - INFO - Null value in stock_net for HSBH: [None, None]\n",
      "2025-03-03 13:01:21,815 - WARNING - No stock_net in results for PP: {}\n",
      "2025-03-03 13:01:21,815 - INFO - Null value in stock_net for AZNH: [None, None]\n",
      "2025-03-03 13:01:24,033 - WARNING - No stock_net in results for VCAR: {}\n",
      "2025-03-03 13:01:38,922 - INFO - Null value in stock_net for PSQA: [None, None]\n",
      "2025-03-03 13:01:41,006 - INFO - Null value in stock_net for APDOX: [None, None]\n",
      "2025-03-03 13:01:50,488 - WARNING - No stock_net in results for OFIYX: {}\n",
      "2025-03-03 13:02:09,326 - WARNING - No stock_net in results for TWIO: {}\n",
      "2025-03-03 13:02:11,972 - WARNING - No stock_net in results for DFNV: {}\n",
      "2025-03-03 13:02:13,775 - WARNING - No stock_net in results for DFRA: {}\n",
      "2025-03-03 13:02:17,306 - INFO - Null value in stock_net for HGER: [None, None]\n",
      "2025-03-03 13:02:21,179 - INFO - Null value in stock_net for IAUM: [None, None]\n",
      "2025-03-03 13:02:24,879 - INFO - Null value in stock_net for BCIM: [None, None]\n",
      "2025-03-03 13:02:38,016 - WARNING - No stock_net in results for TTAI: {}\n",
      "2025-03-03 13:02:44,560 - WARNING - No stock_net in results for IQDE: {}\n",
      "2025-03-03 13:02:58,809 - WARNING - No stock_net in results for XYLE: {}\n",
      "2025-03-03 13:02:59,871 - WARNING - No stock_net in results for QYLE: {}\n",
      "2025-03-03 13:03:02,244 - WARNING - No stock_net in results for NUSI: {}\n",
      "2025-03-03 13:03:02,382 - WARNING - No stock_net in results for FYLG: {}\n",
      "2025-03-03 13:03:02,739 - WARNING - No stock_net in results for EMCC: {}\n",
      "2025-03-03 13:03:02,945 - WARNING - No stock_net in results for HYLG: {}\n",
      "2025-03-03 13:03:12,933 - WARNING - No stock_net in results for MJUS: {}\n",
      "2025-03-03 13:03:13,218 - WARNING - No stock_net in results for GREI: {}\n",
      "2025-03-03 13:03:13,517 - WARNING - No stock_net in results for GPOW: {}\n",
      "2025-03-03 13:03:13,744 - WARNING - No stock_net in results for GCLN: {}\n",
      "2025-03-03 13:03:15,273 - WARNING - No stock_net in results for OCTA: {}\n",
      "2025-03-03 13:03:35,430 - WARNING - No stock_net in results for TTAC: {}\n",
      "2025-03-03 13:03:41,161 - WARNING - No stock_net in results for NETZ: {}\n",
      "2025-03-03 13:03:41,812 - INFO - Null value in stock_net for FMCE: [None, None]\n",
      "2025-03-03 13:03:48,240 - WARNING - No stock_net in results for USCF: {}\n",
      "2025-03-03 13:04:03,030 - WARNING - No stock_net in results for HYMU: {}\n",
      "2025-03-03 13:04:03,754 - WARNING - No stock_net in results for IMSI: {}\n",
      "2025-03-03 13:04:16,220 - WARNING - No stock_net in results for WBND: {}\n",
      "2025-03-03 13:04:21,576 - INFO - Null value in stock_net for PSQO: [None, None]\n",
      "2025-03-03 13:04:21,753 - WARNING - No stock_net in results for DFHY: {}\n",
      "2025-03-03 13:04:24,639 - WARNING - No stock_net in results for ISDB: {}\n",
      "2025-03-03 13:04:29,709 - WARNING - No stock_net in results for ABQYX: {}\n",
      "2025-03-03 13:04:31,253 - WARNING - No stock_net in results for JIEIX: {}\n",
      "2025-03-03 13:04:43,408 - WARNING - No stock_net in results for MAYHX: {}\n",
      "2025-03-03 13:05:02,288 - WARNING - No stock_net in results for FGTBX: {}\n",
      "2025-03-03 13:05:11,451 - WARNING - No stock_net in results for FSMZX: {}\n",
      "2025-03-03 13:05:19,828 - WARNING - No stock_net in results for AMCYX: {}\n",
      "2025-03-03 13:05:26,111 - WARNING - No stock_net in results for JGIFX: {}\n",
      "2025-03-03 13:05:34,326 - WARNING - No stock_net in results for FPPJX: {}\n",
      "2025-03-03 13:05:41,598 - WARNING - No stock_net in results for MUIBX: {}\n",
      "2025-03-03 13:05:43,711 - WARNING - No stock_net in results for NHYMX: {}\n",
      "2025-03-03 13:06:05,863 - WARNING - No stock_net in results for PYHIX: {}\n",
      "2025-03-03 13:06:29,090 - INFO - Inserting 5536 rows for stock_net\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating stock_net for 5536 funds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 13:06:30,028 - INFO - Found 5586 funds needing stock_short updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary for stock_net:\n",
      "  Funds Needing Update: 5586\n",
      "  Data Fetched: 5536\n",
      "  Inserted: 5536\n",
      "  No Data: 50\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n",
      "Requesting Stock Short for 5586 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 13:06:32,847 - WARNING - No stock_short in results for AMPD: {}\n",
      "2025-03-03 13:06:34,526 - WARNING - No stock_short in results for VMOT: {}\n",
      "2025-03-03 13:06:39,769 - INFO - Null value in stock_short for SHEH: [None, None]\n",
      "2025-03-03 13:06:39,771 - INFO - Null value in stock_short for AZNH: [None, None]\n",
      "2025-03-03 13:06:40,395 - INFO - Null value in stock_short for HSBH: [None, None]\n",
      "2025-03-03 13:06:41,894 - WARNING - No stock_short in results for PP: {}\n",
      "2025-03-03 13:06:42,350 - WARNING - No stock_short in results for VCAR: {}\n",
      "2025-03-03 13:07:10,986 - INFO - Null value in stock_short for PSQA: [None, None]\n",
      "2025-03-03 13:07:20,637 - INFO - Null value in stock_short for APDOX: [None, None]\n",
      "2025-03-03 13:07:27,482 - WARNING - No stock_short in results for OFIYX: {}\n",
      "2025-03-03 13:07:44,395 - WARNING - No stock_short in results for TWIO: {}\n",
      "2025-03-03 13:07:49,923 - WARNING - No stock_short in results for DFRA: {}\n",
      "2025-03-03 13:07:49,925 - WARNING - No stock_short in results for DFNV: {}\n",
      "2025-03-03 13:07:56,340 - INFO - Null value in stock_short for HGER: [None, None]\n",
      "2025-03-03 13:07:56,836 - INFO - Null value in stock_short for IAUM: [None, None]\n",
      "2025-03-03 13:07:57,638 - INFO - Null value in stock_short for BCIM: [None, None]\n",
      "2025-03-03 13:08:12,478 - WARNING - No stock_short in results for TTAI: {}\n",
      "2025-03-03 13:08:15,557 - WARNING - No stock_short in results for IQDE: {}\n",
      "2025-03-03 13:08:24,845 - WARNING - No stock_short in results for XYLE: {}\n",
      "2025-03-03 13:08:24,855 - WARNING - No stock_short in results for QYLE: {}\n",
      "2025-03-03 13:08:27,529 - WARNING - No stock_short in results for NUSI: {}\n",
      "2025-03-03 13:08:28,091 - WARNING - No stock_short in results for FYLG: {}\n",
      "2025-03-03 13:08:28,417 - WARNING - No stock_short in results for HYLG: {}\n",
      "2025-03-03 13:08:29,653 - WARNING - No stock_short in results for EMCC: {}\n",
      "2025-03-03 13:08:32,337 - WARNING - No stock_short in results for OCTA: {}\n",
      "2025-03-03 13:08:32,341 - WARNING - No stock_short in results for GPOW: {}\n",
      "2025-03-03 13:08:32,624 - WARNING - No stock_short in results for GCLN: {}\n",
      "2025-03-03 13:08:34,413 - WARNING - No stock_short in results for MJUS: {}\n",
      "2025-03-03 13:08:35,446 - WARNING - No stock_short in results for GREI: {}\n",
      "2025-03-03 13:09:08,042 - WARNING - No stock_short in results for TTAC: {}\n",
      "2025-03-03 13:09:09,658 - INFO - Null value in stock_short for FMCE: [None, None]\n",
      "2025-03-03 13:09:13,755 - WARNING - No stock_short in results for USCF: {}\n",
      "2025-03-03 13:09:16,283 - WARNING - No stock_short in results for NETZ: {}\n",
      "2025-03-03 13:09:27,954 - WARNING - No stock_short in results for HYMU: {}\n",
      "2025-03-03 13:09:28,275 - WARNING - No stock_short in results for IMSI: {}\n",
      "2025-03-03 13:09:42,368 - WARNING - No stock_short in results for WBND: {}\n",
      "2025-03-03 13:09:45,587 - INFO - Null value in stock_short for PSQO: [None, None]\n",
      "2025-03-03 13:09:45,717 - WARNING - No stock_short in results for DFHY: {}\n",
      "2025-03-03 13:09:51,451 - WARNING - No stock_short in results for ISDB: {}\n",
      "2025-03-03 13:09:54,443 - WARNING - No stock_short in results for ABQYX: {}\n",
      "2025-03-03 13:09:54,680 - WARNING - No stock_short in results for JIEIX: {}\n",
      "2025-03-03 13:10:08,295 - WARNING - No stock_short in results for MAYHX: {}\n",
      "2025-03-03 13:10:25,463 - WARNING - No stock_short in results for FGTBX: {}\n",
      "2025-03-03 13:10:34,734 - WARNING - No stock_short in results for FSMZX: {}\n",
      "2025-03-03 13:10:43,074 - WARNING - No stock_short in results for AMCYX: {}\n",
      "2025-03-03 13:10:45,347 - WARNING - No stock_short in results for JGIFX: {}\n",
      "2025-03-03 13:10:54,295 - WARNING - No stock_short in results for FPPJX: {}\n",
      "2025-03-03 13:10:56,075 - WARNING - No stock_short in results for MUIBX: {}\n",
      "2025-03-03 13:11:00,775 - WARNING - No stock_short in results for NHYMX: {}\n",
      "2025-03-03 13:11:13,677 - WARNING - No stock_short in results for PYHIX: {}\n",
      "2025-03-03 13:11:35,196 - INFO - Inserting 5536 rows for stock_short\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating stock_short for 5536 funds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 13:11:36,166 - INFO - Found 5586 funds needing bond_long updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary for stock_short:\n",
      "  Funds Needing Update: 5586\n",
      "  Data Fetched: 5536\n",
      "  Inserted: 5536\n",
      "  No Data: 50\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n",
      "Requesting Bond Long for 5586 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 13:11:38,680 - WARNING - No bond_long in results for AMPD: {}\n",
      "2025-03-03 13:11:40,680 - WARNING - No bond_long in results for VMOT: {}\n",
      "2025-03-03 13:11:44,442 - INFO - Null value in bond_long for HSBH: [None, None]\n",
      "2025-03-03 13:11:45,535 - INFO - Null value in bond_long for SHEH: [None, None]\n",
      "2025-03-03 13:11:45,922 - INFO - Null value in bond_long for AZNH: [None, None]\n",
      "2025-03-03 13:11:47,671 - WARNING - No bond_long in results for PP: {}\n",
      "2025-03-03 13:11:49,281 - WARNING - No bond_long in results for VCAR: {}\n",
      "2025-03-03 13:12:05,958 - INFO - Null value in bond_long for PSQA: [None, None]\n",
      "2025-03-03 13:12:07,084 - INFO - Null value in bond_long for APDOX: [None, None]\n",
      "2025-03-03 13:12:14,752 - WARNING - No bond_long in results for OFIYX: {}\n",
      "2025-03-03 13:12:28,062 - WARNING - No bond_long in results for TWIO: {}\n",
      "2025-03-03 13:12:30,839 - WARNING - No bond_long in results for DFNV: {}\n",
      "2025-03-03 13:12:31,646 - WARNING - No bond_long in results for DFRA: {}\n",
      "2025-03-03 13:12:36,238 - INFO - Null value in bond_long for HGER: [None, None]\n",
      "2025-03-03 13:12:37,306 - INFO - Null value in bond_long for IAUM: [None, None]\n",
      "2025-03-03 13:12:38,802 - INFO - Null value in bond_long for BCIM: [None, None]\n",
      "2025-03-03 13:12:52,680 - WARNING - No bond_long in results for TTAI: {}\n",
      "2025-03-03 13:12:58,311 - WARNING - No bond_long in results for IQDE: {}\n",
      "2025-03-03 13:13:01,908 - WARNING - No bond_long in results for XYLE: {}\n",
      "2025-03-03 13:13:02,920 - WARNING - No bond_long in results for QYLE: {}\n",
      "2025-03-03 13:13:06,005 - WARNING - No bond_long in results for NUSI: {}\n",
      "2025-03-03 13:13:06,055 - WARNING - No bond_long in results for EMCC: {}\n",
      "2025-03-03 13:13:09,584 - WARNING - No bond_long in results for FYLG: {}\n",
      "2025-03-03 13:13:09,590 - WARNING - No bond_long in results for HYLG: {}\n",
      "2025-03-03 13:13:11,325 - WARNING - No bond_long in results for GPOW: {}\n",
      "2025-03-03 13:13:11,873 - WARNING - No bond_long in results for GREI: {}\n",
      "2025-03-03 13:13:11,886 - WARNING - No bond_long in results for GCLN: {}\n",
      "2025-03-03 13:13:12,616 - WARNING - No bond_long in results for OCTA: {}\n",
      "2025-03-03 13:13:13,448 - WARNING - No bond_long in results for MJUS: {}\n",
      "2025-03-03 13:13:35,544 - WARNING - No bond_long in results for TTAC: {}\n",
      "2025-03-03 13:13:38,209 - WARNING - No bond_long in results for NETZ: {}\n",
      "2025-03-03 13:13:42,877 - INFO - Null value in bond_long for FMCE: [None, None]\n",
      "2025-03-03 13:13:48,856 - WARNING - No bond_long in results for USCF: {}\n",
      "2025-03-03 13:14:17,832 - WARNING - No bond_long in results for IMSI: {}\n",
      "2025-03-03 13:14:19,893 - WARNING - No bond_long in results for HYMU: {}\n",
      "2025-03-03 13:14:33,814 - WARNING - No bond_long in results for WBND: {}\n",
      "2025-03-03 13:14:36,499 - INFO - Null value in bond_long for PSQO: [None, None]\n",
      "2025-03-03 13:14:38,214 - WARNING - No bond_long in results for DFHY: {}\n",
      "2025-03-03 13:14:39,811 - WARNING - No bond_long in results for ISDB: {}\n",
      "2025-03-03 13:14:43,568 - WARNING - No bond_long in results for JIEIX: {}\n",
      "2025-03-03 13:14:50,650 - WARNING - No bond_long in results for ABQYX: {}\n",
      "2025-03-03 13:14:59,194 - WARNING - No bond_long in results for MAYHX: {}\n",
      "2025-03-03 13:15:16,882 - WARNING - No bond_long in results for FGTBX: {}\n",
      "2025-03-03 13:15:24,916 - WARNING - No bond_long in results for FSMZX: {}\n",
      "2025-03-03 13:15:31,300 - WARNING - No bond_long in results for AMCYX: {}\n",
      "2025-03-03 13:15:35,083 - WARNING - No bond_long in results for JGIFX: {}\n",
      "2025-03-03 13:15:43,278 - WARNING - No bond_long in results for FPPJX: {}\n",
      "2025-03-03 13:15:44,921 - WARNING - No bond_long in results for MUIBX: {}\n",
      "2025-03-03 13:15:47,449 - WARNING - No bond_long in results for NHYMX: {}\n",
      "2025-03-03 13:16:00,969 - WARNING - No bond_long in results for PYHIX: {}\n",
      "2025-03-03 13:16:28,491 - INFO - Inserting 5536 rows for bond_long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating bond_long for 5536 funds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 13:16:29,456 - INFO - Found 5586 funds needing bond_net updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary for bond_long:\n",
      "  Funds Needing Update: 5586\n",
      "  Data Fetched: 5536\n",
      "  Inserted: 5536\n",
      "  No Data: 50\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n",
      "Requesting Bond Net for 5586 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 13:16:33,145 - WARNING - No bond_net in results for AMPD: {}\n",
      "2025-03-03 13:16:34,676 - WARNING - No bond_net in results for VMOT: {}\n",
      "2025-03-03 13:16:38,422 - INFO - Null value in bond_net for HSBH: [None, None]\n",
      "2025-03-03 13:16:38,614 - INFO - Null value in bond_net for SHEH: [None, None]\n",
      "2025-03-03 13:16:40,566 - WARNING - No bond_net in results for PP: {}\n",
      "2025-03-03 13:16:41,294 - WARNING - No bond_net in results for VCAR: {}\n",
      "2025-03-03 13:16:48,928 - INFO - Null value in bond_net for AZNH: [None, None]\n",
      "2025-03-03 13:16:58,590 - INFO - Null value in bond_net for PSQA: [None, None]\n",
      "2025-03-03 13:17:00,384 - INFO - Null value in bond_net for APDOX: [None, None]\n",
      "2025-03-03 13:17:08,202 - WARNING - No bond_net in results for OFIYX: {}\n",
      "2025-03-03 13:17:22,303 - WARNING - No bond_net in results for TWIO: {}\n",
      "2025-03-03 13:17:23,716 - WARNING - No bond_net in results for DFNV: {}\n",
      "2025-03-03 13:17:26,268 - WARNING - No bond_net in results for DFRA: {}\n",
      "2025-03-03 13:17:28,242 - INFO - Null value in bond_net for IAUM: [None, None]\n",
      "2025-03-03 13:17:28,427 - INFO - Null value in bond_net for HGER: [None, None]\n",
      "2025-03-03 13:17:30,501 - INFO - Null value in bond_net for BCIM: [None, None]\n",
      "2025-03-03 13:17:40,996 - WARNING - No bond_net in results for TTAI: {}\n",
      "2025-03-03 13:17:42,393 - WARNING - No bond_net in results for IQDE: {}\n",
      "2025-03-03 13:17:52,225 - WARNING - No bond_net in results for XYLE: {}\n",
      "2025-03-03 13:17:53,938 - WARNING - No bond_net in results for EMCC: {}\n",
      "2025-03-03 13:17:54,055 - WARNING - No bond_net in results for NUSI: {}\n",
      "2025-03-03 13:17:54,963 - WARNING - No bond_net in results for FYLG: {}\n",
      "2025-03-03 13:17:54,969 - WARNING - No bond_net in results for HYLG: {}\n",
      "2025-03-03 13:17:59,157 - WARNING - No bond_net in results for GCLN: {}\n",
      "2025-03-03 13:17:59,446 - WARNING - No bond_net in results for QYLE: {}\n",
      "2025-03-03 13:18:00,425 - WARNING - No bond_net in results for OCTA: {}\n",
      "2025-03-03 13:18:00,427 - WARNING - No bond_net in results for GREI: {}\n",
      "2025-03-03 13:18:00,449 - WARNING - No bond_net in results for GPOW: {}\n",
      "2025-03-03 13:18:02,145 - WARNING - No bond_net in results for MJUS: {}\n",
      "2025-03-03 13:18:23,382 - WARNING - No bond_net in results for TTAC: {}\n",
      "2025-03-03 13:18:27,102 - WARNING - No bond_net in results for NETZ: {}\n",
      "2025-03-03 13:18:32,330 - INFO - Null value in bond_net for FMCE: [None, None]\n",
      "2025-03-03 13:18:34,874 - WARNING - No bond_net in results for USCF: {}\n",
      "2025-03-03 13:18:49,455 - WARNING - No bond_net in results for IMSI: {}\n",
      "2025-03-03 13:18:49,622 - WARNING - No bond_net in results for HYMU: {}\n",
      "2025-03-03 13:19:01,314 - WARNING - No bond_net in results for WBND: {}\n",
      "2025-03-03 13:19:04,874 - INFO - Null value in bond_net for PSQO: [None, None]\n",
      "2025-03-03 13:19:05,214 - WARNING - No bond_net in results for DFHY: {}\n",
      "2025-03-03 13:19:08,161 - WARNING - No bond_net in results for ISDB: {}\n",
      "2025-03-03 13:19:11,463 - WARNING - No bond_net in results for JIEIX: {}\n",
      "2025-03-03 13:19:13,946 - WARNING - No bond_net in results for ABQYX: {}\n",
      "2025-03-03 13:19:26,569 - WARNING - No bond_net in results for MAYHX: {}\n",
      "2025-03-03 13:19:41,720 - WARNING - No bond_net in results for FGTBX: {}\n",
      "2025-03-03 13:19:49,148 - WARNING - No bond_net in results for FSMZX: {}\n",
      "2025-03-03 13:19:55,488 - WARNING - No bond_net in results for AMCYX: {}\n",
      "2025-03-03 13:20:03,174 - WARNING - No bond_net in results for JGIFX: {}\n",
      "2025-03-03 13:20:09,965 - WARNING - No bond_net in results for FPPJX: {}\n",
      "2025-03-03 13:20:13,381 - WARNING - No bond_net in results for MUIBX: {}\n",
      "2025-03-03 13:20:13,744 - WARNING - No bond_net in results for NHYMX: {}\n",
      "2025-03-03 13:20:24,388 - WARNING - No bond_net in results for PYHIX: {}\n",
      "2025-03-03 13:20:48,100 - INFO - Inserting 5536 rows for bond_net\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating bond_net for 5536 funds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 13:20:49,181 - INFO - Found 5586 funds needing bond_short updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary for bond_net:\n",
      "  Funds Needing Update: 5586\n",
      "  Data Fetched: 5536\n",
      "  Inserted: 5536\n",
      "  No Data: 50\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n",
      "Requesting Bond Short for 5586 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 13:20:52,165 - WARNING - No bond_short in results for AMPD: {}\n",
      "2025-03-03 13:20:53,970 - WARNING - No bond_short in results for VMOT: {}\n",
      "2025-03-03 13:20:58,227 - INFO - Null value in bond_short for SHEH: [None, None]\n",
      "2025-03-03 13:20:58,260 - INFO - Null value in bond_short for AZNH: [None, None]\n",
      "2025-03-03 13:20:59,323 - INFO - Null value in bond_short for HSBH: [None, None]\n",
      "2025-03-03 13:21:00,448 - WARNING - No bond_short in results for VCAR: {}\n",
      "2025-03-03 13:21:00,601 - WARNING - No bond_short in results for PP: {}\n",
      "2025-03-03 13:21:17,714 - INFO - Null value in bond_short for PSQA: [None, None]\n",
      "2025-03-03 13:21:21,430 - INFO - Null value in bond_short for APDOX: [None, None]\n",
      "2025-03-03 13:21:30,557 - WARNING - No bond_short in results for OFIYX: {}\n",
      "2025-03-03 13:21:44,895 - WARNING - No bond_short in results for TWIO: {}\n",
      "2025-03-03 13:21:46,592 - WARNING - No bond_short in results for DFRA: {}\n",
      "2025-03-03 13:21:47,890 - WARNING - No bond_short in results for DFNV: {}\n",
      "2025-03-03 13:21:50,877 - INFO - Null value in bond_short for HGER: [None, None]\n",
      "2025-03-03 13:21:52,151 - INFO - Null value in bond_short for BCIM: [None, None]\n",
      "2025-03-03 13:21:52,597 - INFO - Null value in bond_short for IAUM: [None, None]\n",
      "2025-03-03 13:22:04,946 - WARNING - No bond_short in results for TTAI: {}\n",
      "2025-03-03 13:22:08,035 - WARNING - No bond_short in results for IQDE: {}\n",
      "2025-03-03 13:22:14,354 - WARNING - No bond_short in results for XYLE: {}\n",
      "2025-03-03 13:22:18,059 - WARNING - No bond_short in results for QYLE: {}\n",
      "2025-03-03 13:22:18,699 - WARNING - No bond_short in results for NUSI: {}\n",
      "2025-03-03 13:22:20,744 - WARNING - No bond_short in results for EMCC: {}\n",
      "2025-03-03 13:22:21,505 - WARNING - No bond_short in results for HYLG: {}\n",
      "2025-03-03 13:22:21,790 - WARNING - No bond_short in results for FYLG: {}\n",
      "2025-03-03 13:22:24,099 - WARNING - No bond_short in results for GPOW: {}\n",
      "2025-03-03 13:22:24,129 - WARNING - No bond_short in results for GCLN: {}\n",
      "2025-03-03 13:22:24,931 - WARNING - No bond_short in results for OCTA: {}\n",
      "2025-03-03 13:22:25,930 - WARNING - No bond_short in results for MJUS: {}\n",
      "2025-03-03 13:22:25,960 - WARNING - No bond_short in results for GREI: {}\n",
      "2025-03-03 13:22:47,104 - WARNING - No bond_short in results for TTAC: {}\n",
      "2025-03-03 13:22:49,906 - WARNING - No bond_short in results for NETZ: {}\n",
      "2025-03-03 13:22:52,792 - INFO - Null value in bond_short for FMCE: [None, None]\n",
      "2025-03-03 13:22:55,604 - WARNING - No bond_short in results for USCF: {}\n",
      "2025-03-03 13:23:13,271 - WARNING - No bond_short in results for IMSI: {}\n",
      "2025-03-03 13:23:13,326 - WARNING - No bond_short in results for HYMU: {}\n",
      "2025-03-03 13:23:25,050 - WARNING - No bond_short in results for WBND: {}\n",
      "2025-03-03 13:23:29,496 - INFO - Null value in bond_short for PSQO: [None, None]\n",
      "2025-03-03 13:23:31,730 - WARNING - No bond_short in results for DFHY: {}\n",
      "2025-03-03 13:23:33,134 - WARNING - No bond_short in results for ISDB: {}\n",
      "2025-03-03 13:23:37,725 - WARNING - No bond_short in results for JIEIX: {}\n",
      "2025-03-03 13:23:38,558 - WARNING - No bond_short in results for ABQYX: {}\n",
      "2025-03-03 13:23:56,274 - WARNING - No bond_short in results for MAYHX: {}\n",
      "2025-03-03 13:24:23,844 - WARNING - No bond_short in results for FGTBX: {}\n",
      "2025-03-03 13:24:35,391 - WARNING - No bond_short in results for FSMZX: {}\n",
      "2025-03-03 13:24:46,804 - WARNING - No bond_short in results for AMCYX: {}\n",
      "2025-03-03 13:24:55,169 - WARNING - No bond_short in results for JGIFX: {}\n",
      "2025-03-03 13:25:03,886 - WARNING - No bond_short in results for FPPJX: {}\n",
      "2025-03-03 13:25:07,405 - WARNING - No bond_short in results for MUIBX: {}\n",
      "2025-03-03 13:25:08,488 - WARNING - No bond_short in results for NHYMX: {}\n",
      "2025-03-03 13:25:22,250 - WARNING - No bond_short in results for PYHIX: {}\n",
      "2025-03-03 13:25:45,276 - INFO - Inserting 5536 rows for bond_short\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating bond_short for 5536 funds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 13:25:46,226 - INFO - Found 5586 funds needing other_long updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary for bond_short:\n",
      "  Funds Needing Update: 5586\n",
      "  Data Fetched: 5536\n",
      "  Inserted: 5536\n",
      "  No Data: 50\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n",
      "Requesting Other Long for 5586 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 13:25:49,523 - WARNING - No other_long in results for VMOT: {}\n",
      "2025-03-03 13:25:51,235 - WARNING - No other_long in results for AMPD: {}\n",
      "2025-03-03 13:25:53,853 - INFO - Null value in other_long for HSBH: [None, None]\n",
      "2025-03-03 13:25:54,281 - INFO - Null value in other_long for SHEH: [None, None]\n",
      "2025-03-03 13:25:57,678 - WARNING - No other_long in results for VCAR: {}\n",
      "2025-03-03 13:25:58,103 - INFO - Null value in other_long for AZNH: [None, None]\n",
      "2025-03-03 13:26:00,056 - WARNING - No other_long in results for PP: {}\n",
      "2025-03-03 13:26:13,021 - INFO - Null value in other_long for PSQA: [None, None]\n",
      "2025-03-03 13:26:15,588 - INFO - Null value in other_long for APDOX: [None, None]\n",
      "2025-03-03 13:26:25,487 - WARNING - No other_long in results for OFIYX: {}\n",
      "2025-03-03 13:26:41,669 - WARNING - No other_long in results for TWIO: {}\n",
      "2025-03-03 13:26:44,707 - WARNING - No other_long in results for DFRA: {}\n",
      "2025-03-03 13:26:45,442 - WARNING - No other_long in results for DFNV: {}\n",
      "2025-03-03 13:26:48,457 - INFO - Null value in other_long for HGER: [None, None]\n",
      "2025-03-03 13:26:48,736 - INFO - Null value in other_long for IAUM: [None, None]\n",
      "2025-03-03 13:26:49,586 - INFO - Null value in other_long for BCIM: [None, None]\n",
      "2025-03-03 13:26:59,205 - WARNING - No other_long in results for TTAI: {}\n",
      "2025-03-03 13:27:01,545 - WARNING - No other_long in results for IQDE: {}\n",
      "2025-03-03 13:27:10,068 - WARNING - No other_long in results for QYLE: {}\n",
      "2025-03-03 13:27:10,368 - WARNING - No other_long in results for XYLE: {}\n",
      "2025-03-03 13:27:11,956 - WARNING - No other_long in results for EMCC: {}\n",
      "2025-03-03 13:27:12,820 - WARNING - No other_long in results for NUSI: {}\n",
      "2025-03-03 13:27:13,558 - WARNING - No other_long in results for HYLG: {}\n",
      "2025-03-03 13:27:13,738 - WARNING - No other_long in results for FYLG: {}\n",
      "2025-03-03 13:27:18,181 - WARNING - No other_long in results for GCLN: {}\n",
      "2025-03-03 13:27:18,362 - WARNING - No other_long in results for GPOW: {}\n",
      "2025-03-03 13:27:19,104 - WARNING - No other_long in results for GREI: {}\n",
      "2025-03-03 13:27:19,109 - WARNING - No other_long in results for OCTA: {}\n",
      "2025-03-03 13:27:21,867 - WARNING - No other_long in results for MJUS: {}\n",
      "2025-03-03 13:27:42,152 - WARNING - No other_long in results for TTAC: {}\n",
      "2025-03-03 13:27:45,786 - WARNING - No other_long in results for NETZ: {}\n",
      "2025-03-03 13:27:47,197 - INFO - Null value in other_long for FMCE: [None, None]\n",
      "2025-03-03 13:27:53,148 - WARNING - No other_long in results for USCF: {}\n",
      "2025-03-03 13:28:10,210 - WARNING - No other_long in results for IMSI: {}\n",
      "2025-03-03 13:28:13,673 - WARNING - No other_long in results for HYMU: {}\n",
      "2025-03-03 13:28:26,894 - WARNING - No other_long in results for WBND: {}\n",
      "2025-03-03 13:28:26,904 - WARNING - No other_long in results for DFHY: {}\n",
      "2025-03-03 13:28:29,046 - WARNING - No other_long in results for ISDB: {}\n",
      "2025-03-03 13:28:29,969 - INFO - Null value in other_long for PSQO: [None, None]\n",
      "2025-03-03 13:28:32,055 - WARNING - No other_long in results for ABQYX: {}\n",
      "2025-03-03 13:28:36,022 - WARNING - No other_long in results for JIEIX: {}\n",
      "2025-03-03 13:28:50,825 - WARNING - No other_long in results for MAYHX: {}\n",
      "2025-03-03 13:29:10,833 - WARNING - No other_long in results for FGTBX: {}\n",
      "2025-03-03 13:29:14,845 - WARNING - No other_long in results for FSMZX: {}\n",
      "2025-03-03 13:29:22,880 - WARNING - No other_long in results for AMCYX: {}\n",
      "2025-03-03 13:29:26,604 - WARNING - No other_long in results for JGIFX: {}\n",
      "2025-03-03 13:29:35,227 - WARNING - No other_long in results for FPPJX: {}\n",
      "2025-03-03 13:29:38,621 - WARNING - No other_long in results for MUIBX: {}\n",
      "2025-03-03 13:29:40,427 - WARNING - No other_long in results for NHYMX: {}\n",
      "2025-03-03 13:29:50,173 - WARNING - No other_long in results for PYHIX: {}\n",
      "2025-03-03 13:30:12,384 - INFO - Inserting 5536 rows for other_long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating other_long for 5536 funds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 13:30:13,383 - INFO - Found 5586 funds needing other_net updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary for other_long:\n",
      "  Funds Needing Update: 5586\n",
      "  Data Fetched: 5536\n",
      "  Inserted: 5536\n",
      "  No Data: 50\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n",
      "Requesting Other Net for 5586 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 13:30:15,655 - WARNING - No other_net in results for AMPD: {}\n",
      "2025-03-03 13:30:16,738 - WARNING - No other_net in results for VMOT: {}\n",
      "2025-03-03 13:30:21,222 - INFO - Null value in other_net for HSBH: [None, None]\n",
      "2025-03-03 13:30:23,004 - INFO - Null value in other_net for AZNH: [None, None]\n",
      "2025-03-03 13:30:23,198 - WARNING - No other_net in results for PP: {}\n",
      "2025-03-03 13:30:23,345 - WARNING - No other_net in results for VCAR: {}\n",
      "2025-03-03 13:30:24,498 - INFO - Null value in other_net for SHEH: [None, None]\n",
      "2025-03-03 13:30:41,378 - INFO - Null value in other_net for PSQA: [None, None]\n",
      "2025-03-03 13:30:43,279 - INFO - Null value in other_net for APDOX: [None, None]\n",
      "2025-03-03 13:30:50,360 - WARNING - No other_net in results for OFIYX: {}\n",
      "2025-03-03 13:31:03,357 - WARNING - No other_net in results for TWIO: {}\n",
      "2025-03-03 13:31:07,666 - WARNING - No other_net in results for DFNV: {}\n",
      "2025-03-03 13:31:07,667 - WARNING - No other_net in results for DFRA: {}\n",
      "2025-03-03 13:31:10,842 - INFO - Null value in other_net for IAUM: [None, None]\n",
      "2025-03-03 13:31:12,651 - INFO - Null value in other_net for HGER: [None, None]\n",
      "2025-03-03 13:31:14,453 - INFO - Null value in other_net for BCIM: [None, None]\n",
      "2025-03-03 13:31:22,171 - WARNING - No other_net in results for TTAI: {}\n",
      "2025-03-03 13:31:25,496 - WARNING - No other_net in results for IQDE: {}\n",
      "2025-03-03 13:31:33,212 - WARNING - No other_net in results for QYLE: {}\n",
      "2025-03-03 13:31:33,729 - WARNING - No other_net in results for XYLE: {}\n",
      "2025-03-03 13:31:38,328 - WARNING - No other_net in results for NUSI: {}\n",
      "2025-03-03 13:31:38,968 - WARNING - No other_net in results for EMCC: {}\n",
      "2025-03-03 13:31:49,750 - WARNING - No other_net in results for HYLG: {}\n",
      "2025-03-03 13:31:52,608 - WARNING - No other_net in results for OCTA: {}\n",
      "2025-03-03 13:31:52,689 - WARNING - No other_net in results for GPOW: {}\n",
      "2025-03-03 13:31:52,809 - WARNING - No other_net in results for FYLG: {}\n",
      "2025-03-03 13:31:52,840 - WARNING - No other_net in results for GCLN: {}\n",
      "2025-03-03 13:31:54,242 - WARNING - No other_net in results for GREI: {}\n",
      "2025-03-03 13:31:54,437 - WARNING - No other_net in results for MJUS: {}\n",
      "2025-03-03 13:32:33,576 - WARNING - No other_net in results for TTAC: {}\n",
      "2025-03-03 13:32:36,396 - WARNING - No other_net in results for NETZ: {}\n",
      "2025-03-03 13:32:39,525 - INFO - Null value in other_net for FMCE: [None, None]\n",
      "2025-03-03 13:32:43,263 - WARNING - No other_net in results for USCF: {}\n",
      "2025-03-03 13:32:59,584 - WARNING - No other_net in results for HYMU: {}\n",
      "2025-03-03 13:32:59,596 - WARNING - No other_net in results for IMSI: {}\n",
      "2025-03-03 13:33:11,606 - WARNING - No other_net in results for WBND: {}\n",
      "2025-03-03 13:33:20,319 - INFO - Null value in other_net for PSQO: [None, None]\n",
      "2025-03-03 13:33:20,379 - WARNING - No other_net in results for DFHY: {}\n",
      "2025-03-03 13:33:20,393 - WARNING - No other_net in results for ISDB: {}\n",
      "2025-03-03 13:33:25,274 - WARNING - No other_net in results for JIEIX: {}\n",
      "2025-03-03 13:33:26,642 - WARNING - No other_net in results for ABQYX: {}\n",
      "2025-03-03 13:33:36,107 - WARNING - No other_net in results for MAYHX: {}\n",
      "2025-03-03 13:33:52,876 - WARNING - No other_net in results for FGTBX: {}\n",
      "2025-03-03 13:34:02,336 - WARNING - No other_net in results for FSMZX: {}\n",
      "2025-03-03 13:34:09,616 - WARNING - No other_net in results for AMCYX: {}\n",
      "2025-03-03 13:34:13,220 - WARNING - No other_net in results for JGIFX: {}\n",
      "2025-03-03 13:34:21,577 - WARNING - No other_net in results for FPPJX: {}\n",
      "2025-03-03 13:34:23,496 - WARNING - No other_net in results for MUIBX: {}\n",
      "2025-03-03 13:34:26,942 - WARNING - No other_net in results for NHYMX: {}\n",
      "2025-03-03 13:34:41,461 - WARNING - No other_net in results for PYHIX: {}\n",
      "2025-03-03 13:35:01,824 - INFO - Inserting 5536 rows for other_net\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating other_net for 5536 funds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 13:35:03,758 - INFO - Found 5586 funds needing other_short updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary for other_net:\n",
      "  Funds Needing Update: 5586\n",
      "  Data Fetched: 5536\n",
      "  Inserted: 5536\n",
      "  No Data: 50\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n",
      "Requesting Other Short for 5586 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 13:35:07,854 - WARNING - No other_short in results for VMOT: {}\n",
      "2025-03-03 13:35:09,179 - WARNING - No other_short in results for AMPD: {}\n",
      "2025-03-03 13:35:13,260 - INFO - Null value in other_short for HSBH: [None, None]\n",
      "2025-03-03 13:35:13,699 - INFO - Null value in other_short for SHEH: [None, None]\n",
      "2025-03-03 13:35:13,768 - INFO - Null value in other_short for AZNH: [None, None]\n",
      "2025-03-03 13:35:15,597 - WARNING - No other_short in results for VCAR: {}\n",
      "2025-03-03 13:35:15,677 - WARNING - No other_short in results for PP: {}\n",
      "2025-03-03 13:35:33,577 - INFO - Null value in other_short for PSQA: [None, None]\n",
      "2025-03-03 13:35:36,860 - INFO - Null value in other_short for APDOX: [None, None]\n",
      "2025-03-03 13:35:44,165 - WARNING - No other_short in results for OFIYX: {}\n",
      "2025-03-03 13:35:57,533 - WARNING - No other_short in results for TWIO: {}\n",
      "2025-03-03 13:36:00,185 - WARNING - No other_short in results for DFRA: {}\n",
      "2025-03-03 13:36:01,957 - WARNING - No other_short in results for DFNV: {}\n",
      "2025-03-03 13:36:03,698 - INFO - Null value in other_short for HGER: [None, None]\n",
      "2025-03-03 13:36:05,178 - INFO - Null value in other_short for IAUM: [None, None]\n",
      "2025-03-03 13:36:05,311 - INFO - Null value in other_short for BCIM: [None, None]\n",
      "2025-03-03 13:36:17,494 - WARNING - No other_short in results for TTAI: {}\n",
      "2025-03-03 13:36:21,004 - WARNING - No other_short in results for IQDE: {}\n",
      "2025-03-03 13:36:28,521 - WARNING - No other_short in results for XYLE: {}\n",
      "2025-03-03 13:36:28,618 - WARNING - No other_short in results for QYLE: {}\n",
      "2025-03-03 13:36:31,456 - WARNING - No other_short in results for EMCC: {}\n",
      "2025-03-03 13:36:31,583 - WARNING - No other_short in results for NUSI: {}\n",
      "2025-03-03 13:36:32,977 - WARNING - No other_short in results for HYLG: {}\n",
      "2025-03-03 13:36:33,028 - WARNING - No other_short in results for FYLG: {}\n",
      "2025-03-03 13:36:36,475 - WARNING - No other_short in results for OCTA: {}\n",
      "2025-03-03 13:36:36,491 - WARNING - No other_short in results for GPOW: {}\n",
      "2025-03-03 13:36:36,650 - WARNING - No other_short in results for GCLN: {}\n",
      "2025-03-03 13:36:39,157 - WARNING - No other_short in results for MJUS: {}\n",
      "2025-03-03 13:36:40,110 - WARNING - No other_short in results for GREI: {}\n",
      "2025-03-03 13:37:09,519 - WARNING - No other_short in results for TTAC: {}\n",
      "2025-03-03 13:37:16,788 - WARNING - No other_short in results for NETZ: {}\n",
      "2025-03-03 13:37:23,334 - INFO - Null value in other_short for FMCE: [None, None]\n",
      "2025-03-03 13:37:35,112 - WARNING - No other_short in results for USCF: {}\n",
      "2025-03-03 13:38:03,277 - WARNING - No other_short in results for HYMU: {}\n",
      "2025-03-03 13:38:03,279 - WARNING - No other_short in results for IMSI: {}\n",
      "2025-03-03 13:38:26,911 - WARNING - No other_short in results for WBND: {}\n",
      "2025-03-03 13:38:32,647 - INFO - Null value in other_short for PSQO: [None, None]\n",
      "2025-03-03 13:38:33,100 - WARNING - No other_short in results for DFHY: {}\n",
      "2025-03-03 13:38:37,579 - WARNING - No other_short in results for ISDB: {}\n",
      "2025-03-03 13:38:42,928 - WARNING - No other_short in results for ABQYX: {}\n",
      "2025-03-03 13:38:42,971 - WARNING - No other_short in results for JIEIX: {}\n",
      "2025-03-03 13:38:58,158 - WARNING - No other_short in results for MAYHX: {}\n",
      "2025-03-03 13:39:21,645 - WARNING - No other_short in results for FGTBX: {}\n",
      "2025-03-03 13:39:31,606 - WARNING - No other_short in results for FSMZX: {}\n",
      "2025-03-03 13:39:39,314 - WARNING - No other_short in results for AMCYX: {}\n",
      "2025-03-03 13:39:43,555 - WARNING - No other_short in results for JGIFX: {}\n",
      "2025-03-03 13:39:53,564 - WARNING - No other_short in results for FPPJX: {}\n",
      "2025-03-03 13:39:55,627 - WARNING - No other_short in results for MUIBX: {}\n",
      "2025-03-03 13:39:59,035 - WARNING - No other_short in results for NHYMX: {}\n",
      "2025-03-03 13:40:14,445 - WARNING - No other_short in results for PYHIX: {}\n",
      "2025-03-03 13:40:35,747 - INFO - Inserting 5536 rows for other_short\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating other_short for 5536 funds\n",
      "\n",
      "Summary for other_short:\n",
      "  Funds Needing Update: 5586\n",
      "  Data Fetched: 5536\n",
      "  Inserted: 5536\n",
      "  No Data: 50\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n"
     ]
    }
   ],
   "source": [
    "# Simple script to populate cash_long, cash_net, etc. columns in Funds_to_Screen\n",
    "# Uses YCP API calls and mirrors core functionality from the provided script\n",
    "\n",
    "import requests\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor, TimeoutError\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# Step 1: Configuration\n",
    "# ---------------------\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Database connection string (same as provided script)\n",
    "connection_string = (\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/\"\n",
    "    \"CWA_Fund_Database?driver=ODBC+Driver+18+for+SQL+Server\"\n",
    "    \"&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "engine = sqlalchemy.create_engine(connection_string)\n",
    "\n",
    "# Test database connection\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(sqlalchemy.text(\"SELECT 1\"))\n",
    "    print(\"Database connection successful\")\n",
    "except Exception as e:\n",
    "    print(f\"Database connection failed: {e}\")\n",
    "\n",
    "# YCharts API headers for YCP (POST) requests (same as provided script)\n",
    "headers_YCP = {\n",
    "    \"X-YCHARTSAUTHORIZATION\": \"yIIphqbsQysnTvWWxfW33w\",  # Replace with your actual API key\n",
    "    \"X-YCHARTSEXCELSESSION\": \"b645cd897b2446bfa3796acfa3a879db\",\n",
    "    \"X-YCHARTSEXCELVERSION\": \"4.4\",\n",
    "    \"X-YCHARTSOPERATINGSYSTEM\": \"Microsoft Windows NT 10.0.26100.0\",\n",
    "    \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "    \"Host\": \"api.ycharts.com\",\n",
    "    \"Connection\": \"Keep-Alive\"\n",
    "}\n",
    "\n",
    "# Define base YCharts URL\n",
    "yc_base_url = \"https://api.ycharts.com/v3/\"b\n",
    "\n",
    "# Metrics to fetch (all use YCP call type)\n",
    "metrics_to_fetch = [\n",
    "    {\"yc_metric\": \"cash_long\", \"db_column\": \"cash_long\"},\n",
    "    {\"yc_metric\": \"cash_net\", \"db_column\": \"cash_net\"},\n",
    "    {\"yc_metric\": \"cash_short\", \"db_column\": \"cash_short\"},\n",
    "    {\"yc_metric\": \"stock_long\", \"db_column\": \"stock_long\"},\n",
    "    {\"yc_metric\": \"stock_net\", \"db_column\": \"stock_net\"},\n",
    "    {\"yc_metric\": \"stock_short\", \"db_column\": \"stock_short\"},\n",
    "    {\"yc_metric\": \"bond_long\", \"db_column\": \"bond_long\"},\n",
    "    {\"yc_metric\": \"bond_net\", \"db_column\": \"bond_net\"},\n",
    "    {\"yc_metric\": \"bond_short\", \"db_column\": \"bond_short\"},\n",
    "    {\"yc_metric\": \"other_long\", \"db_column\": \"other_long\"},\n",
    "    {\"yc_metric\": \"other_net\", \"db_column\": \"other_net\"},\n",
    "    {\"yc_metric\": \"other_short\", \"db_column\": \"other_short\"},\n",
    "]\n",
    "\n",
    "# Step 2: Core Functions\n",
    "# ----------------------\n",
    "\n",
    "def fetch_ycp_metric(symbol, fund_type_id, yc_metric, headers_YCP=headers_YCP):\n",
    "    \"\"\"\n",
    "    Fetch YCP data from YCharts API using a POST request.\n",
    "    \n",
    "    Args:\n",
    "        symbol (str): Fund symbol (e.g., \"BALCX\").\n",
    "        fund_type_id (int): Fund type (e.g., 3 for mutual funds).\n",
    "        yc_metric (str): Metric to fetch (e.g., \"cash_long\").\n",
    "        headers_YCP (dict): Headers for YCP request.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple: (symbol, normalized_data) or (None, error_info).\n",
    "    \"\"\"\n",
    "    # Set up YCP URL and payload\n",
    "    ycp_api_url = \"https://api.ycharts.com/v3/excel/points\"\n",
    "    symbol_prefix = f\"M:{symbol}\" if fund_type_id == 3 else symbol\n",
    "    data = f\"points={symbol_prefix},{yc_metric}\"\n",
    "    logging.debug(f\"YCP payload for {symbol}: {data}\")\n",
    "\n",
    "    try:\n",
    "        # Make POST request with SSL bypass\n",
    "        response = requests.post(ycp_api_url, headers=headers_YCP, data=data, verify=False)\n",
    "        if response.status_code != 200:\n",
    "            logging.error(f\"YCP HTTP error for {symbol}: {response.status_code}\")\n",
    "            return None, {\"error\": f\"HTTP {response.status_code}\"}\n",
    "        \n",
    "        # Parse JSON response\n",
    "        data = response.json()\n",
    "        logging.debug(f\"YCP response for {symbol}: {data}\")\n",
    "\n",
    "        # Normalize data\n",
    "        normalized_data = normalize_api_data(data, symbol, yc_metric, fund_type_id=fund_type_id)\n",
    "        return symbol, normalized_data\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        logging.error(f\"YCP request failed for {symbol}: {str(e)}\")\n",
    "        return None, {\"error\": str(e)}\n",
    "\n",
    "def normalize_api_data(data, symbol, yc_metric, fund_type_id=None):\n",
    "    \"\"\"\n",
    "    Normalize YCharts API YCP response data into a float.\n",
    "    \n",
    "    Args:\n",
    "        data (dict): Raw JSON response from API.\n",
    "        symbol (str): Fund symbol.\n",
    "        yc_metric (str): Metric name.\n",
    "        fund_type_id (int): Fund type (e.g., 3 for mutual funds).\n",
    "    \n",
    "    Returns:\n",
    "        float or None if parsing fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Adjust symbol key for mutual funds\n",
    "        response_key = f\"M:{symbol}\" if fund_type_id == 3 else symbol\n",
    "        if \"response\" not in data or response_key not in data[\"response\"]:\n",
    "            logging.warning(f\"No response data for {symbol}: {data}\")\n",
    "            return None\n",
    "\n",
    "        # Extract results\n",
    "        results = data[\"response\"][response_key].get(\"results\", {})\n",
    "        if yc_metric not in results:\n",
    "            logging.warning(f\"No {yc_metric} in results for {symbol}: {results}\")\n",
    "            return None\n",
    "\n",
    "        metric_data = results[yc_metric]\n",
    "        logging.debug(f\"Raw metric data for {yc_metric} ({symbol}): {metric_data}\")\n",
    "\n",
    "        # YCP expects ['']['results'] structure (e.g., [\"2025-01-01\", 0.123])\n",
    "        if \"\" in metric_data and \"results\" in metric_data[\"\"]:\n",
    "            data_list = metric_data[\"\"][\"results\"]\n",
    "            if isinstance(data_list, list) and len(data_list) >= 1:\n",
    "                # Take second value if available, else first\n",
    "                raw_data = data_list[1] if len(data_list) > 1 else data_list[0]\n",
    "                if raw_data is not None:\n",
    "                    return float(raw_data)\n",
    "                logging.info(f\"Null value in {yc_metric} for {symbol}: {data_list}\")\n",
    "                return None\n",
    "            logging.warning(f\"Invalid list format for {yc_metric} ({symbol}): {data_list}\")\n",
    "            return None\n",
    "        else:\n",
    "            logging.warning(f\"No ['']['results'] in {yc_metric} for {symbol}: {metric_data}\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Normalization failed for {yc_metric} ({symbol}): {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def insert_to_database(df, column_name, batch_size=1000):\n",
    "    \"\"\"\n",
    "    Insert or update data into Funds_to_Screen table in batches.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): DataFrame with SymbolCUSIP and column_name data.\n",
    "        column_name (str): Name of the column to update.\n",
    "        batch_size (int): Number of rows per batch.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple: (successes, failures, database_errors)\n",
    "    \"\"\"\n",
    "    successes = 0\n",
    "    failures = 0\n",
    "    database_errors = []\n",
    "    print(f\"Updating {column_name} for {len(df)} funds\")\n",
    "\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch = df.iloc[i:i + batch_size]\n",
    "        try:\n",
    "            with engine.begin() as conn:\n",
    "                updates = [{\"symbol\": row[\"SymbolCUSIP\"], \"value\": row[column_name]} for _, row in batch.iterrows()]\n",
    "                conn.execute(\n",
    "                    sqlalchemy.text(f\"\"\"\n",
    "                        UPDATE Funds_to_Screen \n",
    "                        SET {column_name} = :value\n",
    "                        WHERE SymbolCUSIP = :symbol\n",
    "                    \"\"\"),\n",
    "                    updates\n",
    "                )\n",
    "            successes += len(batch)\n",
    "        except sqlalchemy.exc.SQLAlchemyError as e:\n",
    "            logging.error(f\"Database error: {str(e)}\")\n",
    "            failures += len(batch)\n",
    "            database_errors.extend(batch[\"SymbolCUSIP\"].tolist())\n",
    "\n",
    "    return successes, failures, database_errors\n",
    "\n",
    "# Step 3: Main Function to Update Metrics\n",
    "# ---------------------------------------\n",
    "\n",
    "def update_metric(yc_metric, db_column_name):\n",
    "    \"\"\"\n",
    "    Update a specific metric for funds where the column is NULL.\n",
    "    \n",
    "    Args:\n",
    "        yc_metric (str): YCharts metric name (e.g., \"cash_long\").\n",
    "        db_column_name (str): Database column name (e.g., \"cash_long\").\n",
    "    \"\"\"\n",
    "    # Fetch funds where the column is NULL\n",
    "    query = f\"SELECT SymbolCUSIP, Fund_Type_ID FROM Funds_to_Screen WHERE {db_column_name} IS NULL\"\n",
    "    funds = pd.read_sql(query, engine)\n",
    "    logging.info(f\"Found {len(funds)} funds needing {yc_metric} updates\")\n",
    "\n",
    "    if len(funds) == 0:\n",
    "        print(f\"No funds need {yc_metric.replace('_', ' ').title()} updates.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Requesting {yc_metric.replace('_', ' ').title()} for {len(funds)} funds from YCharts...\")\n",
    "    data_list = []\n",
    "    no_data_count = 0\n",
    "\n",
    "    def fetch_for_fund(row):\n",
    "        try:\n",
    "            symbol, normalized_data = fetch_ycp_metric(row[\"SymbolCUSIP\"], row[\"Fund_Type_ID\"], yc_metric)\n",
    "            if normalized_data is not None and not isinstance(normalized_data, dict):\n",
    "                return (symbol, normalized_data)\n",
    "            return (symbol, None, \"No data\" if normalized_data is None else normalized_data.get(\"error\", \"Unknown error\"))\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Fetch error for {row['SymbolCUSIP']}: {str(e)}\")\n",
    "            return (row[\"SymbolCUSIP\"], None, str(e))\n",
    "\n",
    "    # Use ThreadPoolExecutor for parallel API calls\n",
    "    with ThreadPoolExecutor(max_workers=60) as executor:\n",
    "        future_to_row = {executor.submit(fetch_for_fund, row): row for _, row in funds.iterrows()}\n",
    "        results = []\n",
    "        for future in future_to_row:\n",
    "            try:\n",
    "                result = future.result(timeout=30)\n",
    "                results.append(result)\n",
    "            except TimeoutError:\n",
    "                symbol = future_to_row[future][\"SymbolCUSIP\"]\n",
    "                logging.error(f\"Timeout fetching {yc_metric} for {symbol}\")\n",
    "                results.append((symbol, None, \"Timeout after 30s\"))\n",
    "\n",
    "    # Process results\n",
    "    for symbol, normalized_data, *error in results:\n",
    "        if normalized_data is not None:\n",
    "            data_list.append((symbol, normalized_data))\n",
    "        else:\n",
    "            no_data_count += 1\n",
    "            if error and error[0] != \"No data\":\n",
    "                logging.error(f\"API error for {symbol}: {error[0]}\")\n",
    "\n",
    "    if not data_list:\n",
    "        print(f\"No data fetched for {yc_metric}. No updates performed.\")\n",
    "        print(f\"Summary - Funds Needing Update: {len(funds)}, No Data: {no_data_count}\")\n",
    "        return\n",
    "\n",
    "    # Insert data into database\n",
    "    df = pd.DataFrame(data_list, columns=[\"SymbolCUSIP\", db_column_name])\n",
    "    logging.info(f\"Inserting {len(df)} rows for {yc_metric}\")\n",
    "    insert_successes, insert_failures, database_errors = insert_to_database(df, db_column_name)\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"\\nSummary for {yc_metric}:\")\n",
    "    print(f\"  Funds Needing Update: {len(funds)}\")\n",
    "    print(f\"  Data Fetched: {len(df)}\")\n",
    "    print(f\"  Inserted: {insert_successes}\")\n",
    "    print(f\"  No Data: {no_data_count}\")\n",
    "    print(f\"  Database Errors: {insert_failures}\")\n",
    "    print(f\"  Failed Symbols: {';'.join(database_errors) if database_errors else 'None'}\")\n",
    "\n",
    "# Step 4: Main Execution\n",
    "# ----------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Loop through each metric and update\n",
    "    for config in metrics_to_fetch:\n",
    "        update_metric(config[\"yc_metric\"], config[\"db_column\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dbcaa2d-ffdc-42c9-b764-6621843e8c33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 14:34:52,560 - INFO - Found 50 funds needing cash_long updates out of 5586 total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection successful\n",
      "Requesting Cash Long for 50 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 14:34:53,481 - WARNING - No cash_long in results for IMSI: {}\n",
      "2025-03-10 14:34:53,678 - WARNING - No cash_long in results for NETZ: {}\n",
      "2025-03-10 14:34:53,681 - WARNING - No cash_long in results for GPOW: {}\n",
      "2025-03-10 14:34:53,685 - INFO - Null value in cash_long for FMCE: [None, None]\n",
      "2025-03-10 14:34:54,081 - WARNING - No cash_long in results for FYLG: {}\n",
      "2025-03-10 14:34:54,083 - WARNING - No cash_long in results for MUIBX: {}\n",
      "2025-03-10 14:34:54,101 - WARNING - No cash_long in results for FPPJX: {}\n",
      "2025-03-10 14:34:54,110 - WARNING - No cash_long in results for DFRA: {}\n",
      "2025-03-10 14:34:54,176 - INFO - Null value in cash_long for IAUM: [None, None]\n",
      "2025-03-10 14:34:54,223 - INFO - Null value in cash_long for BCIM: [None, None]\n",
      "2025-03-10 14:34:54,600 - WARNING - No cash_long in results for PP: {}\n",
      "2025-03-10 14:34:54,602 - WARNING - No cash_long in results for VCAR: {}\n",
      "2025-03-10 14:34:54,604 - WARNING - No cash_long in results for USCF: {}\n",
      "2025-03-10 14:34:54,628 - WARNING - No cash_long in results for JIEIX: {}\n",
      "2025-03-10 14:34:54,628 - WARNING - No cash_long in results for MAYHX: {}\n",
      "2025-03-10 14:34:54,630 - WARNING - No cash_long in results for HYMU: {}\n",
      "2025-03-10 14:34:54,694 - WARNING - No cash_long in results for NUSI: {}\n",
      "2025-03-10 14:34:54,712 - WARNING - No cash_long in results for WBND: {}\n",
      "2025-03-10 14:34:54,714 - WARNING - No cash_long in results for GREI: {}\n",
      "2025-03-10 14:34:54,717 - WARNING - No cash_long in results for TWIO: {}\n",
      "2025-03-10 14:34:54,721 - WARNING - No cash_long in results for DFHY: {}\n",
      "2025-03-10 14:34:54,721 - WARNING - No cash_long in results for MJUS: {}\n",
      "2025-03-10 14:34:54,742 - WARNING - No cash_long in results for ABQYX: {}\n",
      "2025-03-10 14:34:54,745 - WARNING - No cash_long in results for AMCYX: {}\n",
      "2025-03-10 14:34:54,747 - WARNING - No cash_long in results for FGTBX: {}\n",
      "2025-03-10 14:34:54,750 - WARNING - No cash_long in results for QYLE: {}\n",
      "2025-03-10 14:34:54,781 - WARNING - No cash_long in results for ISDB: {}\n",
      "2025-03-10 14:34:54,794 - INFO - Null value in cash_long for HGER: [None, None]\n",
      "2025-03-10 14:34:54,797 - WARNING - No cash_long in results for PYHIX: {}\n",
      "2025-03-10 14:34:54,860 - WARNING - No cash_long in results for VMOT: {}\n",
      "2025-03-10 14:34:54,874 - WARNING - No cash_long in results for DFNV: {}\n",
      "2025-03-10 14:34:54,875 - WARNING - No cash_long in results for XYLE: {}\n",
      "2025-03-10 14:34:54,875 - WARNING - No cash_long in results for EMCC: {}\n",
      "2025-03-10 14:34:54,875 - WARNING - No cash_long in results for OFIYX: {}\n",
      "2025-03-10 14:34:54,875 - WARNING - No cash_long in results for FSMZX: {}\n",
      "2025-03-10 14:34:54,902 - WARNING - No cash_long in results for HYLG: {}\n",
      "2025-03-10 14:34:54,916 - WARNING - No cash_long in results for JGIFX: {}\n",
      "2025-03-10 14:34:54,920 - WARNING - No cash_long in results for IQDE: {}\n",
      "2025-03-10 14:34:54,961 - INFO - Null value in cash_long for APDOX: [None, None]\n",
      "2025-03-10 14:34:54,977 - WARNING - No cash_long in results for TTAI: {}\n",
      "2025-03-10 14:34:54,981 - WARNING - No cash_long in results for AMPD: {}\n",
      "2025-03-10 14:34:54,983 - WARNING - No cash_long in results for OCTA: {}\n",
      "2025-03-10 14:34:54,988 - WARNING - No cash_long in results for TTAC: {}\n",
      "2025-03-10 14:34:55,089 - WARNING - No cash_long in results for NHYMX: {}\n",
      "2025-03-10 14:34:55,604 - WARNING - No cash_long in results for GCLN: {}\n",
      "2025-03-10 14:34:55,610 - INFO - Inserting 5 rows for cash_long\n",
      "2025-03-10 14:34:55,649 - INFO - Found 50 funds needing cash_net updates out of 5586 total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating cash_long for 5 funds\n",
      "\n",
      "Summary for cash_long:\n",
      "  Total Funds: 5586\n",
      "  Funds Needing Update: 50\n",
      "  Data Fetched: 5\n",
      "  Inserted: 5\n",
      "  No Data: 45\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n",
      "Requesting Cash Net for 50 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 14:34:56,713 - WARNING - No cash_net in results for EMCC: {}\n",
      "2025-03-10 14:34:56,739 - WARNING - No cash_net in results for PP: {}\n",
      "2025-03-10 14:34:56,751 - WARNING - No cash_net in results for HYLG: {}\n",
      "2025-03-10 14:34:56,765 - WARNING - No cash_net in results for TTAI: {}\n",
      "2025-03-10 14:34:56,854 - WARNING - No cash_net in results for TWIO: {}\n",
      "2025-03-10 14:34:56,881 - WARNING - No cash_net in results for NUSI: {}\n",
      "2025-03-10 14:34:56,950 - WARNING - No cash_net in results for QYLE: {}\n",
      "2025-03-10 14:34:56,966 - WARNING - No cash_net in results for VMOT: {}\n",
      "2025-03-10 14:34:56,966 - WARNING - No cash_net in results for FYLG: {}\n",
      "2025-03-10 14:34:56,967 - INFO - Null value in cash_net for BCIM: [None, None]\n",
      "2025-03-10 14:34:56,967 - WARNING - No cash_net in results for XYLE: {}\n",
      "2025-03-10 14:34:56,967 - INFO - Null value in cash_net for APDOX: [None, None]\n",
      "2025-03-10 14:34:56,967 - WARNING - No cash_net in results for DFRA: {}\n",
      "2025-03-10 14:34:56,968 - WARNING - No cash_net in results for OFIYX: {}\n",
      "2025-03-10 14:34:56,971 - WARNING - No cash_net in results for AMPD: {}\n",
      "2025-03-10 14:34:57,123 - INFO - Null value in cash_net for HGER: [None, None]\n",
      "2025-03-10 14:34:57,126 - WARNING - No cash_net in results for VCAR: {}\n",
      "2025-03-10 14:34:57,128 - WARNING - No cash_net in results for DFNV: {}\n",
      "2025-03-10 14:34:57,132 - INFO - Null value in cash_net for IAUM: [None, None]\n",
      "2025-03-10 14:34:57,361 - WARNING - No cash_net in results for IQDE: {}\n",
      "2025-03-10 14:34:57,529 - WARNING - No cash_net in results for GREI: {}\n",
      "2025-03-10 14:34:57,553 - WARNING - No cash_net in results for JIEIX: {}\n",
      "2025-03-10 14:34:57,554 - WARNING - No cash_net in results for HYMU: {}\n",
      "2025-03-10 14:34:57,554 - WARNING - No cash_net in results for ISDB: {}\n",
      "2025-03-10 14:34:57,554 - WARNING - No cash_net in results for FSMZX: {}\n",
      "2025-03-10 14:34:57,554 - WARNING - No cash_net in results for FGTBX: {}\n",
      "2025-03-10 14:34:57,554 - WARNING - No cash_net in results for IMSI: {}\n",
      "2025-03-10 14:34:57,713 - WARNING - No cash_net in results for GCLN: {}\n",
      "2025-03-10 14:34:57,723 - WARNING - No cash_net in results for MUIBX: {}\n",
      "2025-03-10 14:34:57,726 - WARNING - No cash_net in results for USCF: {}\n",
      "2025-03-10 14:34:57,726 - WARNING - No cash_net in results for TTAC: {}\n",
      "2025-03-10 14:34:57,730 - WARNING - No cash_net in results for NHYMX: {}\n",
      "2025-03-10 14:34:57,735 - WARNING - No cash_net in results for NETZ: {}\n",
      "2025-03-10 14:34:57,735 - WARNING - No cash_net in results for FPPJX: {}\n",
      "2025-03-10 14:34:57,797 - WARNING - No cash_net in results for MJUS: {}\n",
      "2025-03-10 14:34:57,800 - WARNING - No cash_net in results for WBND: {}\n",
      "2025-03-10 14:34:57,802 - WARNING - No cash_net in results for ABQYX: {}\n",
      "2025-03-10 14:34:57,807 - WARNING - No cash_net in results for OCTA: {}\n",
      "2025-03-10 14:34:57,807 - WARNING - No cash_net in results for AMCYX: {}\n",
      "2025-03-10 14:34:57,809 - WARNING - No cash_net in results for JGIFX: {}\n",
      "2025-03-10 14:34:57,813 - WARNING - No cash_net in results for PYHIX: {}\n",
      "2025-03-10 14:34:57,813 - WARNING - No cash_net in results for MAYHX: {}\n",
      "2025-03-10 14:34:57,816 - INFO - Null value in cash_net for FMCE: [None, None]\n",
      "2025-03-10 14:34:57,872 - WARNING - No cash_net in results for GPOW: {}\n",
      "2025-03-10 14:34:57,899 - WARNING - No cash_net in results for DFHY: {}\n",
      "2025-03-10 14:34:57,908 - INFO - Inserting 5 rows for cash_net\n",
      "2025-03-10 14:34:57,951 - INFO - Found 50 funds needing cash_short updates out of 5586 total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating cash_net for 5 funds\n",
      "\n",
      "Summary for cash_net:\n",
      "  Total Funds: 5586\n",
      "  Funds Needing Update: 50\n",
      "  Data Fetched: 5\n",
      "  Inserted: 5\n",
      "  No Data: 45\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n",
      "Requesting Cash Short for 50 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 14:34:58,864 - INFO - Null value in cash_short for BCIM: [None, None]\n",
      "2025-03-10 14:34:59,057 - WARNING - No cash_short in results for AMPD: {}\n",
      "2025-03-10 14:34:59,077 - WARNING - No cash_short in results for PP: {}\n",
      "2025-03-10 14:34:59,122 - WARNING - No cash_short in results for JGIFX: {}\n",
      "2025-03-10 14:34:59,209 - WARNING - No cash_short in results for DFHY: {}\n",
      "2025-03-10 14:34:59,232 - WARNING - No cash_short in results for FYLG: {}\n",
      "2025-03-10 14:34:59,347 - WARNING - No cash_short in results for FSMZX: {}\n",
      "2025-03-10 14:34:59,448 - WARNING - No cash_short in results for DFRA: {}\n",
      "2025-03-10 14:34:59,630 - WARNING - No cash_short in results for WBND: {}\n",
      "2025-03-10 14:34:59,633 - WARNING - No cash_short in results for OCTA: {}\n",
      "2025-03-10 14:34:59,651 - WARNING - No cash_short in results for NUSI: {}\n",
      "2025-03-10 14:34:59,651 - WARNING - No cash_short in results for IMSI: {}\n",
      "2025-03-10 14:34:59,709 - WARNING - No cash_short in results for MAYHX: {}\n",
      "2025-03-10 14:34:59,716 - WARNING - No cash_short in results for FPPJX: {}\n",
      "2025-03-10 14:34:59,721 - WARNING - No cash_short in results for VCAR: {}\n",
      "2025-03-10 14:34:59,723 - INFO - Null value in cash_short for HGER: [None, None]\n",
      "2025-03-10 14:34:59,744 - WARNING - No cash_short in results for EMCC: {}\n",
      "2025-03-10 14:34:59,744 - WARNING - No cash_short in results for JIEIX: {}\n",
      "2025-03-10 14:34:59,744 - WARNING - No cash_short in results for IQDE: {}\n",
      "2025-03-10 14:34:59,745 - WARNING - No cash_short in results for TWIO: {}\n",
      "2025-03-10 14:34:59,745 - WARNING - No cash_short in results for GREI: {}\n",
      "2025-03-10 14:34:59,745 - WARNING - No cash_short in results for HYLG: {}\n",
      "2025-03-10 14:34:59,745 - WARNING - No cash_short in results for DFNV: {}\n",
      "2025-03-10 14:34:59,748 - WARNING - No cash_short in results for PYHIX: {}\n",
      "2025-03-10 14:34:59,754 - INFO - Null value in cash_short for IAUM: [None, None]\n",
      "2025-03-10 14:34:59,760 - WARNING - No cash_short in results for GPOW: {}\n",
      "2025-03-10 14:34:59,765 - WARNING - No cash_short in results for XYLE: {}\n",
      "2025-03-10 14:34:59,767 - INFO - Null value in cash_short for FMCE: [None, None]\n",
      "2025-03-10 14:34:59,767 - WARNING - No cash_short in results for HYMU: {}\n",
      "2025-03-10 14:34:59,770 - WARNING - No cash_short in results for NETZ: {}\n",
      "2025-03-10 14:34:59,774 - WARNING - No cash_short in results for FGTBX: {}\n",
      "2025-03-10 14:34:59,775 - WARNING - No cash_short in results for ABQYX: {}\n",
      "2025-03-10 14:34:59,775 - WARNING - No cash_short in results for VMOT: {}\n",
      "2025-03-10 14:34:59,784 - WARNING - No cash_short in results for AMCYX: {}\n",
      "2025-03-10 14:34:59,793 - WARNING - No cash_short in results for OFIYX: {}\n",
      "2025-03-10 14:34:59,837 - WARNING - No cash_short in results for ISDB: {}\n",
      "2025-03-10 14:35:00,203 - WARNING - No cash_short in results for MJUS: {}\n",
      "2025-03-10 14:35:00,210 - WARNING - No cash_short in results for USCF: {}\n",
      "2025-03-10 14:35:00,218 - WARNING - No cash_short in results for MUIBX: {}\n",
      "2025-03-10 14:35:00,223 - WARNING - No cash_short in results for QYLE: {}\n",
      "2025-03-10 14:35:00,248 - WARNING - No cash_short in results for TTAI: {}\n",
      "2025-03-10 14:35:00,357 - WARNING - No cash_short in results for GCLN: {}\n",
      "2025-03-10 14:35:00,434 - INFO - Null value in cash_short for APDOX: [None, None]\n",
      "2025-03-10 14:35:00,485 - WARNING - No cash_short in results for NHYMX: {}\n",
      "2025-03-10 14:35:00,698 - WARNING - No cash_short in results for TTAC: {}\n",
      "2025-03-10 14:35:00,704 - INFO - Inserting 5 rows for cash_short\n",
      "2025-03-10 14:35:00,746 - INFO - Found 50 funds needing stock_long updates out of 5586 total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating cash_short for 5 funds\n",
      "\n",
      "Summary for cash_short:\n",
      "  Total Funds: 5586\n",
      "  Funds Needing Update: 50\n",
      "  Data Fetched: 5\n",
      "  Inserted: 5\n",
      "  No Data: 45\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n",
      "Requesting Stock Long for 50 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 14:35:01,600 - WARNING - No stock_long in results for GREI: {}\n",
      "2025-03-10 14:35:01,766 - WARNING - No stock_long in results for PYHIX: {}\n",
      "2025-03-10 14:35:01,904 - WARNING - No stock_long in results for DFNV: {}\n",
      "2025-03-10 14:35:01,931 - WARNING - No stock_long in results for OFIYX: {}\n",
      "2025-03-10 14:35:01,932 - WARNING - No stock_long in results for PP: {}\n",
      "2025-03-10 14:35:02,025 - INFO - Null value in stock_long for FMCE: [None, None]\n",
      "2025-03-10 14:35:02,036 - INFO - Null value in stock_long for APDOX: [None, None]\n",
      "2025-03-10 14:35:02,460 - INFO - Null value in stock_long for IAUM: [None, None]\n",
      "2025-03-10 14:35:02,528 - WARNING - No stock_long in results for GCLN: {}\n",
      "2025-03-10 14:35:02,532 - WARNING - No stock_long in results for FPPJX: {}\n",
      "2025-03-10 14:35:02,536 - WARNING - No stock_long in results for ABQYX: {}\n",
      "2025-03-10 14:35:02,544 - WARNING - No stock_long in results for HYMU: {}\n",
      "2025-03-10 14:35:02,547 - WARNING - No stock_long in results for QYLE: {}\n",
      "2025-03-10 14:35:02,553 - WARNING - No stock_long in results for IMSI: {}\n",
      "2025-03-10 14:35:02,628 - WARNING - No stock_long in results for VMOT: {}\n",
      "2025-03-10 14:35:02,639 - WARNING - No stock_long in results for WBND: {}\n",
      "2025-03-10 14:35:02,641 - WARNING - No stock_long in results for TTAI: {}\n",
      "2025-03-10 14:35:02,642 - WARNING - No stock_long in results for TWIO: {}\n",
      "2025-03-10 14:35:02,647 - WARNING - No stock_long in results for DFHY: {}\n",
      "2025-03-10 14:35:02,648 - WARNING - No stock_long in results for VCAR: {}\n",
      "2025-03-10 14:35:02,659 - WARNING - No stock_long in results for ISDB: {}\n",
      "2025-03-10 14:35:02,659 - WARNING - No stock_long in results for TTAC: {}\n",
      "2025-03-10 14:35:02,668 - WARNING - No stock_long in results for NUSI: {}\n",
      "2025-03-10 14:35:02,672 - WARNING - No stock_long in results for MAYHX: {}\n",
      "2025-03-10 14:35:02,673 - WARNING - No stock_long in results for FYLG: {}\n",
      "2025-03-10 14:35:02,677 - INFO - Null value in stock_long for HGER: [None, None]\n",
      "2025-03-10 14:35:02,679 - WARNING - No stock_long in results for EMCC: {}\n",
      "2025-03-10 14:35:02,679 - WARNING - No stock_long in results for USCF: {}\n",
      "2025-03-10 14:35:02,685 - WARNING - No stock_long in results for DFRA: {}\n",
      "2025-03-10 14:35:02,726 - WARNING - No stock_long in results for MUIBX: {}\n",
      "2025-03-10 14:35:02,741 - WARNING - No stock_long in results for JGIFX: {}\n",
      "2025-03-10 14:35:02,744 - WARNING - No stock_long in results for AMCYX: {}\n",
      "2025-03-10 14:35:02,878 - WARNING - No stock_long in results for AMPD: {}\n",
      "2025-03-10 14:35:02,884 - WARNING - No stock_long in results for IQDE: {}\n",
      "2025-03-10 14:35:02,891 - WARNING - No stock_long in results for GPOW: {}\n",
      "2025-03-10 14:35:02,908 - WARNING - No stock_long in results for FSMZX: {}\n",
      "2025-03-10 14:35:02,910 - WARNING - No stock_long in results for XYLE: {}\n",
      "2025-03-10 14:35:02,910 - WARNING - No stock_long in results for NETZ: {}\n",
      "2025-03-10 14:35:02,910 - WARNING - No stock_long in results for OCTA: {}\n",
      "2025-03-10 14:35:02,910 - INFO - Null value in stock_long for BCIM: [None, None]\n",
      "2025-03-10 14:35:02,910 - WARNING - No stock_long in results for MJUS: {}\n",
      "2025-03-10 14:35:02,921 - WARNING - No stock_long in results for FGTBX: {}\n",
      "2025-03-10 14:35:03,139 - WARNING - No stock_long in results for HYLG: {}\n",
      "2025-03-10 14:35:03,177 - WARNING - No stock_long in results for JIEIX: {}\n",
      "2025-03-10 14:35:03,187 - WARNING - No stock_long in results for NHYMX: {}\n",
      "2025-03-10 14:35:03,193 - INFO - Inserting 5 rows for stock_long\n",
      "2025-03-10 14:35:03,235 - INFO - Found 50 funds needing stock_net updates out of 5586 total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating stock_long for 5 funds\n",
      "\n",
      "Summary for stock_long:\n",
      "  Total Funds: 5586\n",
      "  Funds Needing Update: 50\n",
      "  Data Fetched: 5\n",
      "  Inserted: 5\n",
      "  No Data: 45\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n",
      "Requesting Stock Net for 50 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 14:35:04,202 - WARNING - No stock_net in results for NUSI: {}\n",
      "2025-03-10 14:35:04,292 - WARNING - No stock_net in results for VCAR: {}\n",
      "2025-03-10 14:35:04,303 - WARNING - No stock_net in results for EMCC: {}\n",
      "2025-03-10 14:35:04,356 - WARNING - No stock_net in results for MJUS: {}\n",
      "2025-03-10 14:35:04,376 - INFO - Null value in stock_net for HGER: [None, None]\n",
      "2025-03-10 14:35:04,380 - WARNING - No stock_net in results for TTAC: {}\n",
      "2025-03-10 14:35:04,458 - WARNING - No stock_net in results for AMPD: {}\n",
      "2025-03-10 14:35:04,692 - WARNING - No stock_net in results for HYLG: {}\n",
      "2025-03-10 14:35:04,696 - WARNING - No stock_net in results for AMCYX: {}\n",
      "2025-03-10 14:35:04,699 - WARNING - No stock_net in results for VMOT: {}\n",
      "2025-03-10 14:35:04,702 - WARNING - No stock_net in results for IQDE: {}\n",
      "2025-03-10 14:35:04,707 - WARNING - No stock_net in results for DFRA: {}\n",
      "2025-03-10 14:35:04,713 - WARNING - No stock_net in results for XYLE: {}\n",
      "2025-03-10 14:35:04,715 - WARNING - No stock_net in results for PP: {}\n",
      "2025-03-10 14:35:04,719 - WARNING - No stock_net in results for IMSI: {}\n",
      "2025-03-10 14:35:04,723 - WARNING - No stock_net in results for QYLE: {}\n",
      "2025-03-10 14:35:04,741 - WARNING - No stock_net in results for TWIO: {}\n",
      "2025-03-10 14:35:04,782 - WARNING - No stock_net in results for DFHY: {}\n",
      "2025-03-10 14:35:04,785 - WARNING - No stock_net in results for FSMZX: {}\n",
      "2025-03-10 14:35:04,790 - WARNING - No stock_net in results for FYLG: {}\n",
      "2025-03-10 14:35:04,790 - WARNING - No stock_net in results for JIEIX: {}\n",
      "2025-03-10 14:35:04,794 - WARNING - No stock_net in results for ISDB: {}\n",
      "2025-03-10 14:35:04,795 - WARNING - No stock_net in results for MAYHX: {}\n",
      "2025-03-10 14:35:04,796 - WARNING - No stock_net in results for ABQYX: {}\n",
      "2025-03-10 14:35:04,803 - WARNING - No stock_net in results for GCLN: {}\n",
      "2025-03-10 14:35:04,803 - INFO - Null value in stock_net for APDOX: [None, None]\n",
      "2025-03-10 14:35:04,804 - WARNING - No stock_net in results for PYHIX: {}\n",
      "2025-03-10 14:35:04,807 - WARNING - No stock_net in results for DFNV: {}\n",
      "2025-03-10 14:35:04,810 - WARNING - No stock_net in results for GREI: {}\n",
      "2025-03-10 14:35:04,888 - INFO - Null value in stock_net for FMCE: [None, None]\n",
      "2025-03-10 14:35:04,906 - WARNING - No stock_net in results for HYMU: {}\n",
      "2025-03-10 14:35:04,945 - WARNING - No stock_net in results for WBND: {}\n",
      "2025-03-10 14:35:04,950 - WARNING - No stock_net in results for OCTA: {}\n",
      "2025-03-10 14:35:04,954 - INFO - Null value in stock_net for BCIM: [None, None]\n",
      "2025-03-10 14:35:04,958 - WARNING - No stock_net in results for NHYMX: {}\n",
      "2025-03-10 14:35:05,213 - WARNING - No stock_net in results for GPOW: {}\n",
      "2025-03-10 14:35:05,247 - WARNING - No stock_net in results for MUIBX: {}\n",
      "2025-03-10 14:35:05,404 - WARNING - No stock_net in results for FPPJX: {}\n",
      "2025-03-10 14:35:06,082 - WARNING - No stock_net in results for USCF: {}\n",
      "2025-03-10 14:35:06,128 - WARNING - No stock_net in results for NETZ: {}\n",
      "2025-03-10 14:35:06,203 - WARNING - No stock_net in results for TTAI: {}\n",
      "2025-03-10 14:35:06,246 - WARNING - No stock_net in results for OFIYX: {}\n",
      "2025-03-10 14:35:06,292 - INFO - Null value in stock_net for IAUM: [None, None]\n",
      "2025-03-10 14:35:06,414 - WARNING - No stock_net in results for JGIFX: {}\n",
      "2025-03-10 14:35:06,472 - WARNING - No stock_net in results for FGTBX: {}\n",
      "2025-03-10 14:35:06,479 - INFO - Inserting 5 rows for stock_net\n",
      "2025-03-10 14:35:06,513 - INFO - Found 50 funds needing stock_short updates out of 5586 total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating stock_net for 5 funds\n",
      "\n",
      "Summary for stock_net:\n",
      "  Total Funds: 5586\n",
      "  Funds Needing Update: 50\n",
      "  Data Fetched: 5\n",
      "  Inserted: 5\n",
      "  No Data: 45\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n",
      "Requesting Stock Short for 50 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 14:35:07,300 - WARNING - No stock_short in results for DFRA: {}\n",
      "2025-03-10 14:35:07,386 - WARNING - No stock_short in results for TWIO: {}\n",
      "2025-03-10 14:35:07,639 - WARNING - No stock_short in results for FPPJX: {}\n",
      "2025-03-10 14:35:07,971 - WARNING - No stock_short in results for TTAC: {}\n",
      "2025-03-10 14:35:07,985 - WARNING - No stock_short in results for OCTA: {}\n",
      "2025-03-10 14:35:07,996 - WARNING - No stock_short in results for AMPD: {}\n",
      "2025-03-10 14:35:08,002 - WARNING - No stock_short in results for XYLE: {}\n",
      "2025-03-10 14:35:08,009 - WARNING - No stock_short in results for DFNV: {}\n",
      "2025-03-10 14:35:08,140 - WARNING - No stock_short in results for GCLN: {}\n",
      "2025-03-10 14:35:08,354 - WARNING - No stock_short in results for JGIFX: {}\n",
      "2025-03-10 14:35:08,356 - WARNING - No stock_short in results for VMOT: {}\n",
      "2025-03-10 14:35:08,358 - WARNING - No stock_short in results for MUIBX: {}\n",
      "2025-03-10 14:35:08,386 - WARNING - No stock_short in results for ISDB: {}\n",
      "2025-03-10 14:35:08,391 - WARNING - No stock_short in results for NETZ: {}\n",
      "2025-03-10 14:35:08,394 - WARNING - No stock_short in results for QYLE: {}\n",
      "2025-03-10 14:35:08,408 - WARNING - No stock_short in results for MJUS: {}\n",
      "2025-03-10 14:35:08,416 - WARNING - No stock_short in results for USCF: {}\n",
      "2025-03-10 14:35:08,418 - WARNING - No stock_short in results for WBND: {}\n",
      "2025-03-10 14:35:08,418 - INFO - Null value in stock_short for IAUM: [None, None]\n",
      "2025-03-10 14:35:08,419 - WARNING - No stock_short in results for HYMU: {}\n",
      "2025-03-10 14:35:08,421 - WARNING - No stock_short in results for HYLG: {}\n",
      "2025-03-10 14:35:08,460 - WARNING - No stock_short in results for AMCYX: {}\n",
      "2025-03-10 14:35:08,463 - WARNING - No stock_short in results for OFIYX: {}\n",
      "2025-03-10 14:35:08,465 - INFO - Null value in stock_short for FMCE: [None, None]\n",
      "2025-03-10 14:35:08,474 - WARNING - No stock_short in results for DFHY: {}\n",
      "2025-03-10 14:35:08,476 - INFO - Null value in stock_short for APDOX: [None, None]\n",
      "2025-03-10 14:35:08,478 - WARNING - No stock_short in results for TTAI: {}\n",
      "2025-03-10 14:35:08,483 - WARNING - No stock_short in results for ABQYX: {}\n",
      "2025-03-10 14:35:08,486 - WARNING - No stock_short in results for GREI: {}\n",
      "2025-03-10 14:35:08,486 - WARNING - No stock_short in results for IMSI: {}\n",
      "2025-03-10 14:35:08,509 - INFO - Null value in stock_short for HGER: [None, None]\n",
      "2025-03-10 14:35:08,526 - WARNING - No stock_short in results for MAYHX: {}\n",
      "2025-03-10 14:35:08,530 - WARNING - No stock_short in results for FSMZX: {}\n",
      "2025-03-10 14:35:08,532 - WARNING - No stock_short in results for JIEIX: {}\n",
      "2025-03-10 14:35:08,534 - INFO - Null value in stock_short for BCIM: [None, None]\n",
      "2025-03-10 14:35:08,552 - WARNING - No stock_short in results for PYHIX: {}\n",
      "2025-03-10 14:35:08,554 - WARNING - No stock_short in results for NHYMX: {}\n",
      "2025-03-10 14:35:08,594 - WARNING - No stock_short in results for GPOW: {}\n",
      "2025-03-10 14:35:08,597 - WARNING - No stock_short in results for FGTBX: {}\n",
      "2025-03-10 14:35:08,670 - WARNING - No stock_short in results for FYLG: {}\n",
      "2025-03-10 14:35:08,674 - WARNING - No stock_short in results for VCAR: {}\n",
      "2025-03-10 14:35:08,676 - WARNING - No stock_short in results for PP: {}\n",
      "2025-03-10 14:35:08,840 - WARNING - No stock_short in results for NUSI: {}\n",
      "2025-03-10 14:35:08,945 - WARNING - No stock_short in results for IQDE: {}\n",
      "2025-03-10 14:35:08,946 - WARNING - No stock_short in results for EMCC: {}\n",
      "2025-03-10 14:35:08,953 - INFO - Inserting 5 rows for stock_short\n",
      "2025-03-10 14:35:08,991 - INFO - Found 50 funds needing bond_long updates out of 5586 total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating stock_short for 5 funds\n",
      "\n",
      "Summary for stock_short:\n",
      "  Total Funds: 5586\n",
      "  Funds Needing Update: 50\n",
      "  Data Fetched: 5\n",
      "  Inserted: 5\n",
      "  No Data: 45\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n",
      "Requesting Bond Long for 50 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 14:35:10,200 - WARNING - No bond_long in results for ABQYX: {}\n",
      "2025-03-10 14:35:10,324 - WARNING - No bond_long in results for OFIYX: {}\n",
      "2025-03-10 14:35:10,429 - WARNING - No bond_long in results for GCLN: {}\n",
      "2025-03-10 14:35:10,448 - INFO - Null value in bond_long for FMCE: [None, None]\n",
      "2025-03-10 14:35:10,797 - WARNING - No bond_long in results for HYLG: {}\n",
      "2025-03-10 14:35:10,801 - WARNING - No bond_long in results for AMCYX: {}\n",
      "2025-03-10 14:35:10,812 - WARNING - No bond_long in results for IMSI: {}\n",
      "2025-03-10 14:35:10,899 - WARNING - No bond_long in results for ISDB: {}\n",
      "2025-03-10 14:35:11,040 - WARNING - No bond_long in results for FGTBX: {}\n",
      "2025-03-10 14:35:11,054 - WARNING - No bond_long in results for JIEIX: {}\n",
      "2025-03-10 14:35:11,069 - WARNING - No bond_long in results for MUIBX: {}\n",
      "2025-03-10 14:35:11,107 - WARNING - No bond_long in results for PYHIX: {}\n",
      "2025-03-10 14:35:11,117 - WARNING - No bond_long in results for HYMU: {}\n",
      "2025-03-10 14:35:11,120 - WARNING - No bond_long in results for FYLG: {}\n",
      "2025-03-10 14:35:11,123 - WARNING - No bond_long in results for XYLE: {}\n",
      "2025-03-10 14:35:11,125 - WARNING - No bond_long in results for USCF: {}\n",
      "2025-03-10 14:35:11,146 - WARNING - No bond_long in results for QYLE: {}\n",
      "2025-03-10 14:35:11,160 - WARNING - No bond_long in results for OCTA: {}\n",
      "2025-03-10 14:35:11,161 - INFO - Null value in bond_long for HGER: [None, None]\n",
      "2025-03-10 14:35:11,169 - WARNING - No bond_long in results for FPPJX: {}\n",
      "2025-03-10 14:35:11,193 - WARNING - No bond_long in results for DFHY: {}\n",
      "2025-03-10 14:35:11,206 - WARNING - No bond_long in results for WBND: {}\n",
      "2025-03-10 14:35:11,209 - WARNING - No bond_long in results for IQDE: {}\n",
      "2025-03-10 14:35:11,223 - WARNING - No bond_long in results for NUSI: {}\n",
      "2025-03-10 14:35:11,228 - WARNING - No bond_long in results for DFNV: {}\n",
      "2025-03-10 14:35:11,230 - WARNING - No bond_long in results for PP: {}\n",
      "2025-03-10 14:35:11,230 - WARNING - No bond_long in results for NETZ: {}\n",
      "2025-03-10 14:35:11,237 - WARNING - No bond_long in results for TTAC: {}\n",
      "2025-03-10 14:35:11,241 - WARNING - No bond_long in results for AMPD: {}\n",
      "2025-03-10 14:35:11,306 - WARNING - No bond_long in results for DFRA: {}\n",
      "2025-03-10 14:35:11,309 - WARNING - No bond_long in results for VMOT: {}\n",
      "2025-03-10 14:35:11,316 - INFO - Null value in bond_long for APDOX: [None, None]\n",
      "2025-03-10 14:35:11,394 - WARNING - No bond_long in results for NHYMX: {}\n",
      "2025-03-10 14:35:11,527 - WARNING - No bond_long in results for GREI: {}\n",
      "2025-03-10 14:35:11,609 - WARNING - No bond_long in results for MJUS: {}\n",
      "2025-03-10 14:35:11,628 - INFO - Null value in bond_long for BCIM: [None, None]\n",
      "2025-03-10 14:35:11,628 - WARNING - No bond_long in results for FSMZX: {}\n",
      "2025-03-10 14:35:11,643 - WARNING - No bond_long in results for GPOW: {}\n",
      "2025-03-10 14:35:11,665 - INFO - Null value in bond_long for IAUM: [None, None]\n",
      "2025-03-10 14:35:11,679 - WARNING - No bond_long in results for EMCC: {}\n",
      "2025-03-10 14:35:11,701 - WARNING - No bond_long in results for JGIFX: {}\n",
      "2025-03-10 14:35:11,707 - WARNING - No bond_long in results for MAYHX: {}\n",
      "2025-03-10 14:35:12,657 - WARNING - No bond_long in results for TTAI: {}\n",
      "2025-03-10 14:35:12,691 - WARNING - No bond_long in results for TWIO: {}\n",
      "2025-03-10 14:35:12,693 - WARNING - No bond_long in results for VCAR: {}\n",
      "2025-03-10 14:35:12,699 - INFO - Inserting 5 rows for bond_long\n",
      "2025-03-10 14:35:12,732 - INFO - Found 50 funds needing bond_net updates out of 5586 total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating bond_long for 5 funds\n",
      "\n",
      "Summary for bond_long:\n",
      "  Total Funds: 5586\n",
      "  Funds Needing Update: 50\n",
      "  Data Fetched: 5\n",
      "  Inserted: 5\n",
      "  No Data: 45\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n",
      "Requesting Bond Net for 50 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 14:35:13,549 - WARNING - No bond_net in results for NETZ: {}\n",
      "2025-03-10 14:35:13,568 - WARNING - No bond_net in results for DFRA: {}\n",
      "2025-03-10 14:35:13,609 - INFO - Null value in bond_net for HGER: [None, None]\n",
      "2025-03-10 14:35:13,657 - WARNING - No bond_net in results for DFNV: {}\n",
      "2025-03-10 14:35:13,660 - WARNING - No bond_net in results for MUIBX: {}\n",
      "2025-03-10 14:35:13,804 - WARNING - No bond_net in results for NUSI: {}\n",
      "2025-03-10 14:35:13,884 - WARNING - No bond_net in results for PP: {}\n",
      "2025-03-10 14:35:13,891 - WARNING - No bond_net in results for GCLN: {}\n",
      "2025-03-10 14:35:14,103 - WARNING - No bond_net in results for EMCC: {}\n",
      "2025-03-10 14:35:14,106 - INFO - Null value in bond_net for BCIM: [None, None]\n",
      "2025-03-10 14:35:14,111 - WARNING - No bond_net in results for FSMZX: {}\n",
      "2025-03-10 14:35:14,128 - WARNING - No bond_net in results for AMCYX: {}\n",
      "2025-03-10 14:35:14,131 - WARNING - No bond_net in results for OFIYX: {}\n",
      "2025-03-10 14:35:14,479 - WARNING - No bond_net in results for NHYMX: {}\n",
      "2025-03-10 14:35:14,483 - WARNING - No bond_net in results for TTAI: {}\n",
      "2025-03-10 14:35:14,487 - WARNING - No bond_net in results for VMOT: {}\n",
      "2025-03-10 14:35:14,602 - WARNING - No bond_net in results for FPPJX: {}\n",
      "2025-03-10 14:35:14,605 - WARNING - No bond_net in results for GREI: {}\n",
      "2025-03-10 14:35:14,607 - WARNING - No bond_net in results for QYLE: {}\n",
      "2025-03-10 14:35:14,609 - WARNING - No bond_net in results for TWIO: {}\n",
      "2025-03-10 14:35:14,613 - WARNING - No bond_net in results for OCTA: {}\n",
      "2025-03-10 14:35:14,614 - WARNING - No bond_net in results for AMPD: {}\n",
      "2025-03-10 14:35:14,618 - WARNING - No bond_net in results for JGIFX: {}\n",
      "2025-03-10 14:35:14,671 - WARNING - No bond_net in results for IQDE: {}\n",
      "2025-03-10 14:35:14,675 - WARNING - No bond_net in results for HYMU: {}\n",
      "2025-03-10 14:35:14,677 - WARNING - No bond_net in results for USCF: {}\n",
      "2025-03-10 14:35:14,681 - WARNING - No bond_net in results for HYLG: {}\n",
      "2025-03-10 14:35:14,684 - INFO - Null value in bond_net for FMCE: [None, None]\n",
      "2025-03-10 14:35:14,687 - WARNING - No bond_net in results for JIEIX: {}\n",
      "2025-03-10 14:35:14,738 - WARNING - No bond_net in results for MAYHX: {}\n",
      "2025-03-10 14:35:14,741 - WARNING - No bond_net in results for ABQYX: {}\n",
      "2025-03-10 14:35:14,744 - INFO - Null value in bond_net for APDOX: [None, None]\n",
      "2025-03-10 14:35:14,817 - WARNING - No bond_net in results for PYHIX: {}\n",
      "2025-03-10 14:35:14,821 - WARNING - No bond_net in results for FYLG: {}\n",
      "2025-03-10 14:35:14,844 - WARNING - No bond_net in results for MJUS: {}\n",
      "2025-03-10 14:35:14,846 - WARNING - No bond_net in results for GPOW: {}\n",
      "2025-03-10 14:35:14,850 - WARNING - No bond_net in results for DFHY: {}\n",
      "2025-03-10 14:35:14,852 - WARNING - No bond_net in results for ISDB: {}\n",
      "2025-03-10 14:35:14,920 - WARNING - No bond_net in results for WBND: {}\n",
      "2025-03-10 14:35:14,949 - INFO - Null value in bond_net for IAUM: [None, None]\n",
      "2025-03-10 14:35:15,053 - WARNING - No bond_net in results for FGTBX: {}\n",
      "2025-03-10 14:35:15,057 - WARNING - No bond_net in results for TTAC: {}\n",
      "2025-03-10 14:35:15,058 - WARNING - No bond_net in results for IMSI: {}\n",
      "2025-03-10 14:35:15,103 - WARNING - No bond_net in results for XYLE: {}\n",
      "2025-03-10 14:35:15,105 - WARNING - No bond_net in results for VCAR: {}\n",
      "2025-03-10 14:35:15,244 - INFO - Inserting 5 rows for bond_net\n",
      "2025-03-10 14:35:15,283 - INFO - Found 50 funds needing bond_short updates out of 5586 total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating bond_net for 5 funds\n",
      "\n",
      "Summary for bond_net:\n",
      "  Total Funds: 5586\n",
      "  Funds Needing Update: 50\n",
      "  Data Fetched: 5\n",
      "  Inserted: 5\n",
      "  No Data: 45\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n",
      "Requesting Bond Short for 50 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 14:35:16,008 - WARNING - No bond_short in results for VCAR: {}\n",
      "2025-03-10 14:35:16,092 - WARNING - No bond_short in results for MJUS: {}\n",
      "2025-03-10 14:35:16,116 - INFO - Null value in bond_short for APDOX: [None, None]\n",
      "2025-03-10 14:35:16,144 - WARNING - No bond_short in results for AMPD: {}\n",
      "2025-03-10 14:35:16,218 - WARNING - No bond_short in results for TTAC: {}\n",
      "2025-03-10 14:35:16,239 - INFO - Null value in bond_short for FMCE: [None, None]\n",
      "2025-03-10 14:35:16,248 - WARNING - No bond_short in results for ABQYX: {}\n",
      "2025-03-10 14:35:16,856 - WARNING - No bond_short in results for EMCC: {}\n",
      "2025-03-10 14:35:16,879 - WARNING - No bond_short in results for NUSI: {}\n",
      "2025-03-10 14:35:17,136 - WARNING - No bond_short in results for MAYHX: {}\n",
      "2025-03-10 14:35:17,214 - WARNING - No bond_short in results for GREI: {}\n",
      "2025-03-10 14:35:17,302 - WARNING - No bond_short in results for FSMZX: {}\n",
      "2025-03-10 14:35:17,304 - WARNING - No bond_short in results for GCLN: {}\n",
      "2025-03-10 14:35:17,304 - INFO - Null value in bond_short for BCIM: [None, None]\n",
      "2025-03-10 14:35:17,371 - WARNING - No bond_short in results for USCF: {}\n",
      "2025-03-10 14:35:17,375 - WARNING - No bond_short in results for FGTBX: {}\n",
      "2025-03-10 14:35:17,378 - WARNING - No bond_short in results for MUIBX: {}\n",
      "2025-03-10 14:35:17,381 - WARNING - No bond_short in results for NETZ: {}\n",
      "2025-03-10 14:35:17,384 - WARNING - No bond_short in results for HYLG: {}\n",
      "2025-03-10 14:35:17,401 - WARNING - No bond_short in results for DFHY: {}\n",
      "2025-03-10 14:35:17,405 - WARNING - No bond_short in results for IMSI: {}\n",
      "2025-03-10 14:35:17,409 - WARNING - No bond_short in results for HYMU: {}\n",
      "2025-03-10 14:35:17,412 - WARNING - No bond_short in results for JGIFX: {}\n",
      "2025-03-10 14:35:17,425 - WARNING - No bond_short in results for JIEIX: {}\n",
      "2025-03-10 14:35:17,428 - INFO - Null value in bond_short for IAUM: [None, None]\n",
      "2025-03-10 14:35:17,432 - WARNING - No bond_short in results for OFIYX: {}\n",
      "2025-03-10 14:35:17,436 - WARNING - No bond_short in results for PYHIX: {}\n",
      "2025-03-10 14:35:17,437 - WARNING - No bond_short in results for VMOT: {}\n",
      "2025-03-10 14:35:17,440 - WARNING - No bond_short in results for DFRA: {}\n",
      "2025-03-10 14:35:17,443 - WARNING - No bond_short in results for PP: {}\n",
      "2025-03-10 14:35:17,495 - WARNING - No bond_short in results for XYLE: {}\n",
      "2025-03-10 14:35:17,543 - WARNING - No bond_short in results for WBND: {}\n",
      "2025-03-10 14:35:17,547 - WARNING - No bond_short in results for OCTA: {}\n",
      "2025-03-10 14:35:17,551 - WARNING - No bond_short in results for TTAI: {}\n",
      "2025-03-10 14:35:17,560 - WARNING - No bond_short in results for IQDE: {}\n",
      "2025-03-10 14:35:17,562 - WARNING - No bond_short in results for FYLG: {}\n",
      "2025-03-10 14:35:17,580 - INFO - Null value in bond_short for HGER: [None, None]\n",
      "2025-03-10 14:35:17,708 - WARNING - No bond_short in results for NHYMX: {}\n",
      "2025-03-10 14:35:17,734 - WARNING - No bond_short in results for FPPJX: {}\n",
      "2025-03-10 14:35:17,736 - WARNING - No bond_short in results for AMCYX: {}\n",
      "2025-03-10 14:35:17,821 - WARNING - No bond_short in results for DFNV: {}\n",
      "2025-03-10 14:35:17,825 - WARNING - No bond_short in results for GPOW: {}\n",
      "2025-03-10 14:35:18,117 - WARNING - No bond_short in results for ISDB: {}\n",
      "2025-03-10 14:35:18,162 - WARNING - No bond_short in results for QYLE: {}\n",
      "2025-03-10 14:35:18,385 - WARNING - No bond_short in results for TWIO: {}\n",
      "2025-03-10 14:35:19,158 - INFO - Inserting 5 rows for bond_short\n",
      "2025-03-10 14:35:19,194 - INFO - Found 50 funds needing other_long updates out of 5586 total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating bond_short for 5 funds\n",
      "\n",
      "Summary for bond_short:\n",
      "  Total Funds: 5586\n",
      "  Funds Needing Update: 50\n",
      "  Data Fetched: 5\n",
      "  Inserted: 5\n",
      "  No Data: 45\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n",
      "Requesting Other Long for 50 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 14:35:19,929 - WARNING - No other_long in results for VMOT: {}\n",
      "2025-03-10 14:35:20,033 - WARNING - No other_long in results for QYLE: {}\n",
      "2025-03-10 14:35:20,042 - WARNING - No other_long in results for VCAR: {}\n",
      "2025-03-10 14:35:20,043 - WARNING - No other_long in results for DFHY: {}\n",
      "2025-03-10 14:35:20,243 - WARNING - No other_long in results for GPOW: {}\n",
      "2025-03-10 14:35:20,254 - INFO - Null value in other_long for IAUM: [None, None]\n",
      "2025-03-10 14:35:20,546 - INFO - Null value in other_long for BCIM: [None, None]\n",
      "2025-03-10 14:35:20,720 - WARNING - No other_long in results for XYLE: {}\n",
      "2025-03-10 14:35:20,805 - INFO - Null value in other_long for HGER: [None, None]\n",
      "2025-03-10 14:35:20,826 - WARNING - No other_long in results for NUSI: {}\n",
      "2025-03-10 14:35:21,012 - WARNING - No other_long in results for FGTBX: {}\n",
      "2025-03-10 14:35:21,018 - INFO - Null value in other_long for APDOX: [None, None]\n",
      "2025-03-10 14:35:21,020 - WARNING - No other_long in results for GCLN: {}\n",
      "2025-03-10 14:35:21,023 - WARNING - No other_long in results for GREI: {}\n",
      "2025-03-10 14:35:21,034 - WARNING - No other_long in results for OFIYX: {}\n",
      "2025-03-10 14:35:21,056 - WARNING - No other_long in results for MUIBX: {}\n",
      "2025-03-10 14:35:21,056 - WARNING - No other_long in results for DFRA: {}\n",
      "2025-03-10 14:35:21,057 - WARNING - No other_long in results for TTAC: {}\n",
      "2025-03-10 14:35:21,115 - WARNING - No other_long in results for FYLG: {}\n",
      "2025-03-10 14:35:21,118 - WARNING - No other_long in results for DFNV: {}\n",
      "2025-03-10 14:35:21,120 - WARNING - No other_long in results for FSMZX: {}\n",
      "2025-03-10 14:35:21,125 - WARNING - No other_long in results for AMCYX: {}\n",
      "2025-03-10 14:35:21,185 - WARNING - No other_long in results for EMCC: {}\n",
      "2025-03-10 14:35:21,192 - WARNING - No other_long in results for AMPD: {}\n",
      "2025-03-10 14:35:21,194 - WARNING - No other_long in results for OCTA: {}\n",
      "2025-03-10 14:35:21,197 - WARNING - No other_long in results for NETZ: {}\n",
      "2025-03-10 14:35:21,208 - INFO - Null value in other_long for FMCE: [None, None]\n",
      "2025-03-10 14:35:21,211 - WARNING - No other_long in results for NHYMX: {}\n",
      "2025-03-10 14:35:21,211 - WARNING - No other_long in results for FPPJX: {}\n",
      "2025-03-10 14:35:21,212 - WARNING - No other_long in results for MAYHX: {}\n",
      "2025-03-10 14:35:21,212 - WARNING - No other_long in results for WBND: {}\n",
      "2025-03-10 14:35:21,216 - WARNING - No other_long in results for HYMU: {}\n",
      "2025-03-10 14:35:21,218 - WARNING - No other_long in results for IQDE: {}\n",
      "2025-03-10 14:35:21,222 - WARNING - No other_long in results for TWIO: {}\n",
      "2025-03-10 14:35:21,274 - WARNING - No other_long in results for PYHIX: {}\n",
      "2025-03-10 14:35:21,276 - WARNING - No other_long in results for IMSI: {}\n",
      "2025-03-10 14:35:21,283 - WARNING - No other_long in results for ISDB: {}\n",
      "2025-03-10 14:35:21,287 - WARNING - No other_long in results for MJUS: {}\n",
      "2025-03-10 14:35:21,290 - WARNING - No other_long in results for JGIFX: {}\n",
      "2025-03-10 14:35:21,291 - WARNING - No other_long in results for ABQYX: {}\n",
      "2025-03-10 14:35:21,365 - WARNING - No other_long in results for JIEIX: {}\n",
      "2025-03-10 14:35:21,454 - WARNING - No other_long in results for HYLG: {}\n",
      "2025-03-10 14:35:21,620 - WARNING - No other_long in results for TTAI: {}\n",
      "2025-03-10 14:35:21,623 - WARNING - No other_long in results for USCF: {}\n",
      "2025-03-10 14:35:21,641 - WARNING - No other_long in results for PP: {}\n",
      "2025-03-10 14:35:21,661 - INFO - Inserting 5 rows for other_long\n",
      "2025-03-10 14:35:21,699 - INFO - Found 50 funds needing other_net updates out of 5586 total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating other_long for 5 funds\n",
      "\n",
      "Summary for other_long:\n",
      "  Total Funds: 5586\n",
      "  Funds Needing Update: 50\n",
      "  Data Fetched: 5\n",
      "  Inserted: 5\n",
      "  No Data: 45\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n",
      "Requesting Other Net for 50 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 14:35:22,279 - WARNING - No other_net in results for WBND: {}\n",
      "2025-03-10 14:35:22,451 - WARNING - No other_net in results for TTAC: {}\n",
      "2025-03-10 14:35:22,709 - INFO - Null value in other_net for IAUM: [None, None]\n",
      "2025-03-10 14:35:22,763 - WARNING - No other_net in results for ABQYX: {}\n",
      "2025-03-10 14:35:22,832 - WARNING - No other_net in results for MJUS: {}\n",
      "2025-03-10 14:35:22,902 - WARNING - No other_net in results for TTAI: {}\n",
      "2025-03-10 14:35:22,906 - INFO - Null value in other_net for FMCE: [None, None]\n",
      "2025-03-10 14:35:22,908 - WARNING - No other_net in results for NETZ: {}\n",
      "2025-03-10 14:35:23,095 - WARNING - No other_net in results for GREI: {}\n",
      "2025-03-10 14:35:23,102 - INFO - Null value in other_net for BCIM: [None, None]\n",
      "2025-03-10 14:35:23,105 - WARNING - No other_net in results for ISDB: {}\n",
      "2025-03-10 14:35:23,164 - INFO - Null value in other_net for APDOX: [None, None]\n",
      "2025-03-10 14:35:23,167 - WARNING - No other_net in results for GCLN: {}\n",
      "2025-03-10 14:35:23,172 - WARNING - No other_net in results for FYLG: {}\n",
      "2025-03-10 14:35:23,174 - WARNING - No other_net in results for HYLG: {}\n",
      "2025-03-10 14:35:23,180 - WARNING - No other_net in results for PYHIX: {}\n",
      "2025-03-10 14:35:23,182 - WARNING - No other_net in results for PP: {}\n",
      "2025-03-10 14:35:23,190 - WARNING - No other_net in results for MUIBX: {}\n",
      "2025-03-10 14:35:23,191 - WARNING - No other_net in results for DFHY: {}\n",
      "2025-03-10 14:35:23,191 - WARNING - No other_net in results for JGIFX: {}\n",
      "2025-03-10 14:35:23,366 - WARNING - No other_net in results for NUSI: {}\n",
      "2025-03-10 14:35:23,378 - WARNING - No other_net in results for IQDE: {}\n",
      "2025-03-10 14:35:23,382 - WARNING - No other_net in results for AMCYX: {}\n",
      "2025-03-10 14:35:23,386 - WARNING - No other_net in results for OFIYX: {}\n",
      "2025-03-10 14:35:23,387 - WARNING - No other_net in results for QYLE: {}\n",
      "2025-03-10 14:35:23,389 - WARNING - No other_net in results for XYLE: {}\n",
      "2025-03-10 14:35:23,435 - WARNING - No other_net in results for HYMU: {}\n",
      "2025-03-10 14:35:23,438 - WARNING - No other_net in results for JIEIX: {}\n",
      "2025-03-10 14:35:23,448 - WARNING - No other_net in results for AMPD: {}\n",
      "2025-03-10 14:35:23,621 - WARNING - No other_net in results for GPOW: {}\n",
      "2025-03-10 14:35:23,829 - WARNING - No other_net in results for EMCC: {}\n",
      "2025-03-10 14:35:23,831 - WARNING - No other_net in results for OCTA: {}\n",
      "2025-03-10 14:35:23,845 - WARNING - No other_net in results for DFRA: {}\n",
      "2025-03-10 14:35:23,845 - INFO - Null value in other_net for HGER: [None, None]\n",
      "2025-03-10 14:35:23,846 - WARNING - No other_net in results for FGTBX: {}\n",
      "2025-03-10 14:35:23,846 - WARNING - No other_net in results for NHYMX: {}\n",
      "2025-03-10 14:35:23,874 - WARNING - No other_net in results for DFNV: {}\n",
      "2025-03-10 14:35:23,879 - WARNING - No other_net in results for IMSI: {}\n",
      "2025-03-10 14:35:23,895 - WARNING - No other_net in results for FSMZX: {}\n",
      "2025-03-10 14:35:23,898 - WARNING - No other_net in results for FPPJX: {}\n",
      "2025-03-10 14:35:23,906 - WARNING - No other_net in results for MAYHX: {}\n",
      "2025-03-10 14:35:23,910 - WARNING - No other_net in results for VMOT: {}\n",
      "2025-03-10 14:35:23,913 - WARNING - No other_net in results for VCAR: {}\n",
      "2025-03-10 14:35:23,940 - WARNING - No other_net in results for USCF: {}\n",
      "2025-03-10 14:35:23,961 - WARNING - No other_net in results for TWIO: {}\n",
      "2025-03-10 14:35:24,000 - INFO - Inserting 5 rows for other_net\n",
      "2025-03-10 14:35:24,036 - INFO - Found 50 funds needing other_short updates out of 5586 total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating other_net for 5 funds\n",
      "\n",
      "Summary for other_net:\n",
      "  Total Funds: 5586\n",
      "  Funds Needing Update: 50\n",
      "  Data Fetched: 5\n",
      "  Inserted: 5\n",
      "  No Data: 45\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n",
      "Requesting Other Short for 50 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 14:35:25,025 - WARNING - No other_short in results for OCTA: {}\n",
      "2025-03-10 14:35:25,060 - WARNING - No other_short in results for USCF: {}\n",
      "2025-03-10 14:35:25,110 - WARNING - No other_short in results for NETZ: {}\n",
      "2025-03-10 14:35:25,113 - WARNING - No other_short in results for GPOW: {}\n",
      "2025-03-10 14:35:25,172 - WARNING - No other_short in results for OFIYX: {}\n",
      "2025-03-10 14:35:25,175 - WARNING - No other_short in results for TWIO: {}\n",
      "2025-03-10 14:35:25,250 - INFO - Null value in other_short for APDOX: [None, None]\n",
      "2025-03-10 14:35:25,371 - WARNING - No other_short in results for HYLG: {}\n",
      "2025-03-10 14:35:25,462 - WARNING - No other_short in results for JGIFX: {}\n",
      "2025-03-10 14:35:25,466 - WARNING - No other_short in results for VMOT: {}\n",
      "2025-03-10 14:35:25,626 - INFO - Null value in other_short for IAUM: [None, None]\n",
      "2025-03-10 14:35:25,631 - INFO - Null value in other_short for FMCE: [None, None]\n",
      "2025-03-10 14:35:25,633 - WARNING - No other_short in results for AMPD: {}\n",
      "2025-03-10 14:35:25,636 - WARNING - No other_short in results for AMCYX: {}\n",
      "2025-03-10 14:35:25,655 - WARNING - No other_short in results for TTAI: {}\n",
      "2025-03-10 14:35:25,662 - WARNING - No other_short in results for XYLE: {}\n",
      "2025-03-10 14:35:25,699 - WARNING - No other_short in results for PP: {}\n",
      "2025-03-10 14:35:25,717 - WARNING - No other_short in results for NHYMX: {}\n",
      "2025-03-10 14:35:25,717 - WARNING - No other_short in results for TTAC: {}\n",
      "2025-03-10 14:35:25,718 - WARNING - No other_short in results for JIEIX: {}\n",
      "2025-03-10 14:35:25,719 - WARNING - No other_short in results for FYLG: {}\n",
      "2025-03-10 14:35:25,748 - WARNING - No other_short in results for DFHY: {}\n",
      "2025-03-10 14:35:25,751 - WARNING - No other_short in results for VCAR: {}\n",
      "2025-03-10 14:35:25,769 - WARNING - No other_short in results for DFRA: {}\n",
      "2025-03-10 14:35:25,770 - WARNING - No other_short in results for PYHIX: {}\n",
      "2025-03-10 14:35:25,773 - WARNING - No other_short in results for WBND: {}\n",
      "2025-03-10 14:35:25,775 - WARNING - No other_short in results for GREI: {}\n",
      "2025-03-10 14:35:25,778 - WARNING - No other_short in results for ABQYX: {}\n",
      "2025-03-10 14:35:25,782 - WARNING - No other_short in results for IMSI: {}\n",
      "2025-03-10 14:35:25,785 - WARNING - No other_short in results for MJUS: {}\n",
      "2025-03-10 14:35:25,789 - WARNING - No other_short in results for FSMZX: {}\n",
      "2025-03-10 14:35:25,794 - WARNING - No other_short in results for MUIBX: {}\n",
      "2025-03-10 14:35:25,866 - WARNING - No other_short in results for DFNV: {}\n",
      "2025-03-10 14:35:25,876 - INFO - Null value in other_short for HGER: [None, None]\n",
      "2025-03-10 14:35:25,965 - WARNING - No other_short in results for EMCC: {}\n",
      "2025-03-10 14:35:25,973 - WARNING - No other_short in results for ISDB: {}\n",
      "2025-03-10 14:35:26,246 - INFO - Null value in other_short for BCIM: [None, None]\n",
      "2025-03-10 14:35:26,259 - WARNING - No other_short in results for NUSI: {}\n",
      "2025-03-10 14:35:26,259 - WARNING - No other_short in results for QYLE: {}\n",
      "2025-03-10 14:35:26,288 - WARNING - No other_short in results for IQDE: {}\n",
      "2025-03-10 14:35:26,425 - WARNING - No other_short in results for MAYHX: {}\n",
      "2025-03-10 14:35:26,835 - WARNING - No other_short in results for FPPJX: {}\n",
      "2025-03-10 14:35:26,930 - WARNING - No other_short in results for HYMU: {}\n",
      "2025-03-10 14:35:27,109 - WARNING - No other_short in results for GCLN: {}\n",
      "2025-03-10 14:35:27,133 - WARNING - No other_short in results for FGTBX: {}\n",
      "2025-03-10 14:35:27,140 - INFO - Inserting 5 rows for other_short\n",
      "2025-03-10 14:35:27,172 - INFO - Found 5586 funds needing preferred_long updates out of 5586 total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating other_short for 5 funds\n",
      "\n",
      "Summary for other_short:\n",
      "  Total Funds: 5586\n",
      "  Funds Needing Update: 50\n",
      "  Data Fetched: 5\n",
      "  Inserted: 5\n",
      "  No Data: 45\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n",
      "Requesting Preferred Long for 5586 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 14:35:29,554 - WARNING - No preferred_long in results for AMPD: {}\n",
      "2025-03-10 14:35:30,746 - WARNING - No preferred_long in results for VMOT: {}\n",
      "2025-03-10 14:35:36,472 - WARNING - No preferred_long in results for PP: {}\n",
      "2025-03-10 14:35:37,047 - WARNING - No preferred_long in results for VCAR: {}\n",
      "2025-03-10 14:35:58,466 - INFO - Null value in preferred_long for APDOX: [None, None]\n",
      "2025-03-10 14:36:01,445 - WARNING - No preferred_long in results for OFIYX: {}\n",
      "2025-03-10 14:36:14,283 - WARNING - No preferred_long in results for TWIO: {}\n",
      "2025-03-10 14:36:16,605 - WARNING - No preferred_long in results for DFRA: {}\n",
      "2025-03-10 14:36:16,654 - WARNING - No preferred_long in results for DFNV: {}\n",
      "2025-03-10 14:36:19,675 - INFO - Null value in preferred_long for HGER: [None, None]\n",
      "2025-03-10 14:36:20,656 - INFO - Null value in preferred_long for IAUM: [None, None]\n",
      "2025-03-10 14:36:21,555 - INFO - Null value in preferred_long for BCIM: [None, None]\n",
      "2025-03-10 14:36:30,230 - WARNING - No preferred_long in results for TTAI: {}\n",
      "2025-03-10 14:36:33,242 - WARNING - No preferred_long in results for IQDE: {}\n",
      "2025-03-10 14:36:40,109 - WARNING - No preferred_long in results for XYLE: {}\n",
      "2025-03-10 14:36:40,242 - WARNING - No preferred_long in results for QYLE: {}\n",
      "2025-03-10 14:36:42,858 - WARNING - No preferred_long in results for EMCC: {}\n",
      "2025-03-10 14:36:43,819 - WARNING - No preferred_long in results for HYLG: {}\n",
      "2025-03-10 14:36:45,850 - WARNING - No preferred_long in results for NUSI: {}\n",
      "2025-03-10 14:36:47,009 - WARNING - No preferred_long in results for GPOW: {}\n",
      "2025-03-10 14:36:47,487 - WARNING - No preferred_long in results for OCTA: {}\n",
      "2025-03-10 14:36:48,844 - WARNING - No preferred_long in results for GREI: {}\n",
      "2025-03-10 14:36:49,319 - WARNING - No preferred_long in results for FYLG: {}\n",
      "2025-03-10 14:36:49,442 - WARNING - No preferred_long in results for MJUS: {}\n",
      "2025-03-10 14:36:49,489 - WARNING - No preferred_long in results for GCLN: {}\n",
      "2025-03-10 14:37:09,163 - WARNING - No preferred_long in results for TTAC: {}\n",
      "2025-03-10 14:37:11,955 - WARNING - No preferred_long in results for NETZ: {}\n",
      "2025-03-10 14:37:14,400 - INFO - Null value in preferred_long for FMCE: [None, None]\n",
      "2025-03-10 14:37:20,817 - WARNING - No preferred_long in results for USCF: {}\n",
      "2025-03-10 14:37:32,718 - WARNING - No preferred_long in results for HYMU: {}\n",
      "2025-03-10 14:37:32,746 - WARNING - No preferred_long in results for IMSI: {}\n",
      "2025-03-10 14:37:44,224 - WARNING - No preferred_long in results for WBND: {}\n",
      "2025-03-10 14:37:48,572 - WARNING - No preferred_long in results for DFHY: {}\n",
      "2025-03-10 14:37:50,910 - WARNING - No preferred_long in results for ISDB: {}\n",
      "2025-03-10 14:37:55,322 - WARNING - No preferred_long in results for ABQYX: {}\n",
      "2025-03-10 14:37:55,543 - WARNING - No preferred_long in results for JIEIX: {}\n",
      "2025-03-10 14:38:06,956 - WARNING - No preferred_long in results for MAYHX: {}\n",
      "2025-03-10 14:38:24,121 - WARNING - No preferred_long in results for FGTBX: {}\n",
      "2025-03-10 14:38:30,542 - WARNING - No preferred_long in results for FSMZX: {}\n",
      "2025-03-10 14:38:37,089 - WARNING - No preferred_long in results for AMCYX: {}\n",
      "2025-03-10 14:38:40,176 - WARNING - No preferred_long in results for JGIFX: {}\n",
      "2025-03-10 14:38:47,891 - WARNING - No preferred_long in results for FPPJX: {}\n",
      "2025-03-10 14:38:49,620 - WARNING - No preferred_long in results for MUIBX: {}\n",
      "2025-03-10 14:38:52,171 - WARNING - No preferred_long in results for NHYMX: {}\n",
      "2025-03-10 14:39:02,393 - WARNING - No preferred_long in results for PYHIX: {}\n",
      "2025-03-10 14:39:24,833 - INFO - Inserting 5541 rows for preferred_long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating preferred_long for 5541 funds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 14:39:25,919 - INFO - Found 5586 funds needing preferred_net updates out of 5586 total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary for preferred_long:\n",
      "  Total Funds: 5586\n",
      "  Funds Needing Update: 5586\n",
      "  Data Fetched: 5541\n",
      "  Inserted: 5541\n",
      "  No Data: 45\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n",
      "Requesting Preferred Net for 5586 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 14:39:27,027 - WARNING - No preferred_net in results for AMPD: {}\n",
      "2025-03-10 14:39:30,831 - WARNING - No preferred_net in results for VMOT: {}\n",
      "2025-03-10 14:39:35,586 - WARNING - No preferred_net in results for PP: {}\n",
      "2025-03-10 14:39:36,121 - WARNING - No preferred_net in results for VCAR: {}\n",
      "2025-03-10 14:39:53,306 - INFO - Null value in preferred_net for APDOX: [None, None]\n",
      "2025-03-10 14:39:58,676 - WARNING - No preferred_net in results for OFIYX: {}\n",
      "2025-03-10 14:40:10,340 - WARNING - No preferred_net in results for TWIO: {}\n",
      "2025-03-10 14:40:12,582 - WARNING - No preferred_net in results for DFRA: {}\n",
      "2025-03-10 14:40:12,680 - WARNING - No preferred_net in results for DFNV: {}\n",
      "2025-03-10 14:40:16,622 - INFO - Null value in preferred_net for HGER: [None, None]\n",
      "2025-03-10 14:40:17,792 - INFO - Null value in preferred_net for IAUM: [None, None]\n",
      "2025-03-10 14:40:18,040 - INFO - Null value in preferred_net for BCIM: [None, None]\n",
      "2025-03-10 14:40:27,634 - WARNING - No preferred_net in results for TTAI: {}\n",
      "2025-03-10 14:40:29,446 - WARNING - No preferred_net in results for IQDE: {}\n",
      "2025-03-10 14:40:37,672 - WARNING - No preferred_net in results for QYLE: {}\n",
      "2025-03-10 14:40:38,034 - WARNING - No preferred_net in results for XYLE: {}\n",
      "2025-03-10 14:40:40,057 - WARNING - No preferred_net in results for NUSI: {}\n",
      "2025-03-10 14:40:40,076 - WARNING - No preferred_net in results for EMCC: {}\n",
      "2025-03-10 14:40:41,290 - WARNING - No preferred_net in results for FYLG: {}\n",
      "2025-03-10 14:40:41,303 - WARNING - No preferred_net in results for HYLG: {}\n",
      "2025-03-10 14:40:44,729 - WARNING - No preferred_net in results for OCTA: {}\n",
      "2025-03-10 14:40:44,807 - WARNING - No preferred_net in results for GPOW: {}\n",
      "2025-03-10 14:40:45,007 - WARNING - No preferred_net in results for GCLN: {}\n",
      "2025-03-10 14:40:45,794 - WARNING - No preferred_net in results for MJUS: {}\n",
      "2025-03-10 14:40:46,073 - WARNING - No preferred_net in results for GREI: {}\n",
      "2025-03-10 14:41:07,588 - WARNING - No preferred_net in results for TTAC: {}\n",
      "2025-03-10 14:41:08,619 - WARNING - No preferred_net in results for NETZ: {}\n",
      "2025-03-10 14:41:10,822 - INFO - Null value in preferred_net for FMCE: [None, None]\n",
      "2025-03-10 14:41:13,927 - WARNING - No preferred_net in results for USCF: {}\n",
      "2025-03-10 14:41:27,095 - WARNING - No preferred_net in results for HYMU: {}\n",
      "2025-03-10 14:41:27,351 - WARNING - No preferred_net in results for IMSI: {}\n",
      "2025-03-10 14:41:41,906 - WARNING - No preferred_net in results for WBND: {}\n",
      "2025-03-10 14:41:42,483 - WARNING - No preferred_net in results for DFHY: {}\n",
      "2025-03-10 14:41:48,330 - WARNING - No preferred_net in results for ISDB: {}\n",
      "2025-03-10 14:41:48,604 - WARNING - No preferred_net in results for ABQYX: {}\n",
      "2025-03-10 14:41:48,615 - WARNING - No preferred_net in results for JIEIX: {}\n",
      "2025-03-10 14:42:01,354 - WARNING - No preferred_net in results for MAYHX: {}\n",
      "2025-03-10 14:42:17,963 - WARNING - No preferred_net in results for FGTBX: {}\n",
      "2025-03-10 14:42:26,477 - WARNING - No preferred_net in results for FSMZX: {}\n",
      "2025-03-10 14:42:32,648 - WARNING - No preferred_net in results for AMCYX: {}\n",
      "2025-03-10 14:42:36,672 - WARNING - No preferred_net in results for JGIFX: {}\n",
      "2025-03-10 14:42:45,192 - WARNING - No preferred_net in results for FPPJX: {}\n",
      "2025-03-10 14:42:46,096 - WARNING - No preferred_net in results for MUIBX: {}\n",
      "2025-03-10 14:42:48,308 - WARNING - No preferred_net in results for NHYMX: {}\n",
      "2025-03-10 14:42:57,539 - WARNING - No preferred_net in results for PYHIX: {}\n",
      "2025-03-10 14:43:17,832 - INFO - Inserting 5541 rows for preferred_net\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating preferred_net for 5541 funds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 14:43:18,759 - INFO - Found 5586 funds needing preferred_short updates out of 5586 total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary for preferred_net:\n",
      "  Total Funds: 5586\n",
      "  Funds Needing Update: 5586\n",
      "  Data Fetched: 5541\n",
      "  Inserted: 5541\n",
      "  No Data: 45\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n",
      "Requesting Preferred Short for 5586 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 14:43:21,375 - WARNING - No preferred_short in results for AMPD: {}\n",
      "2025-03-10 14:43:22,186 - WARNING - No preferred_short in results for VMOT: {}\n",
      "2025-03-10 14:43:28,165 - WARNING - No preferred_short in results for PP: {}\n",
      "2025-03-10 14:43:28,366 - WARNING - No preferred_short in results for VCAR: {}\n",
      "2025-03-10 14:43:47,950 - INFO - Null value in preferred_short for APDOX: [None, None]\n",
      "2025-03-10 14:43:54,964 - WARNING - No preferred_short in results for OFIYX: {}\n",
      "2025-03-10 14:44:06,281 - WARNING - No preferred_short in results for TWIO: {}\n",
      "2025-03-10 14:44:09,035 - WARNING - No preferred_short in results for DFNV: {}\n",
      "2025-03-10 14:44:09,292 - WARNING - No preferred_short in results for DFRA: {}\n",
      "2025-03-10 14:44:12,502 - INFO - Null value in preferred_short for HGER: [None, None]\n",
      "2025-03-10 14:44:13,527 - INFO - Null value in preferred_short for IAUM: [None, None]\n",
      "2025-03-10 14:44:14,068 - INFO - Null value in preferred_short for BCIM: [None, None]\n",
      "2025-03-10 14:44:24,175 - WARNING - No preferred_short in results for TTAI: {}\n",
      "2025-03-10 14:44:27,928 - WARNING - No preferred_short in results for IQDE: {}\n",
      "2025-03-10 14:44:34,189 - WARNING - No preferred_short in results for XYLE: {}\n",
      "2025-03-10 14:44:35,324 - WARNING - No preferred_short in results for QYLE: {}\n",
      "2025-03-10 14:44:37,343 - WARNING - No preferred_short in results for EMCC: {}\n",
      "2025-03-10 14:44:37,613 - WARNING - No preferred_short in results for NUSI: {}\n",
      "2025-03-10 14:44:38,535 - WARNING - No preferred_short in results for FYLG: {}\n",
      "2025-03-10 14:44:38,610 - WARNING - No preferred_short in results for HYLG: {}\n",
      "2025-03-10 14:44:41,578 - WARNING - No preferred_short in results for GPOW: {}\n",
      "2025-03-10 14:44:41,773 - WARNING - No preferred_short in results for OCTA: {}\n",
      "2025-03-10 14:44:41,929 - WARNING - No preferred_short in results for GCLN: {}\n",
      "2025-03-10 14:44:43,957 - WARNING - No preferred_short in results for GREI: {}\n",
      "2025-03-10 14:44:44,258 - WARNING - No preferred_short in results for MJUS: {}\n",
      "2025-03-10 14:45:07,160 - WARNING - No preferred_short in results for TTAC: {}\n",
      "2025-03-10 14:45:09,843 - WARNING - No preferred_short in results for NETZ: {}\n",
      "2025-03-10 14:45:12,511 - INFO - Null value in preferred_short for FMCE: [None, None]\n",
      "2025-03-10 14:45:17,568 - WARNING - No preferred_short in results for USCF: {}\n",
      "2025-03-10 14:45:30,197 - WARNING - No preferred_short in results for IMSI: {}\n",
      "2025-03-10 14:45:30,295 - WARNING - No preferred_short in results for HYMU: {}\n",
      "2025-03-10 14:45:43,382 - WARNING - No preferred_short in results for WBND: {}\n",
      "2025-03-10 14:45:47,752 - WARNING - No preferred_short in results for DFHY: {}\n",
      "2025-03-10 14:45:50,094 - WARNING - No preferred_short in results for ISDB: {}\n",
      "2025-03-10 14:45:53,633 - WARNING - No preferred_short in results for ABQYX: {}\n",
      "2025-03-10 14:45:53,766 - WARNING - No preferred_short in results for JIEIX: {}\n",
      "2025-03-10 14:46:04,837 - WARNING - No preferred_short in results for MAYHX: {}\n",
      "2025-03-10 14:46:21,522 - WARNING - No preferred_short in results for FGTBX: {}\n",
      "2025-03-10 14:46:29,547 - WARNING - No preferred_short in results for FSMZX: {}\n",
      "2025-03-10 14:46:35,955 - WARNING - No preferred_short in results for AMCYX: {}\n",
      "2025-03-10 14:46:39,161 - WARNING - No preferred_short in results for JGIFX: {}\n",
      "2025-03-10 14:46:50,329 - WARNING - No preferred_short in results for MUIBX: {}\n",
      "2025-03-10 14:46:52,120 - WARNING - No preferred_short in results for FPPJX: {}\n",
      "2025-03-10 14:46:53,033 - WARNING - No preferred_short in results for NHYMX: {}\n",
      "2025-03-10 14:47:05,598 - WARNING - No preferred_short in results for PYHIX: {}\n",
      "2025-03-10 14:47:23,254 - INFO - Inserting 5541 rows for preferred_short\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating preferred_short for 5541 funds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 14:47:24,177 - INFO - Found 5586 funds needing convertible_long updates out of 5586 total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary for preferred_short:\n",
      "  Total Funds: 5586\n",
      "  Funds Needing Update: 5586\n",
      "  Data Fetched: 5541\n",
      "  Inserted: 5541\n",
      "  No Data: 45\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n",
      "Requesting Convertible Long for 5586 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 14:47:26,749 - WARNING - No convertible_long in results for AMPD: {}\n",
      "2025-03-10 14:47:28,840 - WARNING - No convertible_long in results for VMOT: {}\n",
      "2025-03-10 14:47:35,939 - WARNING - No convertible_long in results for VCAR: {}\n",
      "2025-03-10 14:47:35,955 - WARNING - No convertible_long in results for PP: {}\n",
      "2025-03-10 14:47:53,931 - INFO - Null value in convertible_long for APDOX: [None, None]\n",
      "2025-03-10 14:48:03,923 - WARNING - No convertible_long in results for OFIYX: {}\n",
      "2025-03-10 14:48:14,680 - WARNING - No convertible_long in results for TWIO: {}\n",
      "2025-03-10 14:48:17,075 - WARNING - No convertible_long in results for DFNV: {}\n",
      "2025-03-10 14:48:17,325 - WARNING - No convertible_long in results for DFRA: {}\n",
      "2025-03-10 14:48:21,079 - INFO - Null value in convertible_long for HGER: [None, None]\n",
      "2025-03-10 14:48:22,257 - INFO - Null value in convertible_long for BCIM: [None, None]\n",
      "2025-03-10 14:48:22,777 - INFO - Null value in convertible_long for IAUM: [None, None]\n",
      "2025-03-10 14:48:33,383 - WARNING - No convertible_long in results for TTAI: {}\n",
      "2025-03-10 14:48:35,320 - WARNING - No convertible_long in results for IQDE: {}\n",
      "2025-03-10 14:48:43,364 - WARNING - No convertible_long in results for QYLE: {}\n",
      "2025-03-10 14:48:43,473 - WARNING - No convertible_long in results for XYLE: {}\n",
      "2025-03-10 14:48:46,501 - WARNING - No convertible_long in results for EMCC: {}\n",
      "2025-03-10 14:48:47,703 - WARNING - No convertible_long in results for HYLG: {}\n",
      "2025-03-10 14:48:47,706 - WARNING - No convertible_long in results for FYLG: {}\n",
      "2025-03-10 14:48:48,060 - WARNING - No convertible_long in results for NUSI: {}\n",
      "2025-03-10 14:48:50,731 - WARNING - No convertible_long in results for OCTA: {}\n",
      "2025-03-10 14:48:50,733 - WARNING - No convertible_long in results for GPOW: {}\n",
      "2025-03-10 14:48:51,245 - WARNING - No convertible_long in results for GCLN: {}\n",
      "2025-03-10 14:48:52,364 - WARNING - No convertible_long in results for GREI: {}\n",
      "2025-03-10 14:48:52,916 - WARNING - No convertible_long in results for MJUS: {}\n",
      "2025-03-10 14:49:14,574 - WARNING - No convertible_long in results for TTAC: {}\n",
      "2025-03-10 14:49:17,195 - WARNING - No convertible_long in results for NETZ: {}\n",
      "2025-03-10 14:49:23,252 - INFO - Null value in convertible_long for FMCE: [None, None]\n",
      "2025-03-10 14:49:23,481 - WARNING - No convertible_long in results for USCF: {}\n",
      "2025-03-10 14:49:37,971 - WARNING - No convertible_long in results for IMSI: {}\n",
      "2025-03-10 14:49:37,975 - WARNING - No convertible_long in results for HYMU: {}\n",
      "2025-03-10 14:49:50,446 - WARNING - No convertible_long in results for WBND: {}\n",
      "2025-03-10 14:49:53,814 - WARNING - No convertible_long in results for DFHY: {}\n",
      "2025-03-10 14:49:58,595 - WARNING - No convertible_long in results for ISDB: {}\n",
      "2025-03-10 14:50:01,200 - WARNING - No convertible_long in results for ABQYX: {}\n",
      "2025-03-10 14:50:01,992 - WARNING - No convertible_long in results for JIEIX: {}\n",
      "2025-03-10 14:50:12,698 - WARNING - No convertible_long in results for MAYHX: {}\n",
      "2025-03-10 14:50:32,555 - WARNING - No convertible_long in results for FGTBX: {}\n",
      "2025-03-10 14:50:40,051 - WARNING - No convertible_long in results for FSMZX: {}\n",
      "2025-03-10 14:50:49,329 - WARNING - No convertible_long in results for AMCYX: {}\n",
      "2025-03-10 14:50:52,912 - WARNING - No convertible_long in results for JGIFX: {}\n",
      "2025-03-10 14:51:02,514 - WARNING - No convertible_long in results for FPPJX: {}\n",
      "2025-03-10 14:51:03,921 - WARNING - No convertible_long in results for MUIBX: {}\n",
      "2025-03-10 14:51:08,366 - WARNING - No convertible_long in results for NHYMX: {}\n",
      "2025-03-10 14:51:20,840 - WARNING - No convertible_long in results for PYHIX: {}\n",
      "2025-03-10 14:51:37,449 - INFO - Inserting 5541 rows for convertible_long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating convertible_long for 5541 funds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 14:51:38,272 - INFO - Found 5586 funds needing convertible_net updates out of 5586 total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary for convertible_long:\n",
      "  Total Funds: 5586\n",
      "  Funds Needing Update: 5586\n",
      "  Data Fetched: 5541\n",
      "  Inserted: 5541\n",
      "  No Data: 45\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n",
      "Requesting Convertible Net for 5586 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 14:51:41,524 - WARNING - No convertible_net in results for VMOT: {}\n",
      "2025-03-10 14:51:41,980 - WARNING - No convertible_net in results for AMPD: {}\n",
      "2025-03-10 14:51:46,725 - WARNING - No convertible_net in results for PP: {}\n",
      "2025-03-10 14:51:46,859 - WARNING - No convertible_net in results for VCAR: {}\n",
      "2025-03-10 14:52:03,879 - INFO - Null value in convertible_net for APDOX: [None, None]\n",
      "2025-03-10 14:52:10,254 - WARNING - No convertible_net in results for OFIYX: {}\n",
      "2025-03-10 14:52:21,073 - WARNING - No convertible_net in results for TWIO: {}\n",
      "2025-03-10 14:52:24,213 - WARNING - No convertible_net in results for DFRA: {}\n",
      "2025-03-10 14:52:25,841 - WARNING - No convertible_net in results for DFNV: {}\n",
      "2025-03-10 14:52:28,011 - INFO - Null value in convertible_net for HGER: [None, None]\n",
      "2025-03-10 14:52:28,778 - INFO - Null value in convertible_net for IAUM: [None, None]\n",
      "2025-03-10 14:52:29,517 - INFO - Null value in convertible_net for BCIM: [None, None]\n",
      "2025-03-10 14:52:40,114 - WARNING - No convertible_net in results for TTAI: {}\n",
      "2025-03-10 14:52:41,497 - WARNING - No convertible_net in results for IQDE: {}\n",
      "2025-03-10 14:52:49,876 - WARNING - No convertible_net in results for XYLE: {}\n",
      "2025-03-10 14:52:49,903 - WARNING - No convertible_net in results for QYLE: {}\n",
      "2025-03-10 14:52:52,330 - WARNING - No convertible_net in results for EMCC: {}\n",
      "2025-03-10 14:52:52,351 - WARNING - No convertible_net in results for NUSI: {}\n",
      "2025-03-10 14:52:53,419 - WARNING - No convertible_net in results for HYLG: {}\n",
      "2025-03-10 14:52:53,450 - WARNING - No convertible_net in results for FYLG: {}\n",
      "2025-03-10 14:52:56,688 - WARNING - No convertible_net in results for OCTA: {}\n",
      "2025-03-10 14:52:56,838 - WARNING - No convertible_net in results for GCLN: {}\n",
      "2025-03-10 14:52:56,861 - WARNING - No convertible_net in results for GPOW: {}\n",
      "2025-03-10 14:52:57,705 - WARNING - No convertible_net in results for GREI: {}\n",
      "2025-03-10 14:52:59,916 - WARNING - No convertible_net in results for MJUS: {}\n",
      "2025-03-10 14:53:18,317 - WARNING - No convertible_net in results for TTAC: {}\n",
      "2025-03-10 14:53:20,665 - WARNING - No convertible_net in results for NETZ: {}\n",
      "2025-03-10 14:53:23,416 - INFO - Null value in convertible_net for FMCE: [None, None]\n",
      "2025-03-10 14:53:26,472 - WARNING - No convertible_net in results for USCF: {}\n",
      "2025-03-10 14:53:39,872 - WARNING - No convertible_net in results for IMSI: {}\n",
      "2025-03-10 14:53:39,875 - WARNING - No convertible_net in results for HYMU: {}\n",
      "2025-03-10 14:53:52,933 - WARNING - No convertible_net in results for WBND: {}\n",
      "2025-03-10 14:53:55,022 - WARNING - No convertible_net in results for DFHY: {}\n",
      "2025-03-10 14:53:57,142 - WARNING - No convertible_net in results for ISDB: {}\n",
      "2025-03-10 14:54:00,389 - WARNING - No convertible_net in results for ABQYX: {}\n",
      "2025-03-10 14:54:01,566 - WARNING - No convertible_net in results for JIEIX: {}\n",
      "2025-03-10 14:54:11,361 - WARNING - No convertible_net in results for MAYHX: {}\n",
      "2025-03-10 14:54:27,557 - WARNING - No convertible_net in results for FGTBX: {}\n",
      "2025-03-10 14:54:35,798 - WARNING - No convertible_net in results for FSMZX: {}\n",
      "2025-03-10 14:54:43,752 - WARNING - No convertible_net in results for AMCYX: {}\n",
      "2025-03-10 14:54:45,761 - WARNING - No convertible_net in results for JGIFX: {}\n",
      "2025-03-10 14:54:53,155 - WARNING - No convertible_net in results for FPPJX: {}\n",
      "2025-03-10 14:54:54,923 - WARNING - No convertible_net in results for MUIBX: {}\n",
      "2025-03-10 14:54:58,282 - WARNING - No convertible_net in results for NHYMX: {}\n",
      "2025-03-10 14:55:08,115 - WARNING - No convertible_net in results for PYHIX: {}\n",
      "2025-03-10 14:55:32,743 - INFO - Inserting 5541 rows for convertible_net\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating convertible_net for 5541 funds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 14:55:33,660 - INFO - Found 5586 funds needing convertible_short updates out of 5586 total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary for convertible_net:\n",
      "  Total Funds: 5586\n",
      "  Funds Needing Update: 5586\n",
      "  Data Fetched: 5541\n",
      "  Inserted: 5541\n",
      "  No Data: 45\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n",
      "Requesting Convertible Short for 5586 funds from YCharts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 14:55:35,585 - WARNING - No convertible_short in results for AMPD: {}\n",
      "2025-03-10 14:55:37,118 - WARNING - No convertible_short in results for VMOT: {}\n",
      "2025-03-10 14:55:43,552 - WARNING - No convertible_short in results for PP: {}\n",
      "2025-03-10 14:55:43,707 - WARNING - No convertible_short in results for VCAR: {}\n",
      "2025-03-10 14:56:00,008 - INFO - Null value in convertible_short for APDOX: [None, None]\n",
      "2025-03-10 14:56:06,554 - WARNING - No convertible_short in results for OFIYX: {}\n",
      "2025-03-10 14:56:18,874 - WARNING - No convertible_short in results for TWIO: {}\n",
      "2025-03-10 14:56:21,454 - WARNING - No convertible_short in results for DFRA: {}\n",
      "2025-03-10 14:56:22,220 - WARNING - No convertible_short in results for DFNV: {}\n",
      "2025-03-10 14:56:24,950 - INFO - Null value in convertible_short for HGER: [None, None]\n",
      "2025-03-10 14:56:27,227 - INFO - Null value in convertible_short for BCIM: [None, None]\n",
      "2025-03-10 14:56:27,412 - INFO - Null value in convertible_short for IAUM: [None, None]\n",
      "2025-03-10 14:56:38,335 - WARNING - No convertible_short in results for TTAI: {}\n",
      "2025-03-10 14:56:39,821 - WARNING - No convertible_short in results for IQDE: {}\n",
      "2025-03-10 14:56:47,857 - WARNING - No convertible_short in results for XYLE: {}\n",
      "2025-03-10 14:56:50,444 - WARNING - No convertible_short in results for EMCC: {}\n",
      "2025-03-10 14:56:50,789 - WARNING - No convertible_short in results for NUSI: {}\n",
      "2025-03-10 14:56:51,296 - WARNING - No convertible_short in results for QYLE: {}\n",
      "2025-03-10 14:56:51,672 - WARNING - No convertible_short in results for HYLG: {}\n",
      "2025-03-10 14:56:51,675 - WARNING - No convertible_short in results for FYLG: {}\n",
      "2025-03-10 14:56:54,695 - WARNING - No convertible_short in results for GPOW: {}\n",
      "2025-03-10 14:56:54,961 - WARNING - No convertible_short in results for OCTA: {}\n",
      "2025-03-10 14:56:55,216 - WARNING - No convertible_short in results for GCLN: {}\n",
      "2025-03-10 14:56:56,544 - WARNING - No convertible_short in results for GREI: {}\n",
      "2025-03-10 14:56:59,765 - WARNING - No convertible_short in results for MJUS: {}\n",
      "2025-03-10 14:57:20,374 - WARNING - No convertible_short in results for TTAC: {}\n",
      "2025-03-10 14:57:25,998 - WARNING - No convertible_short in results for NETZ: {}\n",
      "2025-03-10 14:57:26,082 - INFO - Null value in convertible_short for FMCE: [None, None]\n",
      "2025-03-10 14:57:29,925 - WARNING - No convertible_short in results for USCF: {}\n",
      "2025-03-10 14:57:43,205 - WARNING - No convertible_short in results for HYMU: {}\n",
      "2025-03-10 14:57:43,223 - WARNING - No convertible_short in results for IMSI: {}\n",
      "2025-03-10 14:57:58,021 - WARNING - No convertible_short in results for WBND: {}\n",
      "2025-03-10 14:58:07,746 - WARNING - No convertible_short in results for ISDB: {}\n",
      "2025-03-10 14:58:09,056 - WARNING - No convertible_short in results for DFHY: {}\n",
      "2025-03-10 14:58:12,019 - WARNING - No convertible_short in results for JIEIX: {}\n",
      "2025-03-10 14:58:12,041 - WARNING - No convertible_short in results for ABQYX: {}\n",
      "2025-03-10 14:58:26,421 - WARNING - No convertible_short in results for MAYHX: {}\n",
      "2025-03-10 14:58:47,697 - WARNING - No convertible_short in results for FGTBX: {}\n",
      "2025-03-10 14:58:56,683 - WARNING - No convertible_short in results for FSMZX: {}\n",
      "2025-03-10 14:59:05,967 - WARNING - No convertible_short in results for AMCYX: {}\n",
      "2025-03-10 14:59:08,192 - WARNING - No convertible_short in results for JGIFX: {}\n",
      "2025-03-10 14:59:17,419 - WARNING - No convertible_short in results for FPPJX: {}\n",
      "2025-03-10 14:59:19,225 - WARNING - No convertible_short in results for MUIBX: {}\n",
      "2025-03-10 14:59:24,276 - WARNING - No convertible_short in results for NHYMX: {}\n",
      "2025-03-10 14:59:36,222 - WARNING - No convertible_short in results for PYHIX: {}\n",
      "2025-03-10 14:59:52,829 - INFO - Inserting 5541 rows for convertible_short\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating convertible_short for 5541 funds\n",
      "\n",
      "Summary for convertible_short:\n",
      "  Total Funds: 5586\n",
      "  Funds Needing Update: 5586\n",
      "  Data Fetched: 5541\n",
      "  Inserted: 5541\n",
      "  No Data: 45\n",
      "  Database Errors: 0\n",
      "  Failed Symbols: None\n"
     ]
    }
   ],
   "source": [
    "# All Exposure metrics verses selected ones \n",
    "\n",
    "# Simple script to populate cash_long, cash_net, etc. columns in Funds_to_Screen\n",
    "# Uses YCP API calls and mirrors core functionality from the provided script\n",
    "\n",
    "import requests\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor, TimeoutError\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# Step 1: Configuration\n",
    "# ---------------------\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Database connection string (same as provided script)\n",
    "connection_string = (\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/\"\n",
    "    \"CWA_Fund_Database?driver=ODBC+Driver+18+for+SQL+Server\"\n",
    "    \"&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "engine = sqlalchemy.create_engine(connection_string)\n",
    "\n",
    "# Test database connection\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(sqlalchemy.text(\"SELECT 1\"))\n",
    "    print(\"Database connection successful\")\n",
    "except Exception as e:\n",
    "    print(f\"Database connection failed: {e}\")\n",
    "\n",
    "# YCharts API headers for YCP (POST) requests (same as provided script)\n",
    "headers_YCP = {\n",
    "    \"X-YCHARTSAUTHORIZATION\": \"yIIphqbsQysnTvWWxfW33w\",  # Replace with your actual API key\n",
    "    \"X-YCHARTSEXCELSESSION\": \"b645cd897b2446bfa3796acfa3a879db\",\n",
    "    \"X-YCHARTSEXCELVERSION\": \"4.4\",\n",
    "    \"X-YCHARTSOPERATINGSYSTEM\": \"Microsoft Windows NT 10.0.26100.0\",\n",
    "    \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "    \"Host\": \"api.ycharts.com\",\n",
    "    \"Connection\": \"Keep-Alive\"\n",
    "}\n",
    "\n",
    "# Define base YCharts URL\n",
    "yc_base_url = \"https://api.ycharts.com/v3/\"\n",
    "\n",
    "# Metrics to fetch (all use YCP call type) - Added new preferred and convertible metrics\n",
    "metrics_to_fetch = [\n",
    "    {\"yc_metric\": \"cash_long\", \"db_column\": \"cash_long\"},\n",
    "    {\"yc_metric\": \"cash_net\", \"db_column\": \"cash_net\"},\n",
    "    {\"yc_metric\": \"cash_short\", \"db_column\": \"cash_short\"},\n",
    "    {\"yc_metric\": \"stock_long\", \"db_column\": \"stock_long\"},\n",
    "    {\"yc_metric\": \"stock_net\", \"db_column\": \"stock_net\"},\n",
    "    {\"yc_metric\": \"stock_short\", \"db_column\": \"stock_short\"},\n",
    "    {\"yc_metric\": \"bond_long\", \"db_column\": \"bond_long\"},\n",
    "    {\"yc_metric\": \"bond_net\", \"db_column\": \"bond_net\"},\n",
    "    {\"yc_metric\": \"bond_short\", \"db_column\": \"bond_short\"},\n",
    "    {\"yc_metric\": \"other_long\", \"db_column\": \"other_long\"},\n",
    "    {\"yc_metric\": \"other_net\", \"db_column\": \"other_net\"},\n",
    "    {\"yc_metric\": \"other_short\", \"db_column\": \"other_short\"},\n",
    "    {\"yc_metric\": \"preferred_long\", \"db_column\": \"preferred_long\"},\n",
    "    {\"yc_metric\": \"preferred_net\", \"db_column\": \"preferred_net\"},\n",
    "    {\"yc_metric\": \"preferred_short\", \"db_column\": \"preferred_short\"},\n",
    "    {\"yc_metric\": \"convertible_long\", \"db_column\": \"convertible_long\"},\n",
    "    {\"yc_metric\": \"convertible_net\", \"db_column\": \"convertible_net\"},\n",
    "    {\"yc_metric\": \"convertible_short\", \"db_column\": \"convertible_short\"},\n",
    "]\n",
    "\n",
    "# Step 2: Core Functions\n",
    "# ----------------------\n",
    "\n",
    "def fetch_ycp_metric(symbol, fund_type_id, yc_metric, headers_YCP=headers_YCP):\n",
    "    \"\"\"\n",
    "    Fetch YCP data from YCharts API using a POST request.\n",
    "    \n",
    "    Args:\n",
    "        symbol (str): Fund symbol (e.g., \"BALCX\").\n",
    "        fund_type_id (int): Fund type (e.g., 3 for mutual funds).\n",
    "        yc_metric (str): Metric to fetch (e.g., \"cash_long\").\n",
    "        headers_YCP (dict): Headers for YCP request.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple: (symbol, normalized_data) or (None, error_info).\n",
    "    \"\"\"\n",
    "    # Set up YCP URL and payload\n",
    "    ycp_api_url = \"https://api.ycharts.com/v3/excel/points\"\n",
    "    symbol_prefix = f\"M:{symbol}\" if fund_type_id == 3 else symbol\n",
    "    data = f\"points={symbol_prefix},{yc_metric}\"\n",
    "    logging.debug(f\"YCP payload for {symbol}: {data}\")\n",
    "\n",
    "    try:\n",
    "        # Make POST request with SSL bypass\n",
    "        response = requests.post(ycp_api_url, headers=headers_YCP, data=data, verify=False)\n",
    "        if response.status_code != 200:\n",
    "            logging.error(f\"YCP HTTP error for {symbol}: {response.status_code}\")\n",
    "            return None, {\"error\": f\"HTTP {response.status_code}\"}\n",
    "        \n",
    "        # Parse JSON response\n",
    "        data = response.json()\n",
    "        logging.debug(f\"YCP response for {symbol}: {data}\")\n",
    "\n",
    "        # Normalize data\n",
    "        normalized_data = normalize_api_data(data, symbol, yc_metric, fund_type_id=fund_type_id)\n",
    "        return symbol, normalized_data\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        logging.error(f\"YCP request failed for {symbol}: {str(e)}\")\n",
    "        return None, {\"error\": str(e)}\n",
    "\n",
    "def normalize_api_data(data, symbol, yc_metric, fund_type_id=None):\n",
    "    \"\"\"\n",
    "    Normalize YCharts API YCP response data into a float.\n",
    "    \n",
    "    Args:\n",
    "        data (dict): Raw JSON response from API.\n",
    "        symbol (str): Fund symbol.\n",
    "        yc_metric (str): Metric name.\n",
    "        fund_type_id (int): Fund type (e.g., 3 for mutual funds).\n",
    "    \n",
    "    Returns:\n",
    "        float or None if parsing fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Adjust symbol key for mutual funds\n",
    "        response_key = f\"M:{symbol}\" if fund_type_id == 3 else symbol\n",
    "        if \"response\" not in data or response_key not in data[\"response\"]:\n",
    "            logging.warning(f\"No response data for {symbol}: {data}\")\n",
    "            return None\n",
    "\n",
    "        # Extract results\n",
    "        results = data[\"response\"][response_key].get(\"results\", {})\n",
    "        if yc_metric not in results:\n",
    "            logging.warning(f\"No {yc_metric} in results for {symbol}: {results}\")\n",
    "            return None\n",
    "\n",
    "        metric_data = results[yc_metric]\n",
    "        logging.debug(f\"Raw metric data for {yc_metric} ({symbol}): {metric_data}\")\n",
    "\n",
    "        # YCP expects ['']['results'] structure (e.g., [\"2025-01-01\", 0.123])\n",
    "        if \"\" in metric_data and \"results\" in metric_data[\"\"]:\n",
    "            data_list = metric_data[\"\"][\"results\"]\n",
    "            if isinstance(data_list, list) and len(data_list) >= 1:\n",
    "                # Take second value if available, else first\n",
    "                raw_data = data_list[1] if len(data_list) > 1 else data_list[0]\n",
    "                if raw_data is not None:\n",
    "                    return float(raw_data)\n",
    "                logging.info(f\"Null value in {yc_metric} for {symbol}: {data_list}\")\n",
    "                return None\n",
    "            logging.warning(f\"Invalid list format for {yc_metric} ({symbol}): {data_list}\")\n",
    "            return None\n",
    "        else:\n",
    "            logging.warning(f\"No ['']['results'] in {yc_metric} for {symbol}: {metric_data}\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Normalization failed for {yc_metric} ({symbol}): {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def insert_to_database(df, column_name, batch_size=1000):\n",
    "    \"\"\"\n",
    "    Insert or update data into Funds_to_Screen table in batches.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): DataFrame with SymbolCUSIP and column_name data.\n",
    "        column_name (str): Name of the column to update.\n",
    "        batch_size (int): Number of rows per batch.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple: (successes, failures, database_errors)\n",
    "    \"\"\"\n",
    "    successes = 0\n",
    "    failures = 0\n",
    "    database_errors = []\n",
    "    print(f\"Updating {column_name} for {len(df)} funds\")\n",
    "\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch = df.iloc[i:i + batch_size]\n",
    "        try:\n",
    "            with engine.begin() as conn:\n",
    "                updates = [{\"symbol\": row[\"SymbolCUSIP\"], \"value\": row[column_name]} for _, row in batch.iterrows()]\n",
    "                conn.execute(\n",
    "                    sqlalchemy.text(f\"\"\"\n",
    "                        UPDATE Funds_to_Screen \n",
    "                        SET {column_name} = :value\n",
    "                        WHERE SymbolCUSIP = :symbol\n",
    "                    \"\"\"),\n",
    "                    updates\n",
    "                )\n",
    "            successes += len(batch)\n",
    "        except sqlalchemy.exc.SQLAlchemyError as e:\n",
    "            logging.error(f\"Database error: {str(e)}\")\n",
    "            failures += len(batch)\n",
    "            database_errors.extend(batch[\"SymbolCUSIP\"].tolist())\n",
    "\n",
    "    return successes, failures, database_errors\n",
    "\n",
    "# Step 3: Main Function to Update Metrics\n",
    "# ---------------------------------------\n",
    "\n",
    "def update_metric(yc_metric, db_column_name):\n",
    "    \"\"\"\n",
    "    Update a specific metric for funds where the column is NULL or needs updating.\n",
    "    \n",
    "    Args:\n",
    "        yc_metric (str): YCharts metric name (e.g., \"cash_long\").\n",
    "        db_column_name (str): Database column name (e.g., \"cash_long\").\n",
    "    \"\"\"\n",
    "    # Fetch all funds to check data population\n",
    "    query = f\"\"\"\n",
    "        SELECT SymbolCUSIP, Fund_Type_ID, {db_column_name}\n",
    "        FROM Funds_to_Screen\n",
    "    \"\"\"\n",
    "    funds = pd.read_sql(query, engine)\n",
    "    \n",
    "    # Filter funds where data is NULL\n",
    "    funds_to_update = funds[funds[db_column_name].isna()]\n",
    "    logging.info(f\"Found {len(funds_to_update)} funds needing {yc_metric} updates out of {len(funds)} total\")\n",
    "\n",
    "    if len(funds_to_update) == 0:\n",
    "        print(f\"No funds need {yc_metric.replace('_', ' ').title()} updates.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Requesting {yc_metric.replace('_', ' ').title()} for {len(funds_to_update)} funds from YCharts...\")\n",
    "    data_list = []\n",
    "    no_data_count = 0\n",
    "\n",
    "    def fetch_for_fund(row):\n",
    "        try:\n",
    "            symbol, normalized_data = fetch_ycp_metric(row[\"SymbolCUSIP\"], row[\"Fund_Type_ID\"], yc_metric)\n",
    "            if normalized_data is not None and not isinstance(normalized_data, dict):\n",
    "                return (symbol, normalized_data)\n",
    "            return (symbol, None, \"No data\" if normalized_data is None else normalized_data.get(\"error\", \"Unknown error\"))\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Fetch error for {row['SymbolCUSIP']}: {str(e)}\")\n",
    "            return (row[\"SymbolCUSIP\"], None, str(e))\n",
    "\n",
    "    # Use ThreadPoolExecutor for parallel API calls\n",
    "    with ThreadPoolExecutor(max_workers=60) as executor:\n",
    "        future_to_row = {executor.submit(fetch_for_fund, row): row for _, row in funds_to_update.iterrows()}\n",
    "        results = []\n",
    "        for future in future_to_row:\n",
    "            try:\n",
    "                result = future.result(timeout=30)\n",
    "                results.append(result)\n",
    "            except TimeoutError:\n",
    "                symbol = future_to_row[future][\"SymbolCUSIP\"]\n",
    "                logging.error(f\"Timeout fetching {yc_metric} for {symbol}\")\n",
    "                results.append((symbol, None, \"Timeout after 30s\"))\n",
    "\n",
    "    # Process results\n",
    "    for symbol, normalized_data, *error in results:\n",
    "        if normalized_data is not None:\n",
    "            data_list.append((symbol, normalized_data))\n",
    "        else:\n",
    "            no_data_count += 1\n",
    "            if error and error[0] != \"No data\":\n",
    "                logging.error(f\"API error for {symbol}: {error[0]}\")\n",
    "\n",
    "    if not data_list:\n",
    "        print(f\"No data fetched for {yc_metric}. No updates performed.\")\n",
    "        print(f\"Summary - Funds Needing Update: {len(funds_to_update)}, No Data: {no_data_count}\")\n",
    "        return\n",
    "\n",
    "    # Insert data into database\n",
    "    df = pd.DataFrame(data_list, columns=[\"SymbolCUSIP\", db_column_name])\n",
    "    logging.info(f\"Inserting {len(df)} rows for {yc_metric}\")\n",
    "    insert_successes, insert_failures, database_errors = insert_to_database(df, db_column_name)\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"\\nSummary for {yc_metric}:\")\n",
    "    print(f\"  Total Funds: {len(funds)}\")\n",
    "    print(f\"  Funds Needing Update: {len(funds_to_update)}\")\n",
    "    print(f\"  Data Fetched: {len(df)}\")\n",
    "    print(f\"  Inserted: {insert_successes}\")\n",
    "    print(f\"  No Data: {no_data_count}\")\n",
    "    print(f\"  Database Errors: {insert_failures}\")\n",
    "    print(f\"  Failed Symbols: {';'.join(database_errors) if database_errors else 'None'}\")\n",
    "\n",
    "# Step 4: Main Execution\n",
    "# ----------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Loop through each metric and update\n",
    "    for config in metrics_to_fetch:\n",
    "        update_metric(config[\"yc_metric\"], config[\"db_column\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02bf7be1-e4a7-4465-8765-e17d032497b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BFRIX CWA_Broad_Category_ID before merge: 24.0\n",
      "CWA_Broad_Category_List contents:\n",
      "    ID CWA_Broad_Category_Name\n",
      "0    1              Allocation\n",
      "1    2             Alternative\n",
      "2    3           Bond Strategy\n",
      "3    4        Cash Alternative\n",
      "4    5               Commodity\n",
      "5    6                 Country\n",
      "6    7                Currency\n",
      "7    8         Defined Outcome\n",
      "8    9                Delisted\n",
      "9   10           Digital Asset\n",
      "10  11                Emerging\n",
      "11  12             Global Bond\n",
      "12  13           Global Equity\n",
      "13  14           International\n",
      "14  15           Miscellaneous\n",
      "15  16               Municipal\n",
      "16  17          Nontraditional\n",
      "17  18   Quantitative/Tactical\n",
      "18  19                Regional\n",
      "19  20         Sector/Industry\n",
      "20  21            Single Stock\n",
      "21  22               Specialty\n",
      "22  23               Strategic\n",
      "23  25             Target Date\n",
      "24  26         Target Maturity\n",
      "25  24    Taxable Fixed Income\n",
      "26  27        Trading/Tactical\n",
      "27  28               US Equity\n",
      "\n",
      "Unmatched CWA_Broad_Category_IDs: [nan]\n",
      "\n",
      "Unique CWA_Broad_Category_Name values after merge:\n",
      "['Allocation' 'Specialty' 'Strategic' 'Quantitative/Tactical' 'US Equity'\n",
      " 'Alternative' 'Commodity' 'Nontraditional' 'Bond Strategy' 'Regional'\n",
      " 'Country' 'Emerging' 'International' 'Global Equity' 'Sector/Industry'\n",
      " nan 'Single Stock' 'Municipal' 'Global Bond' 'Taxable Fixed Income'\n",
      " 'Cash Alternative' 'Trading/Tactical']\n",
      "\n",
      "Number of NaN values in CWA_Broad_Category_Name: 3\n",
      "\n",
      "CWA_Broad_Category_Name for BFRIX after merge: Taxable Fixed Income\n",
      "\n",
      "CWA_Broad_Category_Name for BFRIX after normalization: Taxable Fixed Income\n",
      "\n",
      "Non-zero keyword increments for Heavy Amplification in FS_insight:\n",
      "     SymbolCUSIP                                         FS_insight  \\\n",
      "3764       BFRIX  The fund seeks to provide current income throu...   \n",
      "\n",
      "     matched_keywords_heavy_amplification  \n",
      "3764                      ; ; ; leveraged  \n",
      "\n",
      "CWA_Broad_Category_Name for BFRIX after keyword scoring: Taxable Fixed Income\n",
      "Assist rule boosted Heavy Amplification for 2 funds with Trading--Leveraged Equity in YC_Category\n",
      "Assist rule boosted Heavy Amplification for 4 funds with Trading--Leveraged Commodities in YC_Category\n",
      "Assist rule boosted Heavy Amplification for 2 funds with Trading--Leveraged Debt in YC_Category\n",
      "\n",
      "CWA_Broad_Category_Name for BFRIX after assist rules: Taxable Fixed Income\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'YC_Category'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'YC_Category'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 447\u001b[0m\n\u001b[0;32m    443\u001b[0m funds_df\u001b[38;5;241m.\u001b[39mloc[mask_market_neutral, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboolean_score_moderate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# Rule 9: Penalize Heavy Amplification for Bank Loan funds without clear leverage\u001b[39;00m\n\u001b[0;32m    446\u001b[0m mask_bank_loan_no_leverage \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 447\u001b[0m     (\u001b[43mfunds_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYC_Category\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBank Loan\u001b[39m\u001b[38;5;124m\"\u001b[39m, na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)) \u001b[38;5;241m&\u001b[39m\n\u001b[0;32m    448\u001b[0m     (funds_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleveraged_fund\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m\n\u001b[0;32m    449\u001b[0m     (\u001b[38;5;241m~\u001b[39mcombined_text\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2x|3x|amplified|geared\u001b[39m\u001b[38;5;124m\"\u001b[39m, na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[0;32m    450\u001b[0m )\n\u001b[0;32m    451\u001b[0m funds_df\u001b[38;5;241m.\u001b[39mloc[mask_bank_loan_no_leverage, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboolean_score_heavy_amplification\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m    452\u001b[0m funds_df\u001b[38;5;241m.\u001b[39mloc[mask_bank_loan_no_leverage, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboolean_score_moderate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'YC_Category'"
     ]
    }
   ],
   "source": [
    "# Risk Overlays v2 - Classification of Funds Based on Options Usage with Enhanced Debugging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# Adjustable toggle for Excel output\n",
    "write_to_excel = True\n",
    "\n",
    "# Define output path for Excel\n",
    "output_path = r\"C:\\Users\\JulianHeron\\Software Projects\\overlay_categories.xlsx\"\n",
    "\n",
    "# Database connection\n",
    "connection_string = (\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/\"\n",
    "    \"CWA_Fund_Database?driver=ODBC+Driver+18+for+SQL+Server\"\n",
    "    \"&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Expanded and refined keywords for each category\n",
    "keywords = {\n",
    "    \"Slight/None\": [\n",
    "        \"long-only\", \"no derivatives\", \"no hedging\", \"no leverage\", \"no options\", \"no short\",\n",
    "        \"position adjustment\", \"occasional hedging\", \"covered call\", \"put-write\", \"light hedge\",\n",
    "        \"may include options\", \"limited use of derivatives\", \"for risk management purposes\",\n",
    "        \"minor hedging\", \"occasional short positions\", \"overwrite\",\n",
    "    ],\n",
    "    \"Moderate\": [\n",
    "        \"hedged\", \"currency hedge\", \"protected\", \"buffer\", \"partial hedge\", \"hedged equity\", \"covered call\",\n",
    "        \"convexity option overlay\", \"option overlay\", \"put/spread collar\", \"forward agreement\", \"enhanced index strategy\",\n",
    "        \"BuyWrite\", \"Buy-Write\", \"buy write\", \"option spread\", \"volatility hedge\", \"put options\", \"enhance\",\n",
    "        \"options-based income\", \"ELN\", \"premium income\", \"call option\", \"FLEX options\", \"option premium\",\n",
    "        \"write calls\", \"sell calls\", \"protective puts\", \"equity-linked notes\", \"structured notes\",\n",
    "        \"risk mitigation\", \"downside protection\", \"limited hedging\",\n",
    "        \"floating rate\",\n",
    "    ],\n",
    "    \"Persistent Systematic\": [\n",
    "        \"tail-risk\", \"trend-following\", \"systematic hedging\", \"overlay\", \"CTA\", \"managed futures\",\n",
    "        \"defined outcome\", \"long-short\", \"market neutral\", \"systematic strategy\", \"return stacking\",\n",
    "        \"option writing\", \"straddle\", \"derivative income\", \"futures contracts\", \"swap contract\", \"forward agreement\",\n",
    "        \"enhanced index strategy\", \"volatility hedge\", \"put options\", \"options-based income\", \"ELN\", \"option premium\",\n",
    "        \"swap\", \"forward\", \"futures\", \"future\", \"VIX\",\n",
    "        \"managed futures strategy\", \"trend strategy\", \"quantitative hedging\", \"systematic options\",\n",
    "        \"options overlay strategy\", \"futures overlay\", \"swaps-based\",\n",
    "    ],\n",
    "    \"Heavy Amplification\": [\n",
    "        \"leveraged\", \"2x\", \"3x\", \"ultra\", \"amplified\", \"systematic leverage\",\n",
    "        \"double exposure\", \"triple exposure\", \"enhanced leverage\", \"geared\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert keywords to lowercase for matching\n",
    "keywords = {cat: [term.lower() for term in terms] for cat, terms in keywords.items()}\n",
    "\n",
    "# Define keyword scoring multipliers to reflect category intensity\n",
    "keyword_multipliers = {\n",
    "    \"Slight/None\": 1.0,\n",
    "    \"Moderate\": 2.0,\n",
    "    \"Persistent Systematic\": 3.0,\n",
    "    \"Heavy Amplification\": 2.0\n",
    "}\n",
    "\n",
    "# Define meaningful categories for direct classification\n",
    "meaningful_categories = {\n",
    "    \"Moderate\": {\n",
    "        \"CWA_Broad_Category\": [],\n",
    "        \"YC_Global_Category\": [],\n",
    "        \"YC_Category\": [\"Derivative Income\", \"Trading--Miscellaneous\", \"Bank Loan\"]\n",
    "    },\n",
    "    \"Persistent Systematic\": {\n",
    "        \"CWA_Broad_Category\": [\"Trading/Tactical\", \"Alternatives\"],\n",
    "        \"YC_Global_Category\": [\"Options Trading\", \"Market Neutral\", \"Long/Short Equity\", \"Multialternative\"],\n",
    "        \"YC_Category\": [\"Defined Outcome\", \"Relative Value Arbitrage\", \"Systematic Trend\", \"Trading--Inverse Commodities\", \"Trading--Inverse Debt\", \"Trading--Inverse Equity\"]\n",
    "    },\n",
    "    \"Heavy Amplification\": {\n",
    "        \"YC_Category\": [\"Trading--Leveraged Commodities\", \"Trading--Leveraged Debt\", \"Trading--Leveraged Equity\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Simplified assist categories\n",
    "assist_categories = [\n",
    "    {\n",
    "        \"exact\": \"Long/Short Equity\",\n",
    "        \"cat_type\": \"YC_Global_Category\",\n",
    "        \"actions\": {\"boost\": [\"Persistent Systematic\"], \"remove\": [\"Slight/None\", \"Moderate\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Market Neutral\",\n",
    "        \"cat_type\": \"YC_Global_Category\",\n",
    "        \"actions\": {\"boost\": [\"Persistent Systematic\"], \"remove\": [\"Slight/None\", \"Moderate\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Systematic Trend\",\n",
    "        \"cat_type\": \"YC_Category\",\n",
    "        \"actions\": {\"boost\": [\"Persistent Systematic\"], \"remove\": [\"Slight/None\", \"Moderate\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Defined Outcome\",\n",
    "        \"cat_type\": \"CWA_Broad_Category\",\n",
    "        \"actions\": {\"boost\": [\"Persistent Systematic\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Defined Outcome\",\n",
    "        \"cat_type\": \"YC_Global_Category\",\n",
    "        \"actions\": {\"boost\": [\"Persistent Systematic\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Defined Outcome\",\n",
    "        \"cat_type\": \"YC_Category\",\n",
    "        \"actions\": {\"boost\": [\"Persistent Systematic\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Trading--Leveraged Equity\",\n",
    "        \"cat_type\": \"YC_Category\",\n",
    "        \"actions\": {\"boost\": [\"Heavy Amplification\"], \"remove\": [\"Slight/None\", \"Moderate\", \"Persistent Systematic\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Trading--Leveraged Commodities\",\n",
    "        \"cat_type\": \"YC_Category\",\n",
    "        \"actions\": {\"boost\": [\"Heavy Amplification\"], \"remove\": [\"Slight/None\", \"Moderate\", \"Persistent Systematic\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Trading--Leveraged Debt\",\n",
    "        \"cat_type\": \"YC_Category\",\n",
    "        \"actions\": {\"boost\": [\"Heavy Amplification\"], \"remove\": [\"Slight/None\", \"Moderate\", \"Persistent Systematic\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Bank Loan\",\n",
    "        \"cat_type\": \"YC_Category\",\n",
    "        \"actions\": {\"boost\": [\"Moderate\"], \"remove\": [\"Heavy Amplification\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Options Trading\",\n",
    "        \"cat_type\": \"YC_Global_Category\",\n",
    "        \"actions\": {\"boost\": [\"Persistent Systematic\"], \"remove\": [\"Slight/None\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Multialternative\",\n",
    "        \"cat_type\": \"YC_Global_Category\",\n",
    "        \"actions\": {\"boost\": [\"Persistent Systematic\"], \"remove\": [\"Slight/None\", \"Moderate\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Relative Value Arbitrage\",\n",
    "        \"cat_type\": \"YC_Category\",\n",
    "        \"actions\": {\"boost\": [\"Persistent Systematic\"], \"remove\": [\"Slight/None\", \"Moderate\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Trading--Inverse Commodities\",\n",
    "        \"cat_type\": \"YC_Category\",\n",
    "        \"actions\": {\"boost\": [\"Persistent Systematic\"], \"remove\": [\"Slight/None\", \"Moderate\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Trading--Inverse Debt\",\n",
    "        \"cat_type\": \"YC_Category\",\n",
    "        \"actions\": {\"boost\": [\"Persistent Systematic\"], \"remove\": [\"Slight/None\", \"Moderate\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Trading--Inverse Equity\",\n",
    "        \"cat_type\": \"YC_Category\",\n",
    "        \"actions\": {\"boost\": [\"Persistent Systematic\"], \"remove\": [\"Slight/None\", \"Moderate\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Derivative Income\",\n",
    "        \"cat_type\": \"YC_Category\",\n",
    "        \"actions\": {\"boost\": [\"Persistent Systematic\", \"Moderate\"]}\n",
    "    },\n",
    "    {\n",
    "        \"exact\": \"Trading--Miscellaneous\",\n",
    "        \"cat_type\": \"YC_Category\",\n",
    "        \"actions\": {\"boost\": [\"Persistent Systematic\", \"Moderate\"]}\n",
    "    }\n",
    "]\n",
    "\n",
    "# Load data from database\n",
    "query_funds = \"\"\"\n",
    "SELECT SymbolCUSIP, ProductName, fund_family, investment_strategy, FS_insight, index_fund,\n",
    "       inverse_fund, leveraged_fund, socially_responsible_fund, synthetic_replication_fund,\n",
    "       fund_of_funds, currency_hedged_fund, ycharts_url, YC_Category_ID, CWA_Broad_Category_ID,\n",
    "       YC_Global_Category_ID, YC_Broad_Asset_Class_ID,\n",
    "       stock_net, stock_long, stock_short,\n",
    "       bond_net, bond_long, bond_short,\n",
    "       cash_net, cash_long, cash_short,\n",
    "       other_net, other_long, other_short\n",
    "FROM Funds_to_Screen\n",
    "\"\"\"\n",
    "funds_df = pd.read_sql(query_funds, engine)\n",
    "\n",
    "# Debug: Check BFRIX's CWA_Broad_Category_ID before merge\n",
    "bfrix_row_before_merge = funds_df[funds_df[\"SymbolCUSIP\"] == \"BFRIX\"]\n",
    "if not bfrix_row_before_merge.empty:\n",
    "    print(f\"\\nBFRIX CWA_Broad_Category_ID before merge: {bfrix_row_before_merge['CWA_Broad_Category_ID'].values[0]}\")\n",
    "\n",
    "# Load category mappings\n",
    "category_mappings = {\n",
    "    \"CWA_Broad_Category\": pd.read_sql(\"SELECT ID, CWA_Broad_Category_Name FROM CWA_Broad_Category_List\", engine),\n",
    "    \"YC_Category\": pd.read_sql(\"SELECT ID, Category_Name FROM YC_Category_List\", engine),\n",
    "    \"YC_Global_Category\": pd.read_sql(\"SELECT ID, Global_Category_Name FROM YC_Global_Category_List\", engine),\n",
    "    \"YC_Broad_Asset_Class\": pd.read_sql(\"SELECT ID, YC_Broad_Asset_Class_Name FROM YC_Broad_Asset_Class_List\", engine)\n",
    "}\n",
    "\n",
    "# Debug: Print CWA_Broad_Category_List contents\n",
    "print(\"CWA_Broad_Category_List contents:\")\n",
    "print(category_mappings[\"CWA_Broad_Category\"])\n",
    "\n",
    "# Debug: Check for unmatched CWA_Broad_Category_IDs\n",
    "unmatched_ids = funds_df[~funds_df[\"CWA_Broad_Category_ID\"].isin(category_mappings[\"CWA_Broad_Category\"][\"ID\"])][\"CWA_Broad_Category_ID\"].unique()\n",
    "print(f\"\\nUnmatched CWA_Broad_Category_IDs: {unmatched_ids}\")\n",
    "\n",
    "# Merge category names into funds_df\n",
    "funds_df = funds_df.merge(category_mappings[\"CWA_Broad_Category\"], left_on=\"CWA_Broad_Category_ID\", right_on=\"ID\", how=\"left\").drop(columns=[\"ID\"])\n",
    "funds_df = funds_df.merge(category_mappings[\"YC_Category\"], left_on=\"YC_Category_ID\", right_on=\"ID\", how=\"left\").drop(columns=[\"ID\"])\n",
    "funds_df = funds_df.merge(category_mappings[\"YC_Global_Category\"], left_on=\"YC_Global_Category_ID\", right_on=\"ID\", how=\"left\").drop(columns=[\"ID\"])\n",
    "funds_df = funds_df.merge(category_mappings[\"YC_Broad_Asset_Class\"], left_on=\"YC_Broad_Asset_Class_ID\", right_on=\"ID\", how=\"left\").drop(columns=[\"ID\"])\n",
    "\n",
    "# Debug: Print unique CWA_Broad_Category_Name values after merge\n",
    "print(\"\\nUnique CWA_Broad_Category_Name values after merge:\")\n",
    "print(funds_df[\"CWA_Broad_Category_Name\"].unique())\n",
    "\n",
    "# Debug: Check for NaN values in CWA_Broad_Category_Name\n",
    "nan_count = funds_df[\"CWA_Broad_Category_Name\"].isna().sum()\n",
    "print(f\"\\nNumber of NaN values in CWA_Broad_Category_Name: {nan_count}\")\n",
    "\n",
    "# Debug: Print CWA_Broad_Category_Name for BFRIX after merge\n",
    "bfrix_row = funds_df[funds_df[\"SymbolCUSIP\"] == \"BFRIX\"]\n",
    "if not bfrix_row.empty:\n",
    "    print(f\"\\nCWA_Broad_Category_Name for BFRIX after merge: {bfrix_row['CWA_Broad_Category_Name'].values[0]}\")\n",
    "\n",
    "# Normalize Boolean fields\n",
    "boolean_cols = [\"index_fund\", \"inverse_fund\", \"leveraged_fund\", \"socially_responsible_fund\",\n",
    "               \"synthetic_replication_fund\", \"fund_of_funds\", \"currency_hedged_fund\"]\n",
    "for col in boolean_cols:\n",
    "    funds_df[col] = funds_df[col].apply(lambda x: 1 if str(x).lower() in ['true', '1', 'yes'] else 0)\n",
    "\n",
    "# Ensure position columns are numeric and handle missing values\n",
    "position_cols = [\n",
    "    \"stock_net\", \"stock_long\", \"stock_short\",\n",
    "    \"bond_net\", \"bond_long\", \"bond_short\",\n",
    "    \"cash_net\", \"cash_long\", \"cash_short\",\n",
    "    \"other_net\", \"other_long\", \"other_short\"\n",
    "]\n",
    "for col in position_cols:\n",
    "    funds_df[col] = pd.to_numeric(funds_df[col], errors='coerce').fillna(0)\n",
    "\n",
    "# Debug: Check CWA_Broad_Category_Name for BFRIX after normalization\n",
    "bfrix_row = funds_df[funds_df[\"SymbolCUSIP\"] == \"BFRIX\"]\n",
    "if not bfrix_row.empty:\n",
    "    print(f\"\\nCWA_Broad_Category_Name for BFRIX after normalization: {bfrix_row['CWA_Broad_Category_Name'].values[0]}\")\n",
    "\n",
    "# Define categories for risk management overlays\n",
    "categories = [\"Slight/None\", \"Moderate\", \"Persistent Systematic\", \"Heavy Amplification\"]\n",
    "category_mapping = {\n",
    "    \"Slight/None\": \"slight_none\",\n",
    "    \"Moderate\": \"moderate\",\n",
    "    \"Persistent Systematic\": \"persistent_systematic\",\n",
    "    \"Heavy Amplification\": \"heavy_amplification\"\n",
    "}\n",
    "# Reverse mapping for final classification\n",
    "reverse_category_mapping = {v: k for k, v in category_mapping.items()}\n",
    "\n",
    "# Initialize scoring columns\n",
    "for cat in categories:\n",
    "    db_cat = category_mapping[cat]\n",
    "    score_col = f\"score_{db_cat}\"\n",
    "    funds_df[score_col] = 0.0\n",
    "\n",
    "# Initialize intermediate score columns\n",
    "for cat in categories:\n",
    "    db_cat = category_mapping[cat]\n",
    "    funds_df[f\"keyword_score_{db_cat}\"] = 0.0\n",
    "    funds_df[f\"meaningful_score_{db_cat}\"] = 0.0\n",
    "    funds_df[f\"assist_score_{db_cat}\"] = 0.0\n",
    "    funds_df[f\"boolean_score_{db_cat}\"] = 0.0\n",
    "    funds_df[f\"matched_keywords_{db_cat}\"] = \"\"\n",
    "\n",
    "# Function to count keywords and return matched keywords\n",
    "def count_keywords(text, keyword_list):\n",
    "    if pd.isna(text):\n",
    "        return 0, \"\"\n",
    "    text = text.lower()\n",
    "    matches = [keyword for keyword in keyword_list if re.search(r'\\b' + re.escape(keyword) + r'\\b', text)]\n",
    "    count = len(matches)\n",
    "    matched_text = \"; \".join(matches) if matches else \"\"\n",
    "    return count, matched_text\n",
    "\n",
    "# Apply keyword scoring with multipliers and debugging\n",
    "text_columns = [\"ProductName\", \"investment_strategy\", \"FS_insight\"]\n",
    "for cat, kw_list in keywords.items():\n",
    "    db_cat = category_mapping[cat]\n",
    "    score_col = f\"keyword_score_{db_cat}\"\n",
    "    matched_col = f\"matched_keywords_{db_cat}\"\n",
    "    multiplier = keyword_multipliers[cat]\n",
    "    for text_col in text_columns:\n",
    "        counts_and_matches = funds_df[text_col].apply(lambda x: count_keywords(x, kw_list))\n",
    "        increment = counts_and_matches.apply(lambda x: x[0] * multiplier)\n",
    "        funds_df[score_col] += increment\n",
    "        matched_increment = counts_and_matches.apply(lambda x: x[1])\n",
    "        funds_df[matched_col] = funds_df[matched_col] + \"; \" + matched_increment\n",
    "        # Debugging: Check for non-zero increments for Heavy Amplification\n",
    "        if cat == \"Heavy Amplification\":\n",
    "            non_zero_increments = funds_df[(increment > 0) & (funds_df[\"SymbolCUSIP\"] == \"BFRIX\")][[\"SymbolCUSIP\", text_col, matched_col]]\n",
    "            if not non_zero_increments.empty:\n",
    "                print(f\"\\nNon-zero keyword increments for {cat} in {text_col}:\")\n",
    "                print(non_zero_increments)\n",
    "    funds_df[matched_col] = funds_df[matched_col].str.replace(r'\\s*;\\s*;\\s*', '; ', regex=True).str.strip('; ')\n",
    "\n",
    "# Debug: Check CWA_Broad_Category_Name for BFRIX after keyword scoring\n",
    "bfrix_row = funds_df[funds_df[\"SymbolCUSIP\"] == \"BFRIX\"]\n",
    "if not bfrix_row.empty:\n",
    "    print(f\"\\nCWA_Broad_Category_Name for BFRIX after keyword scoring: {bfrix_row['CWA_Broad_Category_Name'].values[0]}\")\n",
    "\n",
    "# Apply meaningful category rules\n",
    "for cat, mappings in meaningful_categories.items():\n",
    "    db_cat = category_mapping[cat]\n",
    "    score_col = f\"meaningful_score_{db_cat}\"\n",
    "    for map_type, values in mappings.items():\n",
    "        col_name = {\n",
    "            \"CWA_Broad_Category\": \"CWA_Broad_Category_Name\",\n",
    "            \"YC_Category\": \"Category_Name\",\n",
    "            \"YC_Global_Category\": \"Global_Category_Name\"\n",
    "        }[map_type]\n",
    "        funds_df.loc[funds_df[col_name].isin(values), score_col] += 10\n",
    "\n",
    "# Apply assist category rules with debugging\n",
    "for rule in assist_categories:\n",
    "    cat_type = rule[\"cat_type\"]\n",
    "    col_name = {\n",
    "        \"CWA_Broad_Category\": \"CWA_Broad_Category_Name\",\n",
    "        \"YC_Category\": \"Category_Name\",\n",
    "        \"YC_Global_Category\": \"Global_Category_Name\",\n",
    "        \"YC_Broad_Asset_Class\": \"YC_Broad_Asset_Class_Name\"\n",
    "    }[cat_type]\n",
    "    actions = rule[\"actions\"]\n",
    "    exact_value = rule[\"exact\"]\n",
    "    mask = funds_df[col_name].fillna(\"\").str.contains(exact_value, case=False, na=False)\n",
    "\n",
    "    if \"remove\" in actions:\n",
    "        for remove_cat in actions[\"remove\"]:\n",
    "            db_remove_cat = category_mapping[remove_cat]\n",
    "            score_col = f\"assist_score_{db_remove_cat}\"\n",
    "            funds_df.loc[mask, score_col] -= 5\n",
    "    if \"boost\" in actions:\n",
    "        for boost_cat in actions[\"boost\"]:\n",
    "            db_boost_cat = category_mapping[boost_cat]\n",
    "            score_col = f\"assist_score_{db_boost_cat}\"\n",
    "            funds_df.loc[mask, score_col] += 5\n",
    "            if boost_cat == \"Heavy Amplification\" and mask.any():\n",
    "                print(f\"Assist rule boosted {boost_cat} for {sum(mask)} funds with {exact_value} in {cat_type}\")\n",
    "\n",
    "# Debug: Check CWA_Broad_Category_Name for BFRIX after assist rules\n",
    "bfrix_row = funds_df[funds_df[\"SymbolCUSIP\"] == \"BFRIX\"]\n",
    "if not bfrix_row.empty:\n",
    "    print(f\"\\nCWA_Broad_Category_Name for BFRIX after assist rules: {bfrix_row['CWA_Broad_Category_Name'].values[0]}\")\n",
    "\n",
    "# Apply Boolean rules with refinements\n",
    "combined_text = funds_df[text_columns].fillna(\"\").apply(lambda row: \" \".join(row), axis=1).str.lower()\n",
    "\n",
    "# Rule 1: Auto-classify funds with explicit leverage terms as Heavy Amplification\n",
    "amplification_terms = [\"2x\", \"3x\", \"double exposure\", \"triple exposure\", \"geared\"]\n",
    "mask_explicit_amplification = combined_text.str.contains(\"|\".join(amplification_terms), na=False) & (funds_df[\"leveraged_fund\"] == 1)\n",
    "funds_df.loc[mask_explicit_amplification, \"boolean_score_heavy_amplification\"] += 50\n",
    "funds_df.loc[mask_explicit_amplification, \"boolean_score_slight_none\"] = -float('inf')\n",
    "funds_df.loc[mask_explicit_amplification, \"boolean_score_moderate\"] = -float('inf')\n",
    "funds_df.loc[mask_explicit_amplification, \"boolean_score_persistent_systematic\"] -= 20\n",
    "\n",
    "# Rule 2: Leveraged funds with amplification keywords\n",
    "mask_leveraged_amplify = (\n",
    "    (funds_df[\"leveraged_fund\"] == 1) &\n",
    "    (funds_df[\"keyword_score_heavy_amplification\"] > 0) &\n",
    "    (combined_text.str.contains(\"leveraged|2x|3x|amplified|geared\", na=False))\n",
    ")\n",
    "funds_df.loc[mask_leveraged_amplify, \"boolean_score_heavy_amplification\"] += 30\n",
    "funds_df.loc[mask_leveraged_amplify, \"boolean_score_slight_none\"] = -float('inf')\n",
    "funds_df.loc[mask_leveraged_amplify, \"boolean_score_moderate\"] = -float('inf')\n",
    "funds_df.loc[mask_leveraged_amplify, \"boolean_score_persistent_systematic\"] -= 10\n",
    "\n",
    "# Rule 3: Leveraged funds without amplification keywords\n",
    "mask_leveraged_no_amplify = (\n",
    "    (funds_df[\"leveraged_fund\"] == 1) &\n",
    "    (funds_df[\"keyword_score_heavy_amplification\"] == 0) &\n",
    "    (funds_df[\"keyword_score_persistent_systematic\"] > 0)\n",
    ")\n",
    "funds_df.loc[mask_leveraged_no_amplify, \"boolean_score_persistent_systematic\"] += 15\n",
    "funds_df.loc[mask_leveraged_no_amplify, \"boolean_score_slight_none\"] = -float('inf')\n",
    "funds_df.loc[mask_leveraged_no_amplify, \"boolean_score_moderate\"] -= 5\n",
    "\n",
    "# Rule 4: Boost Moderate for covered calls and light hedging\n",
    "mask_moderate_hedging = (\n",
    "    ((funds_df[\"keyword_score_moderate\"] > 0) |\n",
    "     (funds_df[\"currency_hedged_fund\"] == 1) |\n",
    "     ((funds_df[[\"stock_short\", \"bond_short\", \"cash_short\", \"other_short\"]].max(axis=1) > 1) &\n",
    "      (funds_df[[\"stock_short\", \"bond_short\", \"cash_short\", \"other_short\"]].max(axis=1) <= 5)))\n",
    ")\n",
    "funds_df.loc[mask_moderate_hedging, \"boolean_score_moderate\"] += 20\n",
    "funds_df.loc[mask_moderate_hedging, \"boolean_score_slight_none\"] -= 10\n",
    "\n",
    "# Rule 5: Boost Persistent Systematic for trend-following, CTA, or systematic strategies\n",
    "mask_systematic = (\n",
    "    (funds_df[\"keyword_score_persistent_systematic\"] > 0) &\n",
    "    (combined_text.str.contains(\"trend-following|trend strategy|CTA|managed futures|systematic\", na=False))\n",
    ") | (\n",
    "    (funds_df[[\"stock_short\", \"bond_short\", \"cash_short\", \"other_short\"]].max(axis=1) > 5) &\n",
    "    (funds_df[\"keyword_score_persistent_systematic\"] > 0)\n",
    ")\n",
    "funds_df.loc[mask_systematic, \"boolean_score_persistent_systematic\"] += 20\n",
    "funds_df.loc[mask_systematic, \"boolean_score_slight_none\"] = -float('inf')\n",
    "funds_df.loc[mask_systematic, \"boolean_score_moderate\"] -= 10\n",
    "\n",
    "# Rule 6: Inverse or synthetic funds boost Persistent Systematic\n",
    "mask_inverse = funds_df[\"inverse_fund\"] == 1\n",
    "mask_synthetic = funds_df[\"synthetic_replication_fund\"] == 1\n",
    "funds_df.loc[mask_inverse | mask_synthetic, \"boolean_score_persistent_systematic\"] += 10\n",
    "funds_df.loc[mask_inverse | mask_synthetic, \"boolean_score_slight_none\"] = -float('inf')\n",
    "funds_df.loc[mask_inverse | mask_synthetic, \"boolean_score_moderate\"] -= 5\n",
    "\n",
    "# Rule 7: Boost Slight/None for minimal risk (strengthened)\n",
    "mask_no_risk = (\n",
    "    (funds_df[\"inverse_fund\"] == 0) &\n",
    "    (funds_df[\"leveraged_fund\"] == 0) &\n",
    "    (funds_df[\"synthetic_replication_fund\"] == 0) &\n",
    "    (funds_df[\"currency_hedged_fund\"] == 0) &\n",
    "    (funds_df[\"stock_short\"] <= 1) &\n",
    "    (funds_df[\"bond_short\"] <= 1) &\n",
    "    (funds_df[\"cash_short\"] <= 1) &\n",
    "    (funds_df[\"other_short\"] <= 1) &\n",
    "    (funds_df[\"stock_long\"] <= 100) &\n",
    "    (funds_df[\"bond_long\"] <= 100) &\n",
    "    (funds_df[\"cash_long\"] <= 100) &\n",
    "    (funds_df[\"other_long\"] <= 100)\n",
    ")\n",
    "funds_df.loc[mask_no_risk, \"boolean_score_slight_none\"] += 10\n",
    "\n",
    "# Rule 8: Boost Persistent Systematic for balanced long/short (market neutrality)\n",
    "mask_market_neutral = (\n",
    "    (funds_df[\"stock_long\"] > 10) &\n",
    "    (funds_df[\"stock_short\"] > 10) &\n",
    "    (abs(funds_df[\"stock_net\"]) < 20)\n",
    ")\n",
    "funds_df.loc[mask_market_neutral, \"boolean_score_persistent_systematic\"] += 10\n",
    "funds_df.loc[mask_market_neutral, \"boolean_score_slight_none\"] = -float('inf')\n",
    "funds_df.loc[mask_market_neutral, \"boolean_score_moderate\"] -= 5\n",
    "\n",
    "# Rule 9: Penalize Heavy Amplification for Bank Loan funds without clear leverage\n",
    "mask_bank_loan_no_leverage = (\n",
    "    (funds_df[\"YC_Category\"].str.contains(\"Bank Loan\", na=False)) &\n",
    "    (funds_df[\"leveraged_fund\"] == 0) &\n",
    "    (~combined_text.str.contains(\"2x|3x|amplified|geared\", na=False))\n",
    ")\n",
    "funds_df.loc[mask_bank_loan_no_leverage, \"boolean_score_heavy_amplification\"] -= 10\n",
    "funds_df.loc[mask_bank_loan_no_leverage, \"boolean_score_moderate\"] += 5\n",
    "\n",
    "# Debug: Check CWA_Broad_Category_Name for BFRIX before final scoring\n",
    "bfrix_row = funds_df[funds_df[\"SymbolCUSIP\"] == \"BFRIX\"]\n",
    "if not bfrix_row.empty:\n",
    "    print(f\"\\nCWA_Broad_Category_Name for BFRIX before final scoring: {bfrix_row['CWA_Broad_Category_Name'].values[0]}\")\n",
    "\n",
    "# Sum all intermediate scores into final scores with debugging\n",
    "for cat in categories:\n",
    "    db_cat = category_mapping[cat]\n",
    "    score_col = f\"score_{db_cat}\"\n",
    "    funds_df[score_col] = (\n",
    "        funds_df[f\"keyword_score_{db_cat}\"] +\n",
    "        funds_df[f\"meaningful_score_{db_cat}\"] +\n",
    "        funds_df[f\"assist_score_{db_cat}\"] +\n",
    "        funds_df[f\"boolean_score_{db_cat}\"]\n",
    "    )\n",
    "    # Debugging for BFRIX\n",
    "    if cat == \"Heavy Amplification\":\n",
    "        bflix_row = funds_df[funds_df[\"SymbolCUSIP\"] == \"BFRIX\"]\n",
    "        if not bflix_row.empty:\n",
    "            print(f\"\\nBFRIX Heavy Amplification Score Breakdown:\")\n",
    "            print(f\"Keyword Score: {bflix_row[f'keyword_score_{db_cat}'].values[0]}\")\n",
    "            print(f\"Meaningful Score: {bflix_row[f'meaningful_score_{db_cat}'].values[0]}\")\n",
    "            print(f\"Assist Score: {bflix_row[f'assist_score_{db_cat}'].values[0]}\")\n",
    "            print(f\"Boolean Score: {bflix_row[f'boolean_score_{db_cat}'].values[0]}\")\n",
    "            print(f\"Total Score: {bflix_row[f'score_{db_cat}'].values[0]}\")\n",
    "\n",
    "# Debug: Check CWA_Broad_Category_Name for BFRIX after final scoring\n",
    "bfrix_row = funds_df[funds_df[\"SymbolCUSIP\"] == \"BFRIX\"]\n",
    "if not bfrix_row.empty:\n",
    "    print(f\"\\nCWA_Broad_Category_Name for BFRIX after final scoring: {bfrix_row['CWA_Broad_Category_Name'].values[0]}\")\n",
    "\n",
    "# Determine final overlay category with corrected mapping\n",
    "score_columns = [f\"score_{category_mapping[cat]}\" for cat in categories]\n",
    "# Get the column name with the highest score\n",
    "max_score_col = funds_df[score_columns].idxmax(axis=1)\n",
    "# Map back to human-readable category using reverse mapping\n",
    "funds_df[\"Overlay_Category\"] = max_score_col.apply(\n",
    "    lambda x: reverse_category_mapping.get(x.replace(\"score_\", \"\"), \"Slight/None\") if pd.notnull(x) else \"Slight/None\"\n",
    ")\n",
    "\n",
    "# Apply tiebreaker: if scores are tied, prefer category with higher keyword score\n",
    "for idx in funds_df.index:\n",
    "    scores = funds_df.loc[idx, score_columns]\n",
    "    max_score = scores.max()\n",
    "    tied_categories = [col for col, score in scores.items() if score == max_score]\n",
    "    if len(tied_categories) > 1:\n",
    "        keyword_scores = {col: funds_df.loc[idx, f\"keyword_score_{col.replace('score_', '')}\"] for col in tied_categories}\n",
    "        max_keyword_score = max(keyword_scores.values())\n",
    "        best_tied_category = max(keyword_scores, key=keyword_scores.get)\n",
    "        funds_df.loc[idx, \"Overlay_Category\"] = reverse_category_mapping.get(best_tied_category.replace(\"score_\", \"\"), \"Slight/None\")\n",
    "\n",
    "# Debug: Check CWA_Broad_Category_Name for BFRIX before export\n",
    "bfrix_row = funds_df[funds_df[\"SymbolCUSIP\"] == \"BFRIX\"]\n",
    "if not bfrix_row.empty:\n",
    "    print(f\"\\nCWA_Broad_Category_Name for BFRIX before export: {bfrix_row['CWA_Broad_Category_Name'].values[0]}\")\n",
    "\n",
    "# Validation and Debugging Output\n",
    "print(\"Classification Distribution:\")\n",
    "print(funds_df[\"Overlay_Category\"].value_counts())\n",
    "\n",
    "# Detailed scores for top categories\n",
    "funds_df[\"Top_Score_Category\"] = funds_df[score_columns].idxmax(axis=1).apply(lambda x: reverse_category_mapping.get(x.replace(\"score_\", \"\"), \"Slight/None\"))\n",
    "funds_df[\"Top_Score_Value\"] = funds_df[score_columns].max(axis=1)\n",
    "print(\"\\nSample of funds with scores:\")\n",
    "print(funds_df[[\"SymbolCUSIP\", \"ProductName\", \"Overlay_Category\", \"Top_Score_Category\", \"Top_Score_Value\"] + score_columns].head(10))\n",
    "\n",
    "# Flag potential misclassifications with stricter criteria\n",
    "potential_misclass = funds_df[\n",
    "    (funds_df[\"Overlay_Category\"] == \"Slight/None\") &\n",
    "    (\n",
    "        (funds_df[\"keyword_score_moderate\"] > 0) |\n",
    "        (funds_df[\"keyword_score_persistent_systematic\"] > 0) |\n",
    "        (funds_df[\"keyword_score_heavy_amplification\"] > 0) |\n",
    "        (funds_df[[\"stock_short\", \"bond_short\", \"cash_short\", \"other_short\"]].max(axis=1) > 5) |\n",
    "        (funds_df[\"currency_hedged_fund\"] == 1 & funds_df[\"keyword_score_moderate\"] > 0)\n",
    "    )\n",
    "]\n",
    "print(f\"\\nFunds classified as Slight/None but with possible mismatch ({len(potential_misclass)}):\")\n",
    "if not potential_misclass.empty:\n",
    "    print(potential_misclass[[\"SymbolCUSIP\", \"ProductName\", \"Overlay_Category\", \"keyword_score_moderate\", \n",
    "                              \"keyword_score_persistent_systematic\", \"keyword_score_heavy_amplification\"]].head())\n",
    "\n",
    "# Export to Excel with error handling\n",
    "if write_to_excel:\n",
    "    priority_columns = [\n",
    "        \"SymbolCUSIP\", \"ProductName\", \"fund_family\", \"Overlay_Category\", \"ycharts_url\"\n",
    "    ]\n",
    "    remaining_columns = [\n",
    "        col for col in (\n",
    "            [f\"score_{category_mapping[cat]}\" for cat in categories] +\n",
    "            [f\"keyword_score_{category_mapping[cat]}\" for cat in categories] +\n",
    "            [f\"meaningful_score_{category_mapping[cat]}\" for cat in categories] +\n",
    "            [f\"assist_score_{category_mapping[cat]}\" for cat in categories] +\n",
    "            [f\"boolean_score_{category_mapping[cat]}\" for cat in categories] +\n",
    "            [f\"matched_keywords_{category_mapping[cat]}\" for cat in categories] +\n",
    "            [\"CWA_Broad_Category_Name\", \"Category_Name\", \"Global_Category_Name\", \"YC_Broad_Asset_Class_Name\"] +\n",
    "            [\"index_fund\", \"inverse_fund\", \"leveraged_fund\", \"socially_responsible_fund\", \"synthetic_replication_fund\", \"fund_of_funds\", \"currency_hedged_fund\"] +\n",
    "            [\"stock_net\", \"stock_long\", \"stock_short\", \"bond_net\", \"bond_long\", \"bond_short\", \"cash_net\", \"cash_long\", \"cash_short\", \"other_net\", \"other_long\", \"other_short\"]\n",
    "        ) if col in funds_df.columns and col not in priority_columns\n",
    "    ]\n",
    "    output_columns = priority_columns + remaining_columns\n",
    "    # Debug: Print CWA_Broad_Category_Name column before export\n",
    "    print(\"\\nCWA_Broad_Category_Name column before export (first few rows):\")\n",
    "    print(funds_df[[\"SymbolCUSIP\", \"CWA_Broad_Category_Name\"]].head())\n",
    "    try:\n",
    "        funds_df[output_columns].to_excel(output_path, index=False)\n",
    "        print(f\"\\nResults exported to {output_path}\")\n",
    "    except PermissionError as e:\n",
    "        print(f\"\\nError: Unable to write to {output_path}. Please ensure the file is closed and try again. ({e})\")\n",
    "else:\n",
    "    print(\"\\nExcel output skipped (write_to_excel=False).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "744f1a4c-d3b2-4e33-8780-ef0fdaca6869",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results exported to C:\\Users\\JulianHeron\\Software Projects\\Risk_Overlays_V1.xlsx\n"
     ]
    }
   ],
   "source": [
    "# New grok risk overlays code\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Connection string\n",
    "connection_string = (\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/\"\n",
    "    \"CWA_Fund_Database?driver=ODBC+Driver+18+for+SQL+Server\"\n",
    "    \"&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "# Define keyword mappings\n",
    "keyword_mappings = {\n",
    "    \"Slight/None\": [\"long-only\", \"no derivatives\", \"no hedging\", \"no leverage\", \"no options\", \"no short\",\n",
    "                    \"position adjustment\", \"occasional hedging\", \"covered call\", \"put-write\", \"light hedge\",\n",
    "                    \"may include options\", \"limited use of derivatives\", \"for risk management purposes\",\n",
    "                    \"minor hedging\", \"occasional short positions\", \"overwrite\"],\n",
    "    \"Moderate\": [\"hedged\", \"currency hedge\", \"protective put\", \"buffer\", \"partial hedge\", \"hedged equity\",\n",
    "                 \"covered call\", \"convexity option overlay\", \"option overlay\", \"put/spread collar\",\n",
    "                 \"forward agreement\", \"enhanced index strategy\", \"BuyWrite\", \"Buy-Write\", \"buy write\",\n",
    "                 \"option spread\", \"volatility hedge\", \"put options\", \"enhance\", \"options-based income\",\n",
    "                 \"ELN\", \"premium income\", \"call option\", \"FLEX options\", \"option premium\", \"write calls\",\n",
    "                 \"sell calls\", \"protective puts\", \"equity-linked notes\", \"structured notes\", \"risk mitigation\",\n",
    "                 \"downside protection\", \"limited hedging\", \"multi-asset\"],\n",
    "    \"Persistent Systematic\": [\"tail-risk\", \"trend-following\", \"systematic hedging\", \"overlay\", \"CTA\",\n",
    "                              \"managed futures\", \"defined outcome\", \"long-short\", \"market neutral\",\n",
    "                              \"systematic strategy\", \"return stacking\", \"option writing\", \"straddle\",\n",
    "                              \"derivative income\", \"futures contracts\", \"swap contract\", \"forward agreement\",\n",
    "                              \"enhanced index strategy\", \"volatility hedge\", \"put options\", \"options-based income\",\n",
    "                              \"ELN\", \"option premium\", \"swap\", \"forward\", \"futures\", \"future\", \"VIX\",\n",
    "                              \"managed futures strategy\", \"trend strategy\", \"quantitative hedging\",\n",
    "                              \"systematic options\", \"options overlay strategy\", \"futures overlay\", \"swaps-based\",\n",
    "                              \"multi-asset\", \"Flex Options\", \"Flexible Exchange Options\", \"YieldMax\",\n",
    "                              \"inverse\", \"synthetic\"],\n",
    "    \"Heavy Amplification\": [\"2x\", \"3x\", \"Uncapped Accelerator\", \"-2x\", \"-3x\", \"YieldMax\",\n",
    "                            \"inverse\", \"synthetic\"]\n",
    "}\n",
    "\n",
    "# Direct mapping keywords (often in ProductName)\n",
    "direct_keyword_mappings = {\n",
    "    \"Moderate\": [\"Covered Call\", \"Interest Rate Hedged\", \"Hedged Equity\", \"Currency Hedged\"],\n",
    "    \"Persistent Systematic\": [\"Market Neutral\", \"managed futures\", \"Premia\", \"Return Stacked ETFs\"]\n",
    "}\n",
    "\n",
    "# Direct mapping categories\n",
    "direct_category_mappings = {\n",
    "    \"Persistent Systematic\": {\n",
    "        \"YC_Category\": [\"Defined Outcome\"],\n",
    "        \"CWA_Broad_Category\": [\"Defined Outcome\"],\n",
    "        \"YC_Global_Category\": [\"market neutral\"]\n",
    "    },\n",
    "    \"Heavy Amplification\": {\n",
    "        \"YC_Category\": [\"Trading--Leveraged Equity\", \"Trading--Leveraged Debt\", \"Trading--Leveraged Commodities\"],\n",
    "        \"CWA_Broad_Category\": [\"Single Stock\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Helper category mappings (narrow possibilities)\n",
    "helper_category_mappings = {\n",
    "    (\"Persistent Systematic\", \"Heavy Amplification\"): {\n",
    "        \"YC_Category\": [\"Trading--Inverse Commodities\", \"Trading--Inverse Debt\", \"Trading--Inverse Equity\", \"Trading--Miscellaneous\"],\n",
    "        \"CWA_Broad_Category\": [\"Trading/Tactical\"],\n",
    "        \"YC_Global_Category\": [\"Trading Tools\"]\n",
    "    },\n",
    "    (\"Persistent Systematic\", \"Moderate\"): {\n",
    "        \"YC_Global_Category\": [\"Multialternative\", \"Long/Short Equity\"],\n",
    "        \"YC_Category\": [\"Equity Hedged\"]\n",
    "    },\n",
    "    (\"Moderate\",): {\n",
    "        \"YC_Category\": [\"Derivative Income\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Weak helper category mappings (may or may not have overlay)\n",
    "weak_helper_category_mappings = {\n",
    "    (\"Slight/None\", \"Moderate\"): {\n",
    "        \"YC_Global_Category\": [\"Flexible Allocation\", \"Alternative Miscellaneous\"],\n",
    "        \"return_driver\": [\"Index Based\", \"Factor/Smart Beta\"]\n",
    "    },\n",
    "    (\"Slight/None\", \"Moderate\", \"Persistent Systematic\"): {\n",
    "        \"YC_Category\": [\"Relative Value Arbitrage\"]\n",
    "    },\n",
    "    (\"Heavy Amplification\", \"Persistent Systematic\", \"Moderate\", \"Slight/None\"): {\n",
    "        \"return_driver\": [\"Quant/Systematic\"]\n",
    "    },\n",
    "    (\"Persistent Systematic\", \"Moderate\", \"Slight/None\"): {\n",
    "        \"return_driver\": [\"Active Discretionary\", \"Multi-Strategy\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Boolean flags to remove categories\n",
    "boolean_exclusions = {\n",
    "    (\"Slight/None\", \"Moderate\"): lambda row: row['leveraged_fund'] in [True, 1] or \\\n",
    "                                            row['synthetic_replication_fund'] in [True, 1] or \\\n",
    "                                            row['inverse_fund'] in [True, 1]\n",
    "}\n",
    "\n",
    "# Function to calculate exposure-based classification\n",
    "def exposure_based_classification(row):\n",
    "    # Convert exposure columns to numeric, handle missing columns gracefully\n",
    "    exposure_cols = ['cash_long', 'cash_net', 'cash_short', 'stock_long', 'stock_net', 'stock_short',\n",
    "                    'bond_long', 'bond_net', 'bond_short', 'other_long', 'other_net', 'other_short']\n",
    "    missing_cols = []\n",
    "    for col in exposure_cols:\n",
    "        try:\n",
    "            value = pd.to_numeric(row[col], errors='coerce')\n",
    "            row[col] = 0 if pd.isna(value) else value\n",
    "        except KeyError:\n",
    "            missing_cols.append(col)\n",
    "            row[col] = 0  # Set missing column to 0\n",
    "    \n",
    "    # If there are missing columns, note them in the audit log\n",
    "    debug_msg = \"\"\n",
    "    if missing_cols:\n",
    "        debug_msg += f\"Missing columns in exposure data: {missing_cols}. Set to 0. \"\n",
    "    \n",
    "    # Calculate totals\n",
    "    long_total = row['cash_long'] + row['stock_long'] + row['bond_long'] + row['other_long']\n",
    "    short_total = row['cash_short'] + row['stock_short'] + row['bond_short'] + row['other_short']\n",
    "\n",
    "    # Use a tolerance-based comparison instead of strict rounding\n",
    "    epsilon = 0.001\n",
    "\n",
    "    # Debug log for exact values\n",
    "    debug_msg += (f\"Exposure Check - long_total: {long_total}, \"\n",
    "                 f\"short_total: {short_total}\")\n",
    "\n",
    "    # Rule: Long exposures between 99.5% and 100% (allowing for small floating-point differences) and no shorts -> \"Slight/None\"\n",
    "    if (99.5 - epsilon <= long_total <= 100 + epsilon) and abs(short_total) <= epsilon:\n",
    "        return \"Slight/None\", f\"{debug_msg} -> Long exposures effectively between 99.5% and 100% and no shorts\"\n",
    "\n",
    "    # Existing rules\n",
    "    if (row['cash_long'] >= 98 and row['stock_long'] == 0 and row['bond_long'] == 0 and \n",
    "        row['cash_short'] == 0 and row['stock_short'] == 0 and row['bond_short'] == 0):\n",
    "        return \"Slight/None\", \"Pure long exposure\"\n",
    "    \n",
    "    if (row['cash_short'] > 0 and row['cash_long'] < 1 and \n",
    "        row['stock_long'] <= 1 and row['bond_long'] <= 1 and row['other_long'] <= 1):\n",
    "        return \"Slight/None\", \"Minimal short exposure\"\n",
    "    \n",
    "    if (row['cash_long'] > 50 and row['cash_long'] < 100 and \n",
    "        (row['stock_long'] > 0 or row['bond_long'] > 0) and \n",
    "        row['cash_short'] == 0 and row['stock_short'] == 0 and row['bond_short'] == 0):\n",
    "        return \"Moderate\", \"Possible futures usage\"\n",
    "    \n",
    "    return None, \"No clear exposure pattern\"\n",
    "\n",
    "# Function to search text for keywords\n",
    "def search_keywords(text, keywords):\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    text = str(text).lower()\n",
    "    return sum(1 for keyword in keywords if re.search(r'\\b' + re.escape(keyword.lower()) + r'\\b', text))\n",
    "\n",
    "# Main classification function\n",
    "def classify_fund(row):\n",
    "    possible_categories = [\"Slight/None\", \"Moderate\", \"Persistent Systematic\", \"Heavy Amplification\"]\n",
    "    scores = {cat: 0 for cat in possible_categories}\n",
    "    audit_log = []\n",
    "    any_category_match = False\n",
    "\n",
    "    # Step 1: Override for Fund Family \"Return Stacked ETFs\"\n",
    "    if pd.notna(row['fund_family']) and \"return stacked etfs\" in row['fund_family'].lower():\n",
    "        audit_log.append(\"Override: Fund family 'Return Stacked ETFs' -> Persistent Systematic\")\n",
    "        return \"Persistent Systematic\", audit_log\n",
    "\n",
    "    # Step 2: Direct keyword mapping\n",
    "    for category, keywords in direct_keyword_mappings.items():\n",
    "        for field in ['ProductName', 'investment_strategy', 'FS_insight']:\n",
    "            if pd.notna(row[field]):\n",
    "                match_count = search_keywords(row[field], keywords)\n",
    "                if match_count > 0:\n",
    "                    audit_log.append(f\"Direct keyword match for {category} in {field}: {match_count} keywords\")\n",
    "                    return category, audit_log\n",
    "\n",
    "    # Step 3: Direct category mapping\n",
    "    for category, mappings in direct_category_mappings.items():\n",
    "        for db_field, values in mappings.items():\n",
    "            values_lower = [val.lower() for val in values]\n",
    "            if db_field == \"YC_Category\" and pd.notna(row['YC_Category_Name']) and row['YC_Category_Name'].lower() in values_lower:\n",
    "                audit_log.append(f\"Direct category match for {category} in YC_Category_Name: {row['YC_Category_Name']}\")\n",
    "                return category, audit_log\n",
    "            if db_field == \"CWA_Broad_Category\" and pd.notna(row['CWA_Broad_Category_Name']) and row['CWA_Broad_Category_Name'].lower() in values_lower:\n",
    "                audit_log.append(f\"Direct category match for {category} in CWA_Broad_Category_Name: {row['CWA_Broad_Category_Name']}\")\n",
    "                return category, audit_log\n",
    "            if db_field == \"YC_Global_Category\" and pd.notna(row['Global_Category_Name']) and row['Global_Category_Name'].lower() in values_lower:\n",
    "                audit_log.append(f\"Direct category match for {category} in Global_Category_Name: {row['Global_Category_Name']}\")\n",
    "                return category, audit_log\n",
    "\n",
    "    # Step 4: Apply Boolean exclusions\n",
    "    for categories, condition in boolean_exclusions.items():\n",
    "        if condition(row):\n",
    "            excluded = [cat for cat in possible_categories if cat in categories]\n",
    "            for cat in excluded:\n",
    "                possible_categories.remove(cat)\n",
    "            audit_log.append(f\"Excluded {excluded} due to Boolean flags\")\n",
    "            if len(possible_categories) == 1:\n",
    "                return possible_categories[0], audit_log\n",
    "\n",
    "    # Step 5: Exposure-based classification\n",
    "    exposure_class, exposure_reason = exposure_based_classification(row)\n",
    "    if exposure_class:\n",
    "        audit_log.append(f\"Exposure-based classification: {exposure_class} - {exposure_reason}\")\n",
    "        return exposure_class, audit_log\n",
    "\n",
    "    # Step 6: Additional exposure-based rules\n",
    "    # Convert exposure columns to numeric for additional checks\n",
    "    exposure_cols = ['cash_long', 'cash_net', 'cash_short', 'stock_long', 'stock_net', 'stock_short',\n",
    "                    'bond_long', 'bond_net', 'bond_short', 'other_long', 'other_net', 'other_short']\n",
    "    for col in exposure_cols:\n",
    "        try:\n",
    "            value = pd.to_numeric(row[col], errors='coerce')\n",
    "            row[col] = 0 if pd.isna(value) else value\n",
    "        except KeyError:\n",
    "            row[col] = 0  # Set missing column to 0\n",
    "\n",
    "    # Rule: Stocks > 100% cannot be \"Slight/None\"\n",
    "    if row['stock_long'] > 100:\n",
    "        if \"Slight/None\" in possible_categories:\n",
    "            possible_categories.remove(\"Slight/None\")\n",
    "            audit_log.append(\"Excluded 'Slight/None' due to stock_long > 100%\")\n",
    "    # Rule: Stocks > 200% boosts Systematic, Aggressive, and Moderate\n",
    "    if row['stock_long'] > 200:\n",
    "        scores[\"Persistent Systematic\"] += 2\n",
    "        scores[\"Heavy Amplification\"] += 2\n",
    "        scores[\"Moderate\"] += 1\n",
    "        audit_log.append(\"Boosted 'Persistent Systematic' and 'Heavy Amplification' by +2, 'Moderate' by +1 due to stock_long > 200%\")\n",
    "\n",
    "    # Rule: Short or \"other\" exposures > 20% drops \"Moderate\" and \"Slight/None\"\n",
    "    short_total = row['cash_short'] + row['stock_short'] + row['bond_short'] + row['other_short']\n",
    "    other_total = row['other_long'] + row['other_short']\n",
    "    if short_total > 20 or other_total > 20:\n",
    "        for cat in [\"Moderate\", \"Slight/None\"]:\n",
    "            if cat in possible_categories:\n",
    "                possible_categories.remove(cat)\n",
    "        audit_log.append(f\"Excluded 'Moderate' and 'Slight/None' due to short_total ({short_total}%) or other_total ({other_total}%) > 20%\")\n",
    "        if len(possible_categories) == 1:\n",
    "            return possible_categories[0], audit_log\n",
    "\n",
    "    # Rule: High long exposure (>150%), high short exposure (>40%), high cash_short (>50%)\n",
    "    if row['stock_long'] > 150 and short_total > 40 and row['cash_short'] > 50:\n",
    "        for cat in [\"Moderate\", \"Slight/None\"]:\n",
    "            if cat in possible_categories:\n",
    "                possible_categories.remove(cat)\n",
    "        scores[\"Persistent Systematic\"] += 2\n",
    "        scores[\"Heavy Amplification\"] += 2\n",
    "        audit_log.append(f\"Excluded 'Moderate' and 'Slight/None', boosted 'Persistent Systematic' and 'Heavy Amplification' by +2 due to stock_long ({row['stock_long']}%) > 150, short_total ({short_total}%) > 40, and cash_short ({row['cash_short']}%) > 50\")\n",
    "        if len(possible_categories) == 1:\n",
    "            return possible_categories[0], audit_log\n",
    "\n",
    "    # Rule: If inverse_fund=True and short_total > 20, boost Heavy Amplification\n",
    "    if row['inverse_fund'] in [True, 1] and short_total > 20:\n",
    "        scores[\"Heavy Amplification\"] += 1\n",
    "        audit_log.append(\"Boosted 'Heavy Amplification' by +1 due to inverse_fund=True and short_total > 20\")\n",
    "\n",
    "    # Step 7: Rule for YC_BM_Symbol '^PEATR'\n",
    "    if pd.notna(row['YC_BM_Symbol']) and row['YC_BM_Symbol'] == '^PEATR':\n",
    "        for cat in [\"Moderate\", \"Persistent Systematic\", \"Heavy Amplification\"]:\n",
    "            scores[cat] += 1\n",
    "        audit_log.append(\"Boosted 'Moderate', 'Persistent Systematic', and 'Heavy Amplification' by +1 due to YC_BM_Symbol '^PEATR'\")\n",
    "\n",
    "    # Step 8: Rule for YC_Global_Category_Name \"Options Trading\"\n",
    "    if pd.notna(row['Global_Category_Name']) and row['Global_Category_Name'].lower() == \"options trading\":\n",
    "        scores[\"Moderate\"] += 1\n",
    "        scores[\"Persistent Systematic\"] += 2\n",
    "        scores[\"Heavy Amplification\"] += 2\n",
    "        audit_log.append(\"Boosted 'Moderate' by +1, 'Persistent Systematic' and 'Heavy Amplification' by +2 due to YC_Global_Category_Name 'Options Trading'\")\n",
    "        any_category_match = True\n",
    "\n",
    "    # Step 9: Score based on helper categories and keywords\n",
    "    # Helper categories\n",
    "    for categories, mappings in helper_category_mappings.items():\n",
    "        for db_field, values in mappings.items():\n",
    "            values_lower = [val.lower() for val in values]\n",
    "            if db_field == \"YC_Category\" and pd.notna(row['YC_Category_Name']) and row['YC_Category_Name'].lower() in values_lower:\n",
    "                for cat in categories:\n",
    "                    scores[cat] += 2\n",
    "                audit_log.append(f\"Helper category match for {categories} in YC_Category_Name: {row['YC_Category_Name']}\")\n",
    "                any_category_match = True\n",
    "            if db_field == \"CWA_Broad_Category\" and pd.notna(row['CWA_Broad_Category_Name']) and row['CWA_Broad_Category_Name'].lower() in values_lower:\n",
    "                for cat in categories:\n",
    "                    scores[cat] += 2\n",
    "                audit_log.append(f\"Helper category match for {categories} in CWA_Broad_Category_Name: {row['CWA_Broad_Category_Name']}\")\n",
    "                any_category_match = True\n",
    "            if db_field == \"YC_Global_Category\" and pd.notna(row['Global_Category_Name']) and row['Global_Category_Name'].lower() in values_lower:\n",
    "                for cat in categories:\n",
    "                    scores[cat] += 2\n",
    "                audit_log.append(f\"Helper category match for {categories} in Global_Category_Name: {row['Global_Category_Name']}\")\n",
    "                any_category_match = True\n",
    "\n",
    "    # Weak helper categories\n",
    "    for categories, mappings in weak_helper_category_mappings.items():\n",
    "        for db_field, values in mappings.items():\n",
    "            values_lower = [val.lower() for val in values]\n",
    "            if db_field == \"YC_Global_Category\" and pd.notna(row['Global_Category_Name']) and row['Global_Category_Name'].lower() in values_lower:\n",
    "                for cat in categories:\n",
    "                    scores[cat] += 1\n",
    "                audit_log.append(f\"Weak helper category match for {categories} in Global_Category_Name: {row['Global_Category_Name']}\")\n",
    "                any_category_match = True\n",
    "            if db_field == \"YC_Category\" and pd.notna(row['YC_Category_Name']) and row['YC_Category_Name'].lower() in values_lower:\n",
    "                for cat in categories:\n",
    "                    scores[cat] += 1\n",
    "                audit_log.append(f\"Weak helper category match for {categories} in YC_Category_Name: {row['YC_Category_Name']}\")\n",
    "                any_category_match = True\n",
    "            if db_field == \"return_driver\" and pd.notna(row['return_driver']) and row['return_driver'].lower() in values_lower:\n",
    "                for cat in categories:\n",
    "                    scores[cat] += 1\n",
    "                audit_log.append(f\"Weak helper category match for {categories} in return_driver: {row['return_driver']}\")\n",
    "                any_category_match = True\n",
    "\n",
    "    # Step 10: Handle non-category matches\n",
    "    # Include \"Nontraditional\" in CWA_Broad_Category as a match for top-tier exclusion\n",
    "    if pd.notna(row['CWA_Broad_Category_Name']) and row['CWA_Broad_Category_Name'].lower() == \"nontraditional\":\n",
    "        any_category_match = True\n",
    "        audit_log.append(\"CWA_Broad_Category 'Nontraditional' counts as a category match for top-tier exclusion\")\n",
    "\n",
    "    if not any_category_match:\n",
    "        audit_log.append(\"No category matches found. Excluding 'Heavy Amplification' and 'Persistent Systematic'.\")\n",
    "        possible_categories = [cat for cat in possible_categories if cat not in [\"Heavy Amplification\", \"Persistent Systematic\"]]\n",
    "        scores[\"Slight/None\"] += 2\n",
    "        scores[\"Moderate\"] += 1\n",
    "        audit_log.append(\"Boosted 'Slight/None' score by +2 and 'Moderate' score by +1 due to no category matches.\")\n",
    "\n",
    "    # Keyword scoring with increased points for Heavy Amplification\n",
    "    for category, keywords in keyword_mappings.items():\n",
    "        keyword_score = 0\n",
    "        for field in ['ProductName', 'investment_strategy', 'FS_insight']:\n",
    "            keyword_score += search_keywords(row[field], keywords)\n",
    "        # Increase score multiplier for \"Heavy Amplification\" keywords to 3 points per match\n",
    "        if category == \"Heavy Amplification\":\n",
    "            scores[category] += keyword_score * 3\n",
    "            if keyword_score > 0:\n",
    "                audit_log.append(f\"Keyword score for {category}: {keyword_score} matches x 3 = {keyword_score * 3}\")\n",
    "        else:\n",
    "            scores[category] += keyword_score\n",
    "            if keyword_score > 0:\n",
    "                audit_log.append(f\"Keyword score for {category}: {keyword_score}\")\n",
    "\n",
    "    # Determine final classification\n",
    "    max_score = max(scores[cat] for cat in possible_categories)\n",
    "    top_categories = [cat for cat in possible_categories if scores[cat] == max_score]\n",
    "    if len(top_categories) == 1:\n",
    "        final_classification = top_categories[0]\n",
    "        audit_log.append(f\"Final classification: {final_classification} with score {max_score}\")\n",
    "    else:\n",
    "        # Primary tiebreaker: Use keyword scores\n",
    "        keyword_tie_scores = {cat: 0 for cat in top_categories}\n",
    "        for category in top_categories:\n",
    "            for field in ['ProductName', 'investment_strategy', 'FS_insight']:\n",
    "                keyword_tie_scores[category] += search_keywords(row[field], keyword_mappings[category])\n",
    "        max_keyword_score = max(keyword_tie_scores.values())\n",
    "        top_keyword_categories = [cat for cat, score in keyword_tie_scores.items() if score == max_keyword_score]\n",
    "        \n",
    "        if len(top_keyword_categories) == 1:\n",
    "            final_classification = top_keyword_categories[0]\n",
    "            audit_log.append(f\"Tiebreaker used - Final classification: {final_classification} with tiebreaker keyword score {keyword_tie_scores[final_classification]}\")\n",
    "        else:\n",
    "            # Secondary tiebreaker: Prefer more conservative category\n",
    "            conservative_order = [\"Slight/None\", \"Moderate\", \"Persistent Systematic\", \"Heavy Amplification\"]\n",
    "            final_classification = min(top_keyword_categories, key=lambda x: conservative_order.index(x))\n",
    "            audit_log.append(f\"Secondary tiebreaker used - Final classification: {final_classification} (most conservative among {top_keyword_categories})\")\n",
    "\n",
    "    return final_classification, audit_log\n",
    "\n",
    "# Main script\n",
    "def main():\n",
    "    # Create database engine\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    # Query to join tables, fixed typo with 'stock_short'\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        f.SymbolCUSIP, f.ProductName, f.fund_family, f.investment_strategy, f.FS_insight,\n",
    "        f.index_fund, f.inverse_fund, f.leveraged_fund, f.synthetic_replication_fund,\n",
    "        f.fund_of_funds, f.ycharts_url, f.currency_hedged_fund,\n",
    "        f.cash_long, f.cash_net, f.cash_short, f.stock_long, f.stock_net, f.stock_short,\n",
    "        f.bond_long, f.bond_net, f.bond_short, f.other_long, f.other_net, f.other_short,\n",
    "        f.return_driver, f.YC_BM_Symbol,\n",
    "        cwa.CWA_Broad_Category_Name,\n",
    "        yc.Category_Name AS YC_Category_Name,\n",
    "        ycg.Global_Category_Name,\n",
    "        ycba.YC_Broad_Asset_Class_Name\n",
    "    FROM Funds_to_Screen f\n",
    "    LEFT JOIN CWA_Broad_Category_List cwa ON f.CWA_Broad_Category_ID = cwa.ID\n",
    "    LEFT JOIN YC_Category_List yc ON f.YC_Category_ID = yc.ID\n",
    "    LEFT JOIN YC_Global_Category_List ycg ON f.YC_Global_Category_ID = ycg.ID\n",
    "    LEFT JOIN YC_Broad_Asset_Class_List ycba ON f.YC_Broad_Asset_Class_ID = ycba.ID\n",
    "    \"\"\"\n",
    "\n",
    "    # Load data into DataFrame\n",
    "    df = pd.read_sql(query, engine)\n",
    "\n",
    "    # Apply classification\n",
    "    results = []\n",
    "    for idx, row in df.iterrows():\n",
    "        classification, audit_log = classify_fund(row)\n",
    "        result_row = row.copy()\n",
    "        result_row['Final_Classification'] = classification\n",
    "        result_row['Audit_Log'] = \"; \".join(audit_log)\n",
    "        results.append(result_row)\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    result_df = pd.DataFrame(results)\n",
    "\n",
    "    # Ensure desired column order\n",
    "    output_columns = ['SymbolCUSIP', 'ProductName', 'fund_family', 'Final_Classification', 'ycharts_url'] + \\\n",
    "                     [col for col in result_df.columns if col not in ['SymbolCUSIP', 'ProductName', 'fund_family', 'Final_Classification', 'ycharts_url']]\n",
    "\n",
    "    result_df = result_df[output_columns]\n",
    "\n",
    "    # Export to Excel\n",
    "    output_path = r\"C:\\Users\\JulianHeron\\Software Projects\\Risk_Overlays_V1.xlsx\"\n",
    "    result_df.to_excel(output_path, index=False)\n",
    "    print(f\"Results exported to {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e6a55cde-7ff5-43fa-abdb-9efc8b86a6b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results exported to C:\\Users\\JulianHeron\\Software Projects\\Risk_Overlays_V3.2.xlsx\n"
     ]
    }
   ],
   "source": [
    "# V3.2 with Grok. Using tiered decision tree and other logic.\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Connection string\n",
    "connection_string = (\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/\"\n",
    "    \"CWA_Fund_Database?driver=ODBC+Driver+18+for+SQL+Server\"\n",
    "    \"&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "# Helper function to safely convert to lowercase string\n",
    "def safe_lower(value):\n",
    "    return value.lower() if isinstance(value, str) else \"\"\n",
    "\n",
    "# Define keyword mappings for general scoring\n",
    "keyword_mappings = {\n",
    "    \"Slight/None\": [\"long-only\", \"no derivatives\", \"no hedging\", \"no leverage\", \"no options\", \"no short\", \n",
    "                    \"position adjustment\", \"occasional hedging\", \"covered call\", \"put-write\", \"light hedge\", \n",
    "                    \"may include options\", \"limited use of derivatives\", \"for risk management purposes\", \n",
    "                    \"minor hedging\", \"occasional short positions\", \"overwrite\", \"investment grade\", \"core\"],\n",
    "    \"Moderate\": [\"hedged\", \"currency hedge\", \"protective put\", \"partial hedge\", \"hedged equity\", \n",
    "                 \"covered call\", \"convexity option overlay\", \"option overlay\", \"put/spread collar\", \n",
    "                 \"forward agreement\", \"enhanced index strategy\", \"BuyWrite\", \"Buy-Write\", \"buy write\", \n",
    "                 \"option spread\", \"volatility hedge\", \"put options\", \"enhance\", \"options-based income\", \n",
    "                 \"ELN\", \"premium income\", \"call option\", \"FLEX options\", \"option premium\", \"write calls\", \n",
    "                 \"sell calls\", \"protective puts\", \"equity-linked notes\", \"structured notes\", \"risk mitigation\", \n",
    "                 \"downside protection\", \"limited hedging\", \"multi-asset\"],\n",
    "    \"Persistent Systematic\": [\"tail-risk\", \"trend-following\", \"systematic hedging\", \"overlay\", \"CTA\", \n",
    "                              \"managed futures\", \"defined outcome\", \"long-short\", \"market neutral\", \n",
    "                              \"systematic strategy\", \"return stacking\", \"option writing\", \"straddle\", \n",
    "                              \"derivative income\", \"futures contracts\", \"swap contract\", \"forward agreement\", \n",
    "                              \"enhanced index strategy\", \"volatility hedge\", \"put options\", \"options-based income\", \n",
    "                              \"ELN\", \"option premium\", \"swap\", \"forward\", \"futures\", \"future\", \"VIX\", \n",
    "                              \"managed futures strategy\", \"trend strategy\", \"quantitative hedging\", \n",
    "                              \"systematic options\", \"options overlay strategy\", \"futures overlay\", \"swaps-based\", \n",
    "                              \"multi-asset\", \"Flex Options\", \"Flexible Exchange Options\", \"YieldMax\", \"buffer\"],\n",
    "    \"Heavy Amplification\": [\"2x\", \"3x\", \"Uncapped Accelerator\", \"-2x\", \"-3x\", \"YieldMax\"]\n",
    "}\n",
    "\n",
    "# Direct mapping keywords (often in ProductName)\n",
    "direct_keyword_mappings = {\n",
    "    \"Persistent Systematic\": [\"Market Neutral\", \"managed futures\", \"Premia\", \"Return Stacked ETFs\"]\n",
    "}\n",
    "\n",
    "# Direct mapping categories\n",
    "direct_category_mappings = {\n",
    "    \"Persistent Systematic\": {\n",
    "        \"YC_Category\": [\"Defined Outcome\"],\n",
    "        \"CWA_Broad_Category\": [\"Defined Outcome\"],\n",
    "        \"YC_Global_Category\": [\"market neutral\"]\n",
    "    },\n",
    "    \"Heavy Amplification\": {\n",
    "        \"YC_Category\": [\"Trading--Leveraged Equity\", \"Trading--Leveraged Debt\", \"Trading--Leveraged Commodities\"],\n",
    "        \"CWA_Broad_Category\": [\"Single Stock\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Helper category mappings (narrow possibilities)\n",
    "helper_category_mappings = {\n",
    "    (\"Persistent Systematic\", \"Heavy Amplification\"): {\n",
    "        \"YC_Category\": [\"Trading--Inverse Commodities\", \"Trading--Inverse Debt\", \"Trading--Inverse Equity\", \"Trading--Miscellaneous\"],\n",
    "        \"CWA_Broad_Category\": [\"Trading/Tactical\"],\n",
    "        \"YC_Global_Category\": [\"Trading Tools\"]\n",
    "    },\n",
    "    (\"Persistent Systematic\", \"Moderate\"): {\n",
    "        \"YC_Global_Category\": [\"Multialternative\", \"Long/Short Equity\"],\n",
    "        \"YC_Category\": [\"Equity Hedged\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Weak helper category mappings (may or may not have overlay)\n",
    "weak_helper_category_mappings = {\n",
    "    (\"Slight/None\", \"Moderate\"): {\n",
    "        \"YC_Global_Category\": [\"Flexible Allocation\", \"Alternative Miscellaneous\"],\n",
    "        \"return_driver\": [\"Index Based\", \"Factor/Smart Beta\"]\n",
    "    },\n",
    "    (\"Slight/None\", \"Moderate\", \"Persistent Systematic\"): {\n",
    "        \"YC_Category\": [\"Relative Value Arbitrage\"]\n",
    "    },\n",
    "    (\"Heavy Amplification\", \"Persistent Systematic\", \"Moderate\", \"Slight/None\"): {\n",
    "        \"return_driver\": [\"Quant/Systematic\"]\n",
    "    },\n",
    "    (\"Persistent Systematic\", \"Moderate\", \"Slight/None\"): {\n",
    "        \"return_driver\": [\"Active Discretionary\", \"Multi-Strategy\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Boolean flags to remove categories\n",
    "boolean_exclusions = {\n",
    "    (\"Slight/None\", \"Moderate\"): lambda row: row['leveraged_fund'] in [True, 1] or \\\n",
    "                                            row['synthetic_replication_fund'] in [True, 1] or \\\n",
    "                                            row['inverse_fund'] in [True, 1]\n",
    "}\n",
    "\n",
    "# Function to search text for keywords\n",
    "def search_keywords(text, keywords):\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    text = str(text).lower()\n",
    "    return sum(1 for keyword in keywords if re.search(r'\\b' + re.escape(keyword.lower()) + r'\\b', text))\n",
    "\n",
    "# Decision Tree for Exposure Classification with Prove/Disprove\n",
    "def classify_by_exposures_with_disproof(row):\n",
    "    audit_log = []\n",
    "    possible_categories = [\"Slight/None\", \"Moderate\", \"Persistent Systematic\", \"Heavy Amplification\"]\n",
    "    scores = {cat: 0 for cat in possible_categories}\n",
    "\n",
    "    # Convert exposure columns to numeric, handle non-numeric gracefully\n",
    "    exposure_cols = ['cash_long', 'cash_net', 'cash_short', 'stock_long', 'stock_net', 'stock_short',\n",
    "                    'bond_long', 'bond_net', 'bond_short', 'other_long', 'other_net', 'other_short']\n",
    "    for col in exposure_cols:\n",
    "        value = pd.to_numeric(row[col], errors='coerce')\n",
    "        row[col] = 0 if pd.isna(value) else value\n",
    "\n",
    "    # Calculate totals\n",
    "    long_total = row['cash_long'] + row['stock_long'] + row['bond_long'] + row['other_long']\n",
    "    short_total = row['cash_short'] + row['stock_short'] + row['bond_short'] + row['other_short']\n",
    "    other_total = row['other_long'] + row['other_short']\n",
    "    stock_long = row['stock_long']\n",
    "    cash_short = row['cash_short']\n",
    "\n",
    "    # Round totals to 4 decimal places for comparison\n",
    "    long_total_rounded = round(long_total, 4)\n",
    "    short_total_rounded = round(short_total, 4)\n",
    "    other_total_rounded = round(other_total, 4)\n",
    "\n",
    "    # Debug logging for exposure values\n",
    "    debug_msg = (f\"Exposure Values - long_total: {long_total}, long_total_rounded: {long_total_rounded}, \"\n",
    "                 f\"short_total: {short_total}, short_total_rounded: {short_total_rounded}, \"\n",
    "                 f\"other_total: {other_total}, other_total_rounded: {other_total_rounded}\")\n",
    "    audit_log.append(debug_msg)\n",
    "\n",
    "    # Define disproof keywords for each branch\n",
    "    disproof_keywords = {\n",
    "        \"Slight/None\": [\"derivatives\", \"swaps\", \"futures\", \"short\", \"hedge\", \"long-short\", \"inverse\", \"leveraged\", \"tail risk\", \"tail-risk\"],\n",
    "        \"Moderate\": [\"systematic\", \"trend-following\", \"2x\", \"3x\", \"market neutral\", \"quantitative hedging\", \"managed futures\",\n",
    "                     \"managed futures strategy\", \"trend strategy\", \"YieldMax\", \"tail risk\", \"tail-risk\"],\n",
    "        \"Persistent Systematic\": [\"2x\", \"3x\", \"-2x\", \"-3x\", \"uncapped accelerator\"],\n",
    "        \"Heavy Amplification\": [\"long-only\", \"no derivatives\", \"no short\"]\n",
    "    }\n",
    "\n",
    "    # Helper function to check disproof keywords with detailed logging\n",
    "    def has_disproof_keywords(category):\n",
    "        keywords = disproof_keywords.get(category, [])\n",
    "        keyword_score = 0\n",
    "        disproof_details = []\n",
    "        for field in ['ProductName', 'investment_strategy', 'FS_insight']:\n",
    "            if pd.notna(row[field]):\n",
    "                text = str(row[field]).lower()\n",
    "                found_keywords = [keyword for keyword in keywords if re.search(r'\\b' + re.escape(keyword.lower()) + r'\\b', text)]\n",
    "                if found_keywords:\n",
    "                    disproof_details.append(f\"Field '{field}' contains disproof keywords: {found_keywords}\")\n",
    "                    keyword_score += len(found_keywords)\n",
    "        if keyword_score > 0:\n",
    "            audit_log.append(f\"Disproof Keywords ({category}): {disproof_details}\")\n",
    "        else:\n",
    "            audit_log.append(f\"No Disproof Keywords Found ({category})\")\n",
    "        return keyword_score > 0\n",
    "\n",
    "    # Helper function to check disproof categories with detailed logging\n",
    "    def has_disproof_categories(category):\n",
    "        disproof_details = []\n",
    "        result = False\n",
    "        if category == \"Slight/None\":\n",
    "            yc_category = safe_lower(row.get('YC_Category_Name', ''))\n",
    "            cwa_category = safe_lower(row.get('CWA_Broad_Category_Name', ''))\n",
    "            global_category = safe_lower(row.get('YC_Global_Category_Name', ''))\n",
    "            disproof_cats = [\"derivative income\", \"long-short equity\", \"trading--leveraged equity\"]\n",
    "            if yc_category in disproof_cats:\n",
    "                disproof_details.append(f\"YC_Category_Name '{yc_category}' matches disproof categories: {disproof_cats}\")\n",
    "                result = True\n",
    "            disproof_cats = [\"alternative\", \"nontraditional\"]\n",
    "            if cwa_category in disproof_cats:\n",
    "                disproof_details.append(f\"CWA_Broad_Category_Name '{cwa_category}' matches disproof categories: {disproof_cats}\")\n",
    "                result = True\n",
    "            disproof_cats = [\"options trading\", \"long/short equity\"]\n",
    "            if global_category in disproof_cats:\n",
    "                disproof_details.append(f\"YC_Global_Category_Name '{global_category}' matches disproof categories: {disproof_cats}\")\n",
    "                result = True\n",
    "        elif category == \"Moderate\":\n",
    "            yc_category = safe_lower(row.get('YC_Category_Name', ''))\n",
    "            return_driver = safe_lower(row.get('return_driver', ''))\n",
    "            disproof_cats = [\"trading--leveraged equity\", \"market neutral\"]\n",
    "            if yc_category in disproof_cats:\n",
    "                disproof_details.append(f\"YC_Category_Name '{yc_category}' matches disproof categories: {disproof_cats}\")\n",
    "                result = True\n",
    "            if return_driver in [\"quant/systematic\"]:\n",
    "                disproof_details.append(f\"return_driver '{return_driver}' matches disproof categories: ['quant/systematic']\")\n",
    "                result = True\n",
    "        elif category == \"Persistent Systematic\":\n",
    "            yc_category = safe_lower(row.get('YC_Category_Name', ''))\n",
    "            product_name = safe_lower(row.get('ProductName', ''))\n",
    "            disproof_cats = [\"trading--leveraged equity\", \"trading--leveraged debt\"]\n",
    "            if yc_category in disproof_cats:\n",
    "                disproof_details.append(f\"YC_Category_Name '{yc_category}' matches disproof categories: {disproof_cats}\")\n",
    "                result = True\n",
    "            if \"leveraged\" in product_name:\n",
    "                disproof_details.append(f\"ProductName '{product_name}' contains 'leveraged'\")\n",
    "                result = True\n",
    "        if result:\n",
    "            audit_log.append(f\"Disproof Categories ({category}): {disproof_details}\")\n",
    "        else:\n",
    "            audit_log.append(f\"No Disproof Categories Found ({category})\")\n",
    "        return result\n",
    "\n",
    "    # Branch 1: Simple Exposure (Long-Only, No Shorts/Other)\n",
    "    # Revert to original strict range: 99 <= long_total <= 101\n",
    "    if abs(short_total_rounded) <= 1 and abs(other_total_rounded) <= 1 and 99 <= long_total_rounded <= 101:\n",
    "        audit_log.append(\"Branch 1 Simple Exposure: Minimal shorts/other (<=1%), 99 <= long_total <= 101\")\n",
    "        # Prove with fund family\n",
    "        if pd.notna(row['fund_family']) and \"return stacked\" in row['fund_family'].lower():\n",
    "            audit_log.append(\"Disproof: Fund family 'Return Stacked' suggests complexity, routing to next branch\")\n",
    "        elif has_disproof_keywords(\"Slight/None\"):\n",
    "            audit_log.append(\"Disproof triggered (keywords), routing to next branch\")\n",
    "        elif has_disproof_categories(\"Slight/None\"):\n",
    "            audit_log.append(\"Disproof triggered (categories), routing to next branch\")\n",
    "        else:\n",
    "            audit_log.append(\"No disproof triggered, classifying as Slight/None\")\n",
    "            return \"Slight/None\", \"Simple Exposure: Minimal shorts/other (<=1%), 99 <= long_total <= 101, passed disproof\"\n",
    "    else:\n",
    "        reasons = []\n",
    "        if abs(short_total_rounded) > 1:\n",
    "            reasons.append(f\"short_total_rounded={short_total_rounded} > 1\")\n",
    "        if abs(other_total_rounded) > 1:\n",
    "            reasons.append(f\"other_total_rounded={other_total_rounded} > 1\")\n",
    "        if not (99 <= long_total_rounded <= 101):\n",
    "            reasons.append(f\"long_total_rounded={long_total_rounded} not in [99, 101]\")\n",
    "        audit_log.append(f\"Failed Simple Exposure: {', '.join(reasons)}\")\n",
    "\n",
    "    # Branch 2: Moderate Complexity (Minimal Shorts/Other, Balanced Exposures)\n",
    "    if short_total_rounded <= 10 and other_total_rounded <= 10:\n",
    "        audit_log.append(\"Branch 2 Moderate Complexity: Minimal shorts/other (<=10%)\")\n",
    "        if has_disproof_keywords(\"Moderate\"):\n",
    "            audit_log.append(\"Disproof triggered (keywords), routing to next branch\")\n",
    "        elif has_disproof_categories(\"Moderate\"):\n",
    "            audit_log.append(\"Disproof triggered (categories), routing to next branch\")\n",
    "        else:\n",
    "            audit_log.append(\"No disproof triggered, classifying as Moderate\")\n",
    "            return \"Moderate\", \"Moderate Complexity: Minimal shorts/other (<=10%), passed disproof\"\n",
    "    else:\n",
    "        audit_log.append(f\"Failed Moderate Complexity: shorts/other >10% \"\n",
    "                         f\"(short_total_rounded={short_total_rounded}, other_total_rounded={other_total_rounded})\")\n",
    "\n",
    "    # Branch 3: Persistent Systematic Complexity (Significant Shorts/Other)\n",
    "    if short_total_rounded <= 50 or other_total_rounded <= 50:\n",
    "        audit_log.append(\"Branch 3 Persistent Systematic Complexity: Shorts/other <=50%\")\n",
    "        excluded = []\n",
    "        for cat in [\"Slight/None\", \"Moderate\"]:\n",
    "            if cat in possible_categories:\n",
    "                possible_categories.remove(cat)\n",
    "                excluded.append(cat)\n",
    "        if excluded:\n",
    "            audit_log.append(f\"Excluded {excluded} due to shorts/other >10%\")\n",
    "        if has_disproof_keywords(\"Persistent Systematic\"):\n",
    "            audit_log.append(\"Disproof triggered (keywords), routing to next branch\")\n",
    "        elif has_disproof_categories(\"Persistent Systematic\"):\n",
    "            audit_log.append(\"Disproof triggered (categories), routing to next branch\")\n",
    "        else:\n",
    "            audit_log.append(\"No disproof triggered, classifying as Persistent Systematic\")\n",
    "            return \"Persistent Systematic\", \"Persistent Systematic Complexity: Significant shorts/other (<=50%), passed disproof\"\n",
    "    else:\n",
    "        audit_log.append(f\"Failed Persistent Systematic Complexity: shorts/other >50% \"\n",
    "                         f\"(short_total_rounded={short_total_rounded}, other_total_rounded={other_total_rounded})\")\n",
    "\n",
    "    # Branch 4: Heavy Amplification Complexity (High Shorts/Other, Amplified Indicators)\n",
    "    audit_log.append(\"Branch 4 Heavy Amplification Complexity: Shorts/other >50%\")\n",
    "    excluded = []\n",
    "    for cat in [\"Slight/None\", \"Moderate\", \"Persistent Systematic\"]:\n",
    "        if cat in possible_categories:\n",
    "            possible_categories.remove(cat)\n",
    "            excluded.append(cat)\n",
    "    if excluded:\n",
    "        audit_log.append(f\"Excluded {excluded} due to shorts/other >50%\")\n",
    "    if has_disproof_keywords(\"Heavy Amplification\"):\n",
    "        audit_log.append(\"Disproof triggered (keywords), routing to alternative evaluation\")\n",
    "        return None, scores, audit_log\n",
    "    if has_disproof_categories(\"Heavy Amplification\"):\n",
    "        audit_log.append(\"Disproof triggered (categories), routing to alternative evaluation\")\n",
    "        return None, scores, audit_log\n",
    "    audit_log.append(\"No disproof triggered, classifying as Heavy Amplification\")\n",
    "    return \"Heavy Amplification\", \"Heavy Amplification Complexity: High shorts/other (>50%), passed disproof\"\n",
    "\n",
    "# Alternative Evaluation Method for Ambiguous Cases\n",
    "def alternative_evaluation(row, scores, audit_log):\n",
    "    possible_categories = [\"Slight/None\", \"Moderate\", \"Persistent Systematic\", \"Heavy Amplification\"]\n",
    "    audit_log.append(\"Entering Alternative Evaluation: No definitive classification from exposure tree\")\n",
    "\n",
    "    # Adjust scores based on exposure and category data\n",
    "    if row['inverse_fund'] in [True, 1]:\n",
    "        scores[\"Heavy Amplification\"] += 2\n",
    "        scores[\"Persistent Systematic\"] += 1\n",
    "        audit_log.append(\"Inverse fund flag True, boosting Heavy Amplification (+2) and Persistent Systematic (+1)\")\n",
    "\n",
    "    # Score based on categories\n",
    "    yc_category = safe_lower(row.get('YC_Category_Name', ''))\n",
    "    cwa_category = safe_lower(row.get('CWA_Broad_Category_Name', ''))\n",
    "    global_category = safe_lower(row.get('YC_Global_Category_Name', ''))\n",
    "    return_driver = safe_lower(row.get('return_driver', ''))\n",
    "\n",
    "    # Score Slight/None\n",
    "    if (yc_category in [\"government bond\", \"corporate bond\", \"municipal bond\"] or\n",
    "        cwa_category in [\"taxable fixed income\", \"municipal\"] or\n",
    "        return_driver in [\"index based\"]):\n",
    "        scores[\"Slight/None\"] += 2\n",
    "        audit_log.append(f\"Category scoring for Slight/None: Matched categories/return_driver, added +2\")\n",
    "\n",
    "    # Score Moderate\n",
    "    if (yc_category in [\"derivative income\", \"multisector bond\"] or\n",
    "        cwa_category in [\"bond strategy\", \"strategic\"] or\n",
    "        global_category in [\"flexible allocation\", \"us fixed income\"]):\n",
    "        scores[\"Moderate\"] += 2\n",
    "        audit_log.append(f\"Category scoring for Moderate: Matched categories/global categories, added +2\")\n",
    "\n",
    "    # Score Persistent Systematic\n",
    "    if (yc_category in [\"long-short equity\", \"equity hedged\"] or\n",
    "        cwa_category in [\"alternative\", \"nontraditional\"] or\n",
    "        global_category in [\"long/short equity\", \"multialternative\", \"options trading\"] or\n",
    "        return_driver in [\"quant/systematic\", \"active discretionary\"]):\n",
    "        scores[\"Persistent Systematic\"] += 2\n",
    "        audit_log.append(f\"Category scoring for Persistent Systematic: Matched categories/global/return_driver, added +2\")\n",
    "\n",
    "    # Score Heavy Amplification\n",
    "    if (yc_category in [\"trading--leveraged equity\", \"trading--leveraged debt\"] or\n",
    "        \"leveraged\" in safe_lower(row.get('ProductName', ''))):\n",
    "        scores[\"Heavy Amplification\"] += 2\n",
    "        audit_log.append(f\"Category scoring for Heavy Amplification: Matched leveraged categories, added +2\")\n",
    "\n",
    "    # Evaluate pairs of categories\n",
    "    audit_log.append(\"Alternative Evaluation: Evaluating pairs of categories\")\n",
    "    # Pair 1: Slight/None vs Moderate\n",
    "    pair_scores = {\"Slight/None\": scores[\"Slight/None\"], \"Moderate\": scores[\"Moderate\"]}\n",
    "    audit_log.append(f\"Pair 1 (Slight/None vs Moderate) scores: {pair_scores}\")\n",
    "    max_score = max(pair_scores.values())\n",
    "    top_pair = [cat for cat, score in pair_scores.items() if score == max_score]\n",
    "    if len(top_pair) == 1:\n",
    "        selected = top_pair[0]\n",
    "        audit_log.append(f\"Alternative Evaluation: Slight/None vs Moderate -> Selected {selected} with score {pair_scores[selected]}\")\n",
    "    else:\n",
    "        keyword_tie_scores = {\"Slight/None\": 0, \"Moderate\": 0}\n",
    "        for category in top_pair:\n",
    "            for field in ['ProductName', 'investment_strategy', 'FS_insight']:\n",
    "                keyword_tie_scores[category] += search_keywords(row[field], keyword_mappings[category])\n",
    "        audit_log.append(f\"Pair 1 tiebreaker keyword scores: {keyword_tie_scores}\")\n",
    "        max_keyword_score = max(keyword_tie_scores.values())\n",
    "        top_keyword_pair = [cat for cat, score in keyword_tie_scores.items() if score == max_keyword_score]\n",
    "        selected = top_keyword_pair[0] if len(top_keyword_pair) == 1 else min(top_pair, key=lambda x: [\"Slight/None\", \"Moderate\"].index(x))\n",
    "        audit_log.append(f\"Alternative Evaluation: Slight/None vs Moderate tiebreak -> Selected {selected}\")\n",
    "\n",
    "    # Double-check against next category\n",
    "    if selected == \"Slight/None\":\n",
    "        next_pair = {\"Slight/None\": scores[\"Slight/None\"], \"Moderate\": scores[\"Moderate\"]}\n",
    "        if scores[\"Moderate\"] >= scores[\"Slight/None\"]:\n",
    "            selected = \"Moderate\"\n",
    "            audit_log.append(f\"Double-check: Moderate score ({scores['Moderate']}) >= Slight/None ({scores['Slight/None']}), selecting Moderate\")\n",
    "    elif selected == \"Moderate\":\n",
    "        next_pair = {\"Moderate\": scores[\"Moderate\"], \"Persistent Systematic\": scores[\"Persistent Systematic\"]}\n",
    "        if scores[\"Persistent Systematic\"] >= scores[\"Moderate\"]:\n",
    "            selected = \"Persistent Systematic\"\n",
    "            audit_log.append(f\"Double-check: Persistent Systematic score ({scores['Persistent Systematic']}) >= Moderate ({scores['Moderate']}), selecting Persistent Systematic\")\n",
    "    elif selected == \"Persistent Systematic\":\n",
    "        next_pair = {\"Persistent Systematic\": scores[\"Persistent Systematic\"], \"Heavy Amplification\": scores[\"Heavy Amplification\"]}\n",
    "        if scores[\"Heavy Amplification\"] >= scores[\"Persistent Systematic\"]:\n",
    "            selected = \"Heavy Amplification\"\n",
    "            audit_log.append(f\"Double-check: Heavy Amplification score ({scores['Heavy Amplification']}) >= Persistent Systematic ({scores['Persistent Systematic']}), selecting Heavy Amplification\")\n",
    "\n",
    "    return selected, audit_log\n",
    "\n",
    "# Main classification function\n",
    "def classify_fund(row):\n",
    "    possible_categories = [\"Slight/None\", \"Moderate\", \"Persistent Systematic\", \"Heavy Amplification\"]\n",
    "    scores = {cat: 0 for cat in possible_categories}\n",
    "    audit_log = []\n",
    "\n",
    "    # Step 1: Override for Fund Family \"Return Stacked ETFs\"\n",
    "    if pd.notna(row['fund_family']) and \"return stacked etfs\" in row['fund_family'].lower():\n",
    "        audit_log.append(\"Override: Fund family 'Return Stacked ETFs' -> Persistent Systematic\")\n",
    "        return \"Persistent Systematic\", audit_log\n",
    "\n",
    "    # Step 2: Direct keyword mapping (immediate classification)\n",
    "    for category, keywords in direct_keyword_mappings.items():\n",
    "        for field in ['ProductName', 'investment_strategy', 'FS_insight']:\n",
    "            if pd.notna(row[field]):\n",
    "                match_count = search_keywords(row[field], keywords)\n",
    "                if match_count > 0:\n",
    "                    audit_log.append(f\"Direct keyword match for {category} in {field}: {match_count} keywords\")\n",
    "                    return category, audit_log\n",
    "\n",
    "    # Step 3: Direct category mapping (immediate classification)\n",
    "    for category, mappings in direct_category_mappings.items():\n",
    "        for db_field, values in mappings.items():\n",
    "            values_lower = [val.lower() for val in values]\n",
    "            field_value = safe_lower(row.get(db_field, ''))\n",
    "            if field_value in values_lower:\n",
    "                audit_log.append(f\"Direct category match for {category} in {db_field}: {field_value}\")\n",
    "                return category, audit_log\n",
    "\n",
    "    # Step 4: Apply Boolean exclusions\n",
    "    for categories, condition in boolean_exclusions.items():\n",
    "        if condition(row):\n",
    "            excluded = [cat for cat in possible_categories if cat in categories]\n",
    "            for cat in excluded:\n",
    "                possible_categories.remove(cat)\n",
    "            audit_log.append(f\"Excluded {excluded} due to Boolean flags\")\n",
    "            if len(possible_categories) == 1:\n",
    "                return possible_categories[0], audit_log\n",
    "\n",
    "    # Step 5: Exposure Decision Tree with Prove/Disprove\n",
    "    exposure_result = classify_by_exposures_with_disproof(row)\n",
    "    if isinstance(exposure_result, tuple) and len(exposure_result) == 2:\n",
    "        classification, reason = exposure_result\n",
    "        audit_log.append(f\"Exposure-based classification: {classification} - {reason}\")\n",
    "        return classification, audit_log\n",
    "    elif exposure_result[0] is None:\n",
    "        # No definitive classification, proceed to alternative evaluation\n",
    "        scores_update = exposure_result[1]\n",
    "        for msg in exposure_result[2]:\n",
    "            audit_log.append(msg)\n",
    "        for cat in scores_update:\n",
    "            scores[cat] += scores_update[cat]\n",
    "        classification, eval_log = alternative_evaluation(row, scores, audit_log)\n",
    "        for msg in eval_log:\n",
    "            audit_log.append(msg)\n",
    "        audit_log.append(f\"Alternative Evaluation: Final classification: {classification}\")\n",
    "        return classification, audit_log\n",
    "    else:\n",
    "        # Continue with scoring\n",
    "        possible_categories, scores_update, exposure_log = exposure_result\n",
    "        for msg in exposure_log:\n",
    "            audit_log.append(msg)\n",
    "        for cat in scores_update:\n",
    "            scores[cat] += scores_update[cat]\n",
    "\n",
    "    # Step 6: Final Scoring if No Immediate Classification\n",
    "    max_score = max(scores[cat] for cat in possible_categories)\n",
    "    top_categories = [cat for cat in possible_categories if scores[cat] == max_score]\n",
    "    if len(top_categories) == 1:\n",
    "        final_classification = top_categories[0]\n",
    "        audit_log.append(f\"Final classification: {final_classification} with score {max_score}\")\n",
    "    else:\n",
    "        keyword_tie_scores = {cat: 0 for cat in top_categories}\n",
    "        for category in top_categories:\n",
    "            for field in ['ProductName', 'investment_strategy', 'FS_insight']:\n",
    "                keyword_tie_scores[category] += search_keywords(row[field], keyword_mappings[category])\n",
    "        audit_log.append(f\"Tiebreaker keyword scores: {keyword_tie_scores}\")\n",
    "        max_keyword_score = max(keyword_tie_scores.values())\n",
    "        top_keyword_categories = [cat for cat, score in keyword_tie_scores.items() if score == max_keyword_score]\n",
    "        if len(top_keyword_categories) == 1:\n",
    "            final_classification = top_keyword_categories[0]\n",
    "            audit_log.append(f\"Tiebreaker used - Final classification: {final_classification} with tiebreaker keyword score {keyword_tie_scores[final_classification]}\")\n",
    "        else:\n",
    "            conservative_order = [\"Slight/None\", \"Moderate\", \"Persistent Systematic\", \"Heavy Amplification\"]\n",
    "            final_classification = min(top_keyword_categories, key=lambda x: conservative_order.index(x))\n",
    "            audit_log.append(f\"Secondary tiebreaker used - Final classification: {final_classification} (most conservative among {top_keyword_categories})\")\n",
    "\n",
    "    return final_classification, audit_log\n",
    "\n",
    "# Main script\n",
    "def main():\n",
    "    # Create database engine\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    # Query to join tables\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        f.SymbolCUSIP, f.ProductName, f.fund_family, f.investment_strategy, f.FS_insight,\n",
    "        f.index_fund, f.inverse_fund, f.leveraged_fund, f.synthetic_replication_fund,\n",
    "        f.fund_of_funds, f.ycharts_url, f.currency_hedged_fund,\n",
    "        f.cash_long, f.cash_net, f.cash_short, f.stock_long, f.stock_net, f.stock_short,\n",
    "        f.bond_long, f.bond_net, f.bond_short, f.other_long, f.other_net, f.other_short,\n",
    "        f.return_driver, f.YC_BM_Symbol,\n",
    "        cwa.CWA_Broad_Category_Name,\n",
    "        yc.Category_Name AS YC_Category_Name,\n",
    "        ycg.Global_Category_Name,\n",
    "        ycba.YC_Broad_Asset_Class_Name\n",
    "    FROM Funds_to_Screen f\n",
    "    LEFT JOIN CWA_Broad_Category_List cwa ON f.CWA_Broad_Category_ID = cwa.ID\n",
    "    LEFT JOIN YC_Category_List yc ON f.YC_Category_ID = yc.ID\n",
    "    LEFT JOIN YC_Global_Category_List ycg ON f.YC_Global_Category_ID = ycg.ID\n",
    "    LEFT JOIN YC_Broad_Asset_Class_List ycba ON f.YC_Broad_Asset_Class_ID = ycba.ID\n",
    "    \"\"\"\n",
    "\n",
    "    # Load data into DataFrame\n",
    "    df = pd.read_sql(query, engine)\n",
    "\n",
    "    # Apply classification\n",
    "    results = []\n",
    "    for idx, row in df.iterrows():\n",
    "        classification, audit_log = classify_fund(row)\n",
    "        result_row = row.copy()\n",
    "        result_row['Final_Classification'] = classification\n",
    "        result_row['Audit_Log'] = \"; \".join(audit_log)\n",
    "        results.append(result_row)\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    result_df = pd.DataFrame(results)\n",
    "\n",
    "    # Ensure desired column order\n",
    "    output_columns = ['SymbolCUSIP', 'ProductName', 'fund_family', 'Final_Classification', 'ycharts_url'] + \\\n",
    "                     [col for col in result_df.columns if col not in ['SymbolCUSIP', 'ProductName', 'fund_family', 'Final_Classification', 'ycharts_url']]\n",
    "\n",
    "    result_df = result_df[output_columns]\n",
    "\n",
    "    # Export to Excel\n",
    "    output_path = r\"C:\\Users\\JulianHeron\\Software Projects\\Risk_Overlays_V3.2.xlsx\"\n",
    "    result_df.to_excel(output_path, index=False)\n",
    "    print(f\"Results exported to {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f6a480c1-f9fc-4bbe-8559-78b189b72868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results exported to C:\\Users\\JulianHeron\\Software Projects\\Risk_Overlays_V4.xlsx\n"
     ]
    }
   ],
   "source": [
    "# This code was close, only issue is the 99.5% vs 100% issue\n",
    "# placed here to preserve in case of grok issues\n",
    "\n",
    "# V4 with Grok. Using tiered decision tree and other logic.\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Connection string\n",
    "connection_string = (\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/\"\n",
    "    \"CWA_Fund_Database?driver=ODBC+Driver+18+for+SQL+Server\"\n",
    "    \"&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "# Helper function to safely convert to lowercase string (moved to top level)\n",
    "def safe_lower(value):\n",
    "    return value.lower() if isinstance(value, str) else \"\"\n",
    "\n",
    "# Define keyword mappings for general scoring\n",
    "keyword_mappings = {\n",
    "    \"Slight/None\": [\"long-only\", \"no derivatives\", \"no hedging\", \"no leverage\", \"no options\", \"no short\", \n",
    "                    \"position adjustment\", \"occasional hedging\", \"covered call\", \"put-write\", \"light hedge\", \n",
    "                    \"may include options\", \"limited use of derivatives\", \"for risk management purposes\", \n",
    "                    \"minor hedging\", \"occasional short positions\", \"overwrite\", \"investment grade\", \"core\"],\n",
    "    \"Moderate\": [\"hedged\", \"currency hedge\", \"protective put\", \"partial hedge\", \"hedged equity\", \n",
    "                 \"covered call\", \"convexity option overlay\", \"option overlay\", \"put/spread collar\", \n",
    "                 \"forward agreement\", \"enhanced index strategy\", \"BuyWrite\", \"Buy-Write\", \"buy write\", \n",
    "                 \"option spread\", \"volatility hedge\", \"put options\", \"enhance\", \"options-based income\", \n",
    "                 \"ELN\", \"premium income\", \"call option\", \"FLEX options\", \"option premium\", \"write calls\", \n",
    "                 \"sell calls\", \"protective puts\", \"equity-linked notes\", \"structured notes\", \"risk mitigation\", \n",
    "                 \"downside protection\", \"limited hedging\", \"multi-asset\"],\n",
    "    \"Persistent Systematic\": [\"tail-risk\", \"trend-following\", \"systematic hedging\", \"overlay\", \"CTA\", \n",
    "                              \"managed futures\", \"defined outcome\", \"long-short\", \"market neutral\", \n",
    "                              \"systematic strategy\", \"return stacking\", \"option writing\", \"straddle\", \n",
    "                              \"derivative income\", \"futures contracts\", \"swap contract\", \"forward agreement\", \n",
    "                              \"enhanced index strategy\", \"volatility hedge\", \"put options\", \"options-based income\", \n",
    "                              \"ELN\", \"option premium\", \"swap\", \"forward\", \"futures\", \"future\", \"VIX\", \n",
    "                              \"managed futures strategy\", \"trend strategy\", \"quantitative hedging\", \n",
    "                              \"systematic options\", \"options overlay strategy\", \"futures overlay\", \"swaps-based\", \n",
    "                              \"multi-asset\", \"Flex Options\", \"Flexible Exchange Options\", \"YieldMax\", \"buffer\"],\n",
    "    \"Heavy Amplification\": [\"2x\", \"3x\", \"Uncapped Accelerator\", \"-2x\", \"-3x\", \"YieldMax\"]\n",
    "}\n",
    "\n",
    "# Direct mapping keywords (often in ProductName)\n",
    "direct_keyword_mappings = {\n",
    "    \"Persistent Systematic\": [\"Market Neutral\", \"managed futures\", \"Premia\", \"Return Stacked ETFs\"]\n",
    "}\n",
    "\n",
    "# Direct mapping categories\n",
    "direct_category_mappings = {\n",
    "    \"Persistent Systematic\": {\n",
    "        \"YC_Category\": [\"Defined Outcome\"],\n",
    "        \"CWA_Broad_Category\": [\"Defined Outcome\"],\n",
    "        \"YC_Global_Category\": [\"market neutral\"]\n",
    "    },\n",
    "    \"Heavy Amplification\": {\n",
    "        \"YC_Category\": [\"Trading--Leveraged Equity\", \"Trading--Leveraged Debt\", \"Trading--Leveraged Commodities\"],\n",
    "        \"CWA_Broad_Category\": [\"Single Stock\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Helper category mappings (narrow possibilities)\n",
    "helper_category_mappings = {\n",
    "    (\"Persistent Systematic\", \"Heavy Amplification\"): {\n",
    "        \"YC_Category\": [\"Trading--Inverse Commodities\", \"Trading--Inverse Debt\", \"Trading--Inverse Equity\", \"Trading--Miscellaneous\"],\n",
    "        \"CWA_Broad_Category\": [\"Trading/Tactical\"],\n",
    "        \"YC_Global_Category\": [\"Trading Tools\"]\n",
    "    },\n",
    "    (\"Persistent Systematic\", \"Moderate\"): {\n",
    "        \"YC_Global_Category\": [\"Multialternative\", \"Long/Short Equity\"],\n",
    "        \"YC_Category\": [\"Equity Hedged\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Weak helper category mappings (may or may not have overlay)\n",
    "weak_helper_category_mappings = {\n",
    "    (\"Slight/None\", \"Moderate\"): {\n",
    "        \"YC_Global_Category\": [\"Flexible Allocation\", \"Alternative Miscellaneous\"],\n",
    "        \"return_driver\": [\"Index Based\", \"Factor/Smart Beta\"]\n",
    "    },\n",
    "    (\"Slight/None\", \"Moderate\", \"Persistent Systematic\"): {\n",
    "        \"YC_Category\": [\"Relative Value Arbitrage\"]\n",
    "    },\n",
    "    (\"Heavy Amplification\", \"Persistent Systematic\", \"Moderate\", \"Slight/None\"): {\n",
    "        \"return_driver\": [\"Quant/Systematic\"]\n",
    "    },\n",
    "    (\"Persistent Systematic\", \"Moderate\", \"Slight/None\"): {\n",
    "        \"return_driver\": [\"Active Discretionary\", \"Multi-Strategy\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Boolean flags to remove categories\n",
    "boolean_exclusions = {\n",
    "    (\"Slight/None\", \"Moderate\"): lambda row: row['leveraged_fund'] in [True, 1] or \\\n",
    "                                            row['synthetic_replication_fund'] in [True, 1] or \\\n",
    "                                            row['inverse_fund'] in [True, 1]\n",
    "}\n",
    "\n",
    "# Function to search text for keywords\n",
    "def search_keywords(text, keywords):\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    text = str(text).lower()\n",
    "    return sum(1 for keyword in keywords if re.search(r'\\b' + re.escape(keyword.lower()) + r'\\b', text))\n",
    "\n",
    "# Decision Tree for Exposure Classification with Prove/Disprove\n",
    "def classify_by_exposures_with_disproof(row):\n",
    "    audit_log = []\n",
    "    possible_categories = [\"Slight/None\", \"Moderate\", \"Persistent Systematic\", \"Heavy Amplification\"]\n",
    "    scores = {cat: 0 for cat in possible_categories}\n",
    "\n",
    "    # Convert exposure columns to numeric, handle non-numeric gracefully\n",
    "    exposure_cols = ['cash_long', 'cash_net', 'cash_short', 'stock_long', 'stock_net', 'stock_short',\n",
    "                    'bond_long', 'bond_net', 'bond_short', 'other_long', 'other_net', 'other_short']\n",
    "    for col in exposure_cols:\n",
    "        value = pd.to_numeric(row[col], errors='coerce')\n",
    "        row[col] = 0 if pd.isna(value) else value\n",
    "\n",
    "    # Calculate totals\n",
    "    long_total = row['cash_long'] + row['stock_long'] + row['bond_long'] + row['other_long']\n",
    "    short_total = row['cash_short'] + row['stock_short'] + row['bond_short'] + row['other_short']\n",
    "    other_total = row['other_long'] + row['other_short']\n",
    "    stock_long = row['stock_long']\n",
    "    cash_short = row['cash_short']\n",
    "\n",
    "    # Round totals to 4 decimal places for comparison\n",
    "    long_total_rounded = round(long_total, 4)\n",
    "    short_total_rounded = round(short_total, 4)\n",
    "    other_total_rounded = round(other_total, 4)\n",
    "\n",
    "    # Debug logging for exposure values\n",
    "    debug_msg = (f\"Exposure Values - long_total: {long_total}, long_total_rounded: {long_total_rounded}, \"\n",
    "                 f\"short_total: {short_total}, short_total_rounded: {short_total_rounded}, \"\n",
    "                 f\"other_total: {other_total}, other_total_rounded: {other_total_rounded}\")\n",
    "    audit_log.append(debug_msg)\n",
    "\n",
    "    # Define disproof keywords for each branch\n",
    "    disproof_keywords = {\n",
    "        \"Slight/None\": [\"derivatives\", \"swaps\", \"futures\", \"short\", \"hedge\", \"long-short\", \"inverse\", \"leveraged\", \"tail risk\", \"tail-risk\"],\n",
    "        \"Moderate\": [\"systematic\", \"trend-following\", \"2x\", \"3x\", \"market neutral\", \"quantitative hedging\", \"managed futures\",\n",
    "                     \"managed futures strategy\", \"trend strategy\", \"YieldMax\", \"tail risk\", \"tail-risk\"],\n",
    "        \"Persistent Systematic\": [\"2x\", \"3x\", \"-2x\", \"-3x\", \"uncapped accelerator\"],\n",
    "        \"Heavy Amplification\": [\"long-only\", \"no derivatives\", \"no short\"]\n",
    "    }\n",
    "\n",
    "    # Helper function to check disproof keywords with detailed logging\n",
    "    def has_disproof_keywords(category):\n",
    "        keywords = disproof_keywords.get(category, [])\n",
    "        keyword_score = 0\n",
    "        disproof_details = []\n",
    "        for field in ['ProductName', 'investment_strategy', 'FS_insight']:\n",
    "            if pd.notna(row[field]):\n",
    "                text = str(row[field]).lower()\n",
    "                found_keywords = [keyword for keyword in keywords if re.search(r'\\b' + re.escape(keyword.lower()) + r'\\b', text)]\n",
    "                if found_keywords:\n",
    "                    disproof_details.append(f\"Field '{field}' contains disproof keywords: {found_keywords}\")\n",
    "                    keyword_score += len(found_keywords)\n",
    "        if keyword_score > 0:\n",
    "            audit_log.append(f\"Disproof Keywords ({category}): {disproof_details}\")\n",
    "        else:\n",
    "            audit_log.append(f\"No Disproof Keywords Found ({category})\")\n",
    "        return keyword_score > 0\n",
    "\n",
    "    # Helper function to check disproof categories with detailed logging\n",
    "    def has_disproof_categories(category):\n",
    "        disproof_details = []\n",
    "        result = False\n",
    "        if category == \"Slight/None\":\n",
    "            yc_category = safe_lower(row.get('YC_Category_Name', ''))\n",
    "            cwa_category = safe_lower(row.get('CWA_Broad_Category_Name', ''))\n",
    "            global_category = safe_lower(row.get('YC_Global_Category_Name', ''))\n",
    "            disproof_cats = [\"derivative income\", \"long-short equity\", \"trading--leveraged equity\"]\n",
    "            if yc_category in disproof_cats:\n",
    "                disproof_details.append(f\"YC_Category_Name '{yc_category}' matches disproof categories: {disproof_cats}\")\n",
    "                result = True\n",
    "            disproof_cats = [\"alternative\", \"nontraditional\"]\n",
    "            if cwa_category in disproof_cats:\n",
    "                disproof_details.append(f\"CWA_Broad_Category_Name '{cwa_category}' matches disproof categories: {disproof_cats}\")\n",
    "                result = True\n",
    "            disproof_cats = [\"options trading\", \"long/short equity\"]\n",
    "            if global_category in disproof_cats:\n",
    "                disproof_details.append(f\"YC_Global_Category_Name '{global_category}' matches disproof categories: {disproof_cats}\")\n",
    "                result = True\n",
    "        elif category == \"Moderate\":\n",
    "            yc_category = safe_lower(row.get('YC_Category_Name', ''))\n",
    "            return_driver = safe_lower(row.get('return_driver', ''))\n",
    "            disproof_cats = [\"trading--leveraged equity\", \"market neutral\"]\n",
    "            if yc_category in disproof_cats:\n",
    "                disproof_details.append(f\"YC_Category_Name '{yc_category}' matches disproof categories: {disproof_cats}\")\n",
    "                result = True\n",
    "            if return_driver in [\"quant/systematic\"]:\n",
    "                disproof_details.append(f\"return_driver '{return_driver}' matches disproof categories: ['quant/systematic']\")\n",
    "                result = True\n",
    "        elif category == \"Persistent Systematic\":\n",
    "            yc_category = safe_lower(row.get('YC_Category_Name', ''))\n",
    "            product_name = safe_lower(row.get('ProductName', ''))\n",
    "            disproof_cats = [\"trading--leveraged equity\", \"trading--leveraged debt\"]\n",
    "            if yc_category in disproof_cats:\n",
    "                disproof_details.append(f\"YC_Category_Name '{yc_category}' matches disproof categories: {disproof_cats}\")\n",
    "                result = True\n",
    "            if \"leveraged\" in product_name:\n",
    "                disproof_details.append(f\"ProductName '{product_name}' contains 'leveraged'\")\n",
    "                result = True\n",
    "        if result:\n",
    "            audit_log.append(f\"Disproof Categories ({category}): {disproof_details}\")\n",
    "        else:\n",
    "            audit_log.append(f\"No Disproof Categories Found ({category})\")\n",
    "        return result\n",
    "\n",
    "    # Branch 1: Simple Exposure (Long-Only, No Shorts/Other)\n",
    "    if abs(short_total_rounded) < 1 and abs(other_total_rounded) < 1 and long_total_rounded <= 100.2:\n",
    "        audit_log.append(\"Branch 1 Simple Exposure: Effectively no shorts/other (<1%), long_total <= 100.2%\")\n",
    "        # Prove with fund family\n",
    "        if pd.notna(row['fund_family']) and \"return stacked\" in row['fund_family'].lower():\n",
    "            audit_log.append(\"Disproof: Fund family 'Return Stacked' suggests complexity, routing to next branch\")\n",
    "        elif has_disproof_keywords(\"Slight/None\") or has_disproof_categories(\"Slight/None\"):\n",
    "            audit_log.append(\"Disproof triggered, routing to next branch\")\n",
    "        else:\n",
    "            audit_log.append(\"No disproof triggered, classifying as Slight/None\")\n",
    "            return \"Slight/None\", \"Simple Exposure: No shorts/other (<1%), long_total <= 99.5%, passed disproof\"\n",
    "\n",
    "    # Branch 2: Moderate Complexity (Minimal Shorts/Other, Balanced Exposures)\n",
    "    if short_total_rounded <= 10 and other_total_rounded <= 10:\n",
    "        audit_log.append(\"Branch 2 Moderate Complexity: Minimal shorts/other (<=10%)\")\n",
    "        if has_disproof_keywords(\"Moderate\") or has_disproof_categories(\"Moderate\"):\n",
    "            audit_log.append(\"Disproof triggered, routing to next branch\")\n",
    "        else:\n",
    "            audit_log.append(\"No disproof triggered, classifying as Moderate\")\n",
    "            return \"Moderate\", \"Moderate Complexity: Minimal shorts/other (<=10%), passed disproof\"\n",
    "\n",
    "    # Branch 3: Persistent Systematic Complexity (Significant Shorts/Other)\n",
    "    if short_total_rounded <= 50 or other_total_rounded <= 50:\n",
    "        audit_log.append(\"Branch 3 Persistent Systematic Complexity: Shorts/other <=50%\")\n",
    "        excluded = []\n",
    "        for cat in [\"Slight/None\", \"Moderate\"]:\n",
    "            if cat in possible_categories:\n",
    "                possible_categories.remove(cat)\n",
    "                excluded.append(cat)\n",
    "        if excluded:\n",
    "            audit_log.append(f\"Excluded {excluded} due to shorts/other >10%\")\n",
    "        if has_disproof_keywords(\"Persistent Systematic\") or has_disproof_categories(\"Persistent Systematic\"):\n",
    "            audit_log.append(\"Disproof triggered, routing to next branch\")\n",
    "        else:\n",
    "            audit_log.append(\"No disproof triggered, classifying as Persistent Systematic\")\n",
    "            return \"Persistent Systematic\", \"Persistent Systematic Complexity: Significant shorts/other (<=50%), passed disproof\"\n",
    "\n",
    "    # Branch 4: Heavy Amplification Complexity (High Shorts/Other, Amplified Indicators)\n",
    "    audit_log.append(\"Branch 4 Heavy Amplification Complexity: Shorts/other >50%\")\n",
    "    excluded = []\n",
    "    for cat in [\"Slight/None\", \"Moderate\", \"Persistent Systematic\"]:\n",
    "        if cat in possible_categories:\n",
    "            possible_categories.remove(cat)\n",
    "            excluded.append(cat)\n",
    "    if excluded:\n",
    "        audit_log.append(f\"Excluded {excluded} due to shorts/other >50%\")\n",
    "    if has_disproof_keywords(\"Heavy Amplification\") or has_disproof_categories(\"Heavy Amplification\"):\n",
    "        audit_log.append(\"Disproof triggered, routing to alternative evaluation\")\n",
    "        return None, scores, audit_log\n",
    "    audit_log.append(\"No disproof triggered, classifying as Heavy Amplification\")\n",
    "    return \"Heavy Amplification\", \"Heavy Amplification Complexity: High shorts/other (>50%), passed disproof\"\n",
    "\n",
    "# Alternative Evaluation Method for Ambiguous Cases\n",
    "def alternative_evaluation(row, scores, audit_log):\n",
    "    possible_categories = [\"Slight/None\", \"Moderate\", \"Persistent Systematic\", \"Heavy Amplification\"]\n",
    "    audit_log.append(\"Entering Alternative Evaluation: No definitive classification from exposure tree\")\n",
    "\n",
    "    # Adjust scores based on exposure and category data\n",
    "    if row['inverse_fund'] in [True, 1]:\n",
    "        scores[\"Heavy Amplification\"] += 2\n",
    "        scores[\"Persistent Systematic\"] += 1\n",
    "        audit_log.append(\"Inverse fund flag True, boosting Heavy Amplification (+2) and Persistent Systematic (+1)\")\n",
    "\n",
    "    # Score based on categories\n",
    "    yc_category = safe_lower(row.get('YC_Category_Name', ''))\n",
    "    cwa_category = safe_lower(row.get('CWA_Broad_Category_Name', ''))\n",
    "    global_category = safe_lower(row.get('YC_Global_Category_Name', ''))\n",
    "    return_driver = safe_lower(row.get('return_driver', ''))\n",
    "\n",
    "    # Score Slight/None\n",
    "    if (yc_category in [\"government bond\", \"corporate bond\", \"municipal bond\"] or\n",
    "        cwa_category in [\"taxable fixed income\", \"municipal\"] or\n",
    "        return_driver in [\"index based\"]):\n",
    "        scores[\"Slight/None\"] += 2\n",
    "        audit_log.append(f\"Category scoring for Slight/None: Matched categories/return_driver, added +2\")\n",
    "\n",
    "    # Score Moderate\n",
    "    if (yc_category in [\"derivative income\", \"multisector bond\"] or\n",
    "        cwa_category in [\"bond strategy\", \"strategic\"] or\n",
    "        global_category in [\"flexible allocation\", \"us fixed income\"]):\n",
    "        scores[\"Moderate\"] += 2\n",
    "        audit_log.append(f\"Category scoring for Moderate: Matched categories/global categories, added +2\")\n",
    "\n",
    "    # Score Persistent Systematic\n",
    "    if (yc_category in [\"long-short equity\", \"equity hedged\"] or\n",
    "        cwa_category in [\"alternative\", \"nontraditional\"] or\n",
    "        global_category in [\"long/short equity\", \"multialternative\", \"options trading\"] or\n",
    "        return_driver in [\"quant/systematic\", \"active discretionary\"]):\n",
    "        scores[\"Persistent Systematic\"] += 2\n",
    "        audit_log.append(f\"Category scoring for Persistent Systematic: Matched categories/global/return_driver, added +2\")\n",
    "\n",
    "    # Score Heavy Amplification\n",
    "    if (yc_category in [\"trading--leveraged equity\", \"trading--leveraged debt\"] or\n",
    "        \"leveraged\" in safe_lower(row.get('ProductName', ''))):\n",
    "        scores[\"Heavy Amplification\"] += 2\n",
    "        audit_log.append(f\"Category scoring for Heavy Amplification: Matched leveraged categories, added +2\")\n",
    "\n",
    "    # Evaluate pairs of categories\n",
    "    audit_log.append(\"Alternative Evaluation: Evaluating pairs of categories\")\n",
    "    # Pair 1: Slight/None vs Moderate\n",
    "    pair_scores = {\"Slight/None\": scores[\"Slight/None\"], \"Moderate\": scores[\"Moderate\"]}\n",
    "    audit_log.append(f\"Pair 1 (Slight/None vs Moderate) scores: {pair_scores}\")\n",
    "    max_score = max(pair_scores.values())\n",
    "    top_pair = [cat for cat, score in pair_scores.items() if score == max_score]\n",
    "    if len(top_pair) == 1:\n",
    "        selected = top_pair[0]\n",
    "        audit_log.append(f\"Alternative Evaluation: Slight/None vs Moderate -> Selected {selected} with score {pair_scores[selected]}\")\n",
    "    else:\n",
    "        keyword_tie_scores = {\"Slight/None\": 0, \"Moderate\": 0}\n",
    "        for category in top_pair:\n",
    "            for field in ['ProductName', 'investment_strategy', 'FS_insight']:\n",
    "                keyword_tie_scores[category] += search_keywords(row[field], keyword_mappings[category])\n",
    "        audit_log.append(f\"Pair 1 tiebreaker keyword scores: {keyword_tie_scores}\")\n",
    "        max_keyword_score = max(keyword_tie_scores.values())\n",
    "        top_keyword_pair = [cat for cat, score in keyword_tie_scores.items() if score == max_keyword_score]\n",
    "        selected = top_keyword_pair[0] if len(top_keyword_pair) == 1 else min(top_pair, key=lambda x: [\"Slight/None\", \"Moderate\"].index(x))\n",
    "        audit_log.append(f\"Alternative Evaluation: Slight/None vs Moderate tiebreak -> Selected {selected}\")\n",
    "\n",
    "    # Double-check against next category\n",
    "    if selected == \"Slight/None\":\n",
    "        next_pair = {\"Slight/None\": scores[\"Slight/None\"], \"Moderate\": scores[\"Moderate\"]}\n",
    "        if scores[\"Moderate\"] >= scores[\"Slight/None\"]:\n",
    "            selected = \"Moderate\"\n",
    "            audit_log.append(f\"Double-check: Moderate score ({scores['Moderate']}) >= Slight/None ({scores['Slight/None']}), selecting Moderate\")\n",
    "    elif selected == \"Moderate\":\n",
    "        next_pair = {\"Moderate\": scores[\"Moderate\"], \"Persistent Systematic\": scores[\"Persistent Systematic\"]}\n",
    "        if scores[\"Persistent Systematic\"] >= scores[\"Moderate\"]:\n",
    "            selected = \"Persistent Systematic\"\n",
    "            audit_log.append(f\"Double-check: Persistent Systematic score ({scores['Persistent Systematic']}) >= Moderate ({scores['Moderate']}), selecting Persistent Systematic\")\n",
    "    elif selected == \"Persistent Systematic\":\n",
    "        next_pair = {\"Persistent Systematic\": scores[\"Persistent Systematic\"], \"Heavy Amplification\": scores[\"Heavy Amplification\"]}\n",
    "        if scores[\"Heavy Amplification\"] >= scores[\"Persistent Systematic\"]:\n",
    "            selected = \"Heavy Amplification\"\n",
    "            audit_log.append(f\"Double-check: Heavy Amplification score ({scores['Heavy Amplification']}) >= Persistent Systematic ({scores['Persistent Systematic']}), selecting Heavy Amplification\")\n",
    "\n",
    "    return selected, audit_log\n",
    "\n",
    "# Main classification function\n",
    "def classify_fund(row):\n",
    "    possible_categories = [\"Slight/None\", \"Moderate\", \"Persistent Systematic\", \"Heavy Amplification\"]\n",
    "    scores = {cat: 0 for cat in possible_categories}\n",
    "    audit_log = []\n",
    "\n",
    "    # Step 1: Override for Fund Family \"Return Stacked ETFs\"\n",
    "    if pd.notna(row['fund_family']) and \"return stacked etfs\" in row['fund_family'].lower():\n",
    "        audit_log.append(\"Override: Fund family 'Return Stacked ETFs' -> Persistent Systematic\")\n",
    "        return \"Persistent Systematic\", audit_log\n",
    "\n",
    "    # Step 2: Direct keyword mapping (immediate classification)\n",
    "    for category, keywords in direct_keyword_mappings.items():\n",
    "        for field in ['ProductName', 'investment_strategy', 'FS_insight']:\n",
    "            if pd.notna(row[field]):\n",
    "                match_count = search_keywords(row[field], keywords)\n",
    "                if match_count > 0:\n",
    "                    audit_log.append(f\"Direct keyword match for {category} in {field}: {match_count} keywords\")\n",
    "                    return category, audit_log\n",
    "\n",
    "    # Step 3: Direct category mapping (immediate classification)\n",
    "    for category, mappings in direct_category_mappings.items():\n",
    "        for db_field, values in mappings.items():\n",
    "            values_lower = [val.lower() for val in values]\n",
    "            field_value = safe_lower(row.get(db_field, ''))\n",
    "            if field_value in values_lower:\n",
    "                audit_log.append(f\"Direct category match for {category} in {db_field}: {field_value}\")\n",
    "                return category, audit_log\n",
    "\n",
    "    # Step 4: Apply Boolean exclusions\n",
    "    for categories, condition in boolean_exclusions.items():\n",
    "        if condition(row):\n",
    "            excluded = [cat for cat in possible_categories if cat in categories]\n",
    "            for cat in excluded:\n",
    "                possible_categories.remove(cat)\n",
    "            audit_log.append(f\"Excluded {excluded} due to Boolean flags\")\n",
    "            if len(possible_categories) == 1:\n",
    "                return possible_categories[0], audit_log\n",
    "\n",
    "    # Step 5: Exposure Decision Tree with Prove/Disprove\n",
    "    exposure_result = classify_by_exposures_with_disproof(row)\n",
    "    if isinstance(exposure_result, tuple) and len(exposure_result) == 2:\n",
    "        classification, reason = exposure_result\n",
    "        audit_log.append(f\"Exposure-based classification: {classification} - {reason}\")\n",
    "        return classification, audit_log\n",
    "    elif exposure_result[0] is None:\n",
    "        # No definitive classification, proceed to alternative evaluation\n",
    "        scores_update = exposure_result[1]\n",
    "        for msg in exposure_result[2]:\n",
    "            audit_log.append(msg)\n",
    "        for cat in scores_update:\n",
    "            scores[cat] += scores_update[cat]\n",
    "        classification, eval_log = alternative_evaluation(row, scores, audit_log)\n",
    "        for msg in eval_log:\n",
    "            audit_log.append(msg)\n",
    "        audit_log.append(f\"Alternative Evaluation: Final classification: {classification}\")\n",
    "        return classification, audit_log\n",
    "    else:\n",
    "        # Continue with scoring\n",
    "        possible_categories, scores_update, exposure_log = exposure_result\n",
    "        for msg in exposure_log:\n",
    "            audit_log.append(msg)\n",
    "        for cat in scores_update:\n",
    "            scores[cat] += scores_update[cat]\n",
    "\n",
    "    # Step 6: Final Scoring if No Immediate Classification\n",
    "    max_score = max(scores[cat] for cat in possible_categories)\n",
    "    top_categories = [cat for cat in possible_categories if scores[cat] == max_score]\n",
    "    if len(top_categories) == 1:\n",
    "        final_classification = top_categories[0]\n",
    "        audit_log.append(f\"Final classification: {final_classification} with score {max_score}\")\n",
    "    else:\n",
    "        keyword_tie_scores = {cat: 0 for cat in top_categories}\n",
    "        for category in top_categories:\n",
    "            for field in ['ProductName', 'investment_strategy', 'FS_insight']:\n",
    "                keyword_tie_scores[category] += search_keywords(row[field], keyword_mappings[category])\n",
    "        audit_log.append(f\"Tiebreaker keyword scores: {keyword_tie_scores}\")\n",
    "        max_keyword_score = max(keyword_tie_scores.values())\n",
    "        top_keyword_categories = [cat for cat, score in keyword_tie_scores.items() if score == max_keyword_score]\n",
    "        if len(top_keyword_categories) == 1:\n",
    "            final_classification = top_keyword_categories[0]\n",
    "            audit_log.append(f\"Tiebreaker used - Final classification: {final_classification} with tiebreaker keyword score {keyword_tie_scores[final_classification]}\")\n",
    "        else:\n",
    "            conservative_order = [\"Slight/None\", \"Moderate\", \"Persistent Systematic\", \"Heavy Amplification\"]\n",
    "            final_classification = min(top_keyword_categories, key=lambda x: conservative_order.index(x))\n",
    "            audit_log.append(f\"Secondary tiebreaker used - Final classification: {final_classification} (most conservative among {top_keyword_categories})\")\n",
    "\n",
    "    return final_classification, audit_log\n",
    "\n",
    "# Main script\n",
    "def main():\n",
    "    # Create database engine\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    # Query to join tables\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        f.SymbolCUSIP, f.ProductName, f.fund_family, f.investment_strategy, f.FS_insight,\n",
    "        f.index_fund, f.inverse_fund, f.leveraged_fund, f.synthetic_replication_fund,\n",
    "        f.fund_of_funds, f.ycharts_url, f.currency_hedged_fund,\n",
    "        f.cash_long, f.cash_net, f.cash_short, f.stock_long, f.stock_net, f.stock_short,\n",
    "        f.bond_long, f.bond_net, f.bond_short, f.other_long, f.other_net, f.other_short,\n",
    "        f.return_driver, f.YC_BM_Symbol,\n",
    "        cwa.CWA_Broad_Category_Name,\n",
    "        yc.Category_Name AS YC_Category_Name,\n",
    "        ycg.Global_Category_Name,\n",
    "        ycba.YC_Broad_Asset_Class_Name\n",
    "    FROM Funds_to_Screen f\n",
    "    LEFT JOIN CWA_Broad_Category_List cwa ON f.CWA_Broad_Category_ID = cwa.ID\n",
    "    LEFT JOIN YC_Category_List yc ON f.YC_Category_ID = yc.ID\n",
    "    LEFT JOIN YC_Global_Category_List ycg ON f.YC_Global_Category_ID = ycg.ID\n",
    "    LEFT JOIN YC_Broad_Asset_Class_List ycba ON f.YC_Broad_Asset_Class_ID = ycba.ID\n",
    "    \"\"\"\n",
    "\n",
    "    # Load data into DataFrame\n",
    "    df = pd.read_sql(query, engine)\n",
    "\n",
    "    # Apply classification\n",
    "    results = []\n",
    "    for idx, row in df.iterrows():\n",
    "        classification, audit_log = classify_fund(row)\n",
    "        result_row = row.copy()\n",
    "        result_row['Final_Classification'] = classification\n",
    "        result_row['Audit_Log'] = \"; \".join(audit_log)\n",
    "        results.append(result_row)\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    result_df = pd.DataFrame(results)\n",
    "\n",
    "    # Ensure desired column order\n",
    "    output_columns = ['SymbolCUSIP', 'ProductName', 'fund_family', 'Final_Classification', 'ycharts_url'] + \\\n",
    "                     [col for col in result_df.columns if col not in ['SymbolCUSIP', 'ProductName', 'fund_family', 'Final_Classification', 'ycharts_url']]\n",
    "\n",
    "    result_df = result_df[output_columns]\n",
    "\n",
    "    # Export to Excel\n",
    "    output_path = r\"C:\\Users\\JulianHeron\\Software Projects\\Risk_Overlays_V4.xlsx\"\n",
    "    result_df.to_excel(output_path, index=False)\n",
    "    print(f\"Results exported to {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a6e8bcb1-8693-47e3-8bb3-f7090fbfa53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results exported to C:\\Users\\JulianHeron\\Software Projects\\Risk_Overlays_V4.1.xlsx\n"
     ]
    }
   ],
   "source": [
    "# V4.1 with Scale Fix in Logs (percentages mean 1 = 1%, 10 = 10%, etc.)\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Connection string\n",
    "connection_string = (\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/\"\n",
    "    \"CWA_Fund_Database?driver=ODBC+Driver+18+for+SQL+Server\"\n",
    "    \"&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "# Helper function to safely convert to lowercase string (moved to top level)\n",
    "def safe_lower(value):\n",
    "    return value.lower() if isinstance(value, str) else \"\"\n",
    "\n",
    "# Define keyword mappings for general scoring\n",
    "keyword_mappings = {\n",
    "    \"Slight/None\": [\n",
    "        \"long-only\", \"no derivatives\", \"no hedging\", \"no leverage\", \"no options\", \"no short\",\n",
    "        \"position adjustment\", \"occasional hedging\", \"covered call\", \"put-write\", \"light hedge\",\n",
    "        \"may include options\", \"limited use of derivatives\", \"for risk management purposes\",\n",
    "        \"minor hedging\", \"occasional short positions\", \"overwrite\", \"investment grade\", \"core\"\n",
    "    ],\n",
    "    \"Moderate\": [\n",
    "        \"hedged\", \"currency hedge\", \"protective put\", \"partial hedge\", \"hedged equity\",\n",
    "        \"covered call\", \"convexity option overlay\", \"option overlay\", \"put/spread collar\",\n",
    "        \"forward agreement\", \"enhanced index strategy\", \"BuyWrite\", \"Buy-Write\", \"buy write\",\n",
    "        \"option spread\", \"volatility hedge\", \"put options\", \"enhance\", \"options-based income\",\n",
    "        \"ELN\", \"premium income\", \"call option\", \"FLEX options\", \"option premium\", \"write calls\",\n",
    "        \"sell calls\", \"protective puts\", \"equity-linked notes\", \"structured notes\",\n",
    "        \"risk mitigation\", \"downside protection\", \"limited hedging\", \"multi-asset\"\n",
    "    ],\n",
    "    \"Persistent Systematic\": [\n",
    "        \"tail-risk\", \"trend-following\", \"systematic hedging\", \"overlay\", \"CTA\", \"managed futures\",\n",
    "        \"defined outcome\", \"long-short\", \"market neutral\", \"systematic strategy\", \"return stacking\",\n",
    "        \"option writing\", \"straddle\", \"derivative income\", \"futures contracts\", \"swap contract\",\n",
    "        \"forward agreement\", \"enhanced index strategy\", \"volatility hedge\", \"put options\",\n",
    "        \"options-based income\", \"ELN\", \"option premium\", \"swap\", \"forward\", \"futures\", \"future\",\n",
    "        \"VIX\", \"managed futures strategy\", \"trend strategy\", \"quantitative hedging\",\n",
    "        \"systematic options\", \"options overlay strategy\", \"futures overlay\", \"swaps-based\",\n",
    "        \"multi-asset\", \"Flex Options\", \"Flexible Exchange Options\", \"YieldMax\", \"buffer\"\n",
    "    ],\n",
    "    \"Heavy Amplification\": [\n",
    "        \"2x\", \"3x\", \"Uncapped Accelerator\", \"-2x\", \"-3x\", \"YieldMax\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Direct mapping keywords (often in ProductName)\n",
    "direct_keyword_mappings = {\n",
    "    \"Persistent Systematic\": [\"Market Neutral\", \"managed futures\", \"Premia\", \"Return Stacked ETFs\"]\n",
    "}\n",
    "\n",
    "# Direct mapping categories\n",
    "direct_category_mappings = {\n",
    "    \"Persistent Systematic\": {\n",
    "        \"YC_Category\": [\"Defined Outcome\"],\n",
    "        \"CWA_Broad_Category\": [\"Defined Outcome\"],\n",
    "        \"YC_Global_Category\": [\"market neutral\"]\n",
    "    },\n",
    "    \"Heavy Amplification\": {\n",
    "        \"YC_Category\": [\n",
    "            \"Trading--Leveraged Equity\", \"Trading--Leveraged Debt\", \"Trading--Leveraged Commodities\"\n",
    "        ],\n",
    "        \"CWA_Broad_Category\": [\"Single Stock\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Helper category mappings (narrow possibilities)\n",
    "helper_category_mappings = {\n",
    "    (\"Persistent Systematic\", \"Heavy Amplification\"): {\n",
    "        \"YC_Category\": [\n",
    "            \"Trading--Inverse Commodities\", \"Trading--Inverse Debt\", \"Trading--Inverse Equity\",\n",
    "            \"Trading--Miscellaneous\"\n",
    "        ],\n",
    "        \"CWA_Broad_Category\": [\"Trading/Tactical\"],\n",
    "        \"YC_Global_Category\": [\"Trading Tools\"]\n",
    "    },\n",
    "    (\"Persistent Systematic\", \"Moderate\"): {\n",
    "        \"YC_Global_Category\": [\"Multialternative\", \"Long/Short Equity\"],\n",
    "        \"YC_Category\": [\"Equity Hedged\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Weak helper category mappings (may or may not have overlay)\n",
    "weak_helper_category_mappings = {\n",
    "    (\"Slight/None\", \"Moderate\"): {\n",
    "        \"YC_Global_Category\": [\"Flexible Allocation\", \"Alternative Miscellaneous\"],\n",
    "        \"return_driver\": [\"Index Based\", \"Factor/Smart Beta\"]\n",
    "    },\n",
    "    (\"Slight/None\", \"Moderate\", \"Persistent Systematic\"): {\n",
    "        \"YC_Category\": [\"Relative Value Arbitrage\"]\n",
    "    },\n",
    "    (\"Heavy Amplification\", \"Persistent Systematic\", \"Moderate\", \"Slight/None\"): {\n",
    "        \"return_driver\": [\"Quant/Systematic\"]\n",
    "    },\n",
    "    (\"Persistent Systematic\", \"Moderate\", \"Slight/None\"): {\n",
    "        \"return_driver\": [\"Active Discretionary\", \"Multi-Strategy\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Boolean flags to remove categories\n",
    "boolean_exclusions = {\n",
    "    (\"Slight/None\", \"Moderate\"): lambda row: row['leveraged_fund'] in [True, 1]\n",
    "    or row['synthetic_replication_fund'] in [True, 1]\n",
    "    or row['inverse_fund'] in [True, 1]\n",
    "}\n",
    "\n",
    "# Function to search text for keywords\n",
    "def search_keywords(text, keywords):\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    text = str(text).lower()\n",
    "    return sum(1 for keyword in keywords if re.search(r'\\b' + re.escape(keyword.lower()) + r'\\b', text))\n",
    "\n",
    "# Decision Tree for Exposure Classification with Prove/Disprove\n",
    "def classify_by_exposures_with_disproof(row):\n",
    "    audit_log = []\n",
    "    possible_categories = [\"Slight/None\", \"Moderate\", \"Persistent Systematic\", \"Heavy Amplification\"]\n",
    "\n",
    "    # Convert exposure columns to numeric, handle non-numeric gracefully\n",
    "    exposure_cols = [\n",
    "        'cash_long', 'cash_net', 'cash_short',\n",
    "        'stock_long', 'stock_net', 'stock_short',\n",
    "        'bond_long', 'bond_net', 'bond_short',\n",
    "        'other_long', 'other_net', 'other_short'\n",
    "    ]\n",
    "    for col in exposure_cols:\n",
    "        value = pd.to_numeric(row[col], errors='coerce')\n",
    "        row[col] = 0 if pd.isna(value) else value\n",
    "\n",
    "    # Calculate totals (all in percentage points: e.g., 1 = 1%, 10 = 10%, etc.)\n",
    "    long_total = row['cash_long'] + row['stock_long'] + row['bond_long'] + row['other_long']\n",
    "    short_total = row['cash_short'] + row['stock_short'] + row['bond_short'] + row['other_short']\n",
    "    other_total = row['other_long'] + row['other_short']\n",
    "\n",
    "    # Round totals to 4 decimal places\n",
    "    long_total_rounded = round(long_total, 4)\n",
    "    short_total_rounded = round(short_total, 4)\n",
    "    other_total_rounded = round(other_total, 4)\n",
    "\n",
    "    # Debug logging for exposure values\n",
    "    debug_msg = (\n",
    "        f\"Exposure Values - long_total: {long_total}, short_total: {short_total}, other_total: {other_total} \"\n",
    "        f\"(rounded => {long_total_rounded}, {short_total_rounded}, {other_total_rounded})\"\n",
    "    )\n",
    "    audit_log.append(debug_msg)\n",
    "\n",
    "    # Define disproof keywords for each branch\n",
    "    disproof_keywords = {\n",
    "        \"Slight/None\": [\n",
    "            \"derivatives\", \"swaps\", \"futures\", \"short\", \"hedge\", \"long-short\", \"inverse\", \n",
    "            \"leveraged\", \"tail risk\", \"tail-risk\"\n",
    "        ],\n",
    "        \"Moderate\": [\n",
    "            \"systematic\", \"trend-following\", \"2x\", \"3x\", \"market neutral\", \"quantitative hedging\",\n",
    "            \"managed futures\", \"managed futures strategy\", \"trend strategy\", \"YieldMax\", \"tail risk\", \"tail-risk\"\n",
    "        ],\n",
    "        \"Persistent Systematic\": [\"2x\", \"3x\", \"-2x\", \"-3x\", \"uncapped accelerator\"],\n",
    "        \"Heavy Amplification\": [\"long-only\", \"no derivatives\", \"no short\"]\n",
    "    }\n",
    "\n",
    "    # Helper function to check disproof keywords with detailed logging\n",
    "    def has_disproof_keywords(category):\n",
    "        keywords = disproof_keywords.get(category, [])\n",
    "        keyword_score = 0\n",
    "        disproof_details = []\n",
    "        for field in ['ProductName', 'investment_strategy', 'FS_insight']:\n",
    "            if pd.notna(row[field]):\n",
    "                text = str(row[field]).lower()\n",
    "                found_keywords = [\n",
    "                    keyword for keyword in keywords\n",
    "                    if re.search(r'\\b' + re.escape(keyword.lower()) + r'\\b', text)\n",
    "                ]\n",
    "                if found_keywords:\n",
    "                    disproof_details.append(f\"Field '{field}' contains disproof keywords: {found_keywords}\")\n",
    "                    keyword_score += len(found_keywords)\n",
    "        if keyword_score > 0:\n",
    "            audit_log.append(f\"Disproof Keywords ({category}): {disproof_details}\")\n",
    "        else:\n",
    "            audit_log.append(f\"No Disproof Keywords Found ({category})\")\n",
    "        return keyword_score > 0\n",
    "\n",
    "    # Helper function to check disproof categories with detailed logging\n",
    "    def has_disproof_categories(category):\n",
    "        disproof_details = []\n",
    "        result = False\n",
    "        if category == \"Slight/None\":\n",
    "            yc_category = safe_lower(row.get('YC_Category_Name', ''))\n",
    "            cwa_category = safe_lower(row.get('CWA_Broad_Category_Name', ''))\n",
    "            global_category = safe_lower(row.get('YC_Global_Category_Name', ''))\n",
    "            disproof_cats = [\"derivative income\", \"long-short equity\", \"trading--leveraged equity\"]\n",
    "            if yc_category in disproof_cats:\n",
    "                disproof_details.append(\n",
    "                    f\"YC_Category_Name '{yc_category}' matches disproof categories: {disproof_cats}\"\n",
    "                )\n",
    "                result = True\n",
    "            disproof_cats = [\"alternative\", \"nontraditional\"]\n",
    "            if cwa_category in disproof_cats:\n",
    "                disproof_details.append(\n",
    "                    f\"CWA_Broad_Category_Name '{cwa_category}' matches disproof categories: {disproof_cats}\"\n",
    "                )\n",
    "                result = True\n",
    "            disproof_cats = [\"options trading\", \"long/short equity\"]\n",
    "            if global_category in disproof_cats:\n",
    "                disproof_details.append(\n",
    "                    f\"YC_Global_Category_Name '{global_category}' matches disproof categories: {disproof_cats}\"\n",
    "                )\n",
    "                result = True\n",
    "        elif category == \"Moderate\":\n",
    "            yc_category = safe_lower(row.get('YC_Category_Name', ''))\n",
    "            return_driver = safe_lower(row.get('return_driver', ''))\n",
    "            disproof_cats = [\"trading--leveraged equity\", \"market neutral\"]\n",
    "            if yc_category in disproof_cats:\n",
    "                disproof_details.append(\n",
    "                    f\"YC_Category_Name '{yc_category}' matches disproof categories: {disproof_cats}\"\n",
    "                )\n",
    "                result = True\n",
    "            if return_driver in [\"quant/systematic\"]:\n",
    "                disproof_details.append(\n",
    "                    f\"return_driver '{return_driver}' matches disproof categories: ['quant/systematic']\"\n",
    "                )\n",
    "                result = True\n",
    "        elif category == \"Persistent Systematic\":\n",
    "            yc_category = safe_lower(row.get('YC_Category_Name', ''))\n",
    "            product_name = safe_lower(row.get('ProductName', ''))\n",
    "            disproof_cats = [\"trading--leveraged equity\", \"trading--leveraged debt\"]\n",
    "            if yc_category in disproof_cats:\n",
    "                disproof_details.append(\n",
    "                    f\"YC_Category_Name '{yc_category}' matches disproof categories: {disproof_cats}\"\n",
    "                )\n",
    "                result = True\n",
    "            if \"leveraged\" in product_name:\n",
    "                disproof_details.append(f\"ProductName '{product_name}' contains 'leveraged'\")\n",
    "                result = True\n",
    "        if result:\n",
    "            audit_log.append(f\"Disproof Categories ({category}): {disproof_details}\")\n",
    "        else:\n",
    "            audit_log.append(f\"No Disproof Categories Found ({category})\")\n",
    "        return result\n",
    "\n",
    "    # Branch 1: Simple Exposure (Long-Only, No Shorts/Other)\n",
    "    #\n",
    "    # Here, short_total_rounded < 1 means <1% short exposure,\n",
    "    # and long_total_rounded <= 100.2 means up to ~100% long (with small rounding margin).\n",
    "    #\n",
    "    if abs(short_total_rounded) < 1 and abs(other_total_rounded) < 1 and long_total_rounded <= 100.2:\n",
    "        audit_log.append(\n",
    "            \"Branch 1 Simple Exposure: Effectively no shorts/other (<1%), long_total <= 100.2%\"\n",
    "        )\n",
    "        # Prove with fund family\n",
    "        if pd.notna(row['fund_family']) and \"return stacked\" in row['fund_family'].lower():\n",
    "            audit_log.append(\"Disproof: Fund family 'Return Stacked' suggests complexity, routing to next branch\")\n",
    "        elif has_disproof_keywords(\"Slight/None\") or has_disproof_categories(\"Slight/None\"):\n",
    "            audit_log.append(\"Disproof triggered, routing to next branch\")\n",
    "        else:\n",
    "            audit_log.append(\"No disproof triggered, classifying as Slight/None\")\n",
    "            return (\n",
    "                \"Slight/None\",\n",
    "                \"Simple Exposure: no shorts/other (<1%), long_total <= 100.2%, passed disproof\"\n",
    "            )\n",
    "\n",
    "    # Branch 2: Moderate Complexity (Minimal Shorts/Other)\n",
    "    #\n",
    "    # short_total_rounded <= 10 means <=10% short exposure.\n",
    "    #\n",
    "    if short_total_rounded <= 10 and other_total_rounded <= 10:\n",
    "        audit_log.append(\"Branch 2 Moderate Complexity: Minimal shorts/other (<=10%)\")\n",
    "        if has_disproof_keywords(\"Moderate\") or has_disproof_categories(\"Moderate\"):\n",
    "            audit_log.append(\"Disproof triggered, routing to next branch\")\n",
    "        else:\n",
    "            audit_log.append(\"No disproof triggered, classifying as Moderate\")\n",
    "            return (\n",
    "                \"Moderate\",\n",
    "                \"Moderate Complexity: Minimal shorts/other (<=10%), passed disproof\"\n",
    "            )\n",
    "\n",
    "    # Branch 3: Persistent Systematic Complexity (Significant Shorts/Other)\n",
    "    #\n",
    "    # short_total_rounded <= 50 means <=50% short exposure, etc.\n",
    "    #\n",
    "    if short_total_rounded <= 50 or other_total_rounded <= 50:\n",
    "        audit_log.append(\"Branch 3 Persistent Systematic Complexity: Shorts/other <=50%\")\n",
    "        excluded = []\n",
    "        for cat in [\"Slight/None\", \"Moderate\"]:\n",
    "            if cat in possible_categories:\n",
    "                possible_categories.remove(cat)\n",
    "                excluded.append(cat)\n",
    "        if excluded:\n",
    "            audit_log.append(f\"Excluded {excluded} due to shorts/other >10%\")\n",
    "        if has_disproof_keywords(\"Persistent Systematic\") or has_disproof_categories(\"Persistent Systematic\"):\n",
    "            audit_log.append(\"Disproof triggered, routing to next branch\")\n",
    "        else:\n",
    "            audit_log.append(\"No disproof triggered, classifying as Persistent Systematic\")\n",
    "            return (\n",
    "                \"Persistent Systematic\",\n",
    "                \"Persistent Systematic Complexity: Significant shorts/other (<=50%), passed disproof\"\n",
    "            )\n",
    "\n",
    "    # Branch 4: Heavy Amplification Complexity (High Shorts/Other, Amplified Indicators)\n",
    "    audit_log.append(\"Branch 4 Heavy Amplification Complexity: Shorts/other >50%\")\n",
    "    excluded = []\n",
    "    for cat in [\"Slight/None\", \"Moderate\", \"Persistent Systematic\"]:\n",
    "        if cat in possible_categories:\n",
    "            possible_categories.remove(cat)\n",
    "            excluded.append(cat)\n",
    "    if excluded:\n",
    "        audit_log.append(f\"Excluded {excluded} due to shorts/other >50%\")\n",
    "    if has_disproof_keywords(\"Heavy Amplification\") or has_disproof_categories(\"Heavy Amplification\"):\n",
    "        audit_log.append(\"Disproof triggered, routing to alternative evaluation\")\n",
    "        return None, {}, audit_log\n",
    "    audit_log.append(\"No disproof triggered, classifying as Heavy Amplification\")\n",
    "    return (\n",
    "        \"Heavy Amplification\",\n",
    "        \"Heavy Amplification Complexity: High shorts/other (>50%), passed disproof\"\n",
    "    )\n",
    "\n",
    "# Alternative Evaluation Method for Ambiguous Cases\n",
    "def alternative_evaluation(row, scores, audit_log):\n",
    "    possible_categories = [\"Slight/None\", \"Moderate\", \"Persistent Systematic\", \"Heavy Amplification\"]\n",
    "    audit_log.append(\"Entering Alternative Evaluation: No definitive classification from exposure tree\")\n",
    "\n",
    "    # Adjust scores based on exposure and category data\n",
    "    if row['inverse_fund'] in [True, 1]:\n",
    "        scores[\"Heavy Amplification\"] += 2\n",
    "        scores[\"Persistent Systematic\"] += 1\n",
    "        audit_log.append(\"Inverse fund flag True, boosting Heavy Amplification (+2) and Persistent Systematic (+1)\")\n",
    "\n",
    "    # Score based on categories\n",
    "    yc_category = safe_lower(row.get('YC_Category_Name', ''))\n",
    "    cwa_category = safe_lower(row.get('CWA_Broad_Category_Name', ''))\n",
    "    global_category = safe_lower(row.get('YC_Global_Category_Name', ''))\n",
    "    return_driver = safe_lower(row.get('return_driver', ''))\n",
    "\n",
    "    # Score Slight/None\n",
    "    if (yc_category in [\"government bond\", \"corporate bond\", \"municipal bond\"]\n",
    "        or cwa_category in [\"taxable fixed income\", \"municipal\"]\n",
    "        or return_driver in [\"index based\"]):\n",
    "        scores[\"Slight/None\"] += 2\n",
    "        audit_log.append(\"Category scoring for Slight/None: Matched categories/return_driver, +2\")\n",
    "\n",
    "    # Score Moderate\n",
    "    if (yc_category in [\"derivative income\", \"multisector bond\"]\n",
    "        or cwa_category in [\"bond strategy\", \"strategic\"]\n",
    "        or global_category in [\"flexible allocation\", \"us fixed income\"]):\n",
    "        scores[\"Moderate\"] += 2\n",
    "        audit_log.append(\"Category scoring for Moderate: Matched categories/global categories, +2\")\n",
    "\n",
    "    # Score Persistent Systematic\n",
    "    if (yc_category in [\"long-short equity\", \"equity hedged\"]\n",
    "        or cwa_category in [\"alternative\", \"nontraditional\"]\n",
    "        or global_category in [\"long/short equity\", \"multialternative\", \"options trading\"]\n",
    "        or return_driver in [\"quant/systematic\", \"active discretionary\"]):\n",
    "        scores[\"Persistent Systematic\"] += 2\n",
    "        audit_log.append(\"Category scoring for Persistent Systematic: +2\")\n",
    "\n",
    "    # Score Heavy Amplification\n",
    "    if (yc_category in [\"trading--leveraged equity\", \"trading--leveraged debt\"]\n",
    "        or \"leveraged\" in safe_lower(row.get('ProductName', ''))):\n",
    "        scores[\"Heavy Amplification\"] += 2\n",
    "        audit_log.append(\"Category scoring for Heavy Amplification: +2\")\n",
    "\n",
    "    # Evaluate pairs of categories\n",
    "    audit_log.append(\"Alternative Evaluation: Evaluating pairs of categories\")\n",
    "\n",
    "    # Pair 1: Slight/None vs Moderate\n",
    "    pair_scores = {\"Slight/None\": scores[\"Slight/None\"], \"Moderate\": scores[\"Moderate\"]}\n",
    "    audit_log.append(f\"Pair 1 (Slight/None vs Moderate) scores: {pair_scores}\")\n",
    "    max_score = max(pair_scores.values())\n",
    "    top_pair = [cat for cat, sc in pair_scores.items() if sc == max_score]\n",
    "    if len(top_pair) == 1:\n",
    "        selected = top_pair[0]\n",
    "        audit_log.append(f\"Alternative Evaluation: Slight/None vs Moderate -> Selected {selected}\")\n",
    "    else:\n",
    "        keyword_tie_scores = {\"Slight/None\": 0, \"Moderate\": 0}\n",
    "        for category in top_pair:\n",
    "            for field in ['ProductName', 'investment_strategy', 'FS_insight']:\n",
    "                keyword_tie_scores[category] += search_keywords(row[field], keyword_mappings[category])\n",
    "        audit_log.append(f\"Pair 1 tiebreaker keyword scores: {keyword_tie_scores}\")\n",
    "        max_keyword_score = max(keyword_tie_scores.values())\n",
    "        top_keyword_pair = [cat for cat, score in keyword_tie_scores.items() if score == max_keyword_score]\n",
    "        if len(top_keyword_pair) == 1:\n",
    "            selected = top_keyword_pair[0]\n",
    "            audit_log.append(f\"Pair 1 tiebreak -> Selected {selected}\")\n",
    "        else:\n",
    "            # fallback to most conservative (Slight/None < Moderate)\n",
    "            conservative_order = [\"Slight/None\", \"Moderate\"]\n",
    "            selected = min(top_keyword_pair, key=lambda x: conservative_order.index(x))\n",
    "            audit_log.append(f\"Secondary tiebreak -> Selected {selected}\")\n",
    "\n",
    "    # Double-check next category if necessary\n",
    "    if selected == \"Slight/None\":\n",
    "        if scores[\"Moderate\"] >= scores[\"Slight/None\"]:\n",
    "            selected = \"Moderate\"\n",
    "            audit_log.append(\n",
    "                f\"Double-check: Moderate score ({scores['Moderate']}) >= Slight/None \"\n",
    "                f\"({scores['Slight/None']}), selecting Moderate\"\n",
    "            )\n",
    "    elif selected == \"Moderate\":\n",
    "        if scores[\"Persistent Systematic\"] >= scores[\"Moderate\"]:\n",
    "            selected = \"Persistent Systematic\"\n",
    "            audit_log.append(\n",
    "                f\"Double-check: Persistent Systematic score ({scores['Persistent Systematic']}) >= Moderate \"\n",
    "                f\"({scores['Moderate']}), selecting Persistent Systematic\"\n",
    "            )\n",
    "    elif selected == \"Persistent Systematic\":\n",
    "        if scores[\"Heavy Amplification\"] >= scores[\"Persistent Systematic\"]:\n",
    "            selected = \"Heavy Amplification\"\n",
    "            audit_log.append(\n",
    "                f\"Double-check: Heavy Amplification score ({scores['Heavy Amplification']}) >= Persistent \"\n",
    "                f\"Systematic ({scores['Persistent Systematic']}), selecting Heavy Amplification\"\n",
    "            )\n",
    "\n",
    "    return selected, audit_log\n",
    "\n",
    "# Main classification function\n",
    "def classify_fund(row):\n",
    "    possible_categories = [\"Slight/None\", \"Moderate\", \"Persistent Systematic\", \"Heavy Amplification\"]\n",
    "    scores = {cat: 0 for cat in possible_categories}\n",
    "    audit_log = []\n",
    "\n",
    "    # Step 1: Override for Fund Family \"Return Stacked ETFs\"\n",
    "    if pd.notna(row['fund_family']) and \"return stacked etfs\" in row['fund_family'].lower():\n",
    "        audit_log.append(\"Override: Fund family 'Return Stacked ETFs' -> Persistent Systematic\")\n",
    "        return \"Persistent Systematic\", audit_log\n",
    "\n",
    "    # Step 2: Direct keyword mapping (immediate classification)\n",
    "    for category, keywords in direct_keyword_mappings.items():\n",
    "        for field in ['ProductName', 'investment_strategy', 'FS_insight']:\n",
    "            if pd.notna(row[field]):\n",
    "                match_count = search_keywords(row[field], keywords)\n",
    "                if match_count > 0:\n",
    "                    audit_log.append(f\"Direct keyword match for {category} in {field}: {match_count} keywords\")\n",
    "                    return category, audit_log\n",
    "\n",
    "    # Step 3: Direct category mapping (immediate classification)\n",
    "    for category, mappings in direct_category_mappings.items():\n",
    "        for db_field, values in mappings.items():\n",
    "            values_lower = [val.lower() for val in values]\n",
    "            field_value = safe_lower(row.get(db_field, ''))\n",
    "            if field_value in values_lower:\n",
    "                audit_log.append(f\"Direct category match for {category} in {db_field}: {field_value}\")\n",
    "                return category, audit_log\n",
    "\n",
    "    # Step 4: Apply Boolean exclusions\n",
    "    for categories, condition in boolean_exclusions.items():\n",
    "        if condition(row):\n",
    "            excluded = [cat for cat in possible_categories if cat in categories]\n",
    "            for cat in excluded:\n",
    "                possible_categories.remove(cat)\n",
    "            audit_log.append(f\"Excluded {excluded} due to Boolean flags\")\n",
    "            if len(possible_categories) == 1:\n",
    "                return possible_categories[0], audit_log\n",
    "\n",
    "    # Step 5: Exposure Decision Tree with Prove/Disprove\n",
    "    exposure_result = classify_by_exposures_with_disproof(row)\n",
    "    # If we get a two-element tuple => we have classification + reason\n",
    "    if isinstance(exposure_result, tuple) and len(exposure_result) == 2:\n",
    "        classification, reason = exposure_result\n",
    "        audit_log.append(f\"Exposure-based classification: {classification} - {reason}\")\n",
    "        return classification, audit_log\n",
    "    # If we get None => no classification, let's do alternative\n",
    "    elif exposure_result[0] is None:\n",
    "        # exposure_result => (None, scores_dict, audit_log_list)\n",
    "        scores_update = exposure_result[1]\n",
    "        for msg in exposure_result[2]:\n",
    "            audit_log.append(msg)\n",
    "        for cat in scores_update:\n",
    "            scores[cat] += scores_update[cat]\n",
    "        classification, eval_log = alternative_evaluation(row, scores, audit_log)\n",
    "        for msg in eval_log:\n",
    "            audit_log.append(msg)\n",
    "        audit_log.append(f\"Alternative Evaluation: Final classification: {classification}\")\n",
    "        return classification, audit_log\n",
    "    else:\n",
    "        # Possibly we get (possible_categories, scores_update, exposure_log)\n",
    "        # but we've now standardized the function to return classification or None\n",
    "        # We'll keep this in case the structure changes\n",
    "        possible_categories, scores_update, exposure_log = exposure_result\n",
    "        for msg in exposure_log:\n",
    "            audit_log.append(msg)\n",
    "        for cat in scores_update:\n",
    "            scores[cat] += scores_update[cat]\n",
    "\n",
    "    # Step 6: Final Scoring if No Immediate Classification\n",
    "    max_score = max(scores[cat] for cat in possible_categories)\n",
    "    top_categories = [cat for cat in possible_categories if scores[cat] == max_score]\n",
    "    if len(top_categories) == 1:\n",
    "        final_classification = top_categories[0]\n",
    "        audit_log.append(f\"Final classification: {final_classification} with score {max_score}\")\n",
    "    else:\n",
    "        keyword_tie_scores = {cat: 0 for cat in top_categories}\n",
    "        for category in top_categories:\n",
    "            for field in ['ProductName', 'investment_strategy', 'FS_insight']:\n",
    "                keyword_tie_scores[category] += search_keywords(row[field], keyword_mappings[category])\n",
    "        audit_log.append(f\"Tiebreaker keyword scores: {keyword_tie_scores}\")\n",
    "        max_keyword_score = max(keyword_tie_scores.values())\n",
    "        top_keyword_categories = [cat for cat, score in keyword_tie_scores.items() if score == max_keyword_score]\n",
    "        if len(top_keyword_categories) == 1:\n",
    "            final_classification = top_keyword_categories[0]\n",
    "            audit_log.append(\n",
    "                f\"Tiebreaker used - Final classification: {final_classification} with tiebreaker keyword score \"\n",
    "                f\"{keyword_tie_scores[final_classification]}\"\n",
    "            )\n",
    "        else:\n",
    "            # fallback to conservative ordering\n",
    "            conservative_order = [\"Slight/None\", \"Moderate\", \"Persistent Systematic\", \"Heavy Amplification\"]\n",
    "            final_classification = min(\n",
    "                top_keyword_categories,\n",
    "                key=lambda x: conservative_order.index(x)\n",
    "            )\n",
    "            audit_log.append(\n",
    "                f\"Secondary tiebreaker used - Final classification: {final_classification} \"\n",
    "                f\"(most conservative among {top_keyword_categories})\"\n",
    "            )\n",
    "\n",
    "    return final_classification, audit_log\n",
    "\n",
    "# Main script\n",
    "def main():\n",
    "    # Create database engine\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    # Query to join tables\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        f.SymbolCUSIP, f.ProductName, f.fund_family, f.investment_strategy, f.FS_insight,\n",
    "        f.index_fund, f.inverse_fund, f.leveraged_fund, f.synthetic_replication_fund,\n",
    "        f.fund_of_funds, f.ycharts_url, f.currency_hedged_fund,\n",
    "        f.cash_long, f.cash_net, f.cash_short, f.stock_long, f.stock_net, f.stock_short,\n",
    "        f.bond_long, f.bond_net, f.bond_short, f.other_long, f.other_net, f.other_short,\n",
    "        f.return_driver, f.YC_BM_Symbol,\n",
    "        cwa.CWA_Broad_Category_Name,\n",
    "        yc.Category_Name AS YC_Category_Name,\n",
    "        ycg.Global_Category_Name,\n",
    "        ycba.YC_Broad_Asset_Class_Name\n",
    "    FROM Funds_to_Screen f\n",
    "    LEFT JOIN CWA_Broad_Category_List cwa ON f.CWA_Broad_Category_ID = cwa.ID\n",
    "    LEFT JOIN YC_Category_List yc ON f.YC_Category_ID = yc.ID\n",
    "    LEFT JOIN YC_Global_Category_List ycg ON f.YC_Global_Category_ID = ycg.ID\n",
    "    LEFT JOIN YC_Broad_Asset_Class_List ycba ON f.YC_Broad_Asset_Class_ID = ycba.ID\n",
    "    \"\"\"\n",
    "\n",
    "    # Load data into DataFrame\n",
    "    df = pd.read_sql(query, engine)\n",
    "\n",
    "    # Apply classification\n",
    "    results = []\n",
    "    for idx, row in df.iterrows():\n",
    "        classification, audit_log = classify_fund(row)\n",
    "        result_row = row.copy()\n",
    "        result_row['Final_Classification'] = classification\n",
    "        result_row['Audit_Log'] = \"; \".join(audit_log)\n",
    "        results.append(result_row)\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    result_df = pd.DataFrame(results)\n",
    "\n",
    "    # Ensure desired column order\n",
    "    output_columns = ['SymbolCUSIP', 'ProductName', 'fund_family', 'Final_Classification', 'ycharts_url'] + [\n",
    "        col for col in result_df.columns\n",
    "        if col not in ['SymbolCUSIP', 'ProductName', 'fund_family', 'Final_Classification', 'ycharts_url']\n",
    "    ]\n",
    "\n",
    "    result_df = result_df[output_columns]\n",
    "\n",
    "    # Export to Excel\n",
    "    output_path = r\"C:\\Users\\JulianHeron\\Software Projects\\Risk_Overlays_V4.1.xlsx\"\n",
    "    result_df.to_excel(output_path, index=False)\n",
    "    print(f\"Results exported to {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e583d2dd-bacd-4b58-b4d3-c96c7f7db71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results exported to C:\\Users\\JulianHeron\\Software Projects\\Risk_Overlays_V4.2T2.xlsx\n"
     ]
    }
   ],
   "source": [
    "# V4.2 with Actual Fix for Numeric Scale (multiplying exposures by 100)\n",
    "# This ensures that a value of 1.0 is treated as 100%, not 1%.\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Connection string\n",
    "connection_string = (\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/\"\n",
    "    \"CWA_Fund_Database?driver=ODBC+Driver+18+for+SQL+Server\"\n",
    "    \"&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "def safe_lower(value):\n",
    "    return value.lower() if isinstance(value, str) else \"\"\n",
    "\n",
    "# Define keyword mappings for general scoring\n",
    "keyword_mappings = {\n",
    "    \"Slight/None\": [\n",
    "        \"long-only\", \"no derivatives\", \"no hedging\", \"no leverage\", \"no options\", \"no short\",\n",
    "        \"position adjustment\", \"occasional hedging\", \"covered call\", \"put-write\", \"light hedge\",\n",
    "        \"may include options\", \"limited use of derivatives\", \"for risk management purposes\",\n",
    "        \"minor hedging\", \"occasional short positions\", \"overwrite\", \"investment grade\", \"core\"\n",
    "    ],\n",
    "    \"Moderate\": [\n",
    "        \"hedged\", \"currency hedge\", \"protective put\", \"partial hedge\", \"hedged equity\",\n",
    "        \"covered call\", \"convexity option overlay\", \"option overlay\", \"put/spread collar\",\n",
    "        \"forward agreement\", \"enhanced index strategy\", \"BuyWrite\", \"Buy-Write\", \"buy write\",\n",
    "        \"option spread\", \"volatility hedge\", \"put options\", \"enhance\", \"options-based income\",\n",
    "        \"ELN\", \"premium income\", \"call option\", \"FLEX options\", \"option premium\", \"write calls\",\n",
    "        \"sell calls\", \"protective puts\", \"equity-linked notes\", \"structured notes\",\n",
    "        \"risk mitigation\", \"downside protection\", \"limited hedging\", \"multi-asset\"\n",
    "    ],\n",
    "    \"Persistent Systematic\": [\n",
    "        \"tail-risk\", \"trend-following\", \"systematic hedging\", \"overlay\", \"CTA\", \"managed futures\",\n",
    "        \"defined outcome\", \"long-short\", \"market neutral\", \"systematic strategy\", \"return stacking\",\n",
    "        \"option writing\", \"straddle\", \"derivative income\", \"futures contracts\", \"swap contract\",\n",
    "        \"forward agreement\", \"enhanced index strategy\", \"volatility hedge\", \"put options\",\n",
    "        \"options-based income\", \"ELN\", \"option premium\", \"swap\", \"forward\", \"futures\", \"future\",\n",
    "        \"VIX\", \"managed futures strategy\", \"trend strategy\", \"quantitative hedging\",\n",
    "        \"systematic options\", \"options overlay strategy\", \"futures overlay\", \"swaps-based\",\n",
    "        \"multi-asset\", \"Flex Options\", \"Flexible Exchange Options\", \"YieldMax\", \"buffer\"\n",
    "    ],\n",
    "    \"Heavy Amplification\": [\n",
    "        \"2x\", \"3x\", \"Uncapped Accelerator\", \"-2x\", \"-3x\", \"YieldMax\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Direct mapping keywords (often in ProductName)\n",
    "direct_keyword_mappings = {\n",
    "    \"Persistent Systematic\": [\"Market Neutral\", \"managed futures\", \"Premia\", \"Return Stacked ETFs\"]\n",
    "}\n",
    "\n",
    "# Direct mapping categories\n",
    "direct_category_mappings = {\n",
    "    \"Persistent Systematic\": {\n",
    "        \"YC_Category\": [\"Defined Outcome\"],\n",
    "        \"CWA_Broad_Category\": [\"Defined Outcome\"],\n",
    "        \"YC_Global_Category\": [\"market neutral\"]\n",
    "    },\n",
    "    \"Heavy Amplification\": {\n",
    "        \"YC_Category\": [\n",
    "            \"Trading--Leveraged Equity\", \"Trading--Leveraged Debt\", \"Trading--Leveraged Commodities\"\n",
    "        ],\n",
    "        \"CWA_Broad_Category\": [\"Single Stock\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Helper category mappings (narrow possibilities)\n",
    "helper_category_mappings = {\n",
    "    (\"Persistent Systematic\", \"Heavy Amplification\"): {\n",
    "        \"YC_Category\": [\n",
    "            \"Trading--Inverse Commodities\", \"Trading--Inverse Debt\", \"Trading--Inverse Equity\",\n",
    "            \"Trading--Miscellaneous\"\n",
    "        ],\n",
    "        \"CWA_Broad_Category\": [\"Trading/Tactical\"],\n",
    "        \"YC_Global_Category\": [\"Trading Tools\"]\n",
    "    },\n",
    "    (\"Persistent Systematic\", \"Moderate\"): {\n",
    "        \"YC_Global_Category\": [\"Multialternative\", \"Long/Short Equity\"],\n",
    "        \"YC_Category\": [\"Equity Hedged\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Weak helper category mappings (may or may not have overlay)\n",
    "weak_helper_category_mappings = {\n",
    "    (\"Slight/None\", \"Moderate\"): {\n",
    "        \"YC_Global_Category\": [\"Flexible Allocation\", \"Alternative Miscellaneous\"],\n",
    "        \"return_driver\": [\"Index Based\", \"Factor/Smart Beta\"]\n",
    "    },\n",
    "    (\"Slight/None\", \"Moderate\", \"Persistent Systematic\"): {\n",
    "        \"YC_Category\": [\"Relative Value Arbitrage\"]\n",
    "    },\n",
    "    (\"Heavy Amplification\", \"Persistent Systematic\", \"Moderate\", \"Slight/None\"): {\n",
    "        \"return_driver\": [\"Quant/Systematic\"]\n",
    "    },\n",
    "    (\"Persistent Systematic\", \"Moderate\", \"Slight/None\"): {\n",
    "        \"return_driver\": [\"Active Discretionary\", \"Multi-Strategy\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Boolean flags to remove categories\n",
    "boolean_exclusions = {\n",
    "    (\"Slight/None\", \"Moderate\"): lambda row: row['leveraged_fund'] in [True, 1]\n",
    "    or row['synthetic_replication_fund'] in [True, 1]\n",
    "    or row['inverse_fund'] in [True, 1]\n",
    "}\n",
    "\n",
    "# Function to search text for keywords\n",
    "def search_keywords(text, keywords):\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    text = str(text).lower()\n",
    "    return sum(1 for keyword in keywords if re.search(r'\\b' + re.escape(keyword.lower()) + r'\\b', text))\n",
    "\n",
    "# Decision Tree for Exposure Classification with Prove/Disprove\n",
    "def classify_by_exposures_with_disproof(row):\n",
    "    audit_log = []\n",
    "    possible_categories = [\"Slight/None\", \"Moderate\", \"Persistent Systematic\", \"Heavy Amplification\"]\n",
    "\n",
    "    # Convert exposure columns to numeric, handle non-numeric gracefully\n",
    "    exposure_cols = [\n",
    "        'cash_long', 'cash_net', 'cash_short',\n",
    "        'stock_long', 'stock_net', 'stock_short',\n",
    "        'bond_long', 'bond_net', 'bond_short',\n",
    "        'other_long', 'other_net', 'other_short'\n",
    "    ]\n",
    "    for col in exposure_cols:\n",
    "        value = pd.to_numeric(row[col], errors='coerce')\n",
    "        row[col] = 0 if pd.isna(value) else value\n",
    "\n",
    "    # Calculate totals (incoming data presumably 1.0 => 100%)\n",
    "    long_total = row['cash_long'] + row['stock_long'] + row['bond_long'] + row['other_long']\n",
    "    short_total = row['cash_short'] + row['stock_short'] + row['bond_short'] + row['other_short']\n",
    "    other_total = row['other_long'] + row['other_short']\n",
    "\n",
    "    # ---- KEY FIX: Multiply by 100 so that 1.0 becomes 100% ----\n",
    "    long_total *= 100\n",
    "    short_total *= 100\n",
    "    other_total *= 100\n",
    "\n",
    "    # Round totals\n",
    "    long_total_rounded = round(long_total, 4)\n",
    "    short_total_rounded = round(short_total, 4)\n",
    "    other_total_rounded = round(other_total, 4)\n",
    "\n",
    "    debug_msg = (\n",
    "        f\"[Exposure after *100] long_total={long_total_rounded}%, \"\n",
    "        f\"short_total={short_total_rounded}%, other_total={other_total_rounded}%\"\n",
    "    )\n",
    "    audit_log.append(debug_msg)\n",
    "\n",
    "    # Define disproof keywords for each branch\n",
    "    disproof_keywords = {\n",
    "        \"Slight/None\": [\n",
    "            \"derivatives\", \"swaps\", \"futures\", \"short\", \"hedge\", \"long-short\", \"inverse\", \n",
    "            \"leveraged\", \"tail risk\", \"tail-risk\"\n",
    "        ],\n",
    "        \"Moderate\": [\n",
    "            \"systematic\", \"trend-following\", \"2x\", \"3x\", \"market neutral\",\n",
    "            \"quantitative hedging\", \"managed futures\", \"managed futures strategy\",\n",
    "            \"trend strategy\", \"yieldmax\", \"tail risk\", \"tail-risk\"\n",
    "        ],\n",
    "        \"Persistent Systematic\": [\"2x\", \"3x\", \"-2x\", \"-3x\", \"uncapped accelerator\"],\n",
    "        \"Heavy Amplification\": [\"long-only\", \"no derivatives\", \"no short\"]\n",
    "    }\n",
    "\n",
    "    def has_disproof_keywords(category):\n",
    "        keywords = disproof_keywords.get(category, [])\n",
    "        keyword_score = 0\n",
    "        disproof_details = []\n",
    "        for field in ['ProductName', 'investment_strategy', 'FS_insight']:\n",
    "            if pd.notna(row[field]):\n",
    "                text = str(row[field]).lower()\n",
    "                found_keywords = [\n",
    "                    kw for kw in keywords\n",
    "                    if re.search(r'\\b' + re.escape(kw.lower()) + r'\\b', text)\n",
    "                ]\n",
    "                if found_keywords:\n",
    "                    disproof_details.append(f\"Field '{field}' has {found_keywords}\")\n",
    "                    keyword_score += len(found_keywords)\n",
    "        if keyword_score > 0:\n",
    "            audit_log.append(f\"Disproof Keywords ({category}): {disproof_details}\")\n",
    "        else:\n",
    "            audit_log.append(f\"No Disproof Keywords Found ({category})\")\n",
    "        return keyword_score > 0\n",
    "\n",
    "    def has_disproof_categories(category):\n",
    "        # If you need to replicate prior disproof logic, you can do that here.\n",
    "        # For brevity, returning False unless you want the full checks.\n",
    "        return False\n",
    "\n",
    "    # Branch 1: Simple Exposure (Slight/None)\n",
    "    #\n",
    "    # short/other < 1 => <1%, and long <= 100.2 => ~100%\n",
    "    if abs(short_total_rounded) < 1 and abs(other_total_rounded) < 1 and long_total_rounded <= 100.2:\n",
    "        audit_log.append(\n",
    "            \"Branch 1: Simple Exposure => short/other <1%, long <= ~100%\"\n",
    "        )\n",
    "        if pd.notna(row['fund_family']) and \"return stacked\" in row['fund_family'].lower():\n",
    "            audit_log.append(\"Disproof: 'return stacked' fund_family => next branch\")\n",
    "        elif has_disproof_keywords(\"Slight/None\") or has_disproof_categories(\"Slight/None\"):\n",
    "            audit_log.append(\"Disproof triggered => next branch\")\n",
    "        else:\n",
    "            audit_log.append(\"No disproof => Slight/None\")\n",
    "            return \"Slight/None\", \"Simple: short/other <1%, ~100% long\"\n",
    "\n",
    "    # Branch 2: Moderate\n",
    "    #\n",
    "    # short/other <= 10 => <=10%\n",
    "    if short_total_rounded <= 10 and other_total_rounded <= 10:\n",
    "        audit_log.append(\"Branch 2: moderate => short/other <=10%\")\n",
    "        if has_disproof_keywords(\"Moderate\") or has_disproof_categories(\"Moderate\"):\n",
    "            audit_log.append(\"Disproof triggered => next branch\")\n",
    "        else:\n",
    "            audit_log.append(\"No disproof => Moderate\")\n",
    "            return \"Moderate\", \"Moderate: short/other <=10%\"\n",
    "\n",
    "    # Branch 3: Persistent Systematic\n",
    "    #\n",
    "    # short/other <= 50 => <=50%\n",
    "    if short_total_rounded <= 50 or other_total_rounded <= 50:\n",
    "        audit_log.append(\"Branch 3: persistent systematic => short/other <=50%\")\n",
    "        return \"Persistent Systematic\", \"Persistent Systematic: short/other <=50%\"\n",
    "\n",
    "    # Branch 4: Heavy Amplification\n",
    "    #\n",
    "    audit_log.append(\"Branch 4: heavy amplification => short/other >50%\")\n",
    "    return \"Heavy Amplification\", \"Heavy Amplification: short/other >50%\"\n",
    "\n",
    "# Alternative evaluation for ambiguous cases\n",
    "def alternative_evaluation(row, scores, audit_log):\n",
    "    possible_categories = [\"Slight/None\", \"Moderate\", \"Persistent Systematic\", \"Heavy Amplification\"]\n",
    "    audit_log.append(\"Entering Alternative Evaluation\")\n",
    "\n",
    "    # If it's an inverse fund\n",
    "    if row['inverse_fund'] in [True, 1]:\n",
    "        scores[\"Heavy Amplification\"] += 2\n",
    "        scores[\"Persistent Systematic\"] += 1\n",
    "        audit_log.append(\"Inverse fund => +2 Heavy Amplification, +1 Persistent Systematic\")\n",
    "\n",
    "    # Score based on categories\n",
    "    yc_category = safe_lower(row.get('YC_Category_Name', ''))\n",
    "    cwa_category = safe_lower(row.get('CWA_Broad_Category_Name', ''))\n",
    "    global_category = safe_lower(row.get('YC_Global_Category_Name', ''))\n",
    "    return_driver = safe_lower(row.get('return_driver', ''))\n",
    "\n",
    "    # Score Slight/None\n",
    "    if (yc_category in [\"government bond\", \"corporate bond\", \"municipal bond\"]\n",
    "        or cwa_category in [\"taxable fixed income\", \"municipal\"]\n",
    "        or return_driver in [\"index based\"]):\n",
    "        scores[\"Slight/None\"] += 2\n",
    "        audit_log.append(\"Scoring +2 for Slight/None based on category/return_driver\")\n",
    "\n",
    "    # Score Moderate\n",
    "    if (yc_category in [\"derivative income\", \"multisector bond\"]\n",
    "        or cwa_category in [\"bond strategy\", \"strategic\"]\n",
    "        or global_category in [\"flexible allocation\", \"us fixed income\"]):\n",
    "        scores[\"Moderate\"] += 2\n",
    "        audit_log.append(\"Scoring +2 for Moderate\")\n",
    "\n",
    "    # Score Persistent Systematic\n",
    "    if (yc_category in [\"long-short equity\", \"equity hedged\"]\n",
    "        or cwa_category in [\"alternative\", \"nontraditional\"]\n",
    "        or global_category in [\"long/short equity\", \"multialternative\", \"options trading\"]\n",
    "        or return_driver in [\"quant/systematic\", \"active discretionary\"]):\n",
    "        scores[\"Persistent Systematic\"] += 2\n",
    "        audit_log.append(\"Scoring +2 for Persistent Systematic\")\n",
    "\n",
    "    # Score Heavy Amplification\n",
    "    if (yc_category in [\"trading--leveraged equity\", \"trading--leveraged debt\"]\n",
    "        or \"leveraged\" in safe_lower(row.get('ProductName', ''))):\n",
    "        scores[\"Heavy Amplification\"] += 2\n",
    "        audit_log.append(\"Scoring +2 for Heavy Amplification\")\n",
    "\n",
    "    # Evaluate pairs of categories\n",
    "    audit_log.append(\"Evaluating pairs to see if a single category emerges...\")\n",
    "\n",
    "    # For example, you can do your pairwise logic here. \n",
    "    # We'll keep a simplified version that picks the max among the four.\n",
    "    # Then use a tiebreaker on keywords.\n",
    "\n",
    "    return None, audit_log  # or your logic to choose one\n",
    "\n",
    "def classify_fund(row):\n",
    "    possible_categories = [\"Slight/None\", \"Moderate\", \"Persistent Systematic\", \"Heavy Amplification\"]\n",
    "    scores = {cat: 0 for cat in possible_categories}\n",
    "    audit_log = []\n",
    "\n",
    "    # Step 1: Override for Fund Family \"Return Stacked ETFs\"\n",
    "    if pd.notna(row['fund_family']) and \"return stacked etfs\" in row['fund_family'].lower():\n",
    "        audit_log.append(\"Override => 'Return Stacked ETFs' => Persistent Systematic\")\n",
    "        return \"Persistent Systematic\", audit_log\n",
    "\n",
    "    # Step 2: Direct keyword mapping\n",
    "    for category, keywords in direct_keyword_mappings.items():\n",
    "        for field in ['ProductName', 'investment_strategy', 'FS_insight']:\n",
    "            if pd.notna(row[field]):\n",
    "                match_count = search_keywords(row[field], keywords)\n",
    "                if match_count > 0:\n",
    "                    audit_log.append(f\"Direct keyword => {category} in {field}\")\n",
    "                    return category, audit_log\n",
    "\n",
    "    # Step 3: Direct category mapping\n",
    "    for category, mappings in direct_category_mappings.items():\n",
    "        for db_field, values in mappings.items():\n",
    "            values_lower = [val.lower() for val in values]\n",
    "            field_value = safe_lower(row.get(db_field, ''))\n",
    "            if field_value in values_lower:\n",
    "                audit_log.append(f\"Direct category => {category} for {field_value} in {db_field}\")\n",
    "                return category, audit_log\n",
    "\n",
    "    # Step 4: Apply Boolean exclusions\n",
    "    for categories, condition in boolean_exclusions.items():\n",
    "        if condition(row):\n",
    "            excluded = [cat for cat in possible_categories if cat in categories]\n",
    "            for cat in excluded:\n",
    "                possible_categories.remove(cat)\n",
    "            audit_log.append(f\"Excluded {excluded} due to Boolean flags\")\n",
    "            if len(possible_categories) == 1:\n",
    "                return possible_categories[0], audit_log\n",
    "\n",
    "    # Step 5: Exposure Decision Tree\n",
    "    exposure_result = classify_by_exposures_with_disproof(row)\n",
    "\n",
    "    if isinstance(exposure_result, tuple) and len(exposure_result) == 2:\n",
    "        classification, reason = exposure_result\n",
    "        audit_log.append(f\"Exposure-based => {classification} - {reason}\")\n",
    "        return classification, audit_log\n",
    "\n",
    "    # If None or ambiguous, do alternative\n",
    "    elif exposure_result[0] is None:\n",
    "        scores_update = exposure_result[1]\n",
    "        for msg in exposure_result[2]:\n",
    "            audit_log.append(msg)\n",
    "        for cat in scores_update:\n",
    "            scores[cat] += scores_update[cat]\n",
    "        classification, eval_log = alternative_evaluation(row, scores, audit_log)\n",
    "        for msg in eval_log:\n",
    "            audit_log.append(msg)\n",
    "        if classification:\n",
    "            audit_log.append(f\"Alternative => {classification}\")\n",
    "            return classification, audit_log\n",
    "\n",
    "    # Step 6: Final scoring if no immediate classification\n",
    "    max_score = max(scores[cat] for cat in possible_categories)\n",
    "    top_categories = [cat for cat in possible_categories if scores[cat] == max_score]\n",
    "    if len(top_categories) == 1:\n",
    "        final_classification = top_categories[0]\n",
    "        audit_log.append(f\"Final => {final_classification}\")\n",
    "    else:\n",
    "        # Tiebreaker on keywords\n",
    "        keyword_tie_scores = {cat: 0 for cat in top_categories}\n",
    "        for category in top_categories:\n",
    "            for field in ['ProductName', 'investment_strategy', 'FS_insight']:\n",
    "                keyword_tie_scores[category] += search_keywords(row[field], keyword_mappings[category])\n",
    "        audit_log.append(f\"Tiebreaker => {keyword_tie_scores}\")\n",
    "        max_keyword_score = max(keyword_tie_scores.values())\n",
    "        top_keyword_categories = [\n",
    "            cat for cat, score in keyword_tie_scores.items()\n",
    "            if score == max_keyword_score\n",
    "        ]\n",
    "        if len(top_keyword_categories) == 1:\n",
    "            final_classification = top_keyword_categories[0]\n",
    "            audit_log.append(f\"Tiebreaker => {final_classification}\")\n",
    "        else:\n",
    "            # fallback to conservative\n",
    "            conservative_order = [\"Slight/None\", \"Moderate\", \"Persistent Systematic\", \"Heavy Amplification\"]\n",
    "            final_classification = min(\n",
    "                top_keyword_categories,\n",
    "                key=lambda x: conservative_order.index(x)\n",
    "            )\n",
    "            audit_log.append(f\"Conservative fallback => {final_classification}\")\n",
    "\n",
    "    return final_classification, audit_log\n",
    "\n",
    "def main():\n",
    "    # Create database engine\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    # Query to join tables\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        f.SymbolCUSIP, f.ProductName, f.fund_family, f.investment_strategy, f.FS_insight,\n",
    "        f.index_fund, f.inverse_fund, f.leveraged_fund, f.synthetic_replication_fund,\n",
    "        f.fund_of_funds, f.ycharts_url, f.currency_hedged_fund,\n",
    "        f.cash_long, f.cash_net, f.cash_short, f.stock_long, f.stock_net, f.stock_short,\n",
    "        f.bond_long, f.bond_net, f.bond_short, f.other_long, f.other_net, f.other_short,\n",
    "        f.return_driver, f.YC_BM_Symbol,\n",
    "        cwa.CWA_Broad_Category_Name,\n",
    "        yc.Category_Name AS YC_Category_Name,\n",
    "        ycg.Global_Category_Name,\n",
    "        ycba.YC_Broad_Asset_Class_Name\n",
    "    FROM Funds_to_Screen f\n",
    "    LEFT JOIN CWA_Broad_Category_List cwa ON f.CWA_Broad_Category_ID = cwa.ID\n",
    "    LEFT JOIN YC_Category_List yc ON f.YC_Category_ID = yc.ID\n",
    "    LEFT JOIN YC_Global_Category_List ycg ON f.YC_Global_Category_ID = ycg.ID\n",
    "    LEFT JOIN YC_Broad_Asset_Class_List ycba ON f.YC_Broad_Asset_Class_ID = ycba.ID\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_sql(query, engine)\n",
    "\n",
    "    # Apply classification\n",
    "    results = []\n",
    "    for idx, row in df.iterrows():\n",
    "        classification, audit_log = classify_fund(row)\n",
    "        result_row = row.copy()\n",
    "        result_row['Final_Classification'] = classification\n",
    "        result_row['Audit_Log'] = \"; \".join(audit_log)\n",
    "        results.append(result_row)\n",
    "\n",
    "    result_df = pd.DataFrame(results)\n",
    "\n",
    "    # Ensure desired column order\n",
    "    output_columns = [\n",
    "        'SymbolCUSIP', 'ProductName', 'fund_family', 'Final_Classification', 'ycharts_url'\n",
    "    ] + [\n",
    "        col for col in result_df.columns\n",
    "        if col not in ['SymbolCUSIP', 'ProductName', 'fund_family', 'Final_Classification', 'ycharts_url']\n",
    "    ]\n",
    "\n",
    "    result_df = result_df[output_columns]\n",
    "\n",
    "    # Export to Excel - V4.2\n",
    "    output_path = r\"C:\\Users\\JulianHeron\\Software Projects\\Risk_Overlays_V4.2T2.xlsx\"\n",
    "    result_df.to_excel(output_path, index=False)\n",
    "    print(f\"Results exported to {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5f8dd04d-41af-4315-a60c-5597c0437227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported debug version to C:\\Users\\JulianHeron\\Software Projects\\Risk_Overlays_V4.2_DebugT3.xlsx\n"
     ]
    }
   ],
   "source": [
    "# This code seems stable, test then run in DB\n",
    "# V4.2 with Extra Debug Logging for Exposures\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import os\n",
    "\n",
    "connection_string = (\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/\"\n",
    "    \"CWA_Fund_Database?driver=ODBC+Driver+18+for+SQL+Server\"\n",
    "    \"&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "def safe_lower(value):\n",
    "    return value.lower() if isinstance(value, str) else \"\"\n",
    "\n",
    "keyword_mappings = {\n",
    "    \"Slight/None\": [\n",
    "        \"long-only\", \"no derivatives\", \"no hedging\", \"no leverage\", \"no options\", \"no short\",\n",
    "        \"position adjustment\", \"occasional hedging\", \"covered call\", \"put-write\", \"light hedge\",\n",
    "        \"may include options\", \"limited use of derivatives\", \"for risk management purposes\",\n",
    "        \"minor hedging\", \"occasional short positions\", \"overwrite\", \"investment grade\", \"core\"\n",
    "    ],\n",
    "    \"Moderate\": [\n",
    "        \"hedged\", \"currency hedge\", \"protective put\", \"partial hedge\", \"hedged equity\",\n",
    "        \"covered call\", \"convexity option overlay\", \"option overlay\", \"put/spread collar\",\n",
    "        \"forward agreement\", \"enhanced index strategy\", \"BuyWrite\", \"Buy-Write\", \"buy write\",\n",
    "        \"option spread\", \"volatility hedge\", \"put options\", \"enhance\", \"options-based income\",\n",
    "        \"ELN\", \"premium income\", \"call option\", \"FLEX options\", \"option premium\", \"write calls\",\n",
    "        \"sell calls\", \"protective puts\", \"equity-linked notes\", \"structured notes\",\n",
    "        \"risk mitigation\", \"downside protection\", \"limited hedging\", \"multi-asset\"\n",
    "    ],\n",
    "    \"Persistent Systematic\": [\n",
    "        \"tail-risk\", \"trend-following\", \"systematic hedging\", \"overlay\", \"CTA\", \"managed futures\",\n",
    "        \"defined outcome\", \"long-short\", \"market neutral\", \"systematic strategy\", \"return stacking\",\n",
    "        \"option writing\", \"straddle\", \"derivative income\", \"futures contracts\", \"swap contract\",\n",
    "        \"forward agreement\", \"enhanced index strategy\", \"volatility hedge\", \"put options\",\n",
    "        \"options-based income\", \"ELN\", \"option premium\", \"swap\", \"forward\", \"futures\", \"future\",\n",
    "        \"VIX\", \"managed futures strategy\", \"trend strategy\", \"quantitative hedging\",\n",
    "        \"systematic options\", \"options overlay strategy\", \"futures overlay\", \"swaps-based\",\n",
    "        \"multi-asset\", \"Flex Options\", \"Flexible Exchange Options\", \"YieldMax\", \"buffer\"\n",
    "    ],\n",
    "    \"Heavy Amplification\": [\n",
    "        \"2x\", \"3x\", \"Uncapped Accelerator\", \"-2x\", \"-3x\", \"YieldMax\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "direct_keyword_mappings = {\n",
    "    \"Persistent Systematic\": [\"Market Neutral\", \"managed futures\", \"Premia\", \"Return Stacked ETFs\"]\n",
    "}\n",
    "\n",
    "direct_category_mappings = {\n",
    "    \"Persistent Systematic\": {\n",
    "        \"YC_Category\": [\"Defined Outcome\"],\n",
    "        \"CWA_Broad_Category\": [\"Defined Outcome\"],\n",
    "        \"YC_Global_Category\": [\"market neutral\"]\n",
    "    },\n",
    "    \"Heavy Amplification\": {\n",
    "        \"YC_Category\": [\n",
    "            \"Trading--Leveraged Equity\", \"Trading--Leveraged Debt\", \"Trading--Leveraged Commodities\"\n",
    "        ],\n",
    "        \"CWA_Broad_Category\": [\"Single Stock\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "boolean_exclusions = {\n",
    "    (\"Slight/None\", \"Moderate\"): lambda row: row['leveraged_fund'] in [True, 1]\n",
    "    or row['synthetic_replication_fund'] in [True, 1]\n",
    "    or row['inverse_fund'] in [True, 1]\n",
    "}\n",
    "\n",
    "def search_keywords(text, keywords):\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    text = str(text).lower()\n",
    "    return sum(1 for keyword in keywords if re.search(r'\\b' + re.escape(keyword.lower()) + r'\\b', text))\n",
    "\n",
    "def classify_by_exposures_with_disproof(row):\n",
    "    audit_log = []\n",
    "\n",
    "    # Extra debug: Show the raw values from the row *before* we do anything\n",
    "    audit_log.append(\n",
    "        f\"DEBUG: Symbol={row['SymbolCUSIP']}, \"\n",
    "        f\"cash_long={row['cash_long']}, cash_net={row['cash_net']}, cash_short={row['cash_short']}, \"\n",
    "        f\"stock_long={row['stock_long']}, stock_net={row['stock_net']}, stock_short={row['stock_short']}, \"\n",
    "        f\"bond_long={row['bond_long']}, bond_net={row['bond_net']}, bond_short={row['bond_short']}, \"\n",
    "        f\"other_long={row['other_long']}, other_net={row['other_net']}, other_short={row['other_short']}\"\n",
    "    )\n",
    "\n",
    "    possible_categories = [\"Slight/None\", \"Moderate\", \"Persistent Systematic\", \"Heavy Amplification\"]\n",
    "\n",
    "    # Convert to numeric\n",
    "    exposure_cols = [\n",
    "        'cash_long', 'cash_net', 'cash_short',\n",
    "        'stock_long', 'stock_net', 'stock_short',\n",
    "        'bond_long', 'bond_net', 'bond_short',\n",
    "        'other_long', 'other_net', 'other_short'\n",
    "    ]\n",
    "    for col in exposure_cols:\n",
    "        value = pd.to_numeric(row[col], errors='coerce')\n",
    "        row[col] = 0 if pd.isna(value) else value\n",
    "\n",
    "    # Calculate totals\n",
    "    long_total = row['cash_long'] + row['stock_long'] + row['bond_long'] + row['other_long']\n",
    "    short_total = row['cash_short'] + row['stock_short'] + row['bond_short'] + row['other_short']\n",
    "    other_total = row['other_long'] + row['other_short']\n",
    "\n",
    "    # Multiply by 100 so that 1.0 => 100%\n",
    "    long_total *= 100\n",
    "    short_total *= 100\n",
    "    other_total *= 100\n",
    "\n",
    "    # Round\n",
    "    long_total_rounded = round(long_total, 4)\n",
    "    short_total_rounded = round(short_total, 4)\n",
    "    other_total_rounded = round(other_total, 4)\n",
    "\n",
    "    audit_log.append(\n",
    "        f\"[After *100] long_total={long_total_rounded}%, short_total={short_total_rounded}%, other_total={other_total_rounded}%\"\n",
    "    )\n",
    "\n",
    "    # Disproof keywords as before\n",
    "    disproof_keywords = {\n",
    "        \"Slight/None\": [\n",
    "            \"derivatives\", \"swaps\", \"futures\", \"short\", \"hedge\", \"long-short\", \"inverse\", \n",
    "            \"leveraged\", \"tail risk\", \"tail-risk\"\n",
    "        ],\n",
    "        \"Moderate\": [\n",
    "            \"systematic\", \"trend-following\", \"2x\", \"3x\", \"market neutral\",\n",
    "            \"quantitative hedging\", \"managed futures\", \"managed futures strategy\",\n",
    "            \"trend strategy\", \"yieldmax\", \"tail risk\", \"tail-risk\"\n",
    "        ],\n",
    "        \"Persistent Systematic\": [\"2x\", \"3x\", \"-2x\", \"-3x\", \"uncapped accelerator\"],\n",
    "        \"Heavy Amplification\": [\"long-only\", \"no derivatives\", \"no short\"]\n",
    "    }\n",
    "\n",
    "    def has_disproof_keywords(category):\n",
    "        # ...\n",
    "        return False\n",
    "\n",
    "    def has_disproof_categories(category):\n",
    "        # ...\n",
    "        return False\n",
    "\n",
    "    # Branch 1: Slight/None\n",
    "    if abs(short_total_rounded) < 1 and abs(other_total_rounded) < 1 and long_total_rounded <= 100.2:\n",
    "        audit_log.append(\"Branch 1 => Slight/None\")\n",
    "        return \"Slight/None\", \"Simple\"\n",
    "\n",
    "    # Branch 2: Moderate\n",
    "    if short_total_rounded <= 10 and other_total_rounded <= 10:\n",
    "        audit_log.append(\"Branch 2 => Moderate (<=10% short/other)\")\n",
    "        return \"Moderate\", \"Moderate\"\n",
    "\n",
    "    # Branch 3: Persistent Systematic\n",
    "    if short_total_rounded <= 50 or other_total_rounded <= 50:\n",
    "        audit_log.append(\"Branch 3 => Persistent Systematic (<=50% short/other)\")\n",
    "        return \"Persistent Systematic\", \"Persistent Systematic\"\n",
    "\n",
    "    # Branch 4: Heavy Amplification\n",
    "    audit_log.append(\"Branch 4 => Heavy Amplification (>50% short/other)\")\n",
    "    return \"Heavy Amplification\", \"Heavy Amplification\"\n",
    "\n",
    "def classify_fund(row):\n",
    "    audit_log = []\n",
    "\n",
    "    # Potential direct checks / boolean exclusions omitted for brevity\n",
    "    classification, detail = classify_by_exposures_with_disproof(row)\n",
    "    audit_log.append(f\"Exposure-based => {classification}: {detail}\")\n",
    "    return classification, audit_log\n",
    "\n",
    "def main():\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        f.SymbolCUSIP, f.ProductName, f.fund_family, f.investment_strategy, f.FS_insight,\n",
    "        f.index_fund, f.inverse_fund, f.leveraged_fund, f.synthetic_replication_fund,\n",
    "        f.fund_of_funds, f.ycharts_url, f.currency_hedged_fund,\n",
    "        f.cash_long, f.cash_net, f.cash_short, f.stock_long, f.stock_net, f.stock_short,\n",
    "        f.bond_long, f.bond_net, f.bond_short, f.other_long, f.other_net, f.other_short,\n",
    "        f.return_driver, f.YC_BM_Symbol,\n",
    "        cwa.CWA_Broad_Category_Name,\n",
    "        yc.Category_Name AS YC_Category_Name,\n",
    "        ycg.Global_Category_Name,\n",
    "        ycba.YC_Broad_Asset_Class_Name\n",
    "    FROM Funds_to_Screen f\n",
    "    LEFT JOIN CWA_Broad_Category_List cwa ON f.CWA_Broad_Category_ID = cwa.ID\n",
    "    LEFT JOIN YC_Category_List yc ON f.YC_Category_ID = yc.ID\n",
    "    LEFT JOIN YC_Global_Category_List ycg ON f.YC_Global_Category_ID = ycg.ID\n",
    "    LEFT JOIN YC_Broad_Asset_Class_List ycba ON f.YC_Broad_Asset_Class_ID = ycba.ID\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_sql(query, engine)\n",
    "\n",
    "    results = []\n",
    "    for idx, row in df.iterrows():\n",
    "        classification, local_log = classify_fund(row)\n",
    "        newrow = row.copy()\n",
    "        newrow['Final_Classification'] = classification\n",
    "        newrow['Audit_Log'] = \"; \".join(local_log)\n",
    "        results.append(newrow)\n",
    "\n",
    "    outdf = pd.DataFrame(results)\n",
    "\n",
    "    columns_front = [\n",
    "        'SymbolCUSIP','ProductName','fund_family','Final_Classification','ycharts_url'\n",
    "    ]\n",
    "    other_cols = [c for c in outdf.columns if c not in columns_front]\n",
    "    outdf = outdf[columns_front + other_cols]\n",
    "\n",
    "    # v4.2 with debug\n",
    "    output_path = r\"C:\\Users\\JulianHeron\\Software Projects\\Risk_Overlays_V4.2_DebugT3.xlsx\"\n",
    "    outdf.to_excel(output_path, index=False)\n",
    "    print(f\"Exported debug version to {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5478c01b-178a-4b1f-9239-4ff377261971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported v4.3 Extended Logging => C:\\Users\\JulianHeron\\Software Projects\\Risk_Overlays_V4.3_ExtendedLog.xlsx\n"
     ]
    }
   ],
   "source": [
    "# extended debugging before finalizing\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Connection string\n",
    "connection_string = (\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/\"\n",
    "    \"CWA_Fund_Database?driver=ODBC+Driver+18+for+SQL+Server\"\n",
    "    \"&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "def safe_lower(value):\n",
    "    return value.lower() if isinstance(value, str) else \"\"\n",
    "\n",
    "keyword_mappings = {\n",
    "    \"Slight/None\": [\n",
    "        \"long-only\", \"no derivatives\", \"no hedging\", \"no leverage\", \"no options\", \"no short\",\n",
    "        \"position adjustment\", \"occasional hedging\", \"covered call\", \"put-write\", \"light hedge\",\n",
    "        \"may include options\", \"limited use of derivatives\", \"for risk management purposes\",\n",
    "        \"minor hedging\", \"occasional short positions\", \"overwrite\", \"investment grade\", \"core\"\n",
    "    ],\n",
    "    \"Moderate\": [\n",
    "        \"hedged\", \"currency hedge\", \"protective put\", \"partial hedge\", \"hedged equity\",\n",
    "        \"covered call\", \"convexity option overlay\", \"option overlay\", \"put/spread collar\",\n",
    "        \"forward agreement\", \"enhanced index strategy\", \"BuyWrite\", \"Buy-Write\", \"buy write\",\n",
    "        \"option spread\", \"volatility hedge\", \"put options\", \"enhance\", \"options-based income\",\n",
    "        \"ELN\", \"premium income\", \"call option\", \"FLEX options\", \"option premium\", \"write calls\",\n",
    "        \"sell calls\", \"protective puts\", \"equity-linked notes\", \"structured notes\",\n",
    "        \"risk mitigation\", \"downside protection\", \"limited hedging\", \"multi-asset\"\n",
    "    ],\n",
    "    \"Persistent Systematic\": [\n",
    "        \"tail-risk\", \"trend-following\", \"systematic hedging\", \"overlay\", \"CTA\", \"managed futures\",\n",
    "        \"defined outcome\", \"long-short\", \"market neutral\", \"systematic strategy\", \"return stacking\",\n",
    "        \"option writing\", \"straddle\", \"derivative income\", \"futures contracts\", \"swap contract\",\n",
    "        \"forward agreement\", \"enhanced index strategy\", \"volatility hedge\", \"put options\",\n",
    "        \"options-based income\", \"ELN\", \"option premium\", \"swap\", \"forward\", \"futures\", \"future\",\n",
    "        \"VIX\", \"managed futures strategy\", \"trend strategy\", \"quantitative hedging\",\n",
    "        \"systematic options\", \"options overlay strategy\", \"futures overlay\", \"swaps-based\",\n",
    "        \"multi-asset\", \"Flex Options\", \"Flexible Exchange Options\", \"YieldMax\", \"buffer\"\n",
    "    ],\n",
    "    \"Heavy Amplification\": [\n",
    "        \"2x\", \"3x\", \"Uncapped Accelerator\", \"-2x\", \"-3x\", \"YieldMax\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Direct keyword mappings (immediate classification)\n",
    "direct_keyword_mappings = {\n",
    "    \"Persistent Systematic\": [\n",
    "        \"Market Neutral\", \n",
    "        \"managed futures\", \n",
    "        \"Premia\", \n",
    "        \"Return Stacked ETFs\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Direct category mappings (immediate classification)\n",
    "direct_category_mappings = {\n",
    "    \"Persistent Systematic\": {\n",
    "        \"YC_Category\": [\"Defined Outcome\"],\n",
    "        \"CWA_Broad_Category\": [\"Defined Outcome\"],\n",
    "        \"YC_Global_Category\": [\"market neutral\"]\n",
    "    },\n",
    "    \"Heavy Amplification\": {\n",
    "        \"YC_Category\": [\n",
    "            \"Trading--Leveraged Equity\", \n",
    "            \"Trading--Leveraged Debt\", \n",
    "            \"Trading--Leveraged Commodities\"\n",
    "        ],\n",
    "        \"CWA_Broad_Category\": [\"Single Stock\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Boolean flags to remove categories\n",
    "boolean_exclusions = {\n",
    "    (\"Slight/None\", \"Moderate\"): lambda row: row['leveraged_fund'] in [True, 1]\n",
    "        or row['synthetic_replication_fund'] in [True, 1]\n",
    "        or row['inverse_fund'] in [True, 1]\n",
    "}\n",
    "\n",
    "def search_keywords(text, keywords):\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    text = str(text).lower()\n",
    "    return sum(1 for kw in keywords if re.search(r'\\b' + re.escape(kw.lower()) + r'\\b', text))\n",
    "\n",
    "def classify_by_exposures_with_disproof(row, master_log):\n",
    "    \"\"\"\n",
    "    Extended-logging version:\n",
    "    master_log is the same list we pass around to accumulate all messages,\n",
    "    so we can see each branch check.\n",
    "    \"\"\"\n",
    "    master_log.append(\"===== BEGIN EXPOSURE DECISION TREE =====\")\n",
    "    \n",
    "    # Convert to numeric\n",
    "    exposure_cols = [\n",
    "        'cash_long', 'cash_net', 'cash_short',\n",
    "        'stock_long', 'stock_net', 'stock_short',\n",
    "        'bond_long', 'bond_net', 'bond_short',\n",
    "        'other_long', 'other_net', 'other_short'\n",
    "    ]\n",
    "    for col in exposure_cols:\n",
    "        val = pd.to_numeric(row[col], errors='coerce')\n",
    "        row[col] = 0 if pd.isna(val) else val\n",
    "\n",
    "    # Sum\n",
    "    long_total = (row['cash_long'] + row['stock_long'] \n",
    "                  + row['bond_long'] + row['other_long'])\n",
    "    short_total = (row['cash_short'] + row['stock_short'] \n",
    "                   + row['bond_short'] + row['other_short'])\n",
    "    other_total = (row['other_long'] + row['other_short'])\n",
    "\n",
    "    # Multiply by 100 => 1.0 => 100%\n",
    "    long_total_100 = long_total * 100\n",
    "    short_total_100 = short_total * 100\n",
    "    other_total_100 = other_total * 100\n",
    "\n",
    "    # Round\n",
    "    long_r = round(long_total_100, 4)\n",
    "    short_r = round(short_total_100, 4)\n",
    "    other_r = round(other_total_100, 4)\n",
    "\n",
    "    master_log.append(f\"Exposures => long={long_r}%, short={short_r}%, other={other_r}%\")\n",
    "\n",
    "    # Branch 1: \"Slight/None\"\n",
    "    master_log.append(\n",
    "        f\"Branch 1 check: short<{1}?, other<{1}?, long<={100.2}? => short={short_r}, other={other_r}, long={long_r}\"\n",
    "    )\n",
    "    if abs(short_r) < 1 and abs(other_r) < 1 and long_r <= 100.2:\n",
    "        master_log.append(\"=> PASSED => 'Slight/None' (simple long-only exposure)\")\n",
    "        return \"Slight/None\", \"Simple\"\n",
    "\n",
    "    master_log.append(\"=> FAILED => next branch...\")\n",
    "\n",
    "    # Branch 2: \"Moderate\"\n",
    "    master_log.append(\n",
    "        f\"Branch 2 check: short<={10}?, other<={10}? => short={short_r}, other={other_r}\"\n",
    "    )\n",
    "    if short_r <= 10 and other_r <= 10:\n",
    "        master_log.append(\"=> PASSED => 'Moderate'\")\n",
    "        return \"Moderate\", \"Moderate\"\n",
    "\n",
    "    master_log.append(\"=> FAILED => next branch...\")\n",
    "\n",
    "    # Branch 3: \"Persistent Systematic\"\n",
    "    master_log.append(\n",
    "        f\"Branch 3 check: short<={50}? or other<={50}? => short={short_r}, other={other_r}\"\n",
    "    )\n",
    "    if short_r <= 50 or other_r <= 50:\n",
    "        master_log.append(\"=> PASSED => 'Persistent Systematic'\")\n",
    "        return \"Persistent Systematic\", \"Persistent Systematic\"\n",
    "\n",
    "    master_log.append(\"=> FAILED => next branch...\")\n",
    "\n",
    "    # Branch 4: \"Heavy Amplification\"\n",
    "    master_log.append(\n",
    "        f\"Branch 4 => short/other > 50% => => 'Heavy Amplification'\"\n",
    "    )\n",
    "    return \"Heavy Amplification\", \"Heavy Amplification\"\n",
    "\n",
    "def alternative_evaluation(row, scores, master_log):\n",
    "    # If you have alternative logic, put extended logging here.\n",
    "    master_log.append(\"===== BEGIN ALTERNATIVE EVALUATION =====\")\n",
    "    # Return (None, master_log) or a final classification with reason\n",
    "    return (None, master_log)\n",
    "\n",
    "def classify_fund(row):\n",
    "    audit_log = []\n",
    "\n",
    "    # 1) Fund family override\n",
    "    if pd.notna(row['fund_family']) and (\"return stacked etfs\" in row['fund_family'].lower()):\n",
    "        audit_log.append(\n",
    "            \"FUND FAMILY OVERRIDE => 'Return Stacked ETFs' => Persistent Systematic\"\n",
    "        )\n",
    "        return \"Persistent Systematic\", audit_log\n",
    "\n",
    "    # 2) Direct keyword mapping\n",
    "    for category, keywords in direct_keyword_mappings.items():\n",
    "        for field in ['ProductName', 'investment_strategy', 'FS_insight']:\n",
    "            if pd.notna(row[field]):\n",
    "                count = search_keywords(row[field], keywords)\n",
    "                if count > 0:\n",
    "                    audit_log.append(f\"DIRECT KEYWORD => {category} from {field} match\")\n",
    "                    return category, audit_log\n",
    "\n",
    "    # 3) Direct category mapping\n",
    "    for category, mappings in direct_category_mappings.items():\n",
    "        for db_field, values in mappings.items():\n",
    "            vals_lower = [v.lower() for v in values]\n",
    "            field_val = safe_lower(row.get(db_field, ''))\n",
    "            if field_val in vals_lower:\n",
    "                audit_log.append(f\"DIRECT CATEGORY => {category} from {db_field}={field_val}\")\n",
    "                return category, audit_log\n",
    "\n",
    "    # 4) Boolean exclusions\n",
    "    possible_categories = [\"Slight/None\", \"Moderate\", \"Persistent Systematic\", \"Heavy Amplification\"]\n",
    "    for cats_to_exclude, condition_fn in boolean_exclusions.items():\n",
    "        if condition_fn(row):\n",
    "            # i.e. if fund is leveraged => exclude \"Slight/None\" and \"Moderate\"\n",
    "            excluded = [c for c in cats_to_exclude if c in possible_categories]\n",
    "            for c in excluded:\n",
    "                possible_categories.remove(c)\n",
    "            audit_log.append(\n",
    "                f\"BOOLEAN EXCLUSION => Excluding {excluded} for leveraged/inverse/synthetic\"\n",
    "            )\n",
    "            if len(possible_categories) == 1:\n",
    "                # Only one left\n",
    "                final_cat = possible_categories[0]\n",
    "                audit_log.append(f\"Only {final_cat} remains => final classification\")\n",
    "                return final_cat, audit_log\n",
    "\n",
    "    # 5) Exposure-based classification\n",
    "    classification, reason = classify_by_exposures_with_disproof(row, audit_log)\n",
    "    audit_log.append(f\"Exposure-based => {classification} => {reason}\")\n",
    "    return classification, audit_log\n",
    "\n",
    "def main():\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        f.SymbolCUSIP, f.ProductName, f.fund_family, f.investment_strategy, f.FS_insight,\n",
    "        f.index_fund, f.inverse_fund, f.leveraged_fund, f.synthetic_replication_fund,\n",
    "        f.fund_of_funds, f.ycharts_url, f.currency_hedged_fund,\n",
    "        f.cash_long, f.cash_net, f.cash_short, f.stock_long, f.stock_net, f.stock_short,\n",
    "        f.bond_long, f.bond_net, f.bond_short, f.other_long, f.other_net, f.other_short,\n",
    "        f.return_driver, f.YC_BM_Symbol,\n",
    "        cwa.CWA_Broad_Category_Name,\n",
    "        yc.Category_Name AS YC_Category_Name,\n",
    "        ycg.Global_Category_Name,\n",
    "        ycba.YC_Broad_Asset_Class_Name\n",
    "    FROM Funds_to_Screen f\n",
    "    LEFT JOIN CWA_Broad_Category_List cwa ON f.CWA_Broad_Category_ID = cwa.ID\n",
    "    LEFT JOIN YC_Category_List yc ON f.YC_Category_ID = yc.ID\n",
    "    LEFT JOIN YC_Global_Category_List ycg ON f.YC_Global_Category_ID = ycg.ID\n",
    "    LEFT JOIN YC_Broad_Asset_Class_List ycba ON f.YC_Broad_Asset_Class_ID = ycba.ID\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_sql(query, engine)\n",
    "\n",
    "    results = []\n",
    "    for idx, row in df.iterrows():\n",
    "        classification, local_log = classify_fund(row)\n",
    "        newrow = row.copy()\n",
    "        newrow['Final_Classification'] = classification\n",
    "        newrow['Audit_Log'] = \"; \".join(local_log)\n",
    "        results.append(newrow)\n",
    "\n",
    "    outdf = pd.DataFrame(results)\n",
    "\n",
    "    # Order columns\n",
    "    columns_front = [\n",
    "        'SymbolCUSIP','ProductName','fund_family','Final_Classification','ycharts_url'\n",
    "    ]\n",
    "    other_cols = [c for c in outdf.columns if c not in columns_front]\n",
    "    outdf = outdf[columns_front + other_cols]\n",
    "\n",
    "    output_path = r\"C:\\Users\\JulianHeron\\Software Projects\\Risk_Overlays_V4.3_ExtendedLog.xlsx\"\n",
    "    outdf.to_excel(output_path, index=False)\n",
    "    print(f\"Exported v4.3 Extended Logging => {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9df9c11e-6807-4880-a73d-17050575c84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported v4.3 Extended Logging => C:\\Users\\JulianHeron\\Software Projects\\Risk_Overlays_V4.3_ExtLog_PRV_DPRV.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Extended Debugging, but adding back in proof/ disproof logic in tier one exposures\n",
    "\n",
    "# extended debugging before finalizing\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Connection string\n",
    "connection_string = (\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/\"\n",
    "    \"CWA_Fund_Database?driver=ODBC+Driver+18+for+SQL+Server\"\n",
    "    \"&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "\n",
    "def safe_lower(value):\n",
    "    return value.lower() if isinstance(value, str) else \"\"\n",
    "\n",
    "keyword_mappings = {\n",
    "    \"Slight/None\": [\n",
    "        \"long-only\", \"no derivatives\", \"no hedging\", \"no leverage\", \"no options\", \"no short\",\n",
    "        \"position adjustment\", \"occasional hedging\", \"covered call\", \"put-write\", \"light hedge\",\n",
    "        \"may include options\", \"limited use of derivatives\", \"for risk management purposes\",\n",
    "        \"minor hedging\", \"occasional short positions\", \"overwrite\", \"investment grade\", \"core\"\n",
    "    ],\n",
    "    \"Moderate\": [\n",
    "        \"hedged\", \"currency hedge\", \"protective put\", \"partial hedge\", \"hedged equity\",\n",
    "        \"covered call\", \"convexity option overlay\", \"option overlay\", \"put/spread collar\",\n",
    "        \"forward agreement\", \"enhanced index strategy\", \"BuyWrite\", \"Buy-Write\", \"buy write\",\n",
    "        \"option spread\", \"volatility hedge\", \"put options\", \"enhance\", \"options-based income\",\n",
    "        \"ELN\", \"premium income\", \"call option\", \"FLEX options\", \"option premium\", \"write calls\",\n",
    "        \"sell calls\", \"protective puts\", \"equity-linked notes\", \"structured notes\",\n",
    "        \"risk mitigation\", \"downside protection\", \"limited hedging\", \"multi-asset\"\n",
    "    ],\n",
    "    \"Persistent Systematic\": [\n",
    "        \"tail-risk\", \"trend-following\", \"systematic hedging\", \"overlay\", \"CTA\", \"managed futures\",\n",
    "        \"defined outcome\", \"long-short\", \"market neutral\", \"systematic strategy\", \"return stacking\",\n",
    "        \"option writing\", \"straddle\", \"derivative income\", \"futures contracts\", \"swap contract\",\n",
    "        \"forward agreement\", \"enhanced index strategy\", \"volatility hedge\", \"put options\",\n",
    "        \"options-based income\", \"ELN\", \"option premium\", \"swap\", \"forward\", \"futures\", \"future\",\n",
    "        \"VIX\", \"managed futures strategy\", \"trend strategy\", \"quantitative hedging\",\n",
    "        \"systematic options\", \"options overlay strategy\", \"futures overlay\", \"swaps-based\",\n",
    "        \"multi-asset\", \"Flex Options\", \"Flexible Exchange Options\", \"YieldMax\", \"buffer\"\n",
    "    ],\n",
    "    \"Heavy Amplification\": [\n",
    "        \"2x\", \"3x\", \"Uncapped Accelerator\", \"-2x\", \"-3x\", \"YieldMax\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Proof/ Disproof definitions for tier 1\n",
    "slight_proof_phrases = [\n",
    "    \"used for minor duration or risk tweaks\",\n",
    "    \"occasional use for limited exposure adjustments\",\n",
    "    \"used for position adjustments on a case-by-case basis\",\n",
    "    \"applied sparingly to fine-tune risk\",\n",
    "    \"used on an ad hoc basis for hedging\",\n",
    "    \"employed occasionally for cash management\",\n",
    "    \"derivatives used optionally for risk\",\n",
    "    \"can utilize swaps for adjustments\",\n",
    "    \"can use futures to track index\",\n",
    "    \"can employ derivatives occasionally\",\n",
    "    \"derivatives used discretionarily\",\n",
    "    \"derivatives permitted for limited purposes\",\n",
    "    \"may invest in derivatives sparingly\",\n",
    "    \"may employ futures for cash flow\",\n",
    "    \"uses derivatives to adjust exposure\",\n",
    "    \"utilizes futures contracts to equitize cash\",\n",
    "    \"will not use it to increase leveraged exposure\",\n",
    "    \"use of derivatives is permitted within limits\",\n",
    "    \"may use derivatives\",\n",
    "    \"may invest in derivatives\",\n",
    "    \"derivatives only to mitigate\",\n",
    "    \"may utilize derivatives for managing duration, sector exposure, yield curve and risk mitigation\",\n",
    "    \"may utilize derivatives for managing duration\",\n",
    "    \"may invest in derivatives, including foreign currency derivatives\",\n",
    "    \"may also invest in futures contracts and options to manage market exposure\",\n",
    "    \"may use derivatives to leverage exposure or manage cash\",\n",
    "    \"may also use derivatives to leverage or hedge exposure\",\n",
    "    \"may hedge foreign currency exposure through derivatives, although it is not required to do so\"\n",
    "]\n",
    "\n",
    "slight_disproof_phrases = [\n",
    "    \"employs currency forward contracts to hedge exposure\",\n",
    "    \"derivatives are integral to its hedging strategy\",\n",
    "    \"systematically uses derivatives\",\n",
    "    \"uses a quantitative model to generate derivative signals\",\n",
    "    \"systematic use of derivatives\",\n",
    "    \"derivatives are central\",\n",
    "    \"invests primarily in futures, call options, and put options\",\n",
    "    \"hedges currency exposure with derivatives\",\n",
    "    \"writes call options on index\",\n",
    "    \"invests in futures to offset risk\",\n",
    "    \"enters swap transactions for protection\",\n",
    "    \"uses futures to enhance exposure\",\n",
    "    \"invests in derivatives through subsidiary\",\n",
    "    \"hedges interest rates with options\",\n",
    "    \"allocates assets to options strategy\",\n",
    "    \"employs leverage through inverse floaters\",\n",
    "    \"employs options strategies regularly\",\n",
    "    \"rolled according to a fixed schedule\",\n",
    "    \"currency‐related derivatives to hedge\",\n",
    "    \"may invest up to 15% of its total assets in credit default swaps\",\n",
    "    \"applies an options collar strategy\",\n",
    "    \"derivatives to hedge currency exposure\",\n",
    "    \"writing covered calls\",\n",
    "    \"selects put options through a laddered approach that rolls monthly\"\n",
    "]\n",
    "\n",
    "\n",
    "# Direct keyword mappings (immediate classification)\n",
    "direct_keyword_mappings = {\n",
    "    \"Persistent Systematic\": [\n",
    "        \"Market Neutral\", \n",
    "        \"managed futures\", \n",
    "        \"Premia\", \n",
    "        \"Return Stacked ETFs\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Direct category mappings (immediate classification)\n",
    "direct_category_mappings = {\n",
    "    \"Persistent Systematic\": {\n",
    "        \"YC_Category\": [\"Defined Outcome\"],\n",
    "        \"CWA_Broad_Category\": [\"Defined Outcome\"],\n",
    "        \"YC_Global_Category\": [\"market neutral\"]\n",
    "    },\n",
    "    \"Heavy Amplification\": {\n",
    "        \"YC_Category\": [\n",
    "            \"Trading--Leveraged Equity\", \n",
    "            \"Trading--Leveraged Debt\", \n",
    "            \"Trading--Leveraged Commodities\"\n",
    "        ],\n",
    "        \"CWA_Broad_Category\": [\"Single Stock\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Boolean flags to remove categories\n",
    "boolean_exclusions = {\n",
    "    (\"Slight/None\", \"Moderate\"): lambda row: row['leveraged_fund'] in [True, 1]\n",
    "        or row['synthetic_replication_fund'] in [True, 1]\n",
    "        or row['inverse_fund'] in [True, 1]\n",
    "}\n",
    "\n",
    "# Function to define Proof/ Disproof for tier 1\n",
    "def tally_slight_none_proof_disproof(row):\n",
    "    \"\"\"\n",
    "    Returns (proof_score, disproof_score) by checking for the presence \n",
    "    of each phrase in [ProductName, investment_strategy, FS_insight].\n",
    "    Ties go to 'Slight/None'.\n",
    "    \"\"\"\n",
    "    proof_score = 0\n",
    "    disproof_score = 0\n",
    "\n",
    "    fields_to_check = [\"ProductName\", \"investment_strategy\", \"FS_insight\"]\n",
    "    for field in fields_to_check:\n",
    "        if pd.notna(row[field]):\n",
    "            text = row[field].lower()\n",
    "\n",
    "            for phrase in slight_proof_phrases:\n",
    "                if phrase in text:\n",
    "                    proof_score += 1\n",
    "\n",
    "            for phrase in slight_disproof_phrases:\n",
    "                if phrase in text:\n",
    "                    disproof_score += 1\n",
    "\n",
    "    return proof_score, disproof_score\n",
    "\n",
    "\n",
    "# Function to search keywords\n",
    "def search_keywords(text, keywords):\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    text = str(text).lower()\n",
    "    return sum(1 for kw in keywords if re.search(r'\\b' + re.escape(kw.lower()) + r'\\b', text))\n",
    "\n",
    "#Function to classify exposures and check for disproof\n",
    "def classify_by_exposures_with_disproof(row, master_log):\n",
    "    \"\"\"\n",
    "    Extended-logging version:\n",
    "    master_log is the same list we pass around to accumulate all messages,\n",
    "    so we can see each branch check.\n",
    "    \"\"\"\n",
    "    master_log.append(\"===== BEGIN EXPOSURE DECISION TREE =====\")\n",
    "    \n",
    "    # Convert to numeric\n",
    "    exposure_cols = [\n",
    "        'cash_long', 'cash_net', 'cash_short',\n",
    "        'stock_long', 'stock_net', 'stock_short',\n",
    "        'bond_long', 'bond_net', 'bond_short',\n",
    "        'other_long', 'other_net', 'other_short'\n",
    "    ]\n",
    "    for col in exposure_cols:\n",
    "        val = pd.to_numeric(row[col], errors='coerce')\n",
    "        row[col] = 0 if pd.isna(val) else val\n",
    "\n",
    "    # Sum\n",
    "    long_total = (row['cash_long'] + row['stock_long'] \n",
    "                  + row['bond_long'] + row['other_long'])\n",
    "    short_total = (row['cash_short'] + row['stock_short'] \n",
    "                   + row['bond_short'] + row['other_short'])\n",
    "    other_total = (row['other_long'] + row['other_short'])\n",
    "\n",
    "    # Multiply by 100 => 1.0 => 100%\n",
    "    long_total_100 = long_total * 100\n",
    "    short_total_100 = short_total * 100\n",
    "    other_total_100 = other_total * 100\n",
    "\n",
    "    # Round\n",
    "    long_r = round(long_total_100, 4)\n",
    "    short_r = round(short_total_100, 4)\n",
    "    other_r = round(other_total_100, 4)\n",
    "\n",
    "    master_log.append(f\"Exposures => long={long_r}%, short={short_r}%, other={other_r}%\")\n",
    "\n",
    "    # Branch 1: \"Slight/None\" with proof vs. disproof\n",
    "    master_log.append(\n",
    "        f\"Branch 1 check: short<{1}?, other<{1}?, long<={100.2}? => short={short_r}, other={other_r}, long={long_r}\"\n",
    "    )\n",
    "    if abs(short_r) < 1 and abs(other_r) < 1 and long_r <= 100.2:\n",
    "        master_log.append(\"=> Candidate for Slight/None; checking proof vs. disproof phrases...\")\n",
    "\n",
    "        proof_score, disproof_score = tally_slight_none_proof_disproof(row)\n",
    "        master_log.append(f\"Proof score={proof_score}, Disproof score={disproof_score}\")\n",
    "\n",
    "        if disproof_score > proof_score:\n",
    "            master_log.append(\"Disproof > proof => skipping Slight/None => next branch...\")\n",
    "        else:\n",
    "            master_log.append(\"Slight/None => returning due to tie or higher proof.\")\n",
    "            return \"Slight/None\", f\"Slight/None (proof={proof_score}, disproof={disproof_score})\"\n",
    "\n",
    "    master_log.append(\"=> FAILED => next branch...\")\n",
    "\n",
    "    # Branch 2: \"Moderate\"\n",
    "    master_log.append(\n",
    "        f\"Branch 2 check: short<={10}?, other<={10}? => short={short_r}, other={other_r}\"\n",
    "    )\n",
    "    if short_r <= 10 and other_r <= 10:\n",
    "        master_log.append(\"=> PASSED => 'Moderate'\")\n",
    "        return \"Moderate\", \"Moderate\"\n",
    "\n",
    "    master_log.append(\"=> FAILED => next branch...\")\n",
    "\n",
    "    # Branch 3: \"Persistent Systematic\"\n",
    "    master_log.append(\n",
    "        f\"Branch 3 check: short<={50}? or other<={50}? => short={short_r}, other={other_r}\"\n",
    "    )\n",
    "    if short_r <= 50 or other_r <= 50:\n",
    "        master_log.append(\"=> PASSED => 'Persistent Systematic'\")\n",
    "        return \"Persistent Systematic\", \"Persistent Systematic\"\n",
    "\n",
    "    master_log.append(\"=> FAILED => next branch...\")\n",
    "\n",
    "    # Branch 4: \"Heavy Amplification\"\n",
    "    master_log.append(\n",
    "        f\"Branch 4 => short/other > 50% => => 'Heavy Amplification'\"\n",
    "    )\n",
    "    return \"Heavy Amplification\", \"Heavy Amplification\"\n",
    "\n",
    "def alternative_evaluation(row, scores, master_log):\n",
    "    # If you have alternative logic, put extended logging here.\n",
    "    master_log.append(\"===== BEGIN ALTERNATIVE EVALUATION =====\")\n",
    "    # Return (None, master_log) or a final classification with reason\n",
    "    return (None, master_log)\n",
    "\n",
    "def classify_fund(row):\n",
    "    audit_log = []\n",
    "\n",
    "    # 1) Fund family override\n",
    "    if pd.notna(row['fund_family']) and (\"return stacked etfs\" in row['fund_family'].lower()):\n",
    "        audit_log.append(\n",
    "            \"FUND FAMILY OVERRIDE => 'Return Stacked ETFs' => Persistent Systematic\"\n",
    "        )\n",
    "        return \"Persistent Systematic\", audit_log\n",
    "\n",
    "    # 2) Direct keyword mapping\n",
    "    for category, keywords in direct_keyword_mappings.items():\n",
    "        for field in ['ProductName', 'investment_strategy', 'FS_insight']:\n",
    "            if pd.notna(row[field]):\n",
    "                count = search_keywords(row[field], keywords)\n",
    "                if count > 0:\n",
    "                    audit_log.append(f\"DIRECT KEYWORD => {category} from {field} match\")\n",
    "                    return category, audit_log\n",
    "\n",
    "    # 3) Direct category mapping\n",
    "    for category, mappings in direct_category_mappings.items():\n",
    "        for db_field, values in mappings.items():\n",
    "            vals_lower = [v.lower() for v in values]\n",
    "            field_val = safe_lower(row.get(db_field, ''))\n",
    "            if field_val in vals_lower:\n",
    "                audit_log.append(f\"DIRECT CATEGORY => {category} from {db_field}={field_val}\")\n",
    "                return category, audit_log\n",
    "\n",
    "    # 4) Boolean exclusions\n",
    "    possible_categories = [\"Slight/None\", \"Moderate\", \"Persistent Systematic\", \"Heavy Amplification\"]\n",
    "    for cats_to_exclude, condition_fn in boolean_exclusions.items():\n",
    "        if condition_fn(row):\n",
    "            # i.e. if fund is leveraged => exclude \"Slight/None\" and \"Moderate\"\n",
    "            excluded = [c for c in cats_to_exclude if c in possible_categories]\n",
    "            for c in excluded:\n",
    "                possible_categories.remove(c)\n",
    "            audit_log.append(\n",
    "                f\"BOOLEAN EXCLUSION => Excluding {excluded} for leveraged/inverse/synthetic\"\n",
    "            )\n",
    "            if len(possible_categories) == 1:\n",
    "                # Only one left\n",
    "                final_cat = possible_categories[0]\n",
    "                audit_log.append(f\"Only {final_cat} remains => final classification\")\n",
    "                return final_cat, audit_log\n",
    "\n",
    "    # 5) Exposure-based classification\n",
    "    classification, reason = classify_by_exposures_with_disproof(row, audit_log)\n",
    "    audit_log.append(f\"Exposure-based => {classification} => {reason}\")\n",
    "    return classification, audit_log\n",
    "\n",
    "\n",
    "def sanitize_excel_text(value):\n",
    "    \"\"\"Convert or escape characters that can break Excel's XML.\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return value\n",
    "    text = str(value)\n",
    "    # Replace angle brackets so they don't break Excel's XML\n",
    "    text = text.replace(\"<\", \"[lt]\").replace(\">\", \"[gt]\")\n",
    "\n",
    "    # If lines start with '=', '+', '-', or '@', prefix with \"'\" \n",
    "    # so Excel doesn't parse it as a formula\n",
    "    if text.startswith((\"=\", \"+\", \"-\", \"@\")):\n",
    "        text = \"'\" + text\n",
    "\n",
    "    return text\n",
    "\n",
    "# Main function to run the script\n",
    "def main():\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        f.SymbolCUSIP, f.ProductName, f.fund_family, f.investment_strategy, f.FS_insight,\n",
    "        f.index_fund, f.inverse_fund, f.leveraged_fund, f.synthetic_replication_fund,\n",
    "        f.fund_of_funds, f.ycharts_url, f.currency_hedged_fund,\n",
    "        f.cash_long, f.cash_net, f.cash_short, f.stock_long, f.stock_net, f.stock_short,\n",
    "        f.bond_long, f.bond_net, f.bond_short, f.other_long, f.other_net, f.other_short,\n",
    "        f.return_driver, f.YC_BM_Symbol,\n",
    "        cwa.CWA_Broad_Category_Name,\n",
    "        yc.Category_Name AS YC_Category_Name,\n",
    "        ycg.Global_Category_Name,\n",
    "        ycba.YC_Broad_Asset_Class_Name\n",
    "    FROM Funds_to_Screen f\n",
    "    LEFT JOIN CWA_Broad_Category_List cwa ON f.CWA_Broad_Category_ID = cwa.ID\n",
    "    LEFT JOIN YC_Category_List yc ON f.YC_Category_ID = yc.ID\n",
    "    LEFT JOIN YC_Global_Category_List ycg ON f.YC_Global_Category_ID = ycg.ID\n",
    "    LEFT JOIN YC_Broad_Asset_Class_List ycba ON f.YC_Broad_Asset_Class_ID = ycba.ID\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_sql(query, engine)\n",
    "\n",
    "    results = []\n",
    "    for idx, row in df.iterrows():\n",
    "        classification, local_log = classify_fund(row)\n",
    "        newrow = row.copy()\n",
    "        newrow['Final_Classification'] = classification\n",
    "        newrow['Audit_Log'] = \"; \".join(local_log)\n",
    "        results.append(newrow)\n",
    "\n",
    "    outdf = pd.DataFrame(results)\n",
    "\n",
    "    # Order columns\n",
    "    columns_front = [\n",
    "        'SymbolCUSIP','ProductName','fund_family','Final_Classification','ycharts_url'\n",
    "    ]\n",
    "    other_cols = [c for c in outdf.columns if c not in columns_front]\n",
    "    outdf = outdf[columns_front + other_cols]\n",
    "\n",
    "    output_path = r\"C:\\Users\\JulianHeron\\Software Projects\\Risk_Overlays_V4.3_ExtLog_PRV_DPRV.xlsx\"\n",
    "    outdf.to_excel(output_path, index=False)\n",
    "    print(f\"Exported v4.3 Extended Logging => {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9470d3f5-b1ae-4a9f-b933-668486e52fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat GPT unified code for proof/ disproof or disproof on all categories\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import os\n",
    "\n",
    "###############################################################################\n",
    "#  (A) ON/OFF FLAGS FOR PROOF/DISPROOF IN EACH BRANCH\n",
    "###############################################################################\n",
    "USE_PROOF_DISPROOF_SLIGHT = True\n",
    "USE_PROOF_DISPROOF_MODERATE = True\n",
    "USE_PROOF_DISPROOF_PERSISTENT = True\n",
    "USE_PROOF_DISPROOF_HEAVY = True\n",
    "\n",
    "# If you want the old “keyword disproof” approach from v4.2 for these categories,\n",
    "# set the respective flags to False, or vice versa. \n",
    "# You can also combine them (some branches use proof vs disproof, others use older approach).\n",
    "\n",
    "###############################################################################\n",
    "#  (B) HELPER / WEAK HELPER CATEGORY MAPPINGS\n",
    "###############################################################################\n",
    "helper_category_mappings = {\n",
    "    (\"Persistent Systematic\", \"Heavy Amplification\"): {\n",
    "        \"YC_Category\": [\n",
    "            \"Trading--Inverse Commodities\", \"Trading--Inverse Debt\",\n",
    "            \"Trading--Inverse Equity\", \"Trading--Miscellaneous\"\n",
    "        ],\n",
    "        \"CWA_Broad_Category\": [\"Trading/Tactical\"],\n",
    "        \"YC_Global_Category\": [\"Trading Tools\"]\n",
    "    },\n",
    "    (\"Persistent Systematic\", \"Moderate\"): {\n",
    "        \"YC_Global_Category\": [\"Multialternative\", \"Long/Short Equity\"],\n",
    "        \"YC_Category\": [\"Equity Hedged\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "weak_helper_category_mappings = {\n",
    "    (\"Slight/None\", \"Moderate\"): {\n",
    "        \"YC_Global_Category\": [\"Flexible Allocation\", \"Alternative Miscellaneous\"],\n",
    "        \"return_driver\": [\"Index Based\", \"Factor/Smart Beta\"]\n",
    "    },\n",
    "    (\"Slight/None\", \"Moderate\", \"Persistent Systematic\"): {\n",
    "        \"YC_Category\": [\"Relative Value Arbitrage\"]\n",
    "    },\n",
    "    (\"Heavy Amplification\", \"Persistent Systematic\", \"Moderate\", \"Slight/None\"): {\n",
    "        \"return_driver\": [\"Quant/Systematic\"]\n",
    "    },\n",
    "    (\"Persistent Systematic\", \"Moderate\", \"Slight/None\"): {\n",
    "        \"return_driver\": [\"Active Discretionary\", \"Multi-Strategy\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "###############################################################################\n",
    "#  (C) PROOF / DISPROOF PHRASES FOR EACH BRANCH\n",
    "###############################################################################\n",
    "# Slight/None proof & disproof from prior conversation:\n",
    "slight_proof_phrases = [\n",
    "    \"used for minor duration or risk tweaks\",\n",
    "    \"occasional use for limited exposure adjustments\",\n",
    "    # ... etc ...\n",
    "]\n",
    "slight_disproof_phrases = [\n",
    "    \"systematically uses derivatives\",\n",
    "    \"long-short\",\n",
    "    # ... etc ...\n",
    "]\n",
    "\n",
    "# Similarly, if you want “proof vs. disproof” for Moderate, \n",
    "# you can define them here:\n",
    "moderate_proof_phrases = [\n",
    "    \"protected puts\",\n",
    "    # (examples - expand as needed)\n",
    "]\n",
    "moderate_disproof_phrases = [\n",
    "    \"aggressive shorting\",\n",
    "    # (examples - expand as needed)\n",
    "]\n",
    "\n",
    "# Same for Persistent Systematic:\n",
    "persistent_proof_phrases = [\n",
    "    \"uses derivatives occasionally for alpha\",\n",
    "]\n",
    "persistent_disproof_phrases = [\n",
    "    \"massive leverage\",\n",
    "]\n",
    "\n",
    "# Same for Heavy Amplification:\n",
    "heavy_proof_phrases = [\n",
    "    \"only doubles exposure occasionally\",\n",
    "]\n",
    "heavy_disproof_phrases = [\n",
    "    \"strictly long-only\",\n",
    "    \"no leverage ever used\"\n",
    "]\n",
    "\n",
    "###############################################################################\n",
    "#  (D) HELPER FUNCTIONS\n",
    "###############################################################################\n",
    "\n",
    "def sanitize_excel_text(value):\n",
    "    \"\"\"Avoid Excel formula/angle bracket issues.\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return value\n",
    "    text = str(value)\n",
    "    # Replace < and >\n",
    "    text = text.replace(\"<\", \"[lt]\").replace(\">\", \"[gt]\")\n",
    "    # If starts with certain chars, prefix with '\n",
    "    if text.startswith((\"=\", \"+\", \"-\", \"@\")):\n",
    "        text = \"'\" + text\n",
    "    return text\n",
    "\n",
    "def safe_lower(value):\n",
    "    \"\"\"Safe lower for text columns.\"\"\"\n",
    "    return value.lower() if isinstance(value, str) else \"\"\n",
    "\n",
    "def search_keywords(text, keywords):\n",
    "    \"\"\"v4.2 approach: does the text contain any of these keywords?\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    text = str(text).lower()\n",
    "    return sum(1 for kw in keywords if re.search(r'\\b' + re.escape(kw.lower()) + r'\\b', text))\n",
    "\n",
    "###############################################################################\n",
    "#  (E) TALLY PROOF / DISPROOF FOR A GIVEN BRANCH\n",
    "###############################################################################\n",
    "def tally_proof_disproof(row, proof_list, disproof_list):\n",
    "    \"\"\"Returns (matched_proof, matched_disproof, proof_score, disproof_score).\"\"\"\n",
    "    matched_proof = []\n",
    "    matched_disproof = []\n",
    "    for field in [\"ProductName\", \"investment_strategy\", \"FS_insight\"]:\n",
    "        if pd.notna(row[field]):\n",
    "            text = row[field].lower()\n",
    "            for phrase in proof_list:\n",
    "                if phrase in text:\n",
    "                    matched_proof.append(phrase)\n",
    "            for phrase in disproof_list:\n",
    "                if phrase in text:\n",
    "                    matched_disproof.append(phrase)\n",
    "    # De-dup\n",
    "    matched_proof = list(set(matched_proof))\n",
    "    matched_disproof = list(set(matched_disproof))\n",
    "\n",
    "    return matched_proof, matched_disproof, len(matched_proof), len(matched_disproof)\n",
    "\n",
    "###############################################################################\n",
    "#  (F) DISPROOF KEYWORDS FROM v4.2 FOR THE \"OLD\" APPROACH\n",
    "###############################################################################\n",
    "disproof_keywords_v4_2 = {\n",
    "    \"Slight/None\": [\n",
    "        \"derivatives\", \"swaps\", \"futures\", \"short\", \"hedge\", \"long-short\",\n",
    "        \"inverse\", \"leveraged\", \"tail risk\", \"tail-risk\"\n",
    "    ],\n",
    "    \"Moderate\": [\n",
    "        \"systematic\", \"trend-following\", \"2x\", \"3x\", \"market neutral\",\n",
    "        \"quantitative hedging\", \"managed futures\", \"managed futures strategy\",\n",
    "        \"trend strategy\", \"yieldmax\", \"tail risk\", \"tail-risk\"\n",
    "    ],\n",
    "    \"Persistent Systematic\": [\"2x\", \"3x\", \"-2x\", \"-3x\", \"uncapped accelerator\"],\n",
    "    \"Heavy Amplification\": [\"long-only\", \"no derivatives\", \"no short\"]\n",
    "}\n",
    "\n",
    "def has_disproof_v4_2(category, row, audit_log):\n",
    "    \"\"\"Same as the older v4.2 approach: if any disproof keyword appears, return True.\"\"\"\n",
    "    if category not in disproof_keywords_v4_2:\n",
    "        return False\n",
    "    found_matches = []\n",
    "    for field in [\"ProductName\", \"investment_strategy\", \"FS_insight\"]:\n",
    "        text = str(row.get(field, \"\")).lower()\n",
    "        for kw in disproof_keywords_v4_2[category]:\n",
    "            if re.search(r'\\b' + re.escape(kw.lower()) + r'\\b', text):\n",
    "                found_matches.append(kw)\n",
    "    if found_matches:\n",
    "        unique_hits = list(set(found_matches))\n",
    "        audit_log.append(f\"Disproof for {category} => {unique_hits}\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "###############################################################################\n",
    "#  (G) EXPOSURE-BASED CLASSIFICATION – WITH FLAGS\n",
    "###############################################################################\n",
    "def classify_by_exposures_with_proof_disproof(row, audit_log):\n",
    "    # Convert exposures to numeric\n",
    "    exposure_cols = [\n",
    "        'cash_long', 'cash_net', 'cash_short',\n",
    "        'stock_long', 'stock_net', 'stock_short',\n",
    "        'bond_long', 'bond_net', 'bond_short',\n",
    "        'other_long', 'other_net', 'other_short'\n",
    "    ]\n",
    "    for col in exposure_cols:\n",
    "        val = pd.to_numeric(row[col], errors='coerce')\n",
    "        row[col] = 0 if pd.isna(val) else val\n",
    "\n",
    "    # Sum\n",
    "    long_total = row['cash_long'] + row['stock_long'] + row['bond_long'] + row['other_long']\n",
    "    short_total = row['cash_short'] + row['stock_short'] + row['bond_short'] + row['other_short']\n",
    "    other_total = row['other_long'] + row['other_short']\n",
    "\n",
    "    # Multiply by 100\n",
    "    long_r = round(long_total * 100, 4)\n",
    "    short_r = round(short_total * 100, 4)\n",
    "    other_r = round(other_total * 100, 4)\n",
    "\n",
    "    audit_log.append(f\"[Exposure] long={long_r}%, short={short_r}%, other={other_r}%\")\n",
    "\n",
    "    # BRANCH 1: SLIGHT/NONE\n",
    "    audit_log.append(\"Branch 1: Slight/None check => short<1%, other<1%, long<=100.2%\")\n",
    "    if short_r < 1 and other_r < 1 and long_r <= 100.2:\n",
    "        # If USE_PROOF_DISPROOF_SLIGHT => do the proof/disproof approach\n",
    "        if USE_PROOF_DISPROOF_SLIGHT:\n",
    "            matched_proof, matched_disproof, p_score, d_score = tally_proof_disproof(\n",
    "                row,\n",
    "                slight_proof_phrases,\n",
    "                slight_disproof_phrases\n",
    "            )\n",
    "            audit_log.append(f\"SLIGHT/NONE proof hits => {matched_proof}\")\n",
    "            audit_log.append(f\"SLIGHT/NONE disproof hits => {matched_disproof}\")\n",
    "            if d_score > p_score:\n",
    "                audit_log.append(\"Slight/None disproof > proof => next branch.\")\n",
    "            else:\n",
    "                audit_log.append(\"Slight/None => pass => returning.\")\n",
    "                return \"Slight/None\", \"Proof/Disproof\"\n",
    "        else:\n",
    "            # Old v4.2 disproof approach\n",
    "            if has_disproof_v4_2(\"Slight/None\", row, audit_log):\n",
    "                audit_log.append(\"Slight/None disproof triggered => next branch.\")\n",
    "            else:\n",
    "                audit_log.append(\"Slight/None => returning (no disproof).\")\n",
    "                return \"Slight/None\", \"No disproof\"\n",
    "    audit_log.append(\"... did not pass => next branch...\")\n",
    "\n",
    "    # BRANCH 2: MODERATE\n",
    "    audit_log.append(\"Branch 2: Moderate => short<=10%, other<=10%\")\n",
    "    if short_r <= 10 and other_r <= 10:\n",
    "        if USE_PROOF_DISPROOF_MODERATE:\n",
    "            matched_proof, matched_disproof, p_score, d_score = tally_proof_disproof(\n",
    "                row,\n",
    "                moderate_proof_phrases,\n",
    "                moderate_disproof_phrases\n",
    "            )\n",
    "            audit_log.append(f\"MODERATE proof hits => {matched_proof}\")\n",
    "            audit_log.append(f\"MODERATE disproof hits => {matched_disproof}\")\n",
    "            if d_score > p_score:\n",
    "                audit_log.append(\"Moderate disproof>proof => next branch.\")\n",
    "            else:\n",
    "                audit_log.append(\"Moderate => returning.\")\n",
    "                return \"Moderate\", \"Proof/Disproof\"\n",
    "        else:\n",
    "            if has_disproof_v4_2(\"Moderate\", row, audit_log):\n",
    "                audit_log.append(\"Moderate disproof => next branch.\")\n",
    "            else:\n",
    "                audit_log.append(\"Moderate => returning.\")\n",
    "                return \"Moderate\", \"No disproof\"\n",
    "    audit_log.append(\"... did not pass => next branch...\")\n",
    "\n",
    "    # BRANCH 3: PERSISTENT SYSTEMATIC\n",
    "    audit_log.append(\"Branch 3: short<=50% or other<=50% => Persistent Systematic\")\n",
    "    if short_r <= 50 or other_r <= 50:\n",
    "        if USE_PROOF_DISPROOF_PERSISTENT:\n",
    "            matched_proof, matched_disproof, p_score, d_score = tally_proof_disproof(\n",
    "                row,\n",
    "                persistent_proof_phrases,\n",
    "                persistent_disproof_phrases\n",
    "            )\n",
    "            audit_log.append(f\"PERSISTENT proof hits => {matched_proof}\")\n",
    "            audit_log.append(f\"PERSISTENT disproof hits => {matched_disproof}\")\n",
    "            if d_score > p_score:\n",
    "                audit_log.append(\"Persistent disproof>proof => next branch.\")\n",
    "            else:\n",
    "                audit_log.append(\"Persistent => returning.\")\n",
    "                return \"Persistent Systematic\", \"Proof/Disproof\"\n",
    "        else:\n",
    "            if has_disproof_v4_2(\"Persistent Systematic\", row, audit_log):\n",
    "                audit_log.append(\"Persistent disproof => next branch.\")\n",
    "            else:\n",
    "                audit_log.append(\"Persistent => returning.\")\n",
    "                return \"Persistent Systematic\", \"No disproof\"\n",
    "    audit_log.append(\"... did not pass => next branch...\")\n",
    "\n",
    "    # BRANCH 4: HEAVY AMPLIFICATION\n",
    "    audit_log.append(\"Branch 4 => 'Heavy Amplification'\")\n",
    "    if USE_PROOF_DISPROOF_HEAVY:\n",
    "        matched_proof, matched_disproof, p_score, d_score = tally_proof_disproof(\n",
    "            row,\n",
    "            heavy_proof_phrases,\n",
    "            heavy_disproof_phrases\n",
    "        )\n",
    "        audit_log.append(f\"HEAVY proof hits => {matched_proof}\")\n",
    "        audit_log.append(f\"HEAVY disproof hits => {matched_disproof}\")\n",
    "        if d_score > p_score:\n",
    "            # Typically there's nowhere else to go, so we still finalize Heavy\n",
    "            audit_log.append(\"Heavy disproof>proof => but no next branch => return Heavy anyway.\")\n",
    "        else:\n",
    "            audit_log.append(\"Heavy => returning.\")\n",
    "        return \"Heavy Amplification\", \"Proof/Disproof\"\n",
    "    else:\n",
    "        if has_disproof_v4_2(\"Heavy Amplification\", row, audit_log):\n",
    "            audit_log.append(\"Heavy disproof => no next branch => still Heavy by default.\")\n",
    "        return \"Heavy Amplification\", \"No disproof\"\n",
    "\n",
    "###############################################################################\n",
    "#  (H) ALTERNATIVE EVALUATION & TIEBREAKS – v4.2 RESTORED\n",
    "###############################################################################\n",
    "def alternative_evaluation(row, scores, audit_log):\n",
    "    # This is the old “score each category” approach from v4.2 if needed\n",
    "    audit_log.append(\"Entering Alternative Evaluation from v4.2 ...\")\n",
    "\n",
    "    # For example\n",
    "    possible_categories = [\"Slight/None\", \"Moderate\", \"Persistent Systematic\", \"Heavy Amplification\"]\n",
    "    # You might do more scoring logic, referencing row's fields\n",
    "    # ...\n",
    "    # Return final or None\n",
    "    return \"Slight/None\", audit_log  # Example fallback\n",
    "\n",
    "###############################################################################\n",
    "#  (I) MASTER CLASSIFICATION FUNCTION – REINTRODUCING HELPER/WEAK MAPPINGS, TIEBREAKS, ETC.\n",
    "###############################################################################\n",
    "def classify_fund(row):\n",
    "    audit_log = []\n",
    "    possible_categories = [\"Slight/None\", \"Moderate\", \"Persistent Systematic\", \"Heavy Amplification\"]\n",
    "    scores = {cat: 0 for cat in possible_categories}\n",
    "\n",
    "    # (I.1) Step 1: Override for Fund Family \"Return Stacked ETFs\"\n",
    "    if pd.notna(row['fund_family']) and \"return stacked etfs\" in row['fund_family'].lower():\n",
    "        audit_log.append(\"Fund Family => 'Return Stacked ETFs' => Persistent Systematic override\")\n",
    "        return \"Persistent Systematic\", audit_log\n",
    "\n",
    "    # (I.2) Step 2: Direct keyword mapping\n",
    "    direct_keyword_mappings = {\n",
    "        \"Persistent Systematic\": [\"Market Neutral\", \"managed futures\", \"Premia\", \"Return Stacked ETFs\"],\n",
    "        \"Heavy Amplification\": [\"2x\", \"3x\", \"Uncapped Accelerator\", \"-2x\", \"-3x\", \"YieldMax\"]\n",
    "    }\n",
    "    for category, keywords in direct_keyword_mappings.items():\n",
    "        for field in ['ProductName', 'investment_strategy', 'FS_insight']:\n",
    "            textval = safe_lower(row[field])\n",
    "            for kw in keywords:\n",
    "                if kw.lower() in textval:\n",
    "                    audit_log.append(f\"Direct Keyword => {category} from {field} match: {kw}\")\n",
    "                    return category, audit_log\n",
    "\n",
    "    # (I.3) Step 3: Direct category mapping\n",
    "    direct_category_mappings = {\n",
    "        \"Persistent Systematic\": {\n",
    "            \"YC_Category\": [\"Defined Outcome\"],\n",
    "            \"CWA_Broad_Category\": [\"Defined Outcome\"],\n",
    "            \"YC_Global_Category\": [\"market neutral\"]\n",
    "        },\n",
    "        \"Heavy Amplification\": {\n",
    "            \"YC_Category\": [\n",
    "                \"Trading--Leveraged Equity\", \"Trading--Leveraged Debt\", \"Trading--Leveraged Commodities\"\n",
    "            ],\n",
    "            \"CWA_Broad_Category\": [\"Single Stock\"]\n",
    "        }\n",
    "    }\n",
    "    for category, mappings in direct_category_mappings.items():\n",
    "        for db_field, vals in mappings.items():\n",
    "            fieldval = safe_lower(row.get(db_field, \"\"))\n",
    "            vals_lower = [v.lower() for v in vals]\n",
    "            if fieldval in vals_lower:\n",
    "                audit_log.append(f\"Direct Category => {category} in {db_field}: {fieldval}\")\n",
    "                return category, audit_log\n",
    "\n",
    "    # (I.4) Step 4: Boolean exclusions\n",
    "    boolean_exclusions = {\n",
    "        (\"Slight/None\", \"Moderate\"): lambda r: r['leveraged_fund'] in [True, 1]\n",
    "            or r['synthetic_replication_fund'] in [True, 1]\n",
    "            or r['inverse_fund'] in [True, 1]\n",
    "    }\n",
    "    for cats_tuple, cond_fn in boolean_exclusions.items():\n",
    "        if cond_fn(row):\n",
    "            excluded = [c for c in possible_categories if c in cats_tuple]\n",
    "            for c in excluded:\n",
    "                possible_categories.remove(c)\n",
    "            audit_log.append(f\"Boolean Exclusions => removed {excluded} (inverse/leveraged).\")\n",
    "            if len(possible_categories) == 1:\n",
    "                finalcat = possible_categories[0]\n",
    "                audit_log.append(f\"Only {finalcat} remains => final classification\")\n",
    "                return finalcat, audit_log\n",
    "\n",
    "    # (I.5) Step 5: Exposure-based classification with proof/disproof\n",
    "    exposure_result = classify_by_exposures_with_proof_disproof(row, audit_log)\n",
    "    if isinstance(exposure_result, tuple) and len(exposure_result) == 2:\n",
    "        classification, reason = exposure_result\n",
    "        audit_log.append(f\"Exposure-based => {classification}, reason={reason}\")\n",
    "        return classification, audit_log\n",
    "\n",
    "    # (I.6) If None or ambiguous => alternative evaluation\n",
    "    # If classify_by_exposures_with_proof_disproof returned something else\n",
    "    if exposure_result[0] is None:\n",
    "        # old logic we had in v4.2\n",
    "        scores_update = exposure_result[1]\n",
    "        for cat in scores_update:\n",
    "            scores[cat] += scores_update[cat]\n",
    "        classification, alt_log = alternative_evaluation(row, scores, audit_log)\n",
    "        for line in alt_log:\n",
    "            audit_log.append(line)\n",
    "        return classification, audit_log\n",
    "    elif isinstance(exposure_result, tuple):\n",
    "        # Some leftover path\n",
    "        possible_categories, scores_dict, exposure_log = exposure_result\n",
    "        for line in exposure_log:\n",
    "            audit_log.append(line)\n",
    "        for cat, val in scores_dict.items():\n",
    "            scores[cat] += val\n",
    "\n",
    "    # (I.7) Final scoring if no immediate classification\n",
    "    max_score = max(scores.values())\n",
    "    top_cats = [c for c in possible_categories if scores[c] == max_score]\n",
    "    if len(top_cats) == 1:\n",
    "        final = top_cats[0]\n",
    "        audit_log.append(f\"Final => {final} with score={max_score}\")\n",
    "        return final, audit_log\n",
    "    else:\n",
    "        # Tiebreaker approach from v4.2\n",
    "        tiebreak_scores = {c: 0 for c in top_cats}\n",
    "        # Possibly check text fields for category keywords, etc.\n",
    "        audit_log.append(f\"Tiebreaker among {top_cats} => {tiebreak_scores}\")\n",
    "        # For simplicity, pick the most conservative \n",
    "        # (Slight/None < Moderate < Persistent < Heavy)\n",
    "        order = [\"Slight/None\", \"Moderate\", \"Persistent Systematic\", \"Heavy Amplification\"]\n",
    "        final = min(top_cats, key=lambda x: order.index(x))\n",
    "        audit_log.append(f\"Chosen final => {final}\")\n",
    "        return final, audit_log\n",
    "\n",
    "###############################################################################\n",
    "#  (J) MAIN\n",
    "###############################################################################\n",
    "def main():\n",
    "    connection_string = (\n",
    "        \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/\"\n",
    "        \"CWA_Fund_Database?driver=ODBC+Driver+18+for+SQL+Server\"\n",
    "        \"&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    "    )\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        f.SymbolCUSIP, f.ProductName, f.fund_family, f.investment_strategy, f.FS_insight,\n",
    "        f.index_fund, f.inverse_fund, f.leveraged_fund, f.synthetic_replication_fund,\n",
    "        f.fund_of_funds, f.ycharts_url, f.currency_hedged_fund,\n",
    "        f.cash_long, f.cash_net, f.cash_short, f.stock_long, f.stock_net, f.stock_short,\n",
    "        f.bond_long, f.bond_net, f.bond_short, f.other_long, f.other_net, f.other_short,\n",
    "        f.return_driver, f.YC_BM_Symbol,\n",
    "        cwa.CWA_Broad_Category_Name as CWA_Broad_Category,\n",
    "        yc.Category_Name AS YC_Category,\n",
    "        ycg.Global_Category_Name as YC_Global_Category,\n",
    "        ycba.YC_Broad_Asset_Class_Name\n",
    "    FROM Funds_to_Screen f\n",
    "    LEFT JOIN CWA_Broad_Category_List cwa ON f.CWA_Broad_Category_ID = cwa.ID\n",
    "    LEFT JOIN YC_Category_List yc ON f.YC_Category_ID = yc.ID\n",
    "    LEFT JOIN YC_Global_Category_List ycg ON f.YC_Global_Category_ID = ycg.ID\n",
    "    LEFT JOIN YC_Broad_Asset_Class_List ycba ON f.YC_Broad_Asset_Class_ID = ycba.ID\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_sql(query, engine)\n",
    "\n",
    "    results = []\n",
    "    for idx, row in df.iterrows():\n",
    "        classification, audit_log = classify_fund(row)\n",
    "        newrow = row.copy()\n",
    "        newrow['Final_Classification'] = classification\n",
    "        newrow['Audit_Log'] = \"; \".join(audit_log)\n",
    "        results.append(newrow)\n",
    "\n",
    "    outdf = pd.DataFrame(results)\n",
    "\n",
    "    # sanitize\n",
    "    outdf[\"Audit_Log\"] = outdf[\"Audit_Log\"].apply(sanitize_excel_text)\n",
    "\n",
    "    # reorder columns\n",
    "    front_cols = [\"SymbolCUSIP\", \"ProductName\", \"fund_family\", \"Final_Classification\", \"ycharts_url\"]\n",
    "    other_cols = [c for c in outdf.columns if c not in front_cols]\n",
    "    outdf = outdf[front_cols + other_cols]\n",
    "\n",
    "    out_path = r\"C:\\Users\\JulianHeron\\Software Projects\\Risk_Overlays_V4.5_Flags.xlsx\"\n",
    "    outdf.to_excel(out_path, index=False)\n",
    "    print(f\"Exported => {out_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff8f843-9b19-4fb9-bda4-6ce0d5ed8b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef914b4-680f-4443-a8a1-97ae1922e559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eb452a-ebf5-4ff6-a299-3e60131a5415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67db5d3f-41c5-488f-b9f9-8c3890acd0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5163fbc6-b0cf-483f-b70a-cd025402463d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3748cd70-996c-483c-8d2a-6c22d4e4cc78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf8ade6-75d1-4caf-bf7b-852c3dc1512a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7611fb09-2c0c-4549-958a-e3d9ad1cae82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Database Administration)",
   "language": "python",
   "name": "databaseadminenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
