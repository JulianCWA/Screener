{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9043d88-4b64-4872-a9dd-d7563aef0e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R initializer code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3b657ab-4992-4324-8177-644c90b077c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_r_environment():\n",
    "    import os\n",
    "\n",
    "    # üîí Set environment variables BEFORE importing anything from rpy2\n",
    "    os.environ['R_HOME'] = r'C:\\\\Program Files\\\\R\\\\R-4.4.3'\n",
    "    os.environ['R_JIT_ENABLED'] = '0'\n",
    "\n",
    "    # Now import RPy2 safely\n",
    "    import logging\n",
    "    import rpy2.rinterface_lib.callbacks\n",
    "    import rpy2.robjects as ro\n",
    "    from rpy2.robjects.packages import importr\n",
    "    from rpy2.robjects import pandas2ri\n",
    "\n",
    "    # Suppress console spam\n",
    "    rpy2.rinterface_lib.callbacks.logger.setLevel(logging.ERROR)\n",
    "\n",
    "    # Print test R version\n",
    "    try:\n",
    "        print(\"üîÅ R Version:\", ro.r('R.version.string')[0])\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Could not connect to R:\", e)\n",
    "        return None\n",
    "\n",
    "    # Load required packages\n",
    "    try:\n",
    "        aqrr = importr('aqrr')\n",
    "        print(\"‚úÖ Loaded R package: aqrr\")\n",
    "        funcs = ro.r('ls(\"package:aqrr\")')\n",
    "        print(f\"üì¶ AQRR Functions Available: {list(funcs)[:6]} ...\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Failed to load 'aqrr':\", e)\n",
    "        return None\n",
    "\n",
    "    # Enable pandas ‚Üî R dataframe conversion\n",
    "    pandas2ri.activate()\n",
    "\n",
    "    return aqrr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d0732e2-34b0-4829-a901-c2871d1d6152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ R Version: R version 4.4.3 (2025-02-28 ucrt)\n",
      "‚úÖ Loaded R package: aqrr\n",
      "üì¶ AQRR Functions Available: [':=', 'aqr_bab_daily', 'aqr_bab_monthly', 'aqr_commodities_long_run', 'aqr_credit_risk_premium', 'aqr_factor_premia_monthly'] ...\n"
     ]
    }
   ],
   "source": [
    "aqrr = initialize_r_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932e6119-fd2f-4489-85f2-8d94f3a4b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  The code below is to run Factor regressions on funds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598c6e95-3e08-44ea-8324-60872c30a97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10efae11-57ce-4f9e-8102-35e56136afb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "from datetime import timedelta, datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from sqlalchemy import create_engine, text\n",
    "from tqdm import tqdm\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan, acorr_breusch_godfrey\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Section 1: Configuration and Setup\n",
    "connection_string = (\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/CWA_Fund_Database\"\n",
    "    \"?driver=ODBC+Driver+18+for+SQL+Server\"\n",
    "    \"&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "RETURN_METRIC = \"1 Month Return\"\n",
    "ROLLING_PERIODS = [12, 24, 36, 48, 60]  # in months\n",
    "DRY_RUN = True\n",
    "SAMPLE_DRY_RUN = True\n",
    "SAMPLE_SIZE = 100\n",
    "CHUNK_SIZE = 5600\n",
    "BATCH_INSERT_SIZE = 10000\n",
    "\n",
    "# Section 2: Data Source Initialization\n",
    "def initialize_r_environment():\n",
    "    import os\n",
    "    os.environ['R_HOME'] = r'C:\\\\Program Files\\\\R\\\\R-4.4.3'\n",
    "    os.environ['R_JIT_ENABLED'] = '0'\n",
    "    import logging\n",
    "    import rpy2.rinterface_lib.callbacks\n",
    "    import rpy2.robjects as ro\n",
    "    from rpy2.robjects.packages import importr\n",
    "    from rpy2.robjects import pandas2ri\n",
    "    rpy2.rinterface_lib.callbacks.logger.setLevel(logging.ERROR)\n",
    "    try:\n",
    "        version = ro.r('R.version.string')[0]\n",
    "        print(f\"üîÅ R Version: {version}\")\n",
    "        logging.info(f\"R initialized successfully: {version}\")\n",
    "    except (OSError, ValueError) as e:\n",
    "        print(f\"‚ùå Could not connect to R: {e}\")\n",
    "        logging.warning(f\"Could not connect to R: {e}\")\n",
    "        return None\n",
    "    try:\n",
    "        aqrr = importr('aqrr')\n",
    "        ro.r('library(dplyr)')\n",
    "        print(\"‚úÖ Loaded R package: aqrr\")\n",
    "        funcs = ro.r('ls(\"package:aqrr\")')\n",
    "        print(f\"üì¶ AQRR Functions Available: {list(funcs)[:6]} ...\")\n",
    "        logging.info(\"AQRR package loaded successfully\")\n",
    "    except ImportError as e:\n",
    "        print(f\"‚ùå Failed to load 'aqrr': {e}\")\n",
    "        logging.warning(f\"Failed to load 'aqrr': {e}\")\n",
    "        return None\n",
    "    pandas2ri.activate()\n",
    "    return aqrr\n",
    "\n",
    "# Section 3: Data Loading Functions\n",
    "def load_fund_metadata():\n",
    "    query = \"\"\"\n",
    "    SELECT f.SymbolCUSIP, f.YC_Global_Category_ID, c.Global_Category_Name\n",
    "    FROM Funds_to_Screen f\n",
    "    JOIN YC_Global_Category_List c ON f.YC_Global_Category_ID = c.ID\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, engine)\n",
    "    df[[\"Region\", \"FactorProfile\"]] = df[\"Global_Category_Name\"].map(category_to_region).apply(pd.Series)\n",
    "    return df.dropna(subset=[\"Region\", \"FactorProfile\"])\n",
    "\n",
    "def load_fund_returns(fund_ids):\n",
    "    placeholders = \",\".join([f\"'{fid}'\" for fid in fund_ids])\n",
    "    query = f\"\"\"\n",
    "        SELECT SymbolCUSIP, Date, ReturnValue\n",
    "        FROM Fund_Returns_Timeseries\n",
    "        WHERE SymbolCUSIP IN ({placeholders})\n",
    "        AND Metric = '{RETURN_METRIC}'\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, engine, parse_dates=[\"Date\"])\n",
    "    return df.pivot(index=\"Date\", columns=\"SymbolCUSIP\", values=\"ReturnValue\")\n",
    "\n",
    "def load_aqrr_factors(region=\"USA\"):\n",
    "    from rpy2.robjects import r as ro\n",
    "    from rpy2.robjects import pandas2ri\n",
    "    from rpy2.robjects.conversion import localconverter\n",
    "    print(f\"üì¶ Loading AQRR factor data for region: {region}\")\n",
    "    ro('library(dplyr)')\n",
    "    ro(f\"\"\"\n",
    "    mkt <- aqr_mkt_monthly() %>% filter(name == '{region}') %>%\n",
    "      mutate(date = as.character(date)) %>% select(date, mkt = value)\n",
    "    smb <- aqr_smb_monthly() %>% filter(name == '{region}') %>%\n",
    "      mutate(date = as.character(date)) %>% select(date, smb = value)\n",
    "    hml <- aqr_hml_ff_monthly() %>% filter(name == '{region}') %>%\n",
    "      mutate(date = as.character(date)) %>% select(date, hml = value)\n",
    "    umd <- aqr_umd_monthly() %>% filter(name == '{region}') %>%\n",
    "      mutate(date = as.character(date)) %>% select(date, umd = value)\n",
    "    qmj <- aqr_qmj_monthly() %>% filter(name == '{region}') %>%\n",
    "      mutate(date = as.character(date)) %>% select(date, qmj = value)\n",
    "    bab <- aqr_bab_monthly() %>% filter(name == '{region}') %>%\n",
    "      mutate(date = as.character(date)) %>% select(date, bab = value)\n",
    "    \"\"\")\n",
    "    def fix_date(r_obj):\n",
    "        with localconverter(pandas2ri.converter):\n",
    "            df = pandas2ri.rpy2py(r_obj)\n",
    "        df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "        return df[df['date'] >= pd.to_datetime(\"2015-01-31\")].reset_index(drop=True)\n",
    "    factors = (\n",
    "        fix_date(ro['mkt']).merge(fix_date(ro['smb']), on='date')\n",
    "            .merge(fix_date(ro['hml']), on='date')\n",
    "            .merge(fix_date(ro['umd']), on='date')\n",
    "            .merge(fix_date(ro['qmj']), on='date')\n",
    "            .merge(fix_date(ro['bab']), on='date')\n",
    "            .rename(columns={\"date\": \"Date\"})\n",
    "            .sort_values(\"Date\")\n",
    "            .reset_index(drop=True)\n",
    "    )\n",
    "    print(f\"‚úÖ Loaded AQRR factors: {region} | Shape: {factors.shape}\")\n",
    "    return factors\n",
    "\n",
    "def load_db_factors(factor_list, region=\"Global\", table=\"aqr_factors\", portfolio_filter=None):\n",
    "    \"\"\"Load factors from the specified DB table.\"\"\"\n",
    "    query = f\"\"\"\n",
    "        SELECT date AS Date, factor_symbol AS Factor, value AS Value\n",
    "        FROM {table}\n",
    "        WHERE region = :region\n",
    "        AND factor_symbol IN ({','.join([f\"'{f}'\" for f in factor_list])})\n",
    "    \"\"\"\n",
    "    if portfolio_filter:\n",
    "        query += f\" AND portfolio IN ({','.join([f\"'{p}'\" for p in portfolio_filter])})\"\n",
    "    df = pd.read_sql(query, engine, params={'region': region}, parse_dates=['Date'])\n",
    "    df = df.pivot(index=\"Date\", columns=\"Factor\", values=\"Value\")\n",
    "    rename_map = {'MKT': 'mkt', 'SMB': 'smb', 'HML-D': 'hml', 'UMD': 'umd', 'QMJ': 'qmj', 'BAB': 'bab', 'TSM': 'tsm'}\n",
    "    df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})\n",
    "    logging.info(f\"Loaded factors from {table} | Shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "def load_century_factors(asset_class, factor_list, region=\"Global\"):\n",
    "    \"\"\"Load Century paper factors from aqr_century_factors.\"\"\"\n",
    "    query = f\"\"\"\n",
    "        SELECT date AS Date, portfolio AS Factor, value AS Value\n",
    "        FROM aqr_century_factors\n",
    "        WHERE asset_class = :asset_class\n",
    "        AND region = :region\n",
    "        AND portfolio IN ({','.join([f\"'{f}'\" for f in factor_list])})\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, engine, params={'asset_class': asset_class, 'region': region}, parse_dates=['Date'])\n",
    "    df = df.pivot(index=\"Date\", columns=\"Factor\", values=\"Value\")\n",
    "    logging.info(f\"Loaded Century factors for {asset_class} | Shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "def load_fixed_income_factors():\n",
    "    \"\"\"Placeholder for PortfolioVisualizer fixed income factors.\"\"\"\n",
    "    # Assuming TERM, DEF, CRED, LIQ - replace with actual DB query if available\n",
    "    query = \"\"\"\n",
    "        SELECT Date, Factor_Name, ReturnValue\n",
    "        FROM Fixed_Income_Factor_Returns\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, engine, parse_dates=[\"Date\"])\n",
    "    return df.pivot(index=\"Date\", columns=\"Factor_Name\", values=\"ReturnValue\")\n",
    "\n",
    "def merge_all_factors(factors1, factors2):\n",
    "    factors1.index = pd.to_datetime(factors1.index)\n",
    "    factors2.index = pd.to_datetime(factors2.index)\n",
    "    merged = factors1.merge(factors2, how=\"left\", left_index=True, right_index=True)\n",
    "    return merged\n",
    "\n",
    "def compare_and_select_factors(region, r_factors, db_factors):\n",
    "    r_max = r_factors['Date'].max() if not r_factors.empty else pd.Timestamp(\"1900-01-01\")\n",
    "    db_max = db_factors.index.max() if not db_factors.empty else pd.Timestamp(\"1900-01-01\")\n",
    "    print(f\"üìÖ R max date: {r_max.date()} | DB max date: {db_max.date()}\")\n",
    "    if r_max > db_max:\n",
    "        print(\"‚úÖ Using R-based AQRR factors (more recent)\")\n",
    "        return r_factors.set_index(\"Date\")\n",
    "    else:\n",
    "        print(\"‚úÖ Using DB-based AQRR factors\")\n",
    "        return db_factors\n",
    "\n",
    "# Section 4: Rolling Regression Functions\n",
    "def precheck_rolling_periods(returns, factors, rolling_periods):\n",
    "    returns = returns.dropna()\n",
    "    factors = factors.dropna()\n",
    "    min_date = max(returns.index.min(), factors.index.min())\n",
    "    max_date = min(returns.index.max(), factors.index.max())\n",
    "    viable_periods = [w for w in rolling_periods if min_date + relativedelta(months=w) <= max_date]\n",
    "    return viable_periods\n",
    "\n",
    "def run_rolling_regression(fund, returns, factors, regression_type):\n",
    "    results = []\n",
    "    returns.index = pd.to_datetime(returns.index)\n",
    "    factors.index = pd.to_datetime(factors.index)\n",
    "    ran_any = False\n",
    "    \n",
    "    viable_periods = precheck_rolling_periods(returns, factors, ROLLING_PERIODS)\n",
    "    if not viable_periods:\n",
    "        print(f\"‚ö†Ô∏è No viable rolling periods for {fund}\")\n",
    "        return results\n",
    "    \n",
    "    for window in viable_periods:\n",
    "        start = returns.index.min() + relativedelta(months=window)\n",
    "        for end_date in returns.loc[returns.index >= start].index:\n",
    "            start_date = end_date - relativedelta(months=window - 1)\n",
    "            y = returns.loc[start_date:end_date]\n",
    "            X = factors.loc[start_date:end_date]\n",
    "            X, y = X.align(y, join=\"inner\", axis=0)\n",
    "            if len(y) < window or y.isnull().any() or X.isnull().any().any():\n",
    "                continue\n",
    "            try:\n",
    "                X_const = add_constant(X)\n",
    "                model = OLS(y, X_const).fit()\n",
    "                diagnostics = {\n",
    "                    'dw': durbin_watson(model.resid),\n",
    "                    'bp_pval': het_breuschpagan(model.resid, model.model.exog)[1]\n",
    "                }\n",
    "                is_robust = diagnostics['dw'] < 1.5 or diagnostics['bp_pval'] < 0.05\n",
    "                reg_type = \"Robust\" if is_robust else \"OLS\"\n",
    "                if is_robust:\n",
    "                    model = sm.OLS(y, X_const).fit(cov_type='HAC', cov_kwds={'maxlags': 1})\n",
    "                \n",
    "                for factor in X.columns:\n",
    "                    results.append({\n",
    "                        \"SymbolCUSIP\": fund,\n",
    "                        \"MonthEndDate\": end_date,\n",
    "                        \"RollPeriod\": f\"{window}m\",\n",
    "                        \"Factor_Name\": factor,\n",
    "                        \"Coefficient\": model.params.get(factor, np.nan),\n",
    "                        \"P_Value\": model.pvalues.get(factor, np.nan),\n",
    "                        \"T_Stat\": model.tvalues.get(factor, np.nan),\n",
    "                        \"Standard_Error\": model.bse.get(factor, np.nan),\n",
    "                        \"CI_Lower\": model.conf_int().loc[factor][0] if factor in model.params else np.nan,\n",
    "                        \"CI_Upper\": model.conf_int().loc[factor][1] if factor in model.params else np.nan,\n",
    "                        \"Adj_R2\": model.rsquared_adj,\n",
    "                        \"Correlation\": np.corrcoef(y, model.fittedvalues)[0, 1],\n",
    "                        \"Autocorrelation_Flag\": diagnostics['dw'] < 1.5,\n",
    "                        \"Heteroskedasticity_Flag\": diagnostics['bp_pval'] < 0.05,\n",
    "                        \"Regression_Type\": regression_type\n",
    "                    })\n",
    "                ran_any = True\n",
    "            except (np.linalg.LinAlgError, ValueError):\n",
    "                continue\n",
    "    print(f\"{'‚úÖ' if ran_any else '‚ö†Ô∏è'} {'Ran' if ran_any else 'Skipped'} {regression_type} for {fund}\")\n",
    "    return results\n",
    "\n",
    "# Section 5: Main Processing Pipeline\n",
    "def initialize_data_sources():\n",
    "    print(\"üîß Initializing R interface...\")\n",
    "    aqrr = initialize_r_environment()\n",
    "    use_r = aqrr is not None\n",
    "    if not use_r:\n",
    "        logging.warning(\"R unavailable, using DB factors only\")\n",
    "        print(\"‚ö†Ô∏è R unavailable, using DB factors only.\")\n",
    "    return use_r\n",
    "\n",
    "def process_region(region, fund_subset, use_r):\n",
    "    from concurrent.futures import ProcessPoolExecutor\n",
    "    \n",
    "    funds = fund_subset[\"SymbolCUSIP\"].tolist()\n",
    "    if SAMPLE_DRY_RUN:\n",
    "        funds = random.sample(funds, min(SAMPLE_SIZE, len(funds)))\n",
    "        logging.info(f\"Sample dry run: Processing {len(funds)} funds from {region}\")\n",
    "        print(f\"‚ÑπÔ∏è Sample dry run: Processing {len(funds)} funds\")\n",
    "    \n",
    "    profiles = fund_subset.set_index(\"SymbolCUSIP\")[\"FactorProfile\"].to_dict()\n",
    "    \n",
    "    for i in range(0, len(funds), CHUNK_SIZE):\n",
    "        chunk = funds[i:i + CHUNK_SIZE]\n",
    "        fund_returns = load_fund_returns(chunk)\n",
    "        records = []\n",
    "        \n",
    "        with ProcessPoolExecutor() as executor:\n",
    "            futures = {}\n",
    "            for fund in fund_returns.columns:\n",
    "                profile = profiles.get(fund)\n",
    "                region_map = {'USA': 'US', 'Global Ex USA': 'Intl', 'Global': 'Global'}\n",
    "                db_region = region_map.get(region, 'Global')\n",
    "                \n",
    "                if profile in [\"US Equity Large Cap Blend\", \"US Equity Large Cap Growth\", \"US Equity Large Cap Value\", \"US Equity Mid Cap\", \"US Equity Small Cap\"]:\n",
    "                    # US Equities\n",
    "                    factors1 = load_db_factors(['MKT', 'SMB', 'HML-D', 'QMJ', 'UMD', 'BAB', 'TSM'], 'US', portfolio_filter=['Global', 'Equities'])\n",
    "                    factors1['mkt-rf'] = factors1['mkt'] - load_db_factors(['RF'], 'Global')['rf']\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], factors1[['mkt-rf', 'smb', 'hml', 'qmj', 'umd', 'bab', 'tsm']], \"US_AQRR\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], load_century_factors(\"Stock Selection\", [\"US Stock Selection Value\", \"US Stock Selection Momentum\", \"US Stock Selection Defensive\", \"US Stock Selection Multi-Style\"], \"US\"), \"US_Century_Stock\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], load_century_factors(\"Equity Indices\", [\"Equity Indices Value\", \"Equity Indices Momentum\", \"Equity Indices Defensive\", \"Equity Indices Carry\", \"Equity Indices Multi-Style\"], \"US\"), \"US_Century_Equity\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], load_century_factors(\"Macro\", [\"All Macro Value\", \"All Macro Momentum\", \"All Macro Carry\", \"All Macro Defensive\", \"All Macro Multi-style\"], \"Global\"), \"US_Century_Macro\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], load_century_factors(\"All Asset Classes\", [\"All Asset Class Value\", \"All Asset Class Momentum\", \"All Asset Class Defensive\", \"All Asset Class Carry\", \"All Asset Class Multi-Style\"], \"Global\"), \"US_Century_All\")] = fund\n",
    "                \n",
    "                elif profile in [\"Global Equity Large Cap\", \"Global Equity Mid/Small Cap\", \"Global Emerging Markets Equity\"]:\n",
    "                    # Global Equities\n",
    "                    factors1 = load_db_factors(['MKT', 'SMB', 'HML-D', 'QMJ', 'UMD', 'BAB', 'TSM'], 'Global', portfolio_filter=['Global', 'Equities'])\n",
    "                    factors1['mkt-rf'] = factors1['mkt'] - load_db_factors(['RF'], 'Global')['rf']\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], factors1[['mkt-rf', 'smb', 'hml', 'qmj', 'umd', 'bab', 'tsm']], \"Global_AQRR\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], load_century_factors(\"Stock Selection\", [\"All Stock Selection Value\", \"All Stock Selection Momentum\", \"All Stock Selection Defensive\", \"All Stock Selection Multi-Style\"], \"Global\"), \"Global_Century_Stock\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], load_century_factors(\"Equity Indices\", [\"Equity Indices Value\", \"Equity Indices Momentum\", \"Equity Indices Defensive\", \"Equity Indices Carry\", \"Equity Indices Multi-Style\"], \"Global\"), \"Global_Century_Equity\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], load_century_factors(\"Macro\", [\"All Macro Value\", \"All Macro Momentum\", \"All Macro Carry\", \"All Macro Defensive\", \"All Macro Multi-style\"], \"Global\"), \"Global_Century_Macro\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], load_century_factors(\"All Asset Classes\", [\"All Asset Class Value\", \"All Asset Class Momentum\", \"All Asset Class Defensive\", \"All Asset Class Carry\", \"All Asset Class Multi-Style\"], \"Global\"), \"Global_Century_All\")] = fund\n",
    "                \n",
    "                elif profile in [\"Europe Equity Large Cap\", \"Asia Equity\", \"Japan Equity\", \"Emerging Markets Fixed Income\"]:\n",
    "                    # International Equities\n",
    "                    factors1 = load_db_factors(['MKT', 'SMB', 'HML-D', 'QMJ', 'UMD', 'BAB', 'TSM'], 'Global Ex USA', portfolio_filter=['Global', 'Equities'])\n",
    "                    factors1['mkt-rf'] = factors1['mkt'] - load_db_factors(['RF'], 'Global')['rf']\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], factors1[['mkt-rf', 'smb', 'hml', 'qmj', 'umd', 'bab', 'tsm']], \"Intl_AQRR\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], load_century_factors(\"Stock Selection\", [\"International Stock Selection Value\", \"International Stock Selection Momentum\", \"International Stock Selection Defensive\", \"International Stock Selection Multi-Style\"], \"Intl\"), \"Intl_Century_Stock\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], load_century_factors(\"Equity Indices\", [\"Equity Indices Value\", \"Equity Indices Momentum\", \"Equity Indices Defensive\", \"Equity Indices Carry\", \"Equity Indices Multi-Style\"], \"Global\"), \"Intl_Century_Equity\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], load_century_factors(\"Macro\", [\"All Macro Value\", \"All Macro Momentum\", \"All Macro Carry\", \"All Macro Defensive\", \"All Macro Multi-style\"], \"Global\"), \"Intl_Century_Macro\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], load_century_factors(\"All Asset Classes\", [\"All Asset Class Value\", \"All Asset Class Momentum\", \"All Asset Class Defensive\", \"All Asset Class Carry\", \"All Asset Class Multi-Style\"], \"Global\"), \"Intl_Century_All\")] = fund\n",
    "                \n",
    "                elif profile in [\"US Fixed Income\", \"US Municipal Fixed Income\", \"Global Fixed Income\"]:\n",
    "                    # Fixed Income\n",
    "                    fi_factors = load_fixed_income_factors()  # Placeholder for PortfolioVisualizer\n",
    "                    tsm_fi = load_db_factors(['TSM'], 'Global', portfolio_filter=['Fixed Income'])\n",
    "                    factors1 = pd.concat([fi_factors, tsm_fi], axis=1)\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], factors1, \"FI_AQRR\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], load_century_factors(\"Fixed Income\", [\"Fixed Income Value\", \"Fixed Income Momentum\", \"Fixed Income Defensive\", \"Fixed Income Multi-Style\"], \"Global\"), \"FI_Century_FI\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], load_century_factors(\"Macro\", [\"All Macro Value\", \"All Macro Momentum\", \"All Macro Carry\", \"All Macro Defensive\", \"All Macro Multi-style\"], \"Global\"), \"FI_Century_Macro\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], load_century_factors(\"All Asset Classes\", [\"All Asset Class Value\", \"All Asset Class Momentum\", \"All Asset Class Defensive\", \"All Asset Class Carry\", \"All Asset Class Multi-Style\"], \"Global\"), \"FI_Century_All\")] = fund\n",
    "                \n",
    "                elif profile in [\"Flexible Allocation\", \"Aggressive Allocation\", \"Moderate Allocation\", \"Cautious Allocation\"]:\n",
    "                    # Asset Allocation\n",
    "                    factors1 = load_db_factors(['MKT', 'SMB', 'HML-D', 'QMJ', 'UMD', 'BAB', 'TSM'], 'Global', portfolio_filter=['Global', 'Equities', 'Fixed Income'])\n",
    "                    factors1['mkt-rf'] = factors1['mkt'] - load_db_factors(['RF'], 'Global')['rf']\n",
    "                    fi_factors = load_fixed_income_factors()\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], factors1[['mkt-rf', 'smb', 'hml', 'qmj', 'umd', 'bab', 'tsm']], \"AA_AQRR\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], fi_factors, \"AA_PV\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], pd.concat([factors1[['mkt-rf', 'smb', 'hml', 'qmj', 'umd', 'bab', 'tsm']], fi_factors], axis=1), \"AA_Combined\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], load_century_factors(\"Stock Selection\", [\"All Stock Selection Value\", \"All Stock Selection Momentum\", \"All Stock Selection Defensive\", \"All Stock Selection Multi-Style\"], \"Global\"), \"AA_Century_Stock\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], load_century_factors(\"Fixed Income\", [\"Fixed Income Value\", \"Fixed Income Momentum\", \"Fixed Income Defensive\", \"Fixed Income Multi-Style\"], \"Global\"), \"AA_Century_FI\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], load_century_factors(\"Equity Indices\", [\"Equity Indices Value\", \"Equity Indices Momentum\", \"Equity Indices Defensive\", \"Equity Indices Carry\", \"Equity Indices Multi-Style\"], \"Global\"), \"AA_Century_Equity\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], load_century_factors(\"Macro\", [\"All Macro Value\", \"All Macro Momentum\", \"All Macro Carry\", \"All Macro Defensive\", \"All Macro Multi-style\"], \"Global\"), \"AA_Century_Macro\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], load_century_factors(\"All Asset Classes\", [\"All Asset Class Value\", \"All Asset Class Momentum\", \"All Asset Class Defensive\", \"All Asset Class Carry\", \"All Asset Class Multi-Style\"], \"Global\"), \"AA_Century_All\")] = fund\n",
    "                \n",
    "                elif profile in [\"Commodities Broad Basket\", \"Commodities Specified\"]:\n",
    "                    # Commodities (simplified, no split yet)\n",
    "                    com_factors = load_db_factors(['COM', 'TSM'], 'Global', portfolio_filter=['Excess return of equal-weight commodities portfolio', 'Commodities'])\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], com_factors, \"COM_General\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], load_century_factors(\"Commodity\", [\"Commodity Value\", \"Commodity Momentum\", \"Commodity Carry\", \"Commodity Multi-style\"], \"Global\"), \"COM_Century_Com\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], load_century_factors(\"Macro\", [\"All Macro Value\", \"All Macro Momentum\", \"All Macro Carry\", \"All Macro Defensive\", \"All Macro Multi-style\"], \"Global\"), \"COM_Century_Macro\")] = fund\n",
    "                \n",
    "                elif profile in [\"Options Trading\", \"Multialternative\", \"Market Neutral\", \"Long/Short Equity\", \"Alternative Miscellaneous\"]:\n",
    "                    # Alternative Assets\n",
    "                    factors1 = load_db_factors(['MKT', 'SMB', 'HML-D', 'QMJ', 'UMD', 'BAB', 'TSM'], 'Global', portfolio_filter=['Global', 'Equities', 'Fixed Income', 'Commodities', 'Currencies'])\n",
    "                    factors1['mkt-rf'] = factors1['mkt'] - load_db_factors(['RF'], 'Global')['rf']\n",
    "                    fi_factors = load_fixed_income_factors()\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], factors1[['mkt-rf', 'smb', 'hml', 'qmj', 'umd', 'bab', 'tsm']], \"Alt_AQRR\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], fi_factors, \"Alt_PV\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], pd.concat([factors1[['mkt-rf', 'smb', 'hml', 'qmj', 'umd', 'bab', 'tsm']], fi_factors], axis=1), \"Alt_Combined\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], factors1[['mkt-rf', 'smb', 'hml', 'qmj', 'umd', 'bab', 'tsm']], \"Alt_Commodity_Split\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], load_century_factors(\"Stock Selection\", [\"All Stock Selection Value\", \"All Stock Selection Momentum\", \"All Stock Selection Defensive\", \"All Stock Selection Multi-Style\"], \"Global\"), \"Alt_Century_Stock\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], load_century_factors(\"Fixed Income\", [\"Fixed Income Value\", \"Fixed Income Momentum\", \"Fixed Income Defensive\", \"Fixed Income Multi-Style\"], \"Global\"), \"Alt_Century_FI\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], load_century_factors(\"Equity Indices\", [\"Equity Indices Value\", \"Equity Indices Momentum\", \"Equity Indices Defensive\", \"Equity Indices Carry\", \"Equity Indices Multi-Style\"], \"Global\"), \"Alt_Century_Equity\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], load_century_factors(\"Macro\", [\"All Macro Value\", \"All Macro Momentum\", \"All Macro Carry\", \"All Macro Defensive\", \"All Macro Multi-style\"], \"Global\"), \"Alt_Century_Macro\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], load_century_factors(\"Commodity\", [\"Commodity Value\", \"Commodity Momentum\", \"Commodity Carry\", \"Commodity Multi-style\"], \"Global\"), \"Alt_Century_Com\")] = fund\n",
    "                    futures[executor.submit(run_rolling_regression, fund, fund_returns[fund], load_century_factors(\"Currencies\", [\"Currency Value\", \"Currency Momentum\", \"Currency Carry\", \"Currency Multi-style\"], \"Global\"), \"Alt_Century_Currency\")] = fund\n",
    "                \n",
    "            for future in tqdm(futures, desc=f\"üîÅ Region: {region}\"):\n",
    "                try:\n",
    "                    records.extend(future.result())\n",
    "                except concurrent.futures.TimeoutError as e:\n",
    "                    print(f\"‚ö†Ô∏è Error in {futures[future]}: Timeout - {e}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Error in {futures[future]}: Unexpected error - {type(e).__name__}: {e}\")\n",
    "        \n",
    "        if records:\n",
    "            if not DRY_RUN:\n",
    "                insert_batch(records)\n",
    "            else:\n",
    "                logging.info(f\"Dry run: Skipped writing {len(records)} records for chunk {i//CHUNK_SIZE + 1}\")\n",
    "                print(f\"‚ÑπÔ∏è Dry run: Would have written {len(records)} records\")\n",
    "\n",
    "def main():\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    use_r = initialize_data_sources()\n",
    "    fund_meta = load_fund_metadata()\n",
    "    regions = fund_meta[\"Region\"].unique()\n",
    "    print(f\"üß† Total mapped funds: {len(fund_meta)}\")\n",
    "    print(f\"üìç Regions detected: {regions}\\n\")\n",
    "    \n",
    "    for region in regions:\n",
    "        fund_subset = fund_meta[fund_meta[\"Region\"] == region]\n",
    "        process_region(region, fund_subset, use_r)\n",
    "\n",
    "# Section 6: Database Output\n",
    "def insert_batch(records):\n",
    "    df = pd.DataFrame(records)\n",
    "    if not DRY_RUN:\n",
    "        for i in range(0, len(df), BATCH_INSERT_SIZE):\n",
    "            batch = df.iloc[i:i + BATCH_INSERT_SIZE]\n",
    "            batch.to_sql(\"AQRR_Factor_Attribution\", engine, if_exists=\"append\", index=False)\n",
    "    else:\n",
    "        for i in range(0, len(df), BATCH_INSERT_SIZE):\n",
    "            batch_size = len(df.iloc[i:i + BATCH_INSERT_SIZE])\n",
    "            logging.info(f\"Dry run: Skipped batch insert of {batch_size} records\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee51edf9-ac08-42ed-97f7-f7e1f9658ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "from datetime import timedelta, datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from sqlalchemy import create_engine\n",
    "from tqdm import tqdm\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.tools.tools import add_constant\n",
    "import statsmodels.api as sm\n",
    "import time\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri\n",
    "\n",
    "# Section 1: Configuration and Setup\n",
    "connection_string = (\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/CWA_Fund_Database\"\n",
    "    \"?driver=ODBC+Driver+18+for+SQL+Server\"\n",
    "    \"&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "RETURN_METRIC = \"1 Month Return\"\n",
    "ROLLING_PERIODS = [12, 24, 36, 48, 60]  # in months\n",
    "DRY_RUN = True\n",
    "SAMPLE_DRY_RUN = True\n",
    "SAMPLE_SIZE = 100\n",
    "CHUNK_SIZE = 5600\n",
    "BATCH_INSERT_SIZE = 10000\n",
    "MAX_WORKERS = 15  # Optimized for 16-core i9-185H\n",
    "\n",
    "# Section 2: Helper Functions\n",
    "def category_to_region(category):\n",
    "    mapping = {\n",
    "        \"US Equity Large Cap Blend\": (\"USA\", \"US Equity Large Cap Blend\"),\n",
    "        \"US Equity Large Cap Growth\": (\"USA\", \"US Equity Large Cap Growth\"),\n",
    "        \"US Equity Large Cap Value\": (\"USA\", \"US Equity Large Cap Value\"),\n",
    "        \"US Equity Mid Cap\": (\"USA\", \"US Equity Mid Cap\"),\n",
    "        \"US Equity Small Cap\": (\"USA\", \"US Equity Small Cap\"),\n",
    "        \"Global Equity Large Cap\": (\"Global\", \"Global Equity Large Cap\"),\n",
    "        \"Global Equity Mid/Small Cap\": (\"Global\", \"Global Equity Mid/Small Cap\"),\n",
    "        \"Global Emerging Markets Equity\": (\"Global\", \"Global Emerging Markets Equity\"),\n",
    "        \"Europe Equity Large Cap\": (\"International\", \"Europe Equity Large Cap\"),\n",
    "        \"Asia Equity\": (\"International\", \"Asia Equity\"),\n",
    "        \"Japan Equity\": (\"International\", \"Japan Equity\"),\n",
    "        \"Emerging Markets Fixed Income\": (\"International\", \"Emerging Markets Fixed Income\"),\n",
    "        \"US Fixed Income\": (\"USA\", \"US Fixed Income\"),\n",
    "        \"US Municipal Fixed Income\": (\"USA\", \"US Municipal Fixed Income\"),\n",
    "        \"Global Fixed Income\": (\"Global\", \"Global Fixed Income\"),\n",
    "        \"Flexible Allocation\": (\"Global\", \"Flexible Allocation\"),\n",
    "        \"Aggressive Allocation\": (\"Global\", \"Aggressive Allocation\"),\n",
    "        \"Moderate Allocation\": (\"Global\", \"Moderate Allocation\"),\n",
    "        \"Cautious Allocation\": (\"Global\", \"Cautious Allocation\"),\n",
    "        \"Commodities Broad Basket\": (\"Global\", \"Commodities Broad Basket\"),\n",
    "        \"Commodities Specified\": (\"Global\", \"Commodities Specified\"),\n",
    "        \"Options Trading\": (\"Global\", \"Options Trading\"),\n",
    "        \"Multialternative\": (\"Global\", \"Multialternative\"),\n",
    "        \"Market Neutral\": (\"Global\", \"Market Neutral\"),\n",
    "        \"Long/Short Equity\": (\"Global\", \"Long/Short Equity\"),\n",
    "        \"Alternative Miscellaneous\": (\"Global\", \"Alternative Miscellaneous\")\n",
    "    }\n",
    "    return mapping.get(category, (\"Unknown\", \"Unknown\"))\n",
    "\n",
    "def initialize_r_environment():\n",
    "    \"\"\"Initialize R environment for AQRR factor loading, returning None if unavailable.\"\"\"\n",
    "    import os\n",
    "    os.environ['R_HOME'] = r'C:\\\\Program Files\\\\R\\\\R-4.4.3'\n",
    "    os.environ['R_JIT_ENABLED'] = '0'\n",
    "    \n",
    "    import logging\n",
    "    import rpy2.rinterface_lib.callbacks\n",
    "    import rpy2.robjects as ro\n",
    "    from rpy2.robjects.packages import importr\n",
    "    from rpy2.robjects import pandas2ri\n",
    "    \n",
    "    rpy2.rinterface_lib.callbacks.logger.setLevel(logging.ERROR)\n",
    "    \n",
    "    try:\n",
    "        version = ro.r('R.version.string')[0]\n",
    "        print(f\"üîÅ R Version: {version}\")\n",
    "        logging.info(f\"R initialized successfully: {version}\")\n",
    "    except (OSError, ValueError) as e:\n",
    "        print(f\"‚ùå Could not connect to R: {e}\")\n",
    "        logging.warning(f\"Could not connect to R: {e}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        aqrr = importr('aqrr')\n",
    "        print(\"‚úÖ Loaded R package: aqrr\")\n",
    "        funcs = ro.r('ls(\"package:aqrr\")')\n",
    "        print(f\"üì¶ AQRR Functions Available: {list(funcs)[:6]} ...\")\n",
    "        logging.info(\"AQRR package loaded successfully\")\n",
    "    except ImportError as e:\n",
    "        print(f\"‚ùå Failed to load 'aqrr': {e}\")\n",
    "        logging.warning(f\"Failed to load 'aqrr': {e}\")\n",
    "        return None\n",
    "    \n",
    "    pandas2ri.activate()\n",
    "    return aqrr\n",
    "\n",
    "# Section 3: Data Loading Functions\n",
    "def load_fund_metadata():\n",
    "    query = \"\"\"\n",
    "    SELECT f.SymbolCUSIP, f.YC_Global_Category_ID, c.Global_Category_Name\n",
    "    FROM Funds_to_Screen f\n",
    "    JOIN YC_Global_Category_List c ON f.YC_Global_Category_ID = c.ID\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, engine)\n",
    "    df[[\"Region\", \"FactorProfile\"]] = df[\"Global_Category_Name\"].map(category_to_region).apply(pd.Series)\n",
    "    return df.dropna(subset=[\"Region\", \"FactorProfile\"])\n",
    "\n",
    "def load_fund_returns(fund_ids):\n",
    "    placeholders = \",\".join([f\"'{fid}'\" for fid in fund_ids])\n",
    "    query = f\"\"\"\n",
    "        SELECT SymbolCUSIP, Date, ReturnValue\n",
    "        FROM Fund_Returns_Timeseries\n",
    "        WHERE SymbolCUSIP IN ({placeholders})\n",
    "        AND Metric = '{RETURN_METRIC}'\n",
    "    \"\"\"\n",
    "    return pd.read_sql(query, engine, parse_dates=[\"Date\"]).pivot(index=\"Date\", columns=\"SymbolCUSIP\", values=\"ReturnValue\")\n",
    "\n",
    "def load_factors(region, category):\n",
    "    region_map = {\"USA\": \"US\", \"Global\": \"Global\", \"International\": \"Global Ex USA\"}\n",
    "    db_region = region_map.get(region, \"Global\")\n",
    "    \n",
    "    if \"Equity\" in category:\n",
    "        factors = load_db_factors(['MKT', 'SMB', 'HML-D', 'QMJ', 'UMD', 'BAB', 'TSM'], db_region, portfolio_filter=['Global', 'Equities'])\n",
    "        factors['mkt-rf'] = factors['mkt'] - load_db_factors(['RF'], 'Global')['rf']\n",
    "        return factors[['mkt-rf', 'smb', 'hml', 'qmj', 'umd', 'bab', 'tsm']]\n",
    "    elif \"Fixed Income\" in category:\n",
    "        fi_factors = load_fixed_income_factors()\n",
    "        tsm_fi = load_db_factors(['TSM'], 'Global', portfolio_filter=['Fixed Income'])\n",
    "        return pd.concat([fi_factors, tsm_fi], axis=1)\n",
    "    elif \"Commodities\" in category:\n",
    "        return load_db_factors(['COM', 'TSM'], 'Global', portfolio_filter=['Excess return of equal-weight commodities portfolio', 'Commodities'])\n",
    "    elif \"Allocation\" in category or \"Alternative\" in category:\n",
    "        factors = load_db_factors(['MKT', 'SMB', 'HML-D', 'QMJ', 'UMD', 'BAB', 'TSM'], db_region, portfolio_filter=['Global', 'Equities', 'Fixed Income'])\n",
    "        factors['mkt-rf'] = factors['mkt'] - load_db_factors(['RF'], 'Global')['rf']\n",
    "        fi_factors = load_fixed_income_factors()\n",
    "        return pd.concat([factors[['mkt-rf', 'smb', 'hml', 'qmj', 'umd', 'bab', 'tsm']], fi_factors], axis=1)\n",
    "    return pd.DataFrame()  # Default empty for unhandled categories\n",
    "\n",
    "def load_db_factors(factor_list, region=\"Global\", table=\"aqr_factors\", portfolio_filter=None):\n",
    "    query = f\"\"\"\n",
    "        SELECT date AS Date, factor_symbol AS Factor, value AS Value\n",
    "        FROM {table}\n",
    "        WHERE region = :region\n",
    "        AND factor_symbol IN ({','.join([f\"'{f}'\" for f in factor_list])})\n",
    "    \"\"\"\n",
    "    if portfolio_filter:\n",
    "        query += f\" AND portfolio IN ({','.join([f\"'{p}'\" for p in portfolio_filter])})\"\n",
    "    df = pd.read_sql(query, engine, params={'region': region}, parse_dates=['Date'])\n",
    "    return df.pivot(index=\"Date\", columns=\"Factor\", values=\"Value\").rename(columns={'MKT': 'mkt', 'SMB': 'smb', 'HML-D': 'hml', 'UMD': 'umd', 'QMJ': 'qmj', 'BAB': 'bab', 'TSM': 'tsm'})\n",
    "\n",
    "def load_fixed_income_factors():\n",
    "    query = \"\"\"\n",
    "        SELECT Date, Factor_Name, ReturnValue\n",
    "        FROM Fixed_Income_Factor_Returns\n",
    "    \"\"\"\n",
    "    return pd.read_sql(query, engine, parse_dates=[\"Date\"]).pivot(index=\"Date\", columns=\"Factor_Name\", values=\"ReturnValue\")\n",
    "\n",
    "# Section 4: Rolling Regression Functions\n",
    "def run_rolling_regression_python(fund, returns, factors, regression_type):\n",
    "    results = []\n",
    "    returns.index = pd.to_datetime(returns.index)\n",
    "    factors.index = pd.to_datetime(factors.index)\n",
    "    viable_periods = [w for w in ROLLING_PERIODS if (returns.index.max() - relativedelta(months=w)) >= returns.index.min()]\n",
    "    \n",
    "    for window in viable_periods:\n",
    "        start = returns.index.min() + relativedelta(months=window)\n",
    "        for end_date in returns.loc[returns.index >= start].index:\n",
    "            start_date = end_date - relativedelta(months=window - 1)\n",
    "            y = returns.loc[start_date:end_date]\n",
    "            X = factors.loc[start_date:end_date]\n",
    "            X, y = X.align(y, join=\"inner\", axis=0)\n",
    "            if len(y) < window or y.isnull().any() or X.isnull().any().any():\n",
    "                continue\n",
    "            X_const = add_constant(X)\n",
    "            model = OLS(y, X_const).fit()\n",
    "            for factor in X.columns:\n",
    "                results.append({\n",
    "                    \"SymbolCUSIP\": fund,\n",
    "                    \"MonthEndDate\": end_date,\n",
    "                    \"RollPeriod\": f\"{window}m\",\n",
    "                    \"Factor_Name\": factor,\n",
    "                    \"Coefficient\": model.params.get(factor, np.nan),\n",
    "                    \"P_Value\": model.pvalues.get(factor, np.nan),\n",
    "                    \"Regression_Type\": regression_type\n",
    "                })\n",
    "    return results\n",
    "\n",
    "def run_rolling_regression_r(fund, returns, factors, regression_type):\n",
    "    with pandas2ri.localconverter(pandas2ri.converter):\n",
    "        r_returns = pandas2ri.py2rpy(returns)\n",
    "        r_factors = pandas2ri.py2rpy(factors)\n",
    "    ro.r.assign(\"returns\", r_returns)\n",
    "    ro.r.assign(\"factors\", r_factors)\n",
    "    ro.r(\"\"\"\n",
    "    library(dplyr)\n",
    "    results <- list()\n",
    "    for (w in c(12, 24, 36, 48, 60)) {\n",
    "        for (i in (w+1):nrow(returns)) {\n",
    "            fit <- lm(returns[(i-w+1):i] ~ ., data=factors[(i-w+1):i,])\n",
    "            coefs <- summary(fit)$coefficients\n",
    "            results[[length(results)+1]] <- data.frame(\n",
    "                RollPeriod = paste0(w, \"m\"),\n",
    "                Factor_Name = rownames(coefs)[-1],\n",
    "                Coefficient = coefs[-1, \"Estimate\"],\n",
    "                P_Value = coefs[-1, \"Pr(>|t|)\"]\n",
    "            )\n",
    "        }\n",
    "    }\n",
    "    results <- bind_rows(results)\n",
    "    \"\"\")\n",
    "    results = pandas2ri.rpy2py(ro.r[\"results\"])\n",
    "    results[\"SymbolCUSIP\"] = fund\n",
    "    results[\"Regression_Type\"] = regression_type\n",
    "    return results.to_dict(\"records\")\n",
    "\n",
    "def test_regression_speed(fund, returns, factors):\n",
    "    print(f\"Testing regression speed for {fund}...\")\n",
    "    start_time = time.time()\n",
    "    python_results = run_rolling_regression_python(fund, returns, factors, \"Python_OLS\")\n",
    "    python_time = time.time() - start_time\n",
    "    print(f\"Python time: {python_time:.2f} seconds | Results: {len(python_results)}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    r_results = run_rolling_regression_r(fund, returns, factors, \"R_OLS\")\n",
    "    r_time = time.time() - start_time\n",
    "    print(f\"R time: {r_time:.2f} seconds | Results: {len(r_results)}\")\n",
    "    \n",
    "    return \"R\" if r_time < python_time else \"Python\"\n",
    "\n",
    "# Section 5: Main Processing Pipeline\n",
    "def process_region(region, fund_subset, use_r, regression_func):\n",
    "    categories = fund_subset[\"FactorProfile\"].unique()\n",
    "    records = []\n",
    "    \n",
    "    for category in categories:\n",
    "        cat_subset = fund_subset[fund_subset[\"FactorProfile\"] == category]\n",
    "        funds = cat_subset[\"SymbolCUSIP\"].tolist()\n",
    "        if SAMPLE_DRY_RUN:\n",
    "            funds = random.sample(funds, min(SAMPLE_SIZE, len(funds)))\n",
    "            print(f\"‚ÑπÔ∏è Sample dry run: Processing {len(funds)} funds in {region}/{category}\")\n",
    "        \n",
    "        # Load fund returns and factors once per region/category\n",
    "        fund_returns = load_fund_returns(funds)\n",
    "        factors = load_factors(region, category)\n",
    "        \n",
    "        with ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "            futures = {executor.submit(regression_func, fund, fund_returns[fund], factors, f\"{region}_{category}_OLS\"): fund for fund in fund_returns.columns}\n",
    "            for future in tqdm(futures, desc=f\"üîÅ {region}/{category}\"):\n",
    "                try:\n",
    "                    records.extend(future.result())\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Error in {futures[future]}: {e}\")\n",
    "    \n",
    "    if records:\n",
    "        if not DRY_RUN:\n",
    "            insert_batch(records)\n",
    "        else:\n",
    "            print(f\"‚ÑπÔ∏è Dry run: Would have written {len(records)} records for {region}\")\n",
    "\n",
    "def main():\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    use_r = initialize_r_environment()\n",
    "    fund_meta = load_fund_metadata()\n",
    "    regions = fund_meta[\"Region\"].unique()\n",
    "    print(f\"üß† Total mapped funds: {len(fund_meta)}\")\n",
    "    print(f\"üìç Regions detected: {regions}\\n\")\n",
    "    \n",
    "    # Test R vs Python on a sample\n",
    "    sample_funds = fund_meta[\"SymbolCUSIP\"].sample(1).tolist()\n",
    "    sample_returns = load_fund_returns(sample_funds)\n",
    "    sample_factors = load_factors(\"USA\", \"US Equity Large Cap Blend\")  # Default test case\n",
    "    best_method = test_regression_speed(sample_funds[0], sample_returns[sample_funds[0]], sample_factors)\n",
    "    regression_func = run_rolling_regression_r if best_method == \"R\" and use_r is not None else run_rolling_regression_python\n",
    "    print(f\"Using {best_method} for regressions\")\n",
    "    \n",
    "    for region in regions:\n",
    "        fund_subset = fund_meta[fund_meta[\"Region\"] == region]\n",
    "        process_region(region, fund_subset, use_r, regression_func)\n",
    "\n",
    "# Section 6: Database Output\n",
    "def insert_batch(records):\n",
    "    df = pd.DataFrame(records)\n",
    "    if not DRY_RUN:\n",
    "        for i in range(0, len(df), BATCH_INSERT_SIZE):\n",
    "            batch = df.iloc[i:i + BATCH_INSERT_SIZE]\n",
    "            batch.to_sql(\"AQRR_Factor_Attribution\", engine, if_exists=\"append\", index=False)\n",
    "    else:\n",
    "        print(f\"‚ÑπÔ∏è Dry run: Skipped writing {len(df)} records\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc747826-23fc-4c35-aa20-b79eb3e3aca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e27a06f3-427b-497e-b9ce-000eba5c3088",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:R initialized successfully: R version 4.4.3 (2025-02-28 ucrt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ R Version: R version 4.4.3 (2025-02-28 ucrt)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:AQRR package loaded successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded R package: aqrr\n",
      "üì¶ AQRR Functions Available: [':=', 'aqr_bab_daily', 'aqr_bab_monthly', 'aqr_commodities_long_run', 'aqr_credit_risk_premium', 'aqr_factor_premia_monthly'] ...\n",
      "üß† Total mapped funds: 5584\n",
      "üìç Regions detected: ['Global' 'Unknown' 'USA' 'International']\n",
      "\n",
      "Executing query: \n",
      "        SELECT date AS Date, factor_symbol AS Factor, value AS Value\n",
      "        FROM aqr_factors\n",
      "        WHERE region = ?\n",
      "        AND factor_symbol IN ('MKT','SMB','HML-D','QMJ','UMD','BAB','TSM')\n",
      "     AND portfolio IN ('Global','Equities') with param: US\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'mkt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'mkt'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 364\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ÑπÔ∏è Dry run: Skipped writing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m records\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 364\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 344\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    342\u001b[0m sample_funds \u001b[38;5;241m=\u001b[39m fund_meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSymbolCUSIP\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    343\u001b[0m sample_returns \u001b[38;5;241m=\u001b[39m load_fund_returns(sample_funds)\n\u001b[1;32m--> 344\u001b[0m sample_factors \u001b[38;5;241m=\u001b[39m \u001b[43mload_factors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUSA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUS Equity Large Cap Blend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maqrr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    345\u001b[0m best_method \u001b[38;5;241m=\u001b[39m test_regression_speed(sample_funds[\u001b[38;5;241m0\u001b[39m], sample_returns[sample_funds[\u001b[38;5;241m0\u001b[39m]], sample_factors)\n\u001b[0;32m    346\u001b[0m regression_func \u001b[38;5;241m=\u001b[39m run_rolling_regression_r \u001b[38;5;28;01mif\u001b[39;00m best_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m use_r \u001b[38;5;28;01melse\u001b[39;00m run_rolling_regression_python\n",
      "Cell \u001b[1;32mIn[6], line 206\u001b[0m, in \u001b[0;36mload_factors\u001b[1;34m(region, category, aqrr)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEquity\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m category:\n\u001b[0;32m    205\u001b[0m     db_factors \u001b[38;5;241m=\u001b[39m load_db_factors([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMKT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSMB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHML-D\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQMJ\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUMD\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBAB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTSM\u001b[39m\u001b[38;5;124m'\u001b[39m], db_region, portfolio_filter\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGlobal\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEquities\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 206\u001b[0m     db_factors[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmkt-rf\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdb_factors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmkt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m-\u001b[39m load_db_factors([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRF\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGlobal\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    207\u001b[0m     r_factors \u001b[38;5;241m=\u001b[39m load_aqrr_factors(region, aqrr) \u001b[38;5;28;01mif\u001b[39;00m aqrr \u001b[38;5;28;01melse\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m    208\u001b[0m     factors \u001b[38;5;241m=\u001b[39m compare_and_select_factors(region, r_factors, db_factors[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmkt-rf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhml\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqmj\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mumd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbab\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtsm\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'mkt'"
     ]
    }
   ],
   "source": [
    "# Version 3.3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "from datetime import timedelta, datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from sqlalchemy import create_engine\n",
    "from tqdm import tqdm\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.tools.tools import add_constant\n",
    "import statsmodels.api as sm\n",
    "import time\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "\n",
    "# Section 1: Configuration and Setup\n",
    "connection_string = (\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/CWA_Fund_Database\"\n",
    "    \"?driver=ODBC+Driver+18+for+SQL+Server\"\n",
    "    \"&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "RETURN_METRIC = \"1 Month Return\"\n",
    "ROLLING_PERIODS = [12, 24, 36, 48, 60]  # in months\n",
    "DRY_RUN = True\n",
    "SAMPLE_DRY_RUN = True\n",
    "SAMPLE_SIZE = 100\n",
    "CHUNK_SIZE = 5600\n",
    "BATCH_INSERT_SIZE = 10000\n",
    "MAX_WORKERS = 15  # Optimized for 16-core i9-185H\n",
    "\n",
    "# Section 2: Helper Functions\n",
    "def category_to_region(category):\n",
    "    mapping = {\n",
    "        \"US Equity Large Cap Blend\": (\"USA\", \"US Equity Large Cap Blend\"),\n",
    "        \"US Equity Large Cap Growth\": (\"USA\", \"US Equity Large Cap Growth\"),\n",
    "        \"US Equity Large Cap Value\": (\"USA\", \"US Equity Large Cap Value\"),\n",
    "        \"US Equity Mid Cap\": (\"USA\", \"US Equity Mid Cap\"),\n",
    "        \"US Equity Small Cap\": (\"USA\", \"US Equity Small Cap\"),\n",
    "        \"Global Equity Large Cap\": (\"Global\", \"Global Equity Large Cap\"),\n",
    "        \"Global Equity Mid/Small Cap\": (\"Global\", \"Global Equity Mid/Small Cap\"),\n",
    "        \"Global Emerging Markets Equity\": (\"Global\", \"Global Emerging Markets Equity\"),\n",
    "        \"Europe Equity Large Cap\": (\"International\", \"Europe Equity Large Cap\"),\n",
    "        \"Asia Equity\": (\"International\", \"Asia Equity\"),\n",
    "        \"Japan Equity\": (\"International\", \"Japan Equity\"),\n",
    "        \"Emerging Markets Fixed Income\": (\"International\", \"Emerging Markets Fixed Income\"),\n",
    "        \"US Fixed Income\": (\"USA\", \"US Fixed Income\"),\n",
    "        \"US Municipal Fixed Income\": (\"USA\", \"US Municipal Fixed Income\"),\n",
    "        \"Global Fixed Income\": (\"Global\", \"Global Fixed Income\"),\n",
    "        \"Flexible Allocation\": (\"Global\", \"Flexible Allocation\"),\n",
    "        \"Aggressive Allocation\": (\"Global\", \"Aggressive Allocation\"),\n",
    "        \"Moderate Allocation\": (\"Global\", \"Moderate Allocation\"),\n",
    "        \"Cautious Allocation\": (\"Global\", \"Cautious Allocation\"),\n",
    "        \"Commodities Broad Basket\": (\"Global\", \"Commodities Broad Basket\"),\n",
    "        \"Commodities Specified\": (\"Global\", \"Commodities Specified\"),\n",
    "        \"Options Trading\": (\"Global\", \"Options Trading\"),\n",
    "        \"Multialternative\": (\"Global\", \"Multialternative\"),\n",
    "        \"Market Neutral\": (\"Global\", \"Market Neutral\"),\n",
    "        \"Long/Short Equity\": (\"Global\", \"Long/Short Equity\"),\n",
    "        \"Alternative Miscellaneous\": (\"Global\", \"Alternative Miscellaneous\")\n",
    "    }\n",
    "    return mapping.get(category, (\"Unknown\", \"Unknown\"))\n",
    "\n",
    "def initialize_r_environment():\n",
    "    \"\"\"Initialize R environment for AQRR factor loading, returning None if unavailable.\"\"\"\n",
    "    import os\n",
    "    os.environ['R_HOME'] = r'C:\\\\Program Files\\\\R\\\\R-4.4.3'\n",
    "    os.environ['R_JIT_ENABLED'] = '0'\n",
    "    \n",
    "    import logging\n",
    "    import rpy2.rinterface_lib.callbacks\n",
    "    import rpy2.robjects as ro\n",
    "    from rpy2.robjects.packages import importr\n",
    "    from rpy2.robjects import pandas2ri\n",
    "    \n",
    "    rpy2.rinterface_lib.callbacks.logger.setLevel(logging.ERROR)\n",
    "    \n",
    "    try:\n",
    "        version = ro.r('R.version.string')[0]\n",
    "        print(f\"üîÅ R Version: {version}\")\n",
    "        logging.info(f\"R initialized successfully: {version}\")\n",
    "    except (OSError, ValueError) as e:\n",
    "        print(f\"‚ùå Could not connect to R: {e}\")\n",
    "        logging.warning(f\"Could not connect to R: {e}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        aqrr = importr('aqrr')\n",
    "        print(\"‚úÖ Loaded R package: aqrr\")\n",
    "        funcs = ro.r('ls(\"package:aqrr\")')\n",
    "        print(f\"üì¶ AQRR Functions Available: {list(funcs)[:6]} ...\")\n",
    "        logging.info(\"AQRR package loaded successfully\")\n",
    "    except ImportError as e:\n",
    "        print(f\"‚ùå Failed to load 'aqrr': {e}\")\n",
    "        logging.warning(f\"Failed to load 'aqrr': {e}\")\n",
    "        return None\n",
    "    \n",
    "    pandas2ri.activate()\n",
    "    return aqrr\n",
    "\n",
    "# Section 3: Data Loading Functions\n",
    "def load_fund_metadata():\n",
    "    query = \"\"\"\n",
    "    SELECT f.SymbolCUSIP, f.YC_Global_Category_ID, c.Global_Category_Name\n",
    "    FROM Funds_to_Screen f\n",
    "    JOIN YC_Global_Category_List c ON f.YC_Global_Category_ID = c.ID\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, engine)\n",
    "    df[[\"Region\", \"FactorProfile\"]] = df[\"Global_Category_Name\"].map(category_to_region).apply(pd.Series)\n",
    "    return df.dropna(subset=[\"Region\", \"FactorProfile\"])\n",
    "\n",
    "def load_fund_returns(fund_ids):\n",
    "    placeholders = \",\".join([f\"'{fid}'\" for fid in fund_ids])\n",
    "    query = f\"\"\"\n",
    "        SELECT SymbolCUSIP, Date, ReturnValue\n",
    "        FROM Fund_Returns_Timeseries\n",
    "        WHERE SymbolCUSIP IN ({placeholders})\n",
    "        AND Metric = '{RETURN_METRIC}'\n",
    "    \"\"\"\n",
    "    return pd.read_sql(query, engine, parse_dates=[\"Date\"]).pivot(index=\"Date\", columns=\"SymbolCUSIP\", values=\"ReturnValue\")\n",
    "\n",
    "def load_aqrr_factors(region=\"USA\", aqrr=None):\n",
    "    if aqrr is None:\n",
    "        return pd.DataFrame()\n",
    "    region_map = {\"USA\": \"US\", \"Global\": \"Global\", \"International\": \"Global Ex USA\"}\n",
    "    r_region = region_map.get(region, \"Global\")\n",
    "    print(f\"üì¶ Loading AQRR factor data for region: {r_region}\")\n",
    "    ro.r('library(dplyr)')\n",
    "    ro.r(f\"\"\"\n",
    "    mkt <- aqr_mkt_monthly() %>% filter(name == '{r_region}') %>%\n",
    "      mutate(date = as.character(date)) %>% select(date, mkt = value)\n",
    "    smb <- aqr_smb_monthly() %>% filter(name == '{r_region}') %>%\n",
    "      mutate(date = as.character(date)) %>% select(date, smb = value)\n",
    "    hml <- aqr_hml_ff_monthly() %>% filter(name == '{r_region}') %>%\n",
    "      mutate(date = as.character(date)) %>% select(date, hml = value)\n",
    "    umd <- aqr_umd_monthly() %>% filter(name == '{r_region}') %>%\n",
    "      mutate(date = as.character(date)) %>% select(date, umd = value)\n",
    "    qmj <- aqr_qmj_monthly() %>% filter(name == '{r_region}') %>%\n",
    "      mutate(date = as.character(date)) %>% select(date, qmj = value)\n",
    "    bab <- aqr_bab_monthly() %>% filter(name == '{r_region}') %>%\n",
    "      mutate(date = as.character(date)) %>% select(date, bab = value)\n",
    "    \"\"\")\n",
    "    def fix_date(r_obj):\n",
    "        with localconverter(pandas2ri.converter):\n",
    "            df = pandas2ri.rpy2py(r_obj)\n",
    "        df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "        return df[df['date'] >= pd.to_datetime(\"2015-01-31\")].reset_index(drop=True)\n",
    "    factors = (\n",
    "        fix_date(ro.r['mkt']).merge(fix_date(ro.r['smb']), on='date')\n",
    "            .merge(fix_date(ro.r['hml']), on='date')\n",
    "            .merge(fix_date(ro.r['umd']), on='date')\n",
    "            .merge(fix_date(ro.r['qmj']), on='date')\n",
    "            .merge(fix_date(ro.r['bab']), on='date')\n",
    "            .rename(columns={\"date\": \"Date\"})\n",
    "            .sort_values(\"Date\")\n",
    "            .reset_index(drop=True)\n",
    "    )\n",
    "    print(f\"‚úÖ Loaded AQRR factors: {r_region} | Shape: {factors.shape}\")\n",
    "    return factors\n",
    "\n",
    "def load_db_factors(factor_list, region=\"Global\", table=\"aqr_factors\", portfolio_filter=None):\n",
    "    # Use ? placeholder for PyODBC compatibility\n",
    "    factor_in_clause = ','.join([f\"'{f}'\" for f in factor_list])\n",
    "    portfolio_in_clause = ','.join([f\"'{p}'\" for p in portfolio_filter]) if portfolio_filter else ''\n",
    "    query = f\"\"\"\n",
    "        SELECT date AS Date, factor_symbol AS Factor, value AS Value\n",
    "        FROM {table}\n",
    "        WHERE region = ?\n",
    "        AND factor_symbol IN ({factor_in_clause})\n",
    "    \"\"\"\n",
    "    if portfolio_filter:\n",
    "        query += f\" AND portfolio IN ({portfolio_in_clause})\"\n",
    "    print(f\"Executing query: {query} with param: {region}\")  # Debug\n",
    "    df = pd.read_sql(query, engine, params=(region,), parse_dates=['Date'])\n",
    "    return df.pivot(index=\"Date\", columns=\"Factor\", values=\"Value\").rename(columns={'MKT': 'mkt', 'SMB': 'smb', 'HML-D': 'hml', 'UMD': 'umd', 'QMJ': 'qmj', 'BAB': 'bab', 'TSM': 'tsm'})\n",
    "\n",
    "def load_fixed_income_factors():\n",
    "    query = \"\"\"\n",
    "        SELECT Date, Factor_Name, ReturnValue\n",
    "        FROM Fixed_Income_Factor_Returns\n",
    "    \"\"\"\n",
    "    return pd.read_sql(query, engine, parse_dates=[\"Date\"]).pivot(index=\"Date\", columns=\"Factor_Name\", values=\"ReturnValue\")\n",
    "\n",
    "def compare_and_select_factors(region, r_factors, db_factors):\n",
    "    r_max = r_factors['Date'].max() if not r_factors.empty else pd.Timestamp(\"1900-01-01\")\n",
    "    db_max = db_factors.index.max() if not db_factors.empty else pd.Timestamp(\"1900-01-01\")\n",
    "    print(f\"üìÖ R max date: {r_max.date()} | DB max date: {db_max.date()}\")\n",
    "    if r_max > db_max:\n",
    "        print(f\"‚úÖ Using R-based AQRR factors for {region} (more recent)\")\n",
    "        return r_factors.set_index(\"Date\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Using DB-based AQRR factors for {region}\")\n",
    "        return db_factors\n",
    "\n",
    "def load_factors(region, category, aqrr=None):\n",
    "    region_map = {\"USA\": \"US\", \"Global\": \"Global\", \"International\": \"Global Ex USA\"}\n",
    "    db_region = region_map.get(region, \"Global\")\n",
    "    \n",
    "    if \"Equity\" in category:\n",
    "        db_factors = load_db_factors(['MKT', 'SMB', 'HML-D', 'QMJ', 'UMD', 'BAB', 'TSM'], db_region, portfolio_filter=['Global', 'Equities'])\n",
    "        db_factors['mkt-rf'] = db_factors['mkt'] - load_db_factors(['RF'], 'Global')['rf']\n",
    "        r_factors = load_aqrr_factors(region, aqrr) if aqrr else pd.DataFrame()\n",
    "        factors = compare_and_select_factors(region, r_factors, db_factors[['mkt-rf', 'smb', 'hml', 'qmj', 'umd', 'bab', 'tsm']])\n",
    "        return factors\n",
    "    elif \"Fixed Income\" in category:\n",
    "        fi_factors = load_fixed_income_factors()\n",
    "        tsm_fi = load_db_factors(['TSM'], 'Global', portfolio_filter=['Fixed Income'])\n",
    "        return pd.concat([fi_factors, tsm_fi], axis=1)\n",
    "    elif \"Commodities\" in category:\n",
    "        return load_db_factors(['COM', 'TSM'], 'Global', portfolio_filter=['Excess return of equal-weight commodities portfolio', 'Commodities'])\n",
    "    elif \"Allocation\" in category or \"Alternative\" in category:\n",
    "        db_factors = load_db_factors(['MKT', 'SMB', 'HML-D', 'QMJ', 'UMD', 'BAB', 'TSM'], db_region, portfolio_filter=['Global', 'Equities', 'Fixed Income'])\n",
    "        db_factors['mkt-rf'] = db_factors['mkt'] - load_db_factors(['RF'], 'Global')['rf']\n",
    "        r_factors = load_aqrr_factors(region, aqrr) if aqrr else pd.DataFrame()\n",
    "        factors = compare_and_select_factors(region, r_factors, db_factors[['mkt-rf', 'smb', 'hml', 'qmj', 'umd', 'bab', 'tsm']])\n",
    "        fi_factors = load_fixed_income_factors()\n",
    "        return pd.concat([factors, fi_factors], axis=1)\n",
    "    return pd.DataFrame()\n",
    "\n",
    "# Section 4: Rolling Regression Functions\n",
    "def run_rolling_regression_python(fund, returns, factors, regression_type):\n",
    "    results = []\n",
    "    returns.index = pd.to_datetime(returns.index)\n",
    "    factors.index = pd.to_datetime(factors.index)\n",
    "    viable_periods = [w for w in ROLLING_PERIODS if (returns.index.max() - relativedelta(months=w)) >= returns.index.min()]\n",
    "    \n",
    "    for window in viable_periods:\n",
    "        start = returns.index.min() + relativedelta(months=window)\n",
    "        for end_date in returns.loc[returns.index >= start].index:\n",
    "            start_date = end_date - relativedelta(months=window - 1)\n",
    "            y = returns.loc[start_date:end_date]\n",
    "            X = factors.loc[start_date:end_date]\n",
    "            X, y = X.align(y, join=\"inner\", axis=0)\n",
    "            if len(y) < window or y.isnull().any() or X.isnull().any().any():\n",
    "                continue\n",
    "            X_const = add_constant(X)\n",
    "            model = OLS(y, X_const).fit()\n",
    "            for factor in X.columns:\n",
    "                results.append({\n",
    "                    \"SymbolCUSIP\": fund,\n",
    "                    \"MonthEndDate\": end_date,\n",
    "                    \"RollPeriod\": f\"{window}m\",\n",
    "                    \"Factor_Name\": factor,\n",
    "                    \"Coefficient\": model.params.get(factor, np.nan),\n",
    "                    \"P_Value\": model.pvalues.get(factor, np.nan),\n",
    "                    \"Regression_Type\": regression_type\n",
    "                })\n",
    "    return results\n",
    "\n",
    "def run_rolling_regression_r(fund, returns, factors, regression_type):\n",
    "    with pandas2ri.localconverter(pandas2ri.converter):\n",
    "        r_returns = pandas2ri.py2rpy(returns)\n",
    "        r_factors = pandas2ri.py2rpy(factors)\n",
    "    ro.r.assign(\"returns\", r_returns)\n",
    "    ro.r.assign(\"factors\", r_factors)\n",
    "    ro.r(\"\"\"\n",
    "    library(dplyr)\n",
    "    results <- list()\n",
    "    for (w in c(12, 24, 36, 48, 60)) {\n",
    "        for (i in (w+1):nrow(returns)) {\n",
    "            fit <- lm(returns[(i-w+1):i] ~ ., data=factors[(i-w+1):i,])\n",
    "            coefs <- summary(fit)$coefficients\n",
    "            results[[length(results)+1]] <- data.frame(\n",
    "                RollPeriod = paste0(w, \"m\"),\n",
    "                Factor_Name = rownames(coefs)[-1],\n",
    "                Coefficient = coefs[-1, \"Estimate\"],\n",
    "                P_Value = coefs[-1, \"Pr(>|t|)\"]\n",
    "            )\n",
    "        }\n",
    "    }\n",
    "    results <- bind_rows(results)\n",
    "    \"\"\")\n",
    "    results = pandas2ri.rpy2py(ro.r[\"results\"])\n",
    "    results[\"SymbolCUSIP\"] = fund\n",
    "    results[\"Regression_Type\"] = regression_type\n",
    "    return results.to_dict(\"records\")\n",
    "\n",
    "def test_regression_speed(fund, returns, factors):\n",
    "    print(f\"Testing regression speed for {fund}...\")\n",
    "    start_time = time.time()\n",
    "    python_results = run_rolling_regression_python(fund, returns, factors, \"Python_OLS\")\n",
    "    python_time = time.time() - start_time\n",
    "    print(f\"Python time: {python_time:.2f} seconds | Results: {len(python_results)}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        r_results = run_rolling_regression_r(fund, returns, factors, \"R_OLS\")\n",
    "        r_time = time.time() - start_time\n",
    "        print(f\"R time: {r_time:.2f} seconds | Results: {len(r_results)}\")\n",
    "        return \"R\" if r_time < python_time else \"Python\"\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå R regression failed: {e}, falling back to Python\")\n",
    "        return \"Python\"\n",
    "\n",
    "# Section 5: Main Processing Pipeline\n",
    "def process_region(region, fund_subset, aqrr, regression_func):\n",
    "    categories = fund_subset[\"FactorProfile\"].unique()\n",
    "    records = []\n",
    "    \n",
    "    for category in categories:\n",
    "        cat_subset = fund_subset[fund_subset[\"FactorProfile\"] == category]\n",
    "        funds = cat_subset[\"SymbolCUSIP\"].tolist()\n",
    "        if SAMPLE_DRY_RUN:\n",
    "            funds = random.sample(funds, min(SAMPLE_SIZE, len(funds)))\n",
    "            print(f\"‚ÑπÔ∏è Sample dry run: Processing {len(funds)} funds in {region}/{category}\")\n",
    "        \n",
    "        fund_returns = load_fund_returns(funds)\n",
    "        factors = load_factors(region, category, aqrr)\n",
    "        \n",
    "        with ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "            futures = {executor.submit(regression_func, fund, fund_returns[fund], factors, f\"{region}_{category}_OLS\"): fund for fund in fund_returns.columns}\n",
    "            for future in tqdm(futures, desc=f\"üîÅ {region}/{category}\"):\n",
    "                try:\n",
    "                    records.extend(future.result())\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Error in {futures[future]}: {e}\")\n",
    "    \n",
    "    if records:\n",
    "        if not DRY_RUN:\n",
    "            insert_batch(records)\n",
    "        else:\n",
    "            print(f\"‚ÑπÔ∏è Dry run: Would have written {len(records)} records for {region}\")\n",
    "\n",
    "def main():\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    aqrr = initialize_r_environment()\n",
    "    use_r = aqrr is not None\n",
    "    if not use_r:\n",
    "        print(\"‚ö†Ô∏è R initialization failed, using DB factors only\")\n",
    "    \n",
    "    fund_meta = load_fund_metadata()\n",
    "    regions = fund_meta[\"Region\"].unique()\n",
    "    print(f\"üß† Total mapped funds: {len(fund_meta)}\")\n",
    "    print(f\"üìç Regions detected: {regions}\\n\")\n",
    "    \n",
    "    # Test R vs Python on a sample\n",
    "    sample_funds = fund_meta[\"SymbolCUSIP\"].sample(1).tolist()\n",
    "    sample_returns = load_fund_returns(sample_funds)\n",
    "    sample_factors = load_factors(\"USA\", \"US Equity Large Cap Blend\", aqrr)\n",
    "    best_method = test_regression_speed(sample_funds[0], sample_returns[sample_funds[0]], sample_factors)\n",
    "    regression_func = run_rolling_regression_r if best_method == \"R\" and use_r else run_rolling_regression_python\n",
    "    print(f\"Using {best_method} for regressions\")\n",
    "    \n",
    "    for region in regions:\n",
    "        fund_subset = fund_meta[fund_meta[\"Region\"] == region]\n",
    "        process_region(region, fund_subset, aqrr, regression_func)\n",
    "\n",
    "# Section 6: Database Output\n",
    "def insert_batch(records):\n",
    "    df = pd.DataFrame(records)\n",
    "    if not DRY_RUN:\n",
    "        for i in range(0, len(df), BATCH_INSERT_SIZE):\n",
    "            batch = df.iloc[i:i + BATCH_INSERT_SIZE]\n",
    "            batch.to_sql(\"AQRR_Factor_Attribution\", engine, if_exists=\"append\", index=False)\n",
    "    else:\n",
    "        print(f\"‚ÑπÔ∏è Dry run: Skipped writing {len(df)} records\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fa6d723-b01e-463f-bcc7-b42c13cfd6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ R Version: R version 4.4.3 (2025-02-28 ucrt)\n",
      "‚úÖ Loaded R package: aqrr\n",
      "üì¶ AQRR Functions Available: [':=', 'aqr_bab_daily', 'aqr_bab_monthly', 'aqr_commodities_long_run', 'aqr_credit_risk_premium', 'aqr_factor_premia_monthly'] ...\n"
     ]
    }
   ],
   "source": [
    "aqrr = initialize_r_environment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab60d65-322f-4d18-b17a-0c15a0ab966f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856bc910-2fd7-441d-9875-685a0879c49a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f8306f-8ffa-42ed-9e68-e3b4960ce69e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afe35ab-aede-4126-ada1-0d223c1200b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a8b8ba-8b74-4a61-a25c-65ea079bc9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49382231-ec5b-4e83-bed2-3906a12f8206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b8de9e-a90a-42ac-aa22-ce2ebcf6d921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa13722-8ce0-40d1-8d60-8af91b5b0899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563d01e3-3e8b-4e73-a4c1-4f369915b4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0871e3af-f8f9-43b4-96ca-8ec3c23fa9b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bff0b98-5a9d-4684-b3b1-8acc0616de5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474eb513-485d-4dd8-b02a-2463d63fed87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb737bd-92f0-4b4e-aa22-0b1da227a983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b8b4df-ea9e-4568-aeb2-ff1519326ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aecf990-8647-4cf4-b748-12f04e266885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b2501f-369f-4f4f-b12c-cdf51b8bdb47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Database Administration)",
   "language": "python",
   "name": "databaseadminenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
