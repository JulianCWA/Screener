{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5648a5-8be0-47fe-b2a9-6200eca9ba7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53636456-0c1a-4161-a368-541301058aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1525868-bb81-44d9-9e85-12bfe257860a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c0d5bd-12d4-42d4-aa7d-875a26785a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The script below populates the fixed income factor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "310b2a6f-7d9d-43f1-872f-38a4c8cf357e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Inserted 605 new rows into Fixed_Income_Factor_Returns.\n"
     ]
    }
   ],
   "source": [
    "#Section 1: Setup\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "connection_string = (\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/\"\n",
    "    \"CWA_Fund_Database?driver=ODBC+Driver+18+for+SQL+Server\"\n",
    "    \"&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "#Section 2: Define fixed income factors\n",
    "factors = {\n",
    "    'TERM':         ('VGLT', '^BBUTB13MTR'),\n",
    "    'TERM_Int':     ('IEF', '^BBUTB13MTR'),\n",
    "    'TERM_Long':    ('VGLT', 'IEF'),\n",
    "    'CREDIT':       ('^BBUSCOTR', 'VGLT'),\n",
    "    'CREDIT_HY':    ('^BBUSCOHYTR', 'IEF')\n",
    "}\n",
    "symbols = set(s for pair in factors.values() for s in pair)\n",
    "\n",
    "#Section 3: Load all relevant data from both tables\n",
    "symbol_str = \"', '\".join(symbols)\n",
    "query = f\"\"\"\n",
    "    SELECT Symbol, Date, ReturnValue FROM (\n",
    "        SELECT SymbolCUSIP AS Symbol, Date, ReturnValue \n",
    "        FROM dbo.Fund_Returns_Timeseries\n",
    "        WHERE SymbolCUSIP IN ('{symbol_str}')\n",
    "        UNION ALL\n",
    "        SELECT Benchmark_Symbol AS Symbol, Date, ReturnValue \n",
    "        FROM dbo.Benchmark_Returns_Timeseries\n",
    "        WHERE Benchmark_Symbol IN ('{symbol_str}')\n",
    "    ) AS combined\n",
    "\"\"\"\n",
    "all_returns = pd.read_sql(query, engine, parse_dates=['Date'])\n",
    "returns_wide = all_returns.pivot_table(index='Date', columns='Symbol', values='ReturnValue')\n",
    "\n",
    "#Section 4: Load existing factor-date combos to avoid duplication\n",
    "existing_query = \"\"\"\n",
    "    SELECT Factor_Name, Date FROM dbo.Fixed_Income_Factor_Returns\n",
    "\"\"\"\n",
    "existing_df = pd.read_sql(existing_query, engine, parse_dates=['Date'])\n",
    "existing_pairs = set(zip(existing_df['Factor_Name'], existing_df['Date']))\n",
    "\n",
    "#Section 5: Calculate factors\n",
    "factor_dfs = []\n",
    "for factor_name, (s1, s2) in factors.items():\n",
    "    if s1 in returns_wide.columns and s2 in returns_wide.columns:\n",
    "        df = returns_wide[[s1, s2]].dropna().copy()\n",
    "        df['ReturnValue'] = df[s1] - df[s2]\n",
    "        df['Factor_Name'] = factor_name\n",
    "        df['Source_1'] = s1\n",
    "        df['Source_2'] = s2\n",
    "        df['Notes'] = f\"{s1} minus {s2}\"\n",
    "        df['Date'] = df.index\n",
    "        df = df[['Factor_Name', 'Date', 'ReturnValue', 'Source_1', 'Source_2', 'Notes']]\n",
    "        # Filter out rows already in the DB\n",
    "        df = df[~df.set_index(['Factor_Name', 'Date']).index.isin(existing_pairs)]\n",
    "        factor_dfs.append(df.reset_index(drop=True))\n",
    "\n",
    "#Section 6: Combine and insert into SQL\n",
    "if factor_dfs:\n",
    "    final_df = pd.concat(factor_dfs, ignore_index=True)\n",
    "    final_df.to_sql(\"Fixed_Income_Factor_Returns\", engine, if_exists=\"append\", index=False)\n",
    "    print(f\"✅ Inserted {len(final_df)} new rows into Fixed_Income_Factor_Returns.\")\n",
    "else:\n",
    "    print(\"✅ No new factor data to insert — database is up to date.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71c3e74-a229-45e3-a6a5-fa3b7f4e20d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test of the AQRR database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbba39c-6933-49ea-a454-6c0a889a3f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Load R Home To not get fatal errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f01ae985-fa64-4161-999a-1c429c510c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"R version 4.4.3 (2025-02-28 ucrt)\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['R_HOME'] = r'C:\\Program Files\\R\\R-4.4.3'  # Use raw string (r) to handle backslashes\n",
    "import rpy2.robjects as ro\n",
    "print(ro.r('R.version.string'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd09f28c-d3a7-4049-bf7c-65b2fe20c8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Disable JIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e49091c-abed-4eb2-a739-3aec085713fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"R version 4.4.3 (2025-02-28 ucrt)\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['R_JIT_ENABLED'] = '0'  # Disable JIT\n",
    "import rpy2.robjects as ro\n",
    "print(ro.r('R.version.string'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12884e3b-a05a-4734-8cb6-e55c44ed6df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Test connection to R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3dbd29b-83da-4aa7-b493-8486bdc5377f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R version 4.4.3 (2025-02-28 ucrt)']\n"
     ]
    }
   ],
   "source": [
    "import rpy2.robjects as ro\n",
    "print(ro.r('R.version.string'))  # Test basic R connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e724e03-10c3-4cd0-993c-9addeac6da6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: Test connection to AQRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d8c0732-3625-4a7e-a1bd-1dd3352c2ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[':=' 'aqr_bab_daily' 'aqr_bab_monthly' 'aqr_commodities_long_run'\n",
      " 'aqr_credit_risk_premium' 'aqr_factor_premia_monthly'\n",
      " 'aqr_hml_devil_daily' 'aqr_hml_devil_monthly' 'aqr_hml_ff_daily'\n",
      " 'aqr_hml_ff_monthly' 'aqr_mkt_daily' 'aqr_mkt_monthly'\n",
      " 'aqr_momentum_monthly' 'aqr_qmj_daily' 'aqr_qmj_monthly' 'aqr_smb_daily'\n",
      " 'aqr_smb_monthly' 'aqr_umd_daily' 'aqr_umd_monthly' 'as_label' 'as_name'\n",
      " 'enquo' 'enquos']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['R_HOME'] = r'C:\\Program Files\\R\\R-4.4.3'\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "aqrr = importr('aqrr')\n",
    "funcs = ro.r('ls(\"package:aqrr\")')\n",
    "print(funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e6643f3-758f-46c8-8451-ba3fbf939814",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: \n",
      "R[write to console]: -\n",
      "R[write to console]: \n",
      "R[write to console]: /\n",
      "                                                                              \n",
      "R[write to console]: \n",
      "R[write to console]: \n",
      "R[write to console]: /\n",
      "                                                                              \n",
      "R[write to console]: \n",
      "R[write to console]: \n",
      "R[write to console]: -\n",
      "                                                                              \n",
      "R[write to console]: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      date  mkt_excess\n",
      "1 -15860.0    0.028335\n",
      "2 -15829.0    0.026245\n",
      "3 -15799.0    0.003287\n",
      "4 -15768.0   -0.031103\n",
      "5 -15738.0    0.024357\n"
     ]
    }
   ],
   "source": [
    "from rpy2.robjects import r, pandas2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "pandas2ri.activate()\n",
    "aqrr = importr(\"aqrr\")\n",
    "dplyr = importr(\"dplyr\")\n",
    "\n",
    "# Run MKT test\n",
    "r('mkt <- aqr_mkt_monthly() %>% dplyr::filter(name == \"USA\") %>% dplyr::select(date, mkt_excess = value)')\n",
    "mkt = pandas2ri.rpy2py(r['mkt'])\n",
    "print(mkt.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92017a49-6f5d-4b79-b984-ff4a2fa9383a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "cannot load library 'C:\\Program Files\\R\\R-4.4.1\\bin\\x64\\R.dll': error 0x7e",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrpy2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrobjects\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m r, pandas2ri\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrpy2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrobjects\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpackages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m importr\n\u001b[0;32m      5\u001b[0m pandas2ri\u001b[38;5;241m.\u001b[39mactivate()\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\rpy2\\robjects\\__init__.py:16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtypes\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrpy2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrinterface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrinterface\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrpy2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrinterface_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membedded\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrpy2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrinterface_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenrlib\u001b[39;00m\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\rpy2\\rinterface.py:21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Union\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrpy2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrinterface_lib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m openrlib\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrpy2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrinterface_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_rinterface_capi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_rinterface\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrpy2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrinterface_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membedded\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01membedded\u001b[39;00m\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\rpy2\\rinterface_lib\\openrlib.py:58\u001b[0m\n\u001b[0;32m     56\u001b[0m     rlib \u001b[38;5;241m=\u001b[39m _rinterface_cffi\u001b[38;5;241m.\u001b[39mlib\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     rlib \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen_rlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR_HOME\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# R macros and functions\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_symbol_or_fallback\u001b[39m(symbol: \u001b[38;5;28mstr\u001b[39m, fallback: typing\u001b[38;5;241m.\u001b[39mAny):\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\rpy2\\rinterface_lib\\openrlib.py:51\u001b[0m, in \u001b[0;36m_dlopen_rlib\u001b[1;34m(r_home)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe library path cannot be None.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m     rlib \u001b[38;5;241m=\u001b[39m \u001b[43mffi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlib_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rlib\n",
      "\u001b[1;31mOSError\u001b[0m: cannot load library 'C:\\Program Files\\R\\R-4.4.1\\bin\\x64\\R.dll': error 0x7e"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rpy2.robjects import r, pandas2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "pandas2ri.activate()\n",
    "aqrr = importr(\"aqrr\")\n",
    "dplyr = importr(\"dplyr\")\n",
    "\n",
    "def get_aqrr_factors(region=\"USA\"):\n",
    "    # 1. Call AQRR download functions in R\n",
    "    r(f\"mkt <- aqr_mkt_monthly() %>% filter(name == '{region}') %>% select(date, mkt_excess = value)\")\n",
    "    r(f\"smb <- aqr_smb_monthly() %>% filter(name == '{region}') %>% select(date, smb = value)\")\n",
    "    r(f\"hml <- aqr_hml_ff_monthly() %>% filter(name == '{region}') %>% select(date, hml = value)\")\n",
    "    r(f\"umd <- aqr_umd_monthly() %>% filter(name == '{region}') %>% select(date, umd = value)\")\n",
    "    r(f\"qmj <- aqr_qmj_monthly() %>% filter(name == '{region}') %>% select(date, qmj = value)\")\n",
    "    r(f\"bab <- aqr_bab_monthly() %>% filter(name == '{region}') %>% select(date, bab = value)\")\n",
    "\n",
    "    # 2. Merge all by date in R\n",
    "    r(\"\"\"\n",
    "        factors <- Reduce(function(x, y) full_join(x, y, by = \"date\"), \n",
    "                          list(mkt, smb, hml, umd, qmj, bab))\n",
    "    \"\"\")\n",
    "\n",
    "    # 3. Convert to pandas DataFrame\n",
    "    factors_df = pandas2ri.rpy2py(r['factors'])\n",
    "    factors_df = factors_df.sort_values(\"date\").reset_index(drop=True)\n",
    "    \n",
    "    return factors_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63a065b-fb24-484b-9071-cac76c2c9fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rpy2.robjects import r, pandas2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "# Activate conversion\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Load AQRR and dplyr\n",
    "aqrr = importr(\"aqrr\")\n",
    "dplyr = importr(\"dplyr\")\n",
    "\n",
    "# Test region\n",
    "region = \"USA\"\n",
    "print(f\"⏳ Loading MKT factor for region: {region}\")\n",
    "\n",
    "# Call just MKT factor with filtering and renaming\n",
    "r(f\"\"\"\n",
    "mkt <- aqr_mkt_monthly() %>%\n",
    "  dplyr::filter(name == '{region}') %>%\n",
    "  dplyr::select(date, mkt_excess = value)\n",
    "\"\"\")\n",
    "\n",
    "# Pull from R to pandas\n",
    "mkt_df = pandas2ri.rpy2py(r['mkt'])\n",
    "\n",
    "# Show results\n",
    "print(\"✅ Retrieved MKT factor:\")\n",
    "print(mkt_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ce3193-f47d-4905-a5f1-4ef342c57a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from rpy2.robjects import r, pandas2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "# Setup\n",
    "pandas2ri.activate()\n",
    "aqrr = importr(\"aqrr\")\n",
    "dplyr = importr(\"dplyr\")\n",
    "lubridate = importr(\"lubridate\")\n",
    "\n",
    "# Calculate cutoff date for last 3 years\n",
    "cutoff_date = (datetime.today() - timedelta(days=3*365)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# ⏳ Filter and select USA MKT data for last 3 years\n",
    "r(f\"\"\"\n",
    "mkt <- aqr_mkt_monthly() %>%\n",
    "  dplyr::filter(name == \"USA\" & date >= as.Date('{cutoff_date}')) %>%\n",
    "  dplyr::select(date, mkt_excess = value)\n",
    "\"\"\")\n",
    "\n",
    "# Pull into Python\n",
    "mkt_df = pandas2ri.rpy2py(r['mkt'])\n",
    "print(\"✅ MKT data for USA (last 3 years):\")\n",
    "print(mkt_df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc16b22-b5d4-4c23-8581-a5dffa8a0652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2.robjects import r, pandas2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Fix for R 4.4+ JIT issue\n",
    "r(\"compiler::enableJIT(0)\")\n",
    "\n",
    "# Enable pandas ↔ R conversion\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Load R libraries\n",
    "aqrr = importr(\"aqrr\")\n",
    "dplyr = importr(\"dplyr\")\n",
    "\n",
    "# Set date range\n",
    "cutoff_date = (datetime.today() - timedelta(days=3*365)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Run MKT factor query\n",
    "r(f\"\"\"\n",
    "mkt <- aqr_mkt_monthly() %>%\n",
    "  dplyr::filter(name == \"USA\" & date >= as.Date('{cutoff_date}')) %>%\n",
    "  dplyr::select(date, mkt_excess = value)\n",
    "\"\"\")\n",
    "\n",
    "# Pull to pandas\n",
    "mkt_df = pandas2ri.rpy2py(r['mkt'])\n",
    "print(mkt_df.tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f0d511e-8f73-48af-8077-a85f2255f798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R version 4.4.3 (2025-02-28 ucrt)']\n"
     ]
    }
   ],
   "source": [
    "import rpy2.robjects as ro\n",
    "print(ro.r('R.version.string'))  # Test basic R connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecc6128c-0dd2-487f-b096-35228946d77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] \":=\"                        \"aqr_bab_daily\"            \n",
      " [3] \"aqr_bab_monthly\"           \"aqr_commodities_long_run\" \n",
      " [5] \"aqr_credit_risk_premium\"   \"aqr_factor_premia_monthly\"\n",
      " [7] \"aqr_hml_devil_daily\"       \"aqr_hml_devil_monthly\"    \n",
      " [9] \"aqr_hml_ff_daily\"          \"aqr_hml_ff_monthly\"       \n",
      "[11] \"aqr_mkt_daily\"             \"aqr_mkt_monthly\"          \n",
      "[13] \"aqr_momentum_monthly\"      \"aqr_qmj_daily\"            \n",
      "[15] \"aqr_qmj_monthly\"           \"aqr_smb_daily\"            \n",
      "[17] \"aqr_smb_monthly\"           \"aqr_umd_daily\"            \n",
      "[19] \"aqr_umd_monthly\"           \"as_label\"                 \n",
      "[21] \"as_name\"                   \"enquo\"                    \n",
      "[23] \"enquos\"                   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['R_HOME'] = r'C:\\Program Files\\R\\R-4.4.3'\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "aqrr = importr('aqrr')\n",
    "funcs = ro.r('ls(\"package:aqrr\")')\n",
    "print(funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93526c5c-a842-4ca4-ab88-469f659a2e15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: \n",
      "R[write to console]: -\n",
      "R[write to console]: \n",
      "R[write to console]: /\n",
      "                                                                              \n",
      "R[write to console]: \n",
      "R[write to console]: \n",
      "R[write to console]: /\n",
      "                                                                              \n",
      "R[write to console]: \n",
      "R[write to console]: \n",
      "R[write to console]: -\n",
      "                                                                              \n",
      "R[write to console]: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MKT factor (USA, last 3 years):\n",
      "      date  mkt_excess\n",
      "1  19112.0   -0.090538\n",
      "2  19143.0   -0.003493\n",
      "3  19173.0   -0.086723\n",
      "4  19204.0    0.092145\n",
      "5  19235.0   -0.037716\n",
      "       date  mkt_excess\n",
      "10  19388.0    0.068904\n",
      "11  19416.0   -0.027004\n",
      "12  19447.0    0.018459\n",
      "13  19477.0    0.004732\n",
      "14  19508.0   -0.003810\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# ✅ Step 1: Ensure R path is set correctly\n",
    "os.environ['R_HOME'] = r\"C:\\Program Files\\R\\R-4.4.3\"\n",
    "os.environ['PATH'] += r\";C:\\Program Files\\R\\R-4.4.3\\bin\\x64\"\n",
    "\n",
    "# ✅ Step 2: Import rpy2\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "\n",
    "# ✅ Step 3: Enable pandas <-> R conversion\n",
    "pandas2ri.activate()\n",
    "\n",
    "# ✅ Step 4: Import needed R packages\n",
    "aqrr = importr('aqrr')\n",
    "dplyr = importr('dplyr')\n",
    "\n",
    "# ✅ Step 5: Build R filter string\n",
    "cutoff_date = (datetime.today() - timedelta(days=3*365)).strftime(\"%Y-%m-%d\")\n",
    "ro.r(f\"\"\"\n",
    "    library(aqrr)\n",
    "    library(dplyr)\n",
    "    mkt <- aqr_mkt_monthly() %>%\n",
    "        filter(name == 'USA' & date >= as.Date('{cutoff_date}')) %>%\n",
    "        mutate(date = as.Date(date)) %>%\n",
    "        select(date, mkt_excess = value)\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# ✅ Step 6: Bring it into pandas\n",
    "mkt_df = pandas2ri.rpy2py(ro.r['mkt'])\n",
    "\n",
    "# ✅ Step 7: Display result\n",
    "print(\"✅ MKT factor (USA, last 3 years):\")\n",
    "print(mkt_df.head())\n",
    "print(mkt_df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bd0c6b5-4ab6-4b4d-a5d6-1d797c26404a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cutoff date: 2022-04-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: \n",
      "R[write to console]: -\n",
      "R[write to console]: \n",
      "R[write to console]: /\n",
      "                                                                              \n",
      "R[write to console]: \n",
      "R[write to console]: \n",
      "R[write to console]: /\n",
      "                                                                              \n",
      "R[write to console]: \n",
      "R[write to console]: \n",
      "R[write to console]: -\n",
      "                                                                              \n",
      "R[write to console]: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned MKT factor (USA, last 3 years):\n",
      "Empty DataFrame\n",
      "Columns: [date, mkt_excess]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [date, mkt_excess]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# ✅ Step 1: Configure R path\n",
    "os.environ['R_HOME'] = r\"C:\\\\Program Files\\\\R\\\\R-4.4.3\"\n",
    "os.environ['PATH'] += r\";C:\\\\Program Files\\\\R\\\\R-4.4.3\\\\bin\\\\x64\"\n",
    "\n",
    "# ✅ Step 2: rpy2 setup\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "\n",
    "# ✅ Step 3: Load packages\n",
    "aqrr = importr('aqrr')\n",
    "dplyr = importr('dplyr')\n",
    "\n",
    "# ✅ Step 4: Cutoff date for last 3 years\n",
    "cutoff_date = (datetime.today() - timedelta(days=3 * 365)).strftime(\"%Y-%m-%d\")\n",
    "print(\"Using cutoff date:\", cutoff_date)\n",
    "\n",
    "# ✅ Step 5: Pull raw MKT data for USA (date will come as serial)\n",
    "ro.r(f\"\"\"\n",
    "    mkt <- aqr_mkt_monthly() %>%\n",
    "        dplyr::filter(name == \"USA\") %>%\n",
    "        dplyr::select(date, mkt_excess = value)\n",
    "\"\"\")\n",
    "\n",
    "# ✅ Step 6: Convert to pandas\n",
    "mkt_df = pandas2ri.rpy2py(ro.r['mkt'])\n",
    "\n",
    "# ✅ Step 7: Convert Excel serial to datetime\n",
    "mkt_df['date'] = mkt_df['date'].apply(lambda x: datetime(1899, 12, 30) + timedelta(days=int(x)))\n",
    "\n",
    "# ✅ Step 8: Filter in Python to last 3 years\n",
    "cutoff = datetime.today() - timedelta(days=3*365)\n",
    "mkt_df = mkt_df[mkt_df['date'] >= cutoff].reset_index(drop=True)\n",
    "\n",
    "# ✅ Step 9: Show result\n",
    "print(\"✅ Cleaned MKT factor (USA, last 3 years):\")\n",
    "print(mkt_df.head())\n",
    "print(mkt_df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "570cb9e4-3bbc-4fb4-9aa7-62a98fcc2cdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📅 Using cutoff date: 2022-04-03\n",
      "\n",
      "🧪 Raw MKT from R > pandas (first 5):\n",
      "      date       mkt\n",
      "1 -15860.0  0.028335\n",
      "2 -15829.0  0.026245\n",
      "3 -15799.0  0.003287\n",
      "4 -15768.0 -0.031103\n",
      "5 -15738.0  0.024357\n",
      "🧪 dtypes:\n",
      "date    float64\n",
      "mkt     float64\n",
      "dtype: object\n",
      "\n",
      "✅ Final AQRR Factors (USA, Last 3 Years):\n",
      "Empty DataFrame\n",
      "Columns: [date, mkt, smb, hml, umd, qmj, bab]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [date, mkt, smb, hml, umd, qmj, bab]\n",
      "Index: []\n",
      "\n",
      "✅ Shape: (0, 7)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# ✅ R + PATH setup\n",
    "os.environ['R_HOME'] = r\"C:\\\\Program Files\\\\R\\\\R-4.4.3\"\n",
    "os.environ['PATH'] += r\";C:\\\\Program Files\\\\R\\\\R-4.4.3\\\\bin\\\\x64\"\n",
    "\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "import rpy2.rinterface_lib.callbacks\n",
    "import logging\n",
    "\n",
    "# ✅ Suppress R console output (like \"R[write to console]:\")\n",
    "rpy2.rinterface_lib.callbacks.logger.setLevel(logging.ERROR)\n",
    "\n",
    "# ✅ Activate pandas ↔ R DataFrame bridge\n",
    "pandas2ri.activate()\n",
    "\n",
    "# ✅ Load required R packages\n",
    "aqrr = importr('aqrr')\n",
    "dplyr = importr('dplyr')\n",
    "\n",
    "# ✅ Set cutoff date for last 3 years\n",
    "cutoff = datetime.today() - timedelta(days=3 * 365)\n",
    "print(\"📅 Using cutoff date:\", cutoff.date())\n",
    "\n",
    "# ✅ Safe date fixer (detects Excel-style float vs datetime)\n",
    "def fix_excel_date(df):\n",
    "    if pd.api.types.is_float_dtype(df['date']):\n",
    "        df['date'] = df['date'].apply(lambda d: datetime(1899, 12, 30) + timedelta(days=int(d)))\n",
    "    return df[df['date'] >= cutoff].reset_index(drop=True)\n",
    "\n",
    "# ✅ Step 1: Load all 6 AQRR factors from R\n",
    "ro.r(\"\"\"\n",
    "mkt <- aqr_mkt_monthly() %>% filter(name == \"USA\") %>% select(date, mkt = value)\n",
    "smb <- aqr_smb_monthly() %>% filter(name == \"USA\") %>% select(date, smb = value)\n",
    "hml <- aqr_hml_ff_monthly() %>% filter(name == \"USA\") %>% select(date, hml = value)\n",
    "umd <- aqr_umd_monthly() %>% filter(name == \"USA\") %>% select(date, umd = value)\n",
    "qmj <- aqr_qmj_monthly() %>% filter(name == \"USA\") %>% select(date, qmj = value)\n",
    "bab <- aqr_bab_monthly() %>% filter(name == \"USA\") %>% select(date, bab = value)\n",
    "\"\"\")\n",
    "# DEBUG: See raw R > pandas transfer\n",
    "raw_mkt_df = pandas2ri.rpy2py(ro.r['mkt'])\n",
    "print(\"\\n🧪 Raw MKT from R > pandas (first 5):\")\n",
    "print(raw_mkt_df.head())\n",
    "print(\"🧪 dtypes:\")\n",
    "print(raw_mkt_df.dtypes)\n",
    "\n",
    "# ✅ Step 2: Convert to pandas & fix dates\n",
    "mkt_df = fix_excel_date(pandas2ri.rpy2py(ro.r['mkt']))\n",
    "smb_df = fix_excel_date(pandas2ri.rpy2py(ro.r['smb']))\n",
    "hml_df = fix_excel_date(pandas2ri.rpy2py(ro.r['hml']))\n",
    "umd_df = fix_excel_date(pandas2ri.rpy2py(ro.r['umd']))\n",
    "qmj_df = fix_excel_date(pandas2ri.rpy2py(ro.r['qmj']))\n",
    "bab_df = fix_excel_date(pandas2ri.rpy2py(ro.r['bab']))\n",
    "\n",
    "# ✅ Step 3: Merge all on date\n",
    "factors = mkt_df \\\n",
    "    .merge(smb_df, on='date', how='inner') \\\n",
    "    .merge(hml_df, on='date', how='inner') \\\n",
    "    .merge(umd_df, on='date', how='inner') \\\n",
    "    .merge(qmj_df, on='date', how='inner') \\\n",
    "    .merge(bab_df, on='date', how='inner')\n",
    "\n",
    "# ✅ Step 4: Final preview\n",
    "print(\"\\n✅ Final AQRR Factors (USA, Last 3 Years):\")\n",
    "print(factors.head())\n",
    "print(factors.tail())\n",
    "print(f\"\\n✅ Shape: {factors.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a19bad-b3de-480f-8260-2d3f88e41d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code below was to test the issues around date's from R vs Python & test it \n",
    "# There was coruption in how it came over, this code below helped fixed it\n",
    "# Then we verified this fix via an R tupple, then below this incorporated it into a funciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8fe7b83-e3e6-4aa7-9493-e7124787a8e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📅 Using cutoff date: 2022-04-03\n",
      "\n",
      "✅ Final AQRR Factors (USA, Last 3 Years):\n",
      "        date       mkt       smb       hml       umd       qmj       bab\n",
      "0 2022-04-30 -0.090538 -0.011782  0.065451  0.050946  0.048957  0.015034\n",
      "1 2022-05-31 -0.003493 -0.025232  0.075750  0.019250  0.034398  0.000300\n",
      "2 2022-06-30 -0.086723  0.015858 -0.053612  0.007132  0.048585  0.019509\n",
      "3 2022-07-31  0.092145  0.010569 -0.053493 -0.046330 -0.037926 -0.024594\n",
      "4 2022-08-31 -0.037716  0.014321  0.009722  0.026841 -0.033810 -0.018017\n",
      "         date       mkt       smb       hml       umd       qmj       bab\n",
      "9  2023-01-31  0.068904  0.047574 -0.037542 -0.155380 -0.080619 -0.045561\n",
      "10 2023-02-28 -0.027004  0.003444 -0.001986  0.014203  0.027468  0.007468\n",
      "11 2023-03-31  0.018459 -0.051877 -0.072046 -0.017036  0.028151 -0.023685\n",
      "12 2023-04-30  0.004732 -0.037933  0.008794  0.021689  0.010236  0.000746\n",
      "13 2023-05-31 -0.003810  0.020872 -0.086065  0.008928 -0.042434 -0.053512\n",
      "\n",
      "✅ Shape: (14, 7)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# ✅ R + PATH setup\n",
    "os.environ['R_HOME'] = r\"C:\\\\Program Files\\\\R\\\\R-4.4.3\"\n",
    "os.environ['PATH'] += r\";C:\\\\Program Files\\\\R\\\\R-4.4.3\\\\bin\\\\x64\"\n",
    "\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "import rpy2.rinterface_lib.callbacks\n",
    "import logging\n",
    "\n",
    "# ✅ Suppress R[write to console]:\n",
    "rpy2.rinterface_lib.callbacks.logger.setLevel(logging.ERROR)\n",
    "\n",
    "# ✅ Activate R ↔ pandas conversion\n",
    "pandas2ri.activate()\n",
    "\n",
    "# ✅ Load R libraries\n",
    "aqrr = importr('aqrr')\n",
    "dplyr = importr('dplyr')\n",
    "\n",
    "# ✅ Define cutoff date\n",
    "cutoff = datetime.today() - timedelta(days=3 * 365)\n",
    "print(\"📅 Using cutoff date:\", cutoff.date())\n",
    "\n",
    "# ✅ Fix date (handles character or datetime)\n",
    "def fix_date_column(df):\n",
    "    if pd.api.types.is_string_dtype(df['date']):\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "    return df[df['date'] >= cutoff].reset_index(drop=True)\n",
    "\n",
    "# ✅ Step 1: Pull AQRR data in R, force date to character\n",
    "ro.r(\"\"\"\n",
    "mkt <- aqr_mkt_monthly() %>% filter(name == \"USA\") %>% \n",
    "  mutate(date = as.character(date)) %>% select(date, mkt = value)\n",
    "\n",
    "smb <- aqr_smb_monthly() %>% filter(name == \"USA\") %>% \n",
    "  mutate(date = as.character(date)) %>% select(date, smb = value)\n",
    "\n",
    "hml <- aqr_hml_ff_monthly() %>% filter(name == \"USA\") %>% \n",
    "  mutate(date = as.character(date)) %>% select(date, hml = value)\n",
    "\n",
    "umd <- aqr_umd_monthly() %>% filter(name == \"USA\") %>% \n",
    "  mutate(date = as.character(date)) %>% select(date, umd = value)\n",
    "\n",
    "qmj <- aqr_qmj_monthly() %>% filter(name == \"USA\") %>% \n",
    "  mutate(date = as.character(date)) %>% select(date, qmj = value)\n",
    "\n",
    "bab <- aqr_bab_monthly() %>% filter(name == \"USA\") %>% \n",
    "  mutate(date = as.character(date)) %>% select(date, bab = value)\n",
    "\"\"\")\n",
    "\n",
    "# ✅ Step 2: Convert each to pandas + fix dates\n",
    "mkt_df = fix_date_column(pandas2ri.rpy2py(ro.r['mkt']))\n",
    "smb_df = fix_date_column(pandas2ri.rpy2py(ro.r['smb']))\n",
    "hml_df = fix_date_column(pandas2ri.rpy2py(ro.r['hml']))\n",
    "umd_df = fix_date_column(pandas2ri.rpy2py(ro.r['umd']))\n",
    "qmj_df = fix_date_column(pandas2ri.rpy2py(ro.r['qmj']))\n",
    "bab_df = fix_date_column(pandas2ri.rpy2py(ro.r['bab']))\n",
    "\n",
    "# ✅ Step 3: Merge all on date\n",
    "factors = mkt_df \\\n",
    "    .merge(smb_df, on='date', how='inner') \\\n",
    "    .merge(hml_df, on='date', how='inner') \\\n",
    "    .merge(umd_df, on='date', how='inner') \\\n",
    "    .merge(qmj_df, on='date', how='inner') \\\n",
    "    .merge(bab_df, on='date', how='inner')\n",
    "\n",
    "# ✅ Step 4: Final preview\n",
    "print(\"\\n✅ Final AQRR Factors (USA, Last 3 Years):\")\n",
    "print(factors.head())\n",
    "print(factors.tail())\n",
    "print(f\"\\n✅ Shape: {factors.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c86a8c-9a13-4f24-9bdc-95bfb4c74f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code below was to test the issues around date's from R vs Python & test it as a funciton\n",
    "# There was coruption in how it came over, this code below helped fixed it\n",
    "#    # Helper to clean and filter\n",
    "#    def fix_date(df):\n",
    "#        df['date'] = pd.to_datetime(df['date'])\n",
    "#        return df[df['date'] >= cutoff].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2a50b4b-96ff-4851-b434-b20e39c85ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_aqrr_factors(region=\"USA\", years=3):\n",
    "    import os\n",
    "    from datetime import datetime, timedelta\n",
    "    import pandas as pd\n",
    "    from rpy2.robjects import r as ro\n",
    "    from rpy2.robjects.packages import importr\n",
    "    from rpy2.robjects import pandas2ri\n",
    "    import rpy2.rinterface_lib.callbacks\n",
    "    import logging\n",
    "\n",
    "    # R paths\n",
    "    os.environ['R_HOME'] = r\"C:\\\\Program Files\\\\R\\\\R-4.4.3\"\n",
    "    os.environ['PATH'] += r\";C:\\\\Program Files\\\\R\\\\R-4.4.3\\\\bin\\\\x64\"\n",
    "\n",
    "    # Suppress R logging\n",
    "    rpy2.rinterface_lib.callbacks.logger.setLevel(logging.ERROR)\n",
    "\n",
    "    # Load R libs\n",
    "    aqrr = importr('aqrr')\n",
    "    dplyr = importr('dplyr')\n",
    "    pandas2ri.activate()\n",
    "\n",
    "    # Calculate cutoff\n",
    "    cutoff = datetime.today() - timedelta(days=years * 365)\n",
    "    print(f\"📅 Cutoff date: {cutoff.date()} for region: {region}\")\n",
    "\n",
    "    # R: Load and filter factors\n",
    "    ro(f\"\"\"\n",
    "    mkt <- aqr_mkt_monthly() %>% filter(name == '{region}') %>%\n",
    "      mutate(date = as.character(date)) %>% select(date, mkt = value)\n",
    "    smb <- aqr_smb_monthly() %>% filter(name == '{region}') %>%\n",
    "      mutate(date = as.character(date)) %>% select(date, smb = value)\n",
    "    hml <- aqr_hml_ff_monthly() %>% filter(name == '{region}') %>%\n",
    "      mutate(date = as.character(date)) %>% select(date, hml = value)\n",
    "    umd <- aqr_umd_monthly() %>% filter(name == '{region}') %>%\n",
    "      mutate(date = as.character(date)) %>% select(date, umd = value)\n",
    "    qmj <- aqr_qmj_monthly() %>% filter(name == '{region}') %>%\n",
    "      mutate(date = as.character(date)) %>% select(date, qmj = value)\n",
    "    bab <- aqr_bab_monthly() %>% filter(name == '{region}') %>%\n",
    "      mutate(date = as.character(date)) %>% select(date, bab = value)\n",
    "    \"\"\")\n",
    "\n",
    "    # Helper to clean and filter\n",
    "    def fix_date(df):\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        return df[df['date'] >= cutoff].reset_index(drop=True)\n",
    "\n",
    "    # Pull into Python\n",
    "    mkt_df = fix_date(pandas2ri.rpy2py(ro['mkt']))\n",
    "    smb_df = fix_date(pandas2ri.rpy2py(ro['smb']))\n",
    "    hml_df = fix_date(pandas2ri.rpy2py(ro['hml']))\n",
    "    umd_df = fix_date(pandas2ri.rpy2py(ro['umd']))\n",
    "    qmj_df = fix_date(pandas2ri.rpy2py(ro['qmj']))\n",
    "    bab_df = fix_date(pandas2ri.rpy2py(ro['bab']))\n",
    "\n",
    "    # Merge\n",
    "    factors = mkt_df \\\n",
    "        .merge(smb_df, on='date') \\\n",
    "        .merge(hml_df, on='date') \\\n",
    "        .merge(umd_df, on='date') \\\n",
    "        .merge(qmj_df, on='date') \\\n",
    "        .merge(bab_df, on='date')\n",
    "\n",
    "    print(f\"✅ Loaded AQRR factors: {region} | Shape: {factors.shape}\")\n",
    "    return factors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f0182d-2115-45b4-be8e-0c50138efe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_aqrr_factors(region=\"USA\", years=3)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a9aeb2-3893-44f6-a178-ba9463fd1ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First attempt at full code for regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b36156-fc46-4f32-bea0-a572e1dc7ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Section 1: Imports and Config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sqlalchemy import create_engine, text\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "from rpy2.robjects import r, pandas2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "import datetime\n",
    "\n",
    "# Enable R data conversion\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Import R AQRR library\n",
    "aqrr = importr(\"aqrr\")\n",
    "\n",
    "# DB Connection\n",
    "connection_string = (\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/CWA_Fund_Database\"\n",
    "    \"?driver=ODBC+Driver+18+for+SQL+Server\"\n",
    "    \"&trusted_connection=yes\"\n",
    "    \"&TrustServerCertificate=yes\"\n",
    ")\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Config\n",
    "ROLLING_PERIODS = [12, 24, 36, 48, 60]\n",
    "DRY_RUN = True\n",
    "MAX_WORKERS = 8\n",
    "BATCH_SIZE = 200\n",
    "INSERT_CHUNK_SIZE = 3000\n",
    "\n",
    "# Sample region mapping (expand as needed)\n",
    "category_to_region = {\n",
    "    # USA\n",
    "    \"US Equity Large Cap Blend\": \"USA\",\n",
    "    \"US Equity Large Cap Growth\": \"USA\",\n",
    "    \"US Equity Large Cap Value\": \"USA\",\n",
    "    \"US Equity Mid Cap\": \"USA\",\n",
    "    \"US Equity Small Cap\": \"USA\",\n",
    "    \"US Fixed Income\": \"USA\",\n",
    "    \"US Municipal Fixed Income\": \"USA\",\n",
    "    \"Communications Sector Equity\": \"USA\",\n",
    "    \"Consumer Goods & Services Sector Equity\": \"USA\",\n",
    "    \"Energy Sector Equity\": \"USA\",\n",
    "    \"Financials Sector Equity\": \"USA\",\n",
    "    \"Healthcare Sector Equity\": \"USA\",\n",
    "    \"Industrials Sector Equity\": \"USA\",\n",
    "    \"Infrastructure Sector Equity\": \"USA\",\n",
    "    \"Other Sector Equity\": \"USA\",\n",
    "    \"Precious Metals Sector Equity\": \"USA\",\n",
    "    \"Technology Sector Equity\": \"USA\",\n",
    "    \"Utilities Sector Equity\": \"USA\",\n",
    "    \"Real Estate Sector Equity\": \"USA\",\n",
    "    \"Natural Resources Sector Equity\": \"USA\",\n",
    "    \"Options Trading\": \"USA\",\n",
    "    \"Multialternative\": \"USA\",\n",
    "    \"Market Neutral\": \"USA\",\n",
    "    \"Long/Short Equity\": \"USA\",\n",
    "    \"Alternative Miscellaneous\": \"USA\",\n",
    "    \"Allocation Miscellaneous\": \"USA\",\n",
    "    \"Fixed Income Miscellaneous\": \"USA\",\n",
    "    \"Equity Miscellaneous\": \"USA\",\n",
    "    \"Convertibles\": \"USA\",\n",
    "\n",
    "    # Global\n",
    "    \"Global Equity Large Cap\": \"Global\",\n",
    "    \"Global Equity Mid/Small Cap\": \"Global\",\n",
    "    \"Global Fixed Income\": \"Global\",\n",
    "    \"Global Emerging Markets Equity\": \"Global\",\n",
    "    \"Flexible Allocation\": \"Global\",\n",
    "    \"Aggressive Allocation\": \"Global\",\n",
    "    \"Moderate Allocation\": \"Global\",\n",
    "    \"Cautious Allocation\": \"Global\",\n",
    "    \"Convertibles\": \"USA\",\n",
    "\n",
    "    # Global Ex USA\n",
    "    \"Europe Equity Large Cap\": \"Global Ex USA\",\n",
    "    \"Europe Equity Mid/Small Cap\": \"Global Ex USA\",\n",
    "    \"Asia Equity\": \"Global Ex USA\",\n",
    "    \"Asia ex-Japan Equity\": \"Global Ex USA\",\n",
    "    \"India Equity\": \"Global Ex USA\",\n",
    "    \"Latin America Equity\": \"Global Ex USA\",\n",
    "    \"Japan Equity\": \"Global Ex USA\",\n",
    "    \"Korea Equity\": \"Global Ex USA\",\n",
    "    \"Thailand Equity\": \"Global Ex USA\",\n",
    "    \"Mexico Equity\": \"Global Ex USA\",\n",
    "    \"Australia & New Zealand Equity\": \"Global Ex USA\",\n",
    "    \"Greater China Equity\": \"Global Ex USA\",\n",
    "    \"UK Equity Large Cap\": \"Global Ex USA\",\n",
    "    \"Emerging Markets Fixed Income\": \"Global Ex USA\",\n",
    "    \"Canadian Equity Large Cap\": \"Global Ex USA\",\n",
    "\n",
    "    # Skip / None\n",
    "    \"Commodities Broad Basket\": None,\n",
    "    \"Commodities Specified\": None,\n",
    "    \"Target Date\": None,\n",
    "    \"Target Date 2021-2045\": None,\n",
    "    \"Target Date 2046+\": None,\n",
    "    \"Trading Tools\": None,\n",
    "    \"Currency\": None,\n",
    "    \"Uncategorized\": None,\n",
    "}\n",
    "\n",
    "\n",
    "#Section 2: Load Funds & Classification\n",
    "def load_classified_funds():\n",
    "    query = \"\"\"\n",
    "        SELECT f.SymbolCUSIP, f.Fund_Name, g.Global_Category_Name\n",
    "        FROM Funds_to_Screen f\n",
    "        JOIN YC_Global_Category_List g\n",
    "            ON f.YC_Global_Category_ID = g.ID\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, engine)\n",
    "    df[\"AQRR_Region\"] = df[\"Global_Category_Name\"].map(category_to_region)\n",
    "    return df.dropna(subset=[\"AQRR_Region\"]).reset_index(drop=True)\n",
    "\n",
    "#Section 3: Load Fund Returns (per batch)\n",
    "def load_fund_returns(symbols):\n",
    "    symbol_str = \", \".join([f\"'{s}'\" for s in symbols])\n",
    "    query = f\"\"\"\n",
    "        SELECT SymbolCUSIP, Date, ReturnValue\n",
    "        FROM Fund_Returns_Timeseries\n",
    "        WHERE SymbolCUSIP IN ({symbol_str})\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, engine, parse_dates=[\"Date\"])\n",
    "    return df.pivot(index=\"Date\", columns=\"SymbolCUSIP\", values=\"ReturnValue\")\n",
    "\n",
    "#Section 4: Load AQRR Factors\n",
    "def load_aqrr_factors(region):\n",
    "    # Pull and merge from R\n",
    "    r(f\"\"\"\n",
    "        mkt <- aqr_mkt_monthly() %>% filter(name == '{region}') %>% select(date, mkt = value)\n",
    "        smb <- aqr_smb_monthly() %>% filter(name == '{region}') %>% select(date, smb = value)\n",
    "        hml <- aqr_hml_ff_monthly() %>% filter(name == '{region}') %>% select(date, hml = value)\n",
    "        umd <- aqr_umd_monthly() %>% filter(name == '{region}') %>% select(date, umd = value)\n",
    "        qmj <- aqr_qmj_monthly() %>% filter(name == '{region}') %>% select(date, qmj = value)\n",
    "        bab <- aqr_bab_monthly() %>% filter(name == '{region}') %>% select(date, bab = value)\n",
    "        factors <- Reduce(function(x, y) full_join(x, y, by = 'date'), list(mkt, smb, hml, umd, qmj, bab))\n",
    "    \"\"\")\n",
    "    df = pandas2ri.rpy2py(r['factors'])\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    return df.set_index('date')\n",
    "\n",
    "#Section 5: Regression Helper\n",
    "def run_regression(fund_series, factor_df):\n",
    "    results = []\n",
    "    for window in ROLLING_PERIODS:\n",
    "        if len(fund_series) < window:\n",
    "            continue\n",
    "        y = fund_series[-window:]\n",
    "        x = factor_df.loc[y.index].dropna()\n",
    "        y = y.loc[x.index]\n",
    "        if len(x) < window: continue\n",
    "\n",
    "        x = sm.add_constant(x)\n",
    "        model = sm.OLS(y, x).fit()\n",
    "\n",
    "        for factor in factor_df.columns:\n",
    "            ci_low, ci_high = model.conf_int().loc[factor]\n",
    "            results.append({\n",
    "                \"RollPeriod\": window,\n",
    "                \"Factor_Name\": factor,\n",
    "                \"Coefficient\": model.params[factor],\n",
    "                \"P_Value\": model.pvalues[factor],\n",
    "                \"T_Stat\": model.tvalues[factor],\n",
    "                \"Standard_Error\": model.bse[factor],\n",
    "                \"CI_Lower\": ci_low,\n",
    "                \"CI_Upper\": ci_high,\n",
    "                \"Adj_R2\": model.rsquared_adj,\n",
    "                \"Correlation\": np.corrcoef(x[factor], y)[0,1],\n",
    "                \"Autocorrelation_Flag\": False,  # To implement\n",
    "                \"Heteroskedasticity_Flag\": False,  # To implement\n",
    "                \"Regression_Type\": \"OLS\"\n",
    "            })\n",
    "    return results\n",
    "\n",
    "#Section 6: Process Fund Batch\n",
    "def process_fund_batch(fund_batch, fund_returns, factor_df):\n",
    "    rows = []\n",
    "    for _, row in fund_batch.iterrows():\n",
    "        symbol = row.SymbolCUSIP\n",
    "        series = fund_returns.get(symbol)\n",
    "        if series is None: continue\n",
    "        reg_results = run_regression(series.dropna(), factor_df)\n",
    "        for r in reg_results:\n",
    "            r.update({\"SymbolCUSIP\": symbol, \"MonthEndDate\": series.dropna().index[-1]})\n",
    "            rows.append(r)\n",
    "    return rows\n",
    "\n",
    "#Section 7: Main Driver\n",
    "def main():\n",
    "    all_funds = load_classified_funds()\n",
    "    batches = [all_funds[i:i+BATCH_SIZE] for i in range(0, len(all_funds), BATCH_SIZE)]\n",
    "    all_results = []\n",
    "\n",
    "    for batch in tqdm(batches, desc=\"Processing Batches\"):\n",
    "        region = batch[\"AQRR_Region\"].iloc[0]  # Assume batch shares region\n",
    "        factor_df = load_aqrr_factors(region)\n",
    "        fund_returns = load_fund_returns(batch.SymbolCUSIP.tolist())\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "            futures = [executor.submit(process_fund_batch, pd.DataFrame([row]), fund_returns, factor_df)\n",
    "                       for _, row in batch.iterrows()]\n",
    "            for future in futures:\n",
    "                all_results.extend(future.result())\n",
    "\n",
    "    if DRY_RUN:\n",
    "        print(f\"\\n🔍 Dry run complete. Total results: {len(all_results):,}\")\n",
    "        return\n",
    "\n",
    "    # Insert in chunks\n",
    "    for i in range(0, len(all_results), INSERT_CHUNK_SIZE):\n",
    "        chunk = pd.DataFrame(all_results[i:i+INSERT_CHUNK_SIZE])\n",
    "        chunk.to_sql(\"AQRR_Factor_Attribution\", engine, if_exists=\"append\", index=False, method=\"multi\")\n",
    "\n",
    "    print(f\"✅ Inserted {len(all_results):,} rows into AQRR_Factor_Attribution.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6af5d3de-4820-4c29-8e05-8c8942e1caa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on float64 and datetime64[ns] columns for key 'Date'. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 230\u001b[0m\n\u001b[0;32m    227\u001b[0m         df\u001b[38;5;241m.\u001b[39miloc[i:i\u001b[38;5;241m+\u001b[39mBATCH_INSERT_SIZE]\u001b[38;5;241m.\u001b[39mto_sql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAQRR_Factor_Attribution\u001b[39m\u001b[38;5;124m\"\u001b[39m, engine, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 230\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 204\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    202\u001b[0m use_fi \u001b[38;5;241m=\u001b[39m fund_subset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUseFixedIncome\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39many()\n\u001b[0;32m    203\u001b[0m fixed_income_factors \u001b[38;5;241m=\u001b[39m load_fixed_income_factors() \u001b[38;5;28;01mif\u001b[39;00m use_fi \u001b[38;5;28;01melse\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m--> 204\u001b[0m all_factors \u001b[38;5;241m=\u001b[39m \u001b[43mmerge_all_factors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequity_factors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed_income_factors\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fixed_income_factors\u001b[38;5;241m.\u001b[39mempty \u001b[38;5;28;01melse\u001b[39;00m equity_factors\n\u001b[0;32m    205\u001b[0m funds \u001b[38;5;241m=\u001b[39m fund_subset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSymbolCUSIP\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(funds), CHUNK_SIZE):\n",
      "Cell \u001b[1;32mIn[22], line 147\u001b[0m, in \u001b[0;36mmerge_all_factors\u001b[1;34m(equity_df, fixed_income_df)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmerge_all_factors\u001b[39m(equity_df, fixed_income_df):\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mequity_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfixed_income_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\pandas\\core\\frame.py:10832\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m  10813\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m  10814\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m  10815\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10828\u001b[0m     validate: MergeValidate \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m  10829\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m  10830\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[1;32m> 10832\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  10833\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10834\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10836\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10837\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10838\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10841\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10842\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10846\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:170\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[0;32m    156\u001b[0m         left_df,\n\u001b[0;32m    157\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    168\u001b[0m     )\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 170\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:807\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tolerance(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys)\n\u001b[0;32m    805\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m--> 807\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_coerce_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Software Projects\\Database Administration\\env\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1514\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1513\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m-> 1514\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(lk\u001b[38;5;241m.\u001b[39mdtype, DatetimeTZDtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m   1516\u001b[0m     rk\u001b[38;5;241m.\u001b[39mdtype, DatetimeTZDtype\n\u001b[0;32m   1517\u001b[0m ):\n\u001b[0;32m   1518\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to merge on float64 and datetime64[ns] columns for key 'Date'. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sqlalchemy import create_engine, text\n",
    "from tqdm import tqdm\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan, acorr_breusch_godfrey\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#Section1: Configuration\n",
    "connection_string = (\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/CWA_Fund_Database\"\n",
    "    \"?driver=ODBC+Driver+18+for+SQL+Server\"\n",
    "    \"&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "engine = create_engine(connection_string)\n",
    "ROLLING_PERIODS = [12, 24, 36, 48, 60]  # in months\n",
    "DRY_RUN = True\n",
    "CHUNK_SIZE = 200  # Number of funds per chunk\n",
    "BATCH_INSERT_SIZE = 2000\n",
    "\n",
    "# Updated region mapping\n",
    "category_to_region = {\n",
    "    \"US Equity Large Cap Blend\": (\"USA\", False),\n",
    "    \"US Equity Large Cap Growth\": (\"USA\", False),\n",
    "    \"US Equity Large Cap Value\": (\"USA\", False),\n",
    "    \"US Equity Mid Cap\": (\"USA\", False),\n",
    "    \"US Equity Small Cap\": (\"USA\", False),\n",
    "    \"US Fixed Income\": (\"USA\", True),\n",
    "    \"US Municipal Fixed Income\": (\"USA\", True),\n",
    "    \"Communications Sector Equity\": (\"USA\", False),\n",
    "    \"Consumer Goods & Services Sector Equity\": (\"USA\", False),\n",
    "    \"Energy Sector Equity\": (\"USA\", False),\n",
    "    \"Financials Sector Equity\": (\"USA\", False),\n",
    "    \"Healthcare Sector Equity\": (\"USA\", False),\n",
    "    \"Industrials Sector Equity\": (\"USA\", False),\n",
    "    \"Infrastructure Sector Equity\": (\"USA\", False),\n",
    "    \"Other Sector Equity\": (\"USA\", False),\n",
    "    \"Precious Metals Sector Equity\": (\"USA\", False),\n",
    "    \"Technology Sector Equity\": (\"USA\", False),\n",
    "    \"Utilities Sector Equity\": (\"USA\", False),\n",
    "    \"Real Estate Sector Equity\": (\"USA\", False),\n",
    "    \"Natural Resources Sector Equity\": (\"USA\", False),\n",
    "    \"Options Trading\": (\"USA\", False),\n",
    "    \"Multialternative\": (\"USA\", False),\n",
    "    \"Market Neutral\": (\"USA\", False),\n",
    "    \"Long/Short Equity\": (\"USA\", False),\n",
    "    \"Alternative Miscellaneous\": (\"USA\", False),\n",
    "    \"Allocation Miscellaneous\": (\"USA\", True),\n",
    "    \"Fixed Income Miscellaneous\": (\"USA\", True),\n",
    "    \"Equity Miscellaneous\": (\"USA\", False),\n",
    "    \"Convertibles\": (\"USA\", False),\n",
    "\n",
    "    \"Global Equity Large Cap\": (\"Global\", False),\n",
    "    \"Global Equity Mid/Small Cap\": (\"Global\", False),\n",
    "    \"Global Fixed Income\": (\"Global\", True),\n",
    "    \"Global Emerging Markets Equity\": (\"Global\", False),\n",
    "    \"Flexible Allocation\": (\"Global\", True),\n",
    "    \"Aggressive Allocation\": (\"Global\", True),\n",
    "    \"Moderate Allocation\": (\"Global\", True),\n",
    "    \"Cautious Allocation\": (\"Global\", True),\n",
    "\n",
    "    \"Europe Equity Large Cap\": (\"Global Ex USA\", False),\n",
    "    \"Europe Equity Mid/Small Cap\": (\"Global Ex USA\", False),\n",
    "    \"Asia Equity\": (\"Global Ex USA\", False),\n",
    "    \"Asia ex-Japan Equity\": (\"Global Ex USA\", False),\n",
    "    \"India Equity\": (\"Global Ex USA\", False),\n",
    "    \"Latin America Equity\": (\"Global Ex USA\", False),\n",
    "    \"Japan Equity\": (\"Global Ex USA\", False),\n",
    "    \"Korea Equity\": (\"Global Ex USA\", False),\n",
    "    \"Thailand Equity\": (\"Global Ex USA\", False),\n",
    "    \"Mexico Equity\": (\"Global Ex USA\", False),\n",
    "    \"Australia & New Zealand Equity\": (\"Global Ex USA\", False),\n",
    "    \"Greater China Equity\": (\"Global Ex USA\", False),\n",
    "    \"UK Equity Large Cap\": (\"Global Ex USA\", False),\n",
    "    \"Emerging Markets Fixed Income\": (\"Global Ex USA\", True),\n",
    "    \"Canadian Equity Large Cap\": (\"Global Ex USA\", False),\n",
    "\n",
    "    \"Commodities Broad Basket\": (None, False),\n",
    "    \"Commodities Specified\": (None, False),\n",
    "    \"Target Date\": (None, False),\n",
    "    \"Target Date 2021-2045\": (None, False),\n",
    "    \"Target Date 2046+\": (None, False),\n",
    "    \"Trading Tools\": (None, False),\n",
    "    \"Currency\": (None, False),\n",
    "    \"Uncategorized\": (None, False),\n",
    "}\n",
    "\n",
    "#Section2: Load Fund Metadata and Region Mapping\n",
    "def load_fund_metadata():\n",
    "    query = \"\"\"\n",
    "    SELECT f.SymbolCUSIP, f.YC_Global_Category_ID, c.Global_Category_Name\n",
    "    FROM Funds_to_Screen f\n",
    "    JOIN YC_Global_Category_List c ON f.YC_Global_Category_ID = c.ID\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, engine)\n",
    "    df[[\"Region\", \"UseFixedIncome\"]] = df[\"Global_Category_Name\"].map(category_to_region).apply(pd.Series)\n",
    "    return df.dropna(subset=[\"Region\"])\n",
    "\n",
    "#Section3: Load Return Time Series\n",
    "def load_fund_returns(fund_ids):\n",
    "    placeholders = \",\".join([f\"'{fid}'\" for fid in fund_ids])\n",
    "    query = f\"\"\"\n",
    "        SELECT SymbolCUSIP, Date, ReturnValue\n",
    "        FROM Fund_Returns_Timeseries\n",
    "        WHERE SymbolCUSIP IN ({placeholders})\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, engine, parse_dates=[\"Date\"])\n",
    "    return df.pivot(index=\"Date\", columns=\"SymbolCUSIP\", values=\"ReturnValue\")\n",
    "\n",
    "#Section4: Load AQRR Factor Data\n",
    "#Section4: Load AQRR Factor Data\n",
    "def load_aqrr_factors(region):\n",
    "    from rpy2.robjects import r, pandas2ri\n",
    "    from rpy2.robjects.packages import importr\n",
    "    pandas2ri.activate()\n",
    "    aqrr = importr(\"aqrr\")\n",
    "    dplyr = importr(\"dplyr\")\n",
    "    base = importr(\"base\")\n",
    "\n",
    "    r(f\"\"\"\n",
    "        suppressMessages(library(aqrr))\n",
    "        mkt <- aqr_mkt_monthly() %>% filter(name == '{region}') %>% select(date, mkt = value)\n",
    "        smb <- aqr_smb_monthly() %>% filter(name == '{region}') %>% select(date, smb = value)\n",
    "        hml <- aqr_hml_ff_monthly() %>% filter(name == '{region}') %>% select(date, hml = value)\n",
    "        umd <- aqr_umd_monthly() %>% filter(name == '{region}') %>% select(date, umd = value)\n",
    "        qmj <- aqr_qmj_monthly() %>% filter(name == '{region}') %>% select(date, qmj = value)\n",
    "        bab <- aqr_bab_monthly() %>% filter(name == '{region}') %>% select(date, bab = value)\n",
    "        factors <- Reduce(function(x, y) full_join(x, y, by = \"date\"), list(mkt, smb, hml, umd, qmj, bab))\n",
    "    \"\"\")\n",
    "\n",
    "    from datetime import datetime\n",
    "    df = pandas2ri.rpy2py(r[\"factors\"])\n",
    "    df = df.rename(columns={\"date\": \"Date\"})\n",
    "    \n",
    "    # Convert to datetime safely\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "\n",
    "    # Database start of data\n",
    "    df = df[df[\"Date\"] >= pd.to_datetime(\"2015-01-31\")]\n",
    "\n",
    "\n",
    "    df = df.sort_values(\"Date\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "#Section5: Load Fixed Income Factor Data\n",
    "def load_fixed_income_factors():\n",
    "    query = \"\"\"\n",
    "        SELECT Date, Factor_Name, ReturnValue\n",
    "        FROM Fixed_Income_Factor_Returns\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, engine, parse_dates=[\"Date\"])\n",
    "    return df.pivot(index=\"Date\", columns=\"Factor_Name\", values=\"ReturnValue\")\n",
    "\n",
    "#Section6: Merge Factors\n",
    "def merge_all_factors(equity_df, fixed_income_df):\n",
    "    equity_df[\"Date\"] = pd.to_datetime(equity_df[\"Date\"])\n",
    "    fixed_income_df.index = pd.to_datetime(fixed_income_df.index)\n",
    "    return equity_df.merge(fixed_income_df, how=\"left\", left_on=\"Date\", right_index=True)\n",
    "\n",
    "#Section7: Perform Rolling Regression\n",
    "def run_rolling_regression(fund, returns, factors):\n",
    "    results = []\n",
    "    for window in ROLLING_PERIODS:\n",
    "        start = returns.index.min() + relativedelta(months=window)\n",
    "        for end_date in returns.loc[returns.index >= start].index:\n",
    "            start_date = end_date - relativedelta(months=window-1)\n",
    "            y = returns.loc[start_date:end_date]\n",
    "            X = factors.loc[start_date:end_date]\n",
    "            if y.isnull().any() or X.isnull().any().any():\n",
    "                continue\n",
    "            X_const = add_constant(X)\n",
    "            model = OLS(y, X_const).fit()\n",
    "            diagnostics = {\n",
    "                'dw': durbin_watson(model.resid),\n",
    "                'bp_pval': het_breuschpagan(model.resid, model.model.exog)[1]\n",
    "            }\n",
    "            is_robust = diagnostics['dw'] < 1.5 or diagnostics['bp_pval'] < 0.05\n",
    "            reg_type = \"Robust\" if is_robust else \"OLS\"\n",
    "            if is_robust:\n",
    "                model = sm.OLS(y, X_const).fit(cov_type='HAC', cov_kwds={'maxlags':1})\n",
    "            for factor in X.columns:\n",
    "                coeff = model.params.get(factor, np.nan)\n",
    "                pval = model.pvalues.get(factor, np.nan)\n",
    "                tstat = model.tvalues.get(factor, np.nan)\n",
    "                stderr = model.bse.get(factor, np.nan)\n",
    "                ci_low, ci_upp = model.conf_int().loc[factor] if factor in model.params else (np.nan, np.nan)\n",
    "                results.append({\n",
    "                    \"SymbolCUSIP\": fund,\n",
    "                    \"MonthEndDate\": end_date,\n",
    "                    \"RollPeriod\": f\"{window}m\",\n",
    "                    \"Factor_Name\": factor,\n",
    "                    \"Coefficient\": coeff,\n",
    "                    \"P_Value\": pval,\n",
    "                    \"T_Stat\": tstat,\n",
    "                    \"Standard_Error\": stderr,\n",
    "                    \"CI_Lower\": ci_low,\n",
    "                    \"CI_Upper\": ci_upp,\n",
    "                    \"Adj_R2\": model.rsquared_adj,\n",
    "                    \"Correlation\": np.corrcoef(y, model.fittedvalues)[0,1],\n",
    "                    \"Autocorrelation_Flag\": diagnostics['dw'] < 1.5,\n",
    "                    \"Heteroskedasticity_Flag\": diagnostics['bp_pval'] < 0.05,\n",
    "                    \"Regression_Type\": reg_type\n",
    "                })\n",
    "    return results\n",
    "\n",
    "#Section8: Main Batch Driver\n",
    "def main():\n",
    "    fund_meta = load_fund_metadata()\n",
    "    regions = fund_meta[\"Region\"].unique()\n",
    "    for region in regions:\n",
    "        fund_subset = fund_meta[fund_meta[\"Region\"] == region]\n",
    "        equity_factors = load_aqrr_factors(region)\n",
    "        use_fi = fund_subset[\"UseFixedIncome\"].any()\n",
    "        fixed_income_factors = load_fixed_income_factors() if use_fi else pd.DataFrame()\n",
    "        all_factors = merge_all_factors(equity_factors, fixed_income_factors) if not fixed_income_factors.empty else equity_factors\n",
    "        funds = fund_subset[\"SymbolCUSIP\"].tolist()\n",
    "        for i in range(0, len(funds), CHUNK_SIZE):\n",
    "            chunk = funds[i:i+CHUNK_SIZE]\n",
    "            fund_returns = load_fund_returns(chunk)\n",
    "            records = []\n",
    "            with ThreadPoolExecutor() as executor:\n",
    "                futures = {\n",
    "                    executor.submit(run_rolling_regression, fund, fund_returns[fund], all_factors): fund\n",
    "                    for fund in fund_returns.columns\n",
    "                }\n",
    "                for future in tqdm(futures):\n",
    "                    try:\n",
    "                        records.extend(future.result())\n",
    "                    except Exception as e:\n",
    "                        print(f\"⚠️ Error in {futures[future]}: {e}\")\n",
    "            if not DRY_RUN and records:\n",
    "                insert_batch(records)\n",
    "\n",
    "#Section9: Insert to Database\n",
    "def insert_batch(records):\n",
    "    df = pd.DataFrame(records)\n",
    "    for i in range(0, len(df), BATCH_INSERT_SIZE):\n",
    "        df.iloc[i:i+BATCH_INSERT_SIZE].to_sql(\"AQRR_Factor_Attribution\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1012c794-b747-4638-a08f-c59d5616af4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Missing category_to_region mappings for:\n",
      " - Commodities Broad Basket\n",
      " - Commodities Specified\n",
      " - Trading Tools\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sqlalchemy import create_engine, text\n",
    "from tqdm import tqdm\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan, acorr_breusch_godfrey\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#Section1: Configuration\n",
    "import logging\n",
    "from rpy2.rinterface_lib.callbacks import logger as rpy2_logger\n",
    "rpy2_logger.setLevel(logging.ERROR)\n",
    "\n",
    "RETURN_METRIC = \"1 Month Return\"\n",
    "\n",
    "connection_string = (\n",
    "    \"mssql+pyodbc://JULIANS_LAPTOP\\\\SQLEXPRESS/CWA_Fund_Database\"\n",
    "    \"?driver=ODBC+Driver+18+for+SQL+Server\"\n",
    "    \"&trusted_connection=yes&TrustServerCertificate=yes\"\n",
    ")\n",
    "engine = create_engine(connection_string)\n",
    "ROLLING_PERIODS = [12, 24, 36, 48, 60]  # in months\n",
    "DRY_RUN = True\n",
    "CHUNK_SIZE = 200  # Number of funds per chunk\n",
    "BATCH_INSERT_SIZE = 2000\n",
    "\n",
    "# Updated region mapping\n",
    "category_to_region = {\n",
    "    \"US Equity Large Cap Blend\": (\"USA\", False),\n",
    "    \"US Equity Large Cap Growth\": (\"USA\", False),\n",
    "    \"US Equity Large Cap Value\": (\"USA\", False),\n",
    "    \"US Equity Mid Cap\": (\"USA\", False),\n",
    "    \"US Equity Small Cap\": (\"USA\", False),\n",
    "    \"US Fixed Income\": (\"USA\", True),\n",
    "    \"US Municipal Fixed Income\": (\"USA\", True),\n",
    "    \"Communications Sector Equity\": (\"USA\", False),\n",
    "    \"Consumer Goods & Services Sector Equity\": (\"USA\", False),\n",
    "    \"Energy Sector Equity\": (\"USA\", False),\n",
    "    \"Financials Sector Equity\": (\"USA\", False),\n",
    "    \"Healthcare Sector Equity\": (\"USA\", False),\n",
    "    \"Industrials Sector Equity\": (\"USA\", False),\n",
    "    \"Infrastructure Sector Equity\": (\"USA\", False),\n",
    "    \"Other Sector Equity\": (\"USA\", False),\n",
    "    \"Precious Metals Sector Equity\": (\"USA\", False),\n",
    "    \"Technology Sector Equity\": (\"USA\", False),\n",
    "    \"Utilities Sector Equity\": (\"USA\", False),\n",
    "    \"Real Estate Sector Equity\": (\"USA\", False),\n",
    "    \"Natural Resources Sector Equity\": (\"USA\", False),\n",
    "    \"Options Trading\": (\"USA\", False),\n",
    "    \"Multialternative\": (\"USA\", False),\n",
    "    \"Market Neutral\": (\"USA\", False),\n",
    "    \"Long/Short Equity\": (\"USA\", False),\n",
    "    \"Alternative Miscellaneous\": (\"USA\", False),\n",
    "    \"Allocation Miscellaneous\": (\"USA\", True),\n",
    "    \"Fixed Income Miscellaneous\": (\"USA\", True),\n",
    "    \"Equity Miscellaneous\": (\"USA\", False),\n",
    "    \"Convertibles\": (\"USA\", False),\n",
    "\n",
    "    \"Global Equity Large Cap\": (\"Global\", False),\n",
    "    \"Global Equity Mid/Small Cap\": (\"Global\", False),\n",
    "    \"Global Fixed Income\": (\"Global\", True),\n",
    "    \"Global Emerging Markets Equity\": (\"Global\", False),\n",
    "    \"Flexible Allocation\": (\"Global\", True),\n",
    "    \"Aggressive Allocation\": (\"Global\", True),\n",
    "    \"Moderate Allocation\": (\"Global\", True),\n",
    "    \"Cautious Allocation\": (\"Global\", True),\n",
    "\n",
    "    \"Europe Equity Large Cap\": (\"Global Ex USA\", False),\n",
    "    \"Europe Equity Mid/Small Cap\": (\"Global Ex USA\", False),\n",
    "    \"Asia Equity\": (\"Global Ex USA\", False),\n",
    "    \"Asia ex-Japan Equity\": (\"Global Ex USA\", False),\n",
    "    \"India Equity\": (\"Global Ex USA\", False),\n",
    "    \"Latin America Equity\": (\"Global Ex USA\", False),\n",
    "    \"Japan Equity\": (\"Global Ex USA\", False),\n",
    "    \"Korea Equity\": (\"Global Ex USA\", False),\n",
    "    \"Thailand Equity\": (\"Global Ex USA\", False),\n",
    "    \"Mexico Equity\": (\"Global Ex USA\", False),\n",
    "    \"Australia & New Zealand Equity\": (\"Global Ex USA\", False),\n",
    "    \"Greater China Equity\": (\"Global Ex USA\", False),\n",
    "    \"UK Equity Large Cap\": (\"Global Ex USA\", False),\n",
    "    \"Emerging Markets Fixed Income\": (\"Global Ex USA\", True),\n",
    "    \"Canadian Equity Large Cap\": (\"Global Ex USA\", False),\n",
    "\n",
    "    \"Commodities Broad Basket\": (None, False),\n",
    "    \"Commodities Specified\": (None, False),\n",
    "    \"Target Date\": (None, False),\n",
    "    \"Target Date 2021-2045\": (None, False),\n",
    "    \"Target Date 2046+\": (None, False),\n",
    "    \"Trading Tools\": (None, False),\n",
    "    \"Currency\": (None, False),\n",
    "    \"Uncategorized\": (None, False),\n",
    "}\n",
    "\n",
    "#Section2: Load Fund Metadata and Region Mapping\n",
    "def load_fund_metadata():\n",
    "    query = \"\"\"\n",
    "    SELECT f.SymbolCUSIP, f.YC_Global_Category_ID, c.Global_Category_Name\n",
    "    FROM Funds_to_Screen f\n",
    "    JOIN YC_Global_Category_List c ON f.YC_Global_Category_ID = c.ID\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, engine)\n",
    "    df[[\"Region\", \"UseFixedIncome\"]] = df[\"Global_Category_Name\"].map(category_to_region).apply(pd.Series)\n",
    "    \n",
    "    missing = df[df[\"Region\"].isna()][\"Global_Category_Name\"].unique()\n",
    "    if len(missing) > 0:\n",
    "        print(\"⚠️ Missing category_to_region mappings for:\")\n",
    "        for cat in sorted(missing):\n",
    "            print(f\" - {cat}\")\n",
    "    \n",
    "    return df.dropna(subset=[\"Region\"])\n",
    "\n",
    "#Section3: Load Return Time Series\n",
    "def load_fund_returns(fund_ids):\n",
    "    placeholders = \",\".join([f\"'{fid}'\" for fid in fund_ids])\n",
    "    query = f\"\"\"\n",
    "        SELECT SymbolCUSIP, Date, ReturnValue\n",
    "        FROM Fund_Returns_Timeseries\n",
    "        WHERE SymbolCUSIP IN ({placeholders})\n",
    "        AND Metric = '{RETURN_METRIC}'\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, engine, parse_dates=[\"Date\"])\n",
    "    return df.pivot(index=\"Date\", columns=\"SymbolCUSIP\", values=\"ReturnValue\")\n",
    "\n",
    "#Section4: Load AQRR Factor Data\n",
    "def load_aqrr_factors(region):\n",
    "    from rpy2.robjects import r, pandas2ri\n",
    "    from rpy2.robjects.conversion import localconverter\n",
    "    from rpy2.robjects.packages import importr\n",
    "    import pandas as pd\n",
    "\n",
    "    aqrr = importr(\"aqrr\")\n",
    "    dplyr = importr(\"dplyr\")\n",
    "    base = importr(\"base\")\n",
    "\n",
    "    r(f\"\"\"\n",
    "        suppressMessages(library(aqrr))\n",
    "        mkt <- aqr_mkt_monthly() %>% filter(name == '{region}') %>% select(date, mkt = value)\n",
    "        smb <- aqr_smb_monthly() %>% filter(name == '{region}') %>% select(date, smb = value)\n",
    "        hml <- aqr_hml_ff_monthly() %>% filter(name == '{region}') %>% select(date, hml = value)\n",
    "        umd <- aqr_umd_monthly() %>% filter(name == '{region}') %>% select(date, umd = value)\n",
    "        qmj <- aqr_qmj_monthly() %>% filter(name == '{region}') %>% select(date, qmj = value)\n",
    "        bab <- aqr_bab_monthly() %>% filter(name == '{region}') %>% select(date, bab = value)\n",
    "        factors <- Reduce(function(x, y) full_join(x, y, by = \"date\"), list(mkt, smb, hml, umd, qmj, bab))\n",
    "    \"\"\")\n",
    "\n",
    "    with localconverter(pandas2ri.converter):\n",
    "        df = pandas2ri.rpy2py(r[\"factors\"])\n",
    "\n",
    "    df = df.rename(columns={\"date\": \"Date\"})\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "    df = df[df[\"Date\"] >= pd.to_datetime(\"2015-01-31\")]\n",
    "    df = df.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "#Section5: Load Fixed Income Factor Data\n",
    "def load_fixed_income_factors():\n",
    "    query = \"\"\"\n",
    "        SELECT Date, Factor_Name, ReturnValue\n",
    "        FROM Fixed_Income_Factor_Returns\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, engine, parse_dates=[\"Date\"])\n",
    "    return df.pivot(index=\"Date\", columns=\"Factor_Name\", values=\"ReturnValue\")\n",
    "\n",
    "#Section6: Merge Factors\n",
    "def merge_all_factors(equity_df, fixed_income_df):\n",
    "    equity_df[\"Date\"] = pd.to_datetime(equity_df[\"Date\"])\n",
    "    fixed_income_df.index = pd.to_datetime(fixed_income_df.index)\n",
    "    merged = equity_df.merge(fixed_income_df, how=\"left\", left_on=\"Date\", right_index=True)\n",
    "\n",
    "    # Set date as index and drop any remaining 'Date' column just in case\n",
    "    merged = merged.set_index(\"Date\")\n",
    "    return merged\n",
    "\n",
    "#Section7: Perform Rolling Regression\n",
    "def run_rolling_regression(fund, returns, factors):\n",
    "    results = []\n",
    "    for window in ROLLING_PERIODS:\n",
    "        start = returns.index.min() + relativedelta(months=window)\n",
    "        for end_date in returns.loc[returns.index >= start].index:\n",
    "            start_date = end_date - relativedelta(months=window - 1)\n",
    "            y = returns.loc[start_date:end_date]\n",
    "\n",
    "            try:\n",
    "                y = y.astype(float)\n",
    "                X = factors.loc[start_date:end_date].copy()\n",
    "\n",
    "                if \"Date\" in X.columns:\n",
    "                    X = X.drop(columns=[\"Date\"])\n",
    "\n",
    "                X = X.astype(float)\n",
    "\n",
    "                if y.isnull().any() or X.isnull().any().any():\n",
    "                    continue\n",
    "\n",
    "                X_const = add_constant(X)\n",
    "                model = OLS(y, X_const).fit()\n",
    "\n",
    "                diagnostics = {\n",
    "                    'dw': durbin_watson(model.resid),\n",
    "                    'bp_pval': het_breuschpagan(model.resid, model.model.exog)[1]\n",
    "                }\n",
    "\n",
    "                is_robust = diagnostics['dw'] < 1.5 or diagnostics['bp_pval'] < 0.05\n",
    "                reg_type = \"Robust\" if is_robust else \"OLS\"\n",
    "\n",
    "                if is_robust:\n",
    "                    model = sm.OLS(y, X_const).fit(cov_type='HAC', cov_kwds={'maxlags': 1})\n",
    "\n",
    "                for factor in X.columns:\n",
    "                    coeff = model.params.get(factor, np.nan)\n",
    "                    pval = model.pvalues.get(factor, np.nan)\n",
    "                    tstat = model.tvalues.get(factor, np.nan)\n",
    "                    stderr = model.bse.get(factor, np.nan)\n",
    "                    ci_low, ci_upp = model.conf_int().loc[factor] if factor in model.params else (np.nan, np.nan)\n",
    "\n",
    "                    results.append({\n",
    "                        \"SymbolCUSIP\": fund,\n",
    "                        \"MonthEndDate\": end_date,\n",
    "                        \"RollPeriod\": f\"{window}m\",\n",
    "                        \"Factor_Name\": factor,\n",
    "                        \"Coefficient\": coeff,\n",
    "                        \"P_Value\": pval,\n",
    "                        \"T_Stat\": tstat,\n",
    "                        \"Standard_Error\": stderr,\n",
    "                        \"CI_Lower\": ci_low,\n",
    "                        \"CI_Upper\": ci_upp,\n",
    "                        \"Adj_R2\": model.rsquared_adj,\n",
    "                        \"Correlation\": np.corrcoef(y, model.fittedvalues)[0, 1],\n",
    "                        \"Autocorrelation_Flag\": diagnostics['dw'] < 1.5,\n",
    "                        \"Heteroskedasticity_Flag\": diagnostics['bp_pval'] < 0.05,\n",
    "                        \"Regression_Type\": reg_type\n",
    "                    })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Regression error for {fund} [{start_date.date()} to {end_date.date()}]: {e}\")\n",
    "                print(\"X types:\\n\", X.dtypes if 'X' in locals() else 'X not defined')\n",
    "                print(\"X head:\\n\", X.head() if 'X' in locals() else 'X not defined')\n",
    "                print(\"Y head:\\n\", y.head() if 'y' in locals() else 'y not defined')\n",
    "                continue\n",
    "\n",
    "    return results\n",
    "\n",
    "#Section8: Main Batch Driver\n",
    "def main():\n",
    "    fund_meta = load_fund_metadata()\n",
    "    regions = fund_meta[\"Region\"].unique()\n",
    "    for region in regions:\n",
    "        fund_subset = fund_meta[fund_meta[\"Region\"] == region]\n",
    "        equity_factors = load_aqrr_factors(region)\n",
    "        use_fi = fund_subset[\"UseFixedIncome\"].any()\n",
    "        fixed_income_factors = load_fixed_income_factors() if use_fi else pd.DataFrame()\n",
    "        all_factors = merge_all_factors(equity_factors, fixed_income_factors) if not fixed_income_factors.empty else equity_factors\n",
    "        funds = fund_subset[\"SymbolCUSIP\"].tolist()\n",
    "        for i in range(0, len(funds), CHUNK_SIZE):\n",
    "            chunk = funds[i:i+CHUNK_SIZE]\n",
    "            fund_returns = load_fund_returns(chunk)\n",
    "            records = []\n",
    "            with ThreadPoolExecutor() as executor:\n",
    "                futures = {\n",
    "                    executor.submit(run_rolling_regression, fund, fund_returns[fund], all_factors): fund\n",
    "                    for fund in fund_returns.columns\n",
    "                }\n",
    "                for future in tqdm(futures):\n",
    "                    try:\n",
    "                        records.extend(future.result())\n",
    "                    except Exception as e:\n",
    "                        print(f\"⚠️ Error in {futures[future]}: {e}\")\n",
    "            if not DRY_RUN and records:\n",
    "                insert_batch(records)\n",
    "\n",
    "#Section9: Insert to Database\n",
    "def insert_batch(records):\n",
    "    df = pd.DataFrame(records)\n",
    "    for i in range(0, len(df), BATCH_INSERT_SIZE):\n",
    "        df.iloc[i:i+BATCH_INSERT_SIZE].to_sql(\"AQRR_Factor_Attribution\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fb2bfe-52e9-49ad-9bae-510cb6c5a094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18358399-6d4c-401c-be5c-0b8e9e7a6d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dda4829-ac95-4b9e-8f21-2e66bab9a2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82860f08-2b74-4bee-a787-eb7d76845d26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770691f8-031c-4276-b600-b2d56ebc1190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2789c5-1478-481a-be80-2bf37ef3d132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4668f3b1-a742-4ccb-b26a-489672530dca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb702f8-db34-49ad-a9fb-f49019a449d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0e8ad6-70fc-46bb-b4e2-fd39ac5f6501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63362f72-34b2-4a96-8cbb-60ade1d08d23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307bf102-1076-4c3d-823b-320b88befb3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac8f943-cdc4-4fa3-876b-b950dc4424d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dfd8d0-2182-4cba-b5fe-639ce15e87b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61177e9-9069-4895-8922-ba24754bbafe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56603b9-9e2a-431a-94e8-f53869681f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1b4180-5d25-4ca0-a601-32fc1de7a816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ae3878-c455-40f6-b900-41190e5adce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f031476b-3bd5-4880-8f60-0652a23728bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba575e5c-4ded-4eae-9c42-549866c06048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6710bd0-e324-48ff-989d-fbebe4efe04e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cab0a1-a111-47e4-a37c-fc7a312ccef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f79e0e-b159-450f-a0a1-1678191dd574",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Database Administration)",
   "language": "python",
   "name": "databaseadminenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
